
Due to MODULEPATH changes, the following have been reloaded:
  1) python/3.6

tensorboard X not installed, visualizing wont be available
------------ Options -------------
arch: mconvnet
batch_size: 16
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
dataroot: datasets/cubes
dataset_mode: classification
epoch_count: 1
export_folder: 
fc_n: 100
flip_edges: 0.2
gpu_ids: [0]
init_gain: 0.02
init_type: normal
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
name: cubes_original
ncf: [64, 128, 256, 256]
ninput_edges: 750
niter: 100
niter_decay: 2000
no_vis: False
norm: group
num_aug: 20
num_groups: 16
num_threads: 3
phase: train
pool_res: [600, 450, 300, 210]
print_freq: 10
resblocks: 1
run_test_freq: 1
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: False
seed: None
serial_batches: False
slide_verts: 0.2
verbose_plot: False
which_epoch: latest
-------------- End ----------------
loaded mean / std from cache
#training meshes = 3722
---------- Network initialized -------------
[Network] Total number of parameters : 1.323 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 16)
(epoch: 1, iters: 80, time: 0.109, data: 0.630) loss: 3.077 
(epoch: 1, iters: 160, time: 0.106, data: 0.000) loss: 3.070 
(epoch: 1, iters: 240, time: 0.107, data: 0.038) loss: 3.120 
(epoch: 1, iters: 320, time: 0.109, data: 0.000) loss: 3.074 
(epoch: 1, iters: 400, time: 0.105, data: 0.012) loss: 3.035 
(epoch: 1, iters: 480, time: 0.109, data: 0.000) loss: 3.088 
(epoch: 1, iters: 560, time: 0.106, data: 0.011) loss: 3.039 
(epoch: 1, iters: 640, time: 0.109, data: 0.000) loss: 3.030 
(epoch: 1, iters: 720, time: 0.107, data: 0.000) loss: 3.047 
(epoch: 1, iters: 800, time: 0.107, data: 0.038) loss: 2.984 
(epoch: 1, iters: 880, time: 0.108, data: 0.000) loss: 3.002 
(epoch: 1, iters: 960, time: 0.107, data: 0.011) loss: 2.917 
(epoch: 1, iters: 1040, time: 0.108, data: 0.000) loss: 2.882 
(epoch: 1, iters: 1120, time: 0.106, data: 0.011) loss: 2.989 
(epoch: 1, iters: 1200, time: 0.109, data: 0.000) loss: 2.978 
(epoch: 1, iters: 1280, time: 0.108, data: 0.000) loss: 2.947 
(epoch: 1, iters: 1360, time: 0.106, data: 0.038) loss: 2.793 
(epoch: 1, iters: 1440, time: 0.107, data: 0.000) loss: 2.925 
(epoch: 1, iters: 1520, time: 0.104, data: 0.012) loss: 2.791 
(epoch: 1, iters: 1600, time: 0.107, data: 0.000) loss: 2.730 
(epoch: 1, iters: 1680, time: 0.106, data: 0.011) loss: 2.695 
(epoch: 1, iters: 1760, time: 0.108, data: 0.000) loss: 2.701 
(epoch: 1, iters: 1840, time: 0.105, data: 0.000) loss: 2.515 
(epoch: 1, iters: 1920, time: 0.107, data: 0.046) loss: 2.812 
(epoch: 1, iters: 2000, time: 0.108, data: 0.000) loss: 2.458 
(epoch: 1, iters: 2080, time: 0.104, data: 0.012) loss: 2.723 
(epoch: 1, iters: 2160, time: 0.108, data: 0.000) loss: 2.720 
(epoch: 1, iters: 2240, time: 0.106, data: 0.011) loss: 2.712 
(epoch: 1, iters: 2320, time: 0.106, data: 0.000) loss: 2.543 
(epoch: 1, iters: 2400, time: 0.105, data: 0.000) loss: 2.581 
(epoch: 1, iters: 2480, time: 0.106, data: 0.038) loss: 2.551 
(epoch: 1, iters: 2560, time: 0.106, data: 0.000) loss: 2.327 
(epoch: 1, iters: 2640, time: 0.103, data: 0.011) loss: 2.601 
(epoch: 1, iters: 2720, time: 0.106, data: 0.000) loss: 2.408 
(epoch: 1, iters: 2800, time: 0.104, data: 0.011) loss: 2.274 
(epoch: 1, iters: 2880, time: 0.106, data: 0.000) loss: 2.396 
(epoch: 1, iters: 2960, time: 0.104, data: 0.000) loss: 2.329 
(epoch: 1, iters: 3040, time: 0.106, data: 0.038) loss: 2.419 
(epoch: 1, iters: 3120, time: 0.105, data: 0.000) loss: 2.576 
(epoch: 1, iters: 3200, time: 0.104, data: 0.011) loss: 2.188 
(epoch: 1, iters: 3280, time: 0.106, data: 0.000) loss: 2.200 
(epoch: 1, iters: 3360, time: 0.106, data: 0.011) loss: 2.364 
(epoch: 1, iters: 3440, time: 0.107, data: 0.000) loss: 2.492 
(epoch: 1, iters: 3520, time: 0.104, data: 0.000) loss: 2.043 
(epoch: 1, iters: 3600, time: 0.105, data: 0.039) loss: 2.507 
(epoch: 1, iters: 3680, time: 0.100, data: 0.000) loss: 2.261 
saving the model at the end of epoch 1, iters 3728
End of epoch 1 / 2100 	 Time Taken: 399 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 1, TEST ACC: [26.404 %]

saving the latest model (epoch 2, total_steps 3744)
(epoch: 2, iters: 32, time: 0.099, data: 0.004) loss: 1.964 
(epoch: 2, iters: 112, time: 0.104, data: 0.027) loss: 2.024 
(epoch: 2, iters: 192, time: 0.106, data: 0.000) loss: 2.149 
(epoch: 2, iters: 272, time: 0.105, data: 0.000) loss: 2.009 
(epoch: 2, iters: 352, time: 0.106, data: 0.048) loss: 1.791 
(epoch: 2, iters: 432, time: 0.105, data: 0.000) loss: 1.953 
(epoch: 2, iters: 512, time: 0.103, data: 0.021) loss: 2.009 
(epoch: 2, iters: 592, time: 0.106, data: 0.000) loss: 2.116 
(epoch: 2, iters: 672, time: 0.104, data: 0.011) loss: 2.125 
(epoch: 2, iters: 752, time: 0.106, data: 0.000) loss: 2.101 
(epoch: 2, iters: 832, time: 0.104, data: 0.000) loss: 2.199 
(epoch: 2, iters: 912, time: 0.105, data: 0.038) loss: 1.918 
(epoch: 2, iters: 992, time: 0.106, data: 0.000) loss: 2.147 
(epoch: 2, iters: 1072, time: 0.102, data: 0.012) loss: 1.779 
(epoch: 2, iters: 1152, time: 0.105, data: 0.000) loss: 2.216 
(epoch: 2, iters: 1232, time: 0.104, data: 0.012) loss: 2.247 
(epoch: 2, iters: 1312, time: 0.105, data: 0.000) loss: 1.839 
(epoch: 2, iters: 1392, time: 0.104, data: 0.000) loss: 2.133 
(epoch: 2, iters: 1472, time: 0.105, data: 0.038) loss: 1.923 
(epoch: 2, iters: 1552, time: 0.105, data: 0.000) loss: 2.070 
(epoch: 2, iters: 1632, time: 0.103, data: 0.012) loss: 1.937 
(epoch: 2, iters: 1712, time: 0.104, data: 0.000) loss: 2.041 
(epoch: 2, iters: 1792, time: 0.105, data: 0.011) loss: 1.712 
(epoch: 2, iters: 1872, time: 0.105, data: 0.000) loss: 1.729 
(epoch: 2, iters: 1952, time: 0.104, data: 0.000) loss: 1.928 
(epoch: 2, iters: 2032, time: 0.105, data: 0.047) loss: 2.081 
(epoch: 2, iters: 2112, time: 0.106, data: 0.000) loss: 1.809 
(epoch: 2, iters: 2192, time: 0.102, data: 0.011) loss: 1.910 
(epoch: 2, iters: 2272, time: 0.106, data: 0.000) loss: 1.966 
(epoch: 2, iters: 2352, time: 0.104, data: 0.011) loss: 1.820 
(epoch: 2, iters: 2432, time: 0.105, data: 0.000) loss: 2.213 
(epoch: 2, iters: 2512, time: 0.104, data: 0.000) loss: 2.144 
(epoch: 2, iters: 2592, time: 0.105, data: 0.039) loss: 2.132 
(epoch: 2, iters: 2672, time: 0.104, data: 0.000) loss: 2.021 
(epoch: 2, iters: 2752, time: 0.102, data: 0.011) loss: 1.959 
(epoch: 2, iters: 2832, time: 0.105, data: 0.000) loss: 1.861 
(epoch: 2, iters: 2912, time: 0.104, data: 0.011) loss: 1.788 
(epoch: 2, iters: 2992, time: 0.105, data: 0.000) loss: 1.979 
(epoch: 2, iters: 3072, time: 0.105, data: 0.000) loss: 1.957 
(epoch: 2, iters: 3152, time: 0.105, data: 0.038) loss: 2.067 
(epoch: 2, iters: 3232, time: 0.105, data: 0.000) loss: 2.246 
(epoch: 2, iters: 3312, time: 0.103, data: 0.011) loss: 1.682 
(epoch: 2, iters: 3392, time: 0.105, data: 0.000) loss: 1.809 
(epoch: 2, iters: 3472, time: 0.104, data: 0.011) loss: 1.651 
(epoch: 2, iters: 3552, time: 0.105, data: 0.000) loss: 2.266 
(epoch: 2, iters: 3632, time: 0.102, data: 0.000) loss: 1.652 
(epoch: 2, iters: 3712, time: 0.099, data: 0.035) loss: 2.046 
saving the model at the end of epoch 2, iters 7456
End of epoch 2 / 2100 	 Time Taken: 392 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 2, TEST ACC: [33.536 %]

saving the latest model (epoch 3, total_steps 7472)
(epoch: 3, iters: 64, time: 0.104, data: 0.000) loss: 2.123 
(epoch: 3, iters: 144, time: 0.104, data: 0.000) loss: 1.638 
(epoch: 3, iters: 224, time: 0.105, data: 0.000) loss: 1.934 
(epoch: 3, iters: 304, time: 0.104, data: 0.000) loss: 1.680 
(epoch: 3, iters: 384, time: 0.104, data: 0.047) loss: 2.051 
(epoch: 3, iters: 464, time: 0.106, data: 0.000) loss: 1.940 
(epoch: 3, iters: 544, time: 0.103, data: 0.011) loss: 1.544 
(epoch: 3, iters: 624, time: 0.105, data: 0.000) loss: 1.757 
(epoch: 3, iters: 704, time: 0.103, data: 0.011) loss: 1.791 
(epoch: 3, iters: 784, time: 0.106, data: 0.000) loss: 1.754 
(epoch: 3, iters: 864, time: 0.104, data: 0.000) loss: 1.522 
(epoch: 3, iters: 944, time: 0.105, data: 0.038) loss: 1.612 
(epoch: 3, iters: 1024, time: 0.105, data: 0.000) loss: 1.872 
(epoch: 3, iters: 1104, time: 0.102, data: 0.011) loss: 1.844 
(epoch: 3, iters: 1184, time: 0.106, data: 0.000) loss: 1.872 
(epoch: 3, iters: 1264, time: 0.104, data: 0.012) loss: 1.822 
(epoch: 3, iters: 1344, time: 0.105, data: 0.000) loss: 1.701 
(epoch: 3, iters: 1424, time: 0.103, data: 0.000) loss: 1.521 
(epoch: 3, iters: 1504, time: 0.105, data: 0.038) loss: 1.535 
(epoch: 3, iters: 1584, time: 0.105, data: 0.000) loss: 1.397 
(epoch: 3, iters: 1664, time: 0.102, data: 0.012) loss: 1.430 
(epoch: 3, iters: 1744, time: 0.104, data: 0.000) loss: 1.915 
(epoch: 3, iters: 1824, time: 0.104, data: 0.012) loss: 1.985 
(epoch: 3, iters: 1904, time: 0.106, data: 0.000) loss: 1.736 
(epoch: 3, iters: 1984, time: 0.105, data: 0.000) loss: 1.822 
(epoch: 3, iters: 2064, time: 0.106, data: 0.039) loss: 1.775 
(epoch: 3, iters: 2144, time: 0.105, data: 0.000) loss: 1.673 
(epoch: 3, iters: 2224, time: 0.102, data: 0.011) loss: 1.526 
(epoch: 3, iters: 2304, time: 0.105, data: 0.000) loss: 1.760 
(epoch: 3, iters: 2384, time: 0.104, data: 0.011) loss: 1.676 
(epoch: 3, iters: 2464, time: 0.105, data: 0.000) loss: 2.728 
(epoch: 3, iters: 2544, time: 0.105, data: 0.000) loss: 1.866 
(epoch: 3, iters: 2624, time: 0.105, data: 0.048) loss: 1.789 
(epoch: 3, iters: 2704, time: 0.105, data: 0.000) loss: 1.533 
(epoch: 3, iters: 2784, time: 0.103, data: 0.011) loss: 1.925 
(epoch: 3, iters: 2864, time: 0.105, data: 0.000) loss: 1.618 
(epoch: 3, iters: 2944, time: 0.104, data: 0.011) loss: 1.203 
(epoch: 3, iters: 3024, time: 0.105, data: 0.000) loss: 1.919 
(epoch: 3, iters: 3104, time: 0.103, data: 0.000) loss: 1.952 
(epoch: 3, iters: 3184, time: 0.104, data: 0.049) loss: 1.407 
(epoch: 3, iters: 3264, time: 0.106, data: 0.000) loss: 1.642 
(epoch: 3, iters: 3344, time: 0.103, data: 0.011) loss: 1.657 
(epoch: 3, iters: 3424, time: 0.105, data: 0.000) loss: 1.592 
(epoch: 3, iters: 3504, time: 0.104, data: 0.011) loss: 1.679 
(epoch: 3, iters: 3584, time: 0.106, data: 0.000) loss: 1.949 
(epoch: 3, iters: 3664, time: 0.098, data: 0.000) loss: 1.891 
saving the model at the end of epoch 3, iters 11184
End of epoch 3 / 2100 	 Time Taken: 392 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 3, TEST ACC: [42.792 %]

(epoch: 4, iters: 16, time: 0.118, data: 0.012) loss: 1.152 
saving the latest model (epoch 4, total_steps 11200)
(epoch: 4, iters: 96, time: 0.105, data: 0.000) loss: 1.949 
(epoch: 4, iters: 176, time: 0.104, data: 0.000) loss: 1.664 
(epoch: 4, iters: 256, time: 0.105, data: 0.039) loss: 2.093 
(epoch: 4, iters: 336, time: 0.105, data: 0.000) loss: 1.285 
(epoch: 4, iters: 416, time: 0.103, data: 0.011) loss: 1.699 
(epoch: 4, iters: 496, time: 0.105, data: 0.000) loss: 1.695 
(epoch: 4, iters: 576, time: 0.104, data: 0.011) loss: 1.734 
(epoch: 4, iters: 656, time: 0.104, data: 0.000) loss: 1.422 
(epoch: 4, iters: 736, time: 0.104, data: 0.000) loss: 1.275 
(epoch: 4, iters: 816, time: 0.105, data: 0.039) loss: 1.917 
(epoch: 4, iters: 896, time: 0.105, data: 0.000) loss: 1.432 
(epoch: 4, iters: 976, time: 0.102, data: 0.011) loss: 1.622 
(epoch: 4, iters: 1056, time: 0.104, data: 0.000) loss: 1.617 
(epoch: 4, iters: 1136, time: 0.104, data: 0.012) loss: 1.906 
(epoch: 4, iters: 1216, time: 0.105, data: 0.000) loss: 1.455 
(epoch: 4, iters: 1296, time: 0.104, data: 0.000) loss: 1.963 
(epoch: 4, iters: 1376, time: 0.105, data: 0.038) loss: 1.706 
(epoch: 4, iters: 1456, time: 0.106, data: 0.000) loss: 1.550 
(epoch: 4, iters: 1536, time: 0.103, data: 0.011) loss: 1.915 
(epoch: 4, iters: 1616, time: 0.105, data: 0.000) loss: 1.780 
(epoch: 4, iters: 1696, time: 0.104, data: 0.012) loss: 1.924 
(epoch: 4, iters: 1776, time: 0.105, data: 0.000) loss: 1.706 
(epoch: 4, iters: 1856, time: 0.104, data: 0.000) loss: 1.506 
(epoch: 4, iters: 1936, time: 0.104, data: 0.039) loss: 1.554 
(epoch: 4, iters: 2016, time: 0.105, data: 0.000) loss: 1.393 
(epoch: 4, iters: 2096, time: 0.102, data: 0.012) loss: 1.867 
(epoch: 4, iters: 2176, time: 0.105, data: 0.000) loss: 1.058 
(epoch: 4, iters: 2256, time: 0.105, data: 0.012) loss: 1.667 
(epoch: 4, iters: 2336, time: 0.106, data: 0.000) loss: 1.792 
(epoch: 4, iters: 2416, time: 0.104, data: 0.000) loss: 1.380 
(epoch: 4, iters: 2496, time: 0.105, data: 0.039) loss: 1.661 
(epoch: 4, iters: 2576, time: 0.106, data: 0.000) loss: 1.172 
(epoch: 4, iters: 2656, time: 0.102, data: 0.011) loss: 1.739 
(epoch: 4, iters: 2736, time: 0.105, data: 0.000) loss: 1.443 
(epoch: 4, iters: 2816, time: 0.104, data: 0.012) loss: 1.607 
(epoch: 4, iters: 2896, time: 0.106, data: 0.000) loss: 1.482 
(epoch: 4, iters: 2976, time: 0.104, data: 0.000) loss: 1.740 
(epoch: 4, iters: 3056, time: 0.106, data: 0.047) loss: 1.592 
(epoch: 4, iters: 3136, time: 0.107, data: 0.000) loss: 1.535 
(epoch: 4, iters: 3216, time: 0.104, data: 0.011) loss: 1.373 
(epoch: 4, iters: 3296, time: 0.105, data: 0.000) loss: 1.272 
(epoch: 4, iters: 3376, time: 0.104, data: 0.011) loss: 1.598 
(epoch: 4, iters: 3456, time: 0.105, data: 0.000) loss: 1.348 
(epoch: 4, iters: 3536, time: 0.104, data: 0.000) loss: 1.342 
(epoch: 4, iters: 3616, time: 0.105, data: 0.038) loss: 1.453 
(epoch: 4, iters: 3696, time: 0.099, data: 0.000) loss: 1.048 
saving the model at the end of epoch 4, iters 14912
End of epoch 4 / 2100 	 Time Taken: 392 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 4, TEST ACC: [52.049 %]

saving the latest model (epoch 5, total_steps 14928)
(epoch: 5, iters: 48, time: 0.106, data: 0.000) loss: 1.206 
(epoch: 5, iters: 128, time: 0.106, data: 0.026) loss: 2.544 
(epoch: 5, iters: 208, time: 0.103, data: 0.011) loss: 1.178 
(epoch: 5, iters: 288, time: 0.105, data: 0.000) loss: 1.768 
(epoch: 5, iters: 368, time: 0.105, data: 0.011) loss: 1.404 
(epoch: 5, iters: 448, time: 0.105, data: 0.000) loss: 1.308 
(epoch: 5, iters: 528, time: 0.104, data: 0.000) loss: 1.422 
(epoch: 5, iters: 608, time: 0.106, data: 0.048) loss: 1.593 
(epoch: 5, iters: 688, time: 0.106, data: 0.000) loss: 1.555 
(epoch: 5, iters: 768, time: 0.103, data: 0.011) loss: 1.319 
(epoch: 5, iters: 848, time: 0.106, data: 0.000) loss: 1.236 
(epoch: 5, iters: 928, time: 0.104, data: 0.011) loss: 1.337 
(epoch: 5, iters: 1008, time: 0.106, data: 0.000) loss: 1.072 
(epoch: 5, iters: 1088, time: 0.105, data: 0.000) loss: 1.369 
(epoch: 5, iters: 1168, time: 0.105, data: 0.039) loss: 1.264 
(epoch: 5, iters: 1248, time: 0.106, data: 0.000) loss: 1.238 
(epoch: 5, iters: 1328, time: 0.103, data: 0.011) loss: 1.276 
(epoch: 5, iters: 1408, time: 0.105, data: 0.000) loss: 1.523 
(epoch: 5, iters: 1488, time: 0.104, data: 0.011) loss: 1.627 
(epoch: 5, iters: 1568, time: 0.106, data: 0.000) loss: 1.657 
(epoch: 5, iters: 1648, time: 0.103, data: 0.000) loss: 1.030 
(epoch: 5, iters: 1728, time: 0.105, data: 0.038) loss: 1.038 
(epoch: 5, iters: 1808, time: 0.105, data: 0.000) loss: 1.353 
(epoch: 5, iters: 1888, time: 0.101, data: 0.011) loss: 0.928 
(epoch: 5, iters: 1968, time: 0.105, data: 0.000) loss: 1.418 
(epoch: 5, iters: 2048, time: 0.105, data: 0.012) loss: 1.489 
(epoch: 5, iters: 2128, time: 0.105, data: 0.000) loss: 1.131 
(epoch: 5, iters: 2208, time: 0.104, data: 0.000) loss: 1.446 
(epoch: 5, iters: 2288, time: 0.105, data: 0.038) loss: 1.574 
(epoch: 5, iters: 2368, time: 0.106, data: 0.000) loss: 1.174 
(epoch: 5, iters: 2448, time: 0.103, data: 0.012) loss: 1.261 
(epoch: 5, iters: 2528, time: 0.104, data: 0.000) loss: 1.599 
(epoch: 5, iters: 2608, time: 0.105, data: 0.011) loss: 1.497 
(epoch: 5, iters: 2688, time: 0.106, data: 0.000) loss: 1.199 
(epoch: 5, iters: 2768, time: 0.105, data: 0.000) loss: 0.987 
(epoch: 5, iters: 2848, time: 0.106, data: 0.038) loss: 2.082 
(epoch: 5, iters: 2928, time: 0.105, data: 0.000) loss: 1.521 
(epoch: 5, iters: 3008, time: 0.102, data: 0.012) loss: 1.043 
(epoch: 5, iters: 3088, time: 0.105, data: 0.000) loss: 1.627 
(epoch: 5, iters: 3168, time: 0.104, data: 0.011) loss: 0.944 
(epoch: 5, iters: 3248, time: 0.105, data: 0.000) loss: 1.428 
(epoch: 5, iters: 3328, time: 0.103, data: 0.000) loss: 1.327 
(epoch: 5, iters: 3408, time: 0.105, data: 0.039) loss: 1.274 
(epoch: 5, iters: 3488, time: 0.105, data: 0.000) loss: 1.149 
(epoch: 5, iters: 3568, time: 0.104, data: 0.012) loss: 1.253 
(epoch: 5, iters: 3648, time: 0.099, data: 0.000) loss: 0.851 
(epoch: 5, iters: 3728, time: 0.065, data: 0.010) loss: 1.555 
saving the model at the end of epoch 5, iters 18640
End of epoch 5 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 5, TEST ACC: [59.788 %]

saving the latest model (epoch 6, total_steps 18656)
(epoch: 6, iters: 80, time: 0.105, data: 0.545) loss: 1.099 
(epoch: 6, iters: 160, time: 0.104, data: 0.000) loss: 1.307 
(epoch: 6, iters: 240, time: 0.106, data: 0.039) loss: 1.273 
(epoch: 6, iters: 320, time: 0.105, data: 0.000) loss: 1.621 
(epoch: 6, iters: 400, time: 0.103, data: 0.012) loss: 0.817 
(epoch: 6, iters: 480, time: 0.104, data: 0.000) loss: 1.247 
(epoch: 6, iters: 560, time: 0.105, data: 0.011) loss: 1.522 
(epoch: 6, iters: 640, time: 0.106, data: 0.000) loss: 1.300 
(epoch: 6, iters: 720, time: 0.104, data: 0.000) loss: 1.772 
(epoch: 6, iters: 800, time: 0.105, data: 0.039) loss: 1.148 
(epoch: 6, iters: 880, time: 0.106, data: 0.000) loss: 1.353 
(epoch: 6, iters: 960, time: 0.102, data: 0.012) loss: 1.211 
(epoch: 6, iters: 1040, time: 0.105, data: 0.000) loss: 1.230 
(epoch: 6, iters: 1120, time: 0.104, data: 0.011) loss: 1.436 
(epoch: 6, iters: 1200, time: 0.106, data: 0.000) loss: 1.041 
(epoch: 6, iters: 1280, time: 0.105, data: 0.000) loss: 0.906 
(epoch: 6, iters: 1360, time: 0.105, data: 0.039) loss: 1.098 
(epoch: 6, iters: 1440, time: 0.106, data: 0.000) loss: 0.824 
(epoch: 6, iters: 1520, time: 0.102, data: 0.011) loss: 1.064 
(epoch: 6, iters: 1600, time: 0.106, data: 0.000) loss: 1.131 
(epoch: 6, iters: 1680, time: 0.103, data: 0.011) loss: 1.180 
(epoch: 6, iters: 1760, time: 0.106, data: 0.000) loss: 1.246 
(epoch: 6, iters: 1840, time: 0.104, data: 0.000) loss: 1.413 
(epoch: 6, iters: 1920, time: 0.106, data: 0.040) loss: 0.977 
(epoch: 6, iters: 2000, time: 0.105, data: 0.000) loss: 0.832 
(epoch: 6, iters: 2080, time: 0.102, data: 0.011) loss: 0.944 
(epoch: 6, iters: 2160, time: 0.106, data: 0.000) loss: 1.049 
(epoch: 6, iters: 2240, time: 0.104, data: 0.012) loss: 1.084 
(epoch: 6, iters: 2320, time: 0.105, data: 0.000) loss: 1.034 
(epoch: 6, iters: 2400, time: 0.104, data: 0.000) loss: 0.569 
(epoch: 6, iters: 2480, time: 0.106, data: 0.040) loss: 1.076 
(epoch: 6, iters: 2560, time: 0.106, data: 0.000) loss: 0.788 
(epoch: 6, iters: 2640, time: 0.103, data: 0.012) loss: 0.773 
(epoch: 6, iters: 2720, time: 0.105, data: 0.000) loss: 0.913 
(epoch: 6, iters: 2800, time: 0.105, data: 0.012) loss: 1.138 
(epoch: 6, iters: 2880, time: 0.107, data: 0.000) loss: 1.030 
(epoch: 6, iters: 2960, time: 0.105, data: 0.000) loss: 1.126 
(epoch: 6, iters: 3040, time: 0.105, data: 0.039) loss: 1.630 
(epoch: 6, iters: 3120, time: 0.105, data: 0.000) loss: 0.938 
(epoch: 6, iters: 3200, time: 0.103, data: 0.011) loss: 1.052 
(epoch: 6, iters: 3280, time: 0.105, data: 0.000) loss: 1.183 
(epoch: 6, iters: 3360, time: 0.104, data: 0.011) loss: 1.529 
(epoch: 6, iters: 3440, time: 0.105, data: 0.000) loss: 1.176 
(epoch: 6, iters: 3520, time: 0.104, data: 0.000) loss: 1.288 
(epoch: 6, iters: 3600, time: 0.104, data: 0.039) loss: 1.248 
(epoch: 6, iters: 3680, time: 0.100, data: 0.000) loss: 1.128 
saving the model at the end of epoch 6, iters 22368
End of epoch 6 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 6, TEST ACC: [36.419 %]

saving the latest model (epoch 7, total_steps 22384)
(epoch: 7, iters: 32, time: 0.098, data: 0.004) loss: 0.942 
(epoch: 7, iters: 112, time: 0.105, data: 0.000) loss: 0.854 
(epoch: 7, iters: 192, time: 0.104, data: 0.000) loss: 0.874 
(epoch: 7, iters: 272, time: 0.104, data: 0.039) loss: 1.232 
(epoch: 7, iters: 352, time: 0.105, data: 0.000) loss: 0.888 
(epoch: 7, iters: 432, time: 0.103, data: 0.012) loss: 1.077 
(epoch: 7, iters: 512, time: 0.105, data: 0.000) loss: 0.957 
(epoch: 7, iters: 592, time: 0.105, data: 0.011) loss: 0.552 
(epoch: 7, iters: 672, time: 0.107, data: 0.000) loss: 0.949 
(epoch: 7, iters: 752, time: 0.105, data: 0.000) loss: 1.142 
(epoch: 7, iters: 832, time: 0.105, data: 0.039) loss: 1.095 
(epoch: 7, iters: 912, time: 0.105, data: 0.000) loss: 0.850 
(epoch: 7, iters: 992, time: 0.102, data: 0.011) loss: 0.843 
(epoch: 7, iters: 1072, time: 0.105, data: 0.000) loss: 0.893 
(epoch: 7, iters: 1152, time: 0.104, data: 0.011) loss: 0.690 
(epoch: 7, iters: 1232, time: 0.106, data: 0.000) loss: 1.038 
(epoch: 7, iters: 1312, time: 0.104, data: 0.000) loss: 0.636 
(epoch: 7, iters: 1392, time: 0.105, data: 0.039) loss: 1.079 
(epoch: 7, iters: 1472, time: 0.105, data: 0.000) loss: 1.024 
(epoch: 7, iters: 1552, time: 0.102, data: 0.011) loss: 0.647 
(epoch: 7, iters: 1632, time: 0.105, data: 0.000) loss: 0.683 
(epoch: 7, iters: 1712, time: 0.104, data: 0.011) loss: 1.015 
(epoch: 7, iters: 1792, time: 0.106, data: 0.000) loss: 1.198 
(epoch: 7, iters: 1872, time: 0.104, data: 0.000) loss: 0.885 
(epoch: 7, iters: 1952, time: 0.105, data: 0.038) loss: 0.914 
(epoch: 7, iters: 2032, time: 0.106, data: 0.000) loss: 0.852 
(epoch: 7, iters: 2112, time: 0.103, data: 0.011) loss: 0.986 
(epoch: 7, iters: 2192, time: 0.105, data: 0.000) loss: 0.806 
(epoch: 7, iters: 2272, time: 0.104, data: 0.011) loss: 1.125 
(epoch: 7, iters: 2352, time: 0.105, data: 0.000) loss: 0.998 
(epoch: 7, iters: 2432, time: 0.105, data: 0.000) loss: 0.870 
(epoch: 7, iters: 2512, time: 0.106, data: 0.038) loss: 1.131 
(epoch: 7, iters: 2592, time: 0.106, data: 0.000) loss: 1.307 
(epoch: 7, iters: 2672, time: 0.103, data: 0.011) loss: 1.093 
(epoch: 7, iters: 2752, time: 0.105, data: 0.000) loss: 1.439 
(epoch: 7, iters: 2832, time: 0.104, data: 0.012) loss: 0.991 
(epoch: 7, iters: 2912, time: 0.106, data: 0.000) loss: 0.625 
(epoch: 7, iters: 2992, time: 0.104, data: 0.000) loss: 1.088 
(epoch: 7, iters: 3072, time: 0.104, data: 0.039) loss: 0.844 
(epoch: 7, iters: 3152, time: 0.106, data: 0.000) loss: 1.088 
(epoch: 7, iters: 3232, time: 0.103, data: 0.012) loss: 1.125 
(epoch: 7, iters: 3312, time: 0.105, data: 0.000) loss: 0.692 
(epoch: 7, iters: 3392, time: 0.105, data: 0.011) loss: 0.935 
(epoch: 7, iters: 3472, time: 0.105, data: 0.000) loss: 0.852 
(epoch: 7, iters: 3552, time: 0.105, data: 0.000) loss: 0.849 
(epoch: 7, iters: 3632, time: 0.103, data: 0.038) loss: 0.604 
(epoch: 7, iters: 3712, time: 0.100, data: 0.000) loss: 0.810 
saving the model at the end of epoch 7, iters 26096
End of epoch 7 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 7, TEST ACC: [49.772 %]

saving the latest model (epoch 8, total_steps 26112)
(epoch: 8, iters: 64, time: 0.104, data: 0.000) loss: 1.203 
(epoch: 8, iters: 144, time: 0.106, data: 0.026) loss: 0.930 
(epoch: 8, iters: 224, time: 0.105, data: 0.000) loss: 1.572 
(epoch: 8, iters: 304, time: 0.103, data: 0.011) loss: 1.057 
(epoch: 8, iters: 384, time: 0.105, data: 0.000) loss: 1.168 
(epoch: 8, iters: 464, time: 0.104, data: 0.011) loss: 0.928 
(epoch: 8, iters: 544, time: 0.105, data: 0.000) loss: 0.938 
(epoch: 8, iters: 624, time: 0.104, data: 0.000) loss: 1.079 
(epoch: 8, iters: 704, time: 0.104, data: 0.038) loss: 0.887 
(epoch: 8, iters: 784, time: 0.105, data: 0.000) loss: 1.101 
(epoch: 8, iters: 864, time: 0.103, data: 0.011) loss: 0.865 
(epoch: 8, iters: 944, time: 0.104, data: 0.000) loss: 0.677 
(epoch: 8, iters: 1024, time: 0.104, data: 0.011) loss: 0.538 
(epoch: 8, iters: 1104, time: 0.105, data: 0.000) loss: 1.556 
(epoch: 8, iters: 1184, time: 0.104, data: 0.000) loss: 0.628 
(epoch: 8, iters: 1264, time: 0.104, data: 0.039) loss: 0.567 
(epoch: 8, iters: 1344, time: 0.106, data: 0.000) loss: 0.641 
(epoch: 8, iters: 1424, time: 0.103, data: 0.011) loss: 0.670 
(epoch: 8, iters: 1504, time: 0.104, data: 0.000) loss: 0.573 
(epoch: 8, iters: 1584, time: 0.103, data: 0.011) loss: 1.051 
(epoch: 8, iters: 1664, time: 0.104, data: 0.000) loss: 0.549 
(epoch: 8, iters: 1744, time: 0.104, data: 0.000) loss: 1.005 
(epoch: 8, iters: 1824, time: 0.104, data: 0.038) loss: 0.871 
(epoch: 8, iters: 1904, time: 0.105, data: 0.000) loss: 1.061 
(epoch: 8, iters: 1984, time: 0.103, data: 0.011) loss: 0.684 
(epoch: 8, iters: 2064, time: 0.104, data: 0.000) loss: 0.891 
(epoch: 8, iters: 2144, time: 0.104, data: 0.011) loss: 0.704 
(epoch: 8, iters: 2224, time: 0.106, data: 0.000) loss: 1.008 
(epoch: 8, iters: 2304, time: 0.104, data: 0.000) loss: 0.684 
(epoch: 8, iters: 2384, time: 0.105, data: 0.046) loss: 0.751 
(epoch: 8, iters: 2464, time: 0.106, data: 0.000) loss: 0.889 
(epoch: 8, iters: 2544, time: 0.103, data: 0.011) loss: 0.988 
(epoch: 8, iters: 2624, time: 0.106, data: 0.000) loss: 1.058 
(epoch: 8, iters: 2704, time: 0.104, data: 0.011) loss: 0.758 
(epoch: 8, iters: 2784, time: 0.106, data: 0.000) loss: 1.038 
(epoch: 8, iters: 2864, time: 0.104, data: 0.000) loss: 0.354 
(epoch: 8, iters: 2944, time: 0.104, data: 0.047) loss: 0.708 
(epoch: 8, iters: 3024, time: 0.106, data: 0.000) loss: 0.756 
(epoch: 8, iters: 3104, time: 0.103, data: 0.011) loss: 0.645 
(epoch: 8, iters: 3184, time: 0.105, data: 0.000) loss: 0.712 
(epoch: 8, iters: 3264, time: 0.106, data: 0.011) loss: 0.999 
(epoch: 8, iters: 3344, time: 0.106, data: 0.000) loss: 0.691 
(epoch: 8, iters: 3424, time: 0.104, data: 0.000) loss: 0.648 
(epoch: 8, iters: 3504, time: 0.106, data: 0.047) loss: 0.890 
(epoch: 8, iters: 3584, time: 0.106, data: 0.000) loss: 0.743 
(epoch: 8, iters: 3664, time: 0.099, data: 0.011) loss: 0.798 
saving the model at the end of epoch 8, iters 29824
End of epoch 8 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 8, TEST ACC: [54.78 %]

(epoch: 9, iters: 16, time: 0.120, data: 0.012) loss: 0.739 
saving the latest model (epoch 9, total_steps 29840)
(epoch: 9, iters: 96, time: 0.106, data: 0.011) loss: 0.785 
(epoch: 9, iters: 176, time: 0.104, data: 0.012) loss: 0.831 
(epoch: 9, iters: 256, time: 0.104, data: 0.000) loss: 0.638 
(epoch: 9, iters: 336, time: 0.104, data: 0.011) loss: 0.684 
(epoch: 9, iters: 416, time: 0.105, data: 0.000) loss: 0.745 
(epoch: 9, iters: 496, time: 0.105, data: 0.000) loss: 0.652 
(epoch: 9, iters: 576, time: 0.105, data: 0.039) loss: 1.017 
(epoch: 9, iters: 656, time: 0.105, data: 0.000) loss: 0.650 
(epoch: 9, iters: 736, time: 0.103, data: 0.011) loss: 0.618 
(epoch: 9, iters: 816, time: 0.105, data: 0.000) loss: 0.629 
(epoch: 9, iters: 896, time: 0.104, data: 0.011) loss: 0.764 
(epoch: 9, iters: 976, time: 0.106, data: 0.000) loss: 0.557 
(epoch: 9, iters: 1056, time: 0.105, data: 0.000) loss: 0.676 
(epoch: 9, iters: 1136, time: 0.105, data: 0.039) loss: 0.797 
(epoch: 9, iters: 1216, time: 0.106, data: 0.000) loss: 0.581 
(epoch: 9, iters: 1296, time: 0.103, data: 0.012) loss: 0.673 
(epoch: 9, iters: 1376, time: 0.105, data: 0.000) loss: 0.805 
(epoch: 9, iters: 1456, time: 0.105, data: 0.011) loss: 0.961 
(epoch: 9, iters: 1536, time: 0.105, data: 0.000) loss: 0.526 
(epoch: 9, iters: 1616, time: 0.105, data: 0.000) loss: 0.761 
(epoch: 9, iters: 1696, time: 0.104, data: 0.038) loss: 0.678 
(epoch: 9, iters: 1776, time: 0.106, data: 0.000) loss: 0.586 
(epoch: 9, iters: 1856, time: 0.102, data: 0.012) loss: 1.080 
(epoch: 9, iters: 1936, time: 0.104, data: 0.000) loss: 0.681 
(epoch: 9, iters: 2016, time: 0.104, data: 0.011) loss: 0.936 
(epoch: 9, iters: 2096, time: 0.106, data: 0.000) loss: 0.655 
(epoch: 9, iters: 2176, time: 0.104, data: 0.000) loss: 0.473 
(epoch: 9, iters: 2256, time: 0.105, data: 0.038) loss: 0.765 
(epoch: 9, iters: 2336, time: 0.105, data: 0.000) loss: 0.435 
(epoch: 9, iters: 2416, time: 0.103, data: 0.011) loss: 0.420 
(epoch: 9, iters: 2496, time: 0.105, data: 0.000) loss: 0.717 
(epoch: 9, iters: 2576, time: 0.104, data: 0.011) loss: 0.774 
(epoch: 9, iters: 2656, time: 0.105, data: 0.000) loss: 0.729 
(epoch: 9, iters: 2736, time: 0.104, data: 0.000) loss: 0.889 
(epoch: 9, iters: 2816, time: 0.104, data: 0.038) loss: 0.519 
(epoch: 9, iters: 2896, time: 0.105, data: 0.000) loss: 0.627 
(epoch: 9, iters: 2976, time: 0.103, data: 0.012) loss: 1.250 
(epoch: 9, iters: 3056, time: 0.104, data: 0.000) loss: 0.420 
(epoch: 9, iters: 3136, time: 0.105, data: 0.011) loss: 0.929 
(epoch: 9, iters: 3216, time: 0.106, data: 0.000) loss: 0.790 
(epoch: 9, iters: 3296, time: 0.104, data: 0.000) loss: 0.320 
(epoch: 9, iters: 3376, time: 0.104, data: 0.038) loss: 0.725 
(epoch: 9, iters: 3456, time: 0.105, data: 0.000) loss: 0.594 
(epoch: 9, iters: 3536, time: 0.103, data: 0.012) loss: 0.787 
(epoch: 9, iters: 3616, time: 0.105, data: 0.000) loss: 0.870 
(epoch: 9, iters: 3696, time: 0.100, data: 0.011) loss: 1.155 
saving the model at the end of epoch 9, iters 33552
End of epoch 9 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 9, TEST ACC: [57.967 %]

saving the latest model (epoch 10, total_steps 33568)
(epoch: 10, iters: 48, time: 0.105, data: 0.000) loss: 1.026 
(epoch: 10, iters: 128, time: 0.105, data: 0.026) loss: 0.427 
(epoch: 10, iters: 208, time: 0.105, data: 0.000) loss: 0.955 
(epoch: 10, iters: 288, time: 0.103, data: 0.011) loss: 0.501 
(epoch: 10, iters: 368, time: 0.105, data: 0.000) loss: 0.503 
(epoch: 10, iters: 448, time: 0.104, data: 0.011) loss: 0.794 
(epoch: 10, iters: 528, time: 0.105, data: 0.000) loss: 0.653 
(epoch: 10, iters: 608, time: 0.105, data: 0.000) loss: 1.141 
(epoch: 10, iters: 688, time: 0.105, data: 0.038) loss: 0.532 
(epoch: 10, iters: 768, time: 0.106, data: 0.000) loss: 0.741 
(epoch: 10, iters: 848, time: 0.104, data: 0.012) loss: 0.415 
(epoch: 10, iters: 928, time: 0.105, data: 0.000) loss: 0.689 
(epoch: 10, iters: 1008, time: 0.105, data: 0.012) loss: 0.654 
(epoch: 10, iters: 1088, time: 0.106, data: 0.000) loss: 0.694 
(epoch: 10, iters: 1168, time: 0.105, data: 0.000) loss: 0.467 
(epoch: 10, iters: 1248, time: 0.106, data: 0.038) loss: 0.547 
(epoch: 10, iters: 1328, time: 0.106, data: 0.000) loss: 0.660 
(epoch: 10, iters: 1408, time: 0.102, data: 0.011) loss: 0.658 
(epoch: 10, iters: 1488, time: 0.104, data: 0.000) loss: 0.477 
(epoch: 10, iters: 1568, time: 0.104, data: 0.011) loss: 0.653 
(epoch: 10, iters: 1648, time: 0.105, data: 0.000) loss: 0.631 
(epoch: 10, iters: 1728, time: 0.105, data: 0.000) loss: 0.802 
(epoch: 10, iters: 1808, time: 0.105, data: 0.038) loss: 0.555 
(epoch: 10, iters: 1888, time: 0.106, data: 0.000) loss: 0.396 
(epoch: 10, iters: 1968, time: 0.103, data: 0.011) loss: 0.630 
(epoch: 10, iters: 2048, time: 0.106, data: 0.000) loss: 0.463 
(epoch: 10, iters: 2128, time: 0.104, data: 0.011) loss: 0.302 
(epoch: 10, iters: 2208, time: 0.106, data: 0.000) loss: 0.340 
(epoch: 10, iters: 2288, time: 0.105, data: 0.000) loss: 0.804 
(epoch: 10, iters: 2368, time: 0.106, data: 0.039) loss: 0.802 
(epoch: 10, iters: 2448, time: 0.105, data: 0.000) loss: 0.906 
(epoch: 10, iters: 2528, time: 0.104, data: 0.011) loss: 1.032 
(epoch: 10, iters: 2608, time: 0.105, data: 0.000) loss: 0.499 
(epoch: 10, iters: 2688, time: 0.105, data: 0.012) loss: 0.641 
(epoch: 10, iters: 2768, time: 0.106, data: 0.000) loss: 0.839 
(epoch: 10, iters: 2848, time: 0.104, data: 0.000) loss: 0.359 
(epoch: 10, iters: 2928, time: 0.106, data: 0.038) loss: 0.607 
(epoch: 10, iters: 3008, time: 0.106, data: 0.000) loss: 0.734 
(epoch: 10, iters: 3088, time: 0.103, data: 0.012) loss: 0.502 
(epoch: 10, iters: 3168, time: 0.105, data: 0.000) loss: 0.951 
(epoch: 10, iters: 3248, time: 0.104, data: 0.011) loss: 0.648 
(epoch: 10, iters: 3328, time: 0.106, data: 0.000) loss: 0.475 
(epoch: 10, iters: 3408, time: 0.105, data: 0.000) loss: 0.315 
(epoch: 10, iters: 3488, time: 0.105, data: 0.038) loss: 0.898 
(epoch: 10, iters: 3568, time: 0.106, data: 0.000) loss: 0.897 
(epoch: 10, iters: 3648, time: 0.098, data: 0.011) loss: 1.270 
(epoch: 10, iters: 3728, time: 0.065, data: 0.000) loss: 0.604 
saving the model at the end of epoch 10, iters 37280
End of epoch 10 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 10, TEST ACC: [67.982 %]

saving the latest model (epoch 11, total_steps 37296)
(epoch: 11, iters: 80, time: 0.106, data: 0.554) loss: 0.510 
(epoch: 11, iters: 160, time: 0.105, data: 0.000) loss: 0.537 
(epoch: 11, iters: 240, time: 0.105, data: 0.039) loss: 0.574 
(epoch: 11, iters: 320, time: 0.105, data: 0.000) loss: 0.576 
(epoch: 11, iters: 400, time: 0.103, data: 0.012) loss: 0.440 
(epoch: 11, iters: 480, time: 0.105, data: 0.000) loss: 1.086 
(epoch: 11, iters: 560, time: 0.105, data: 0.011) loss: 0.748 
(epoch: 11, iters: 640, time: 0.106, data: 0.000) loss: 0.914 
(epoch: 11, iters: 720, time: 0.104, data: 0.000) loss: 0.814 
(epoch: 11, iters: 800, time: 0.106, data: 0.038) loss: 0.446 
(epoch: 11, iters: 880, time: 0.106, data: 0.000) loss: 0.450 
(epoch: 11, iters: 960, time: 0.103, data: 0.012) loss: 0.738 
(epoch: 11, iters: 1040, time: 0.105, data: 0.000) loss: 0.968 
(epoch: 11, iters: 1120, time: 0.105, data: 0.011) loss: 0.347 
(epoch: 11, iters: 1200, time: 0.105, data: 0.000) loss: 0.177 
(epoch: 11, iters: 1280, time: 0.104, data: 0.000) loss: 0.715 
(epoch: 11, iters: 1360, time: 0.105, data: 0.039) loss: 0.615 
(epoch: 11, iters: 1440, time: 0.105, data: 0.000) loss: 0.505 
(epoch: 11, iters: 1520, time: 0.104, data: 0.011) loss: 0.703 
(epoch: 11, iters: 1600, time: 0.105, data: 0.000) loss: 1.001 
(epoch: 11, iters: 1680, time: 0.105, data: 0.011) loss: 0.446 
(epoch: 11, iters: 1760, time: 0.106, data: 0.000) loss: 0.488 
(epoch: 11, iters: 1840, time: 0.105, data: 0.000) loss: 0.605 
(epoch: 11, iters: 1920, time: 0.105, data: 0.038) loss: 0.640 
(epoch: 11, iters: 2000, time: 0.105, data: 0.000) loss: 0.399 
(epoch: 11, iters: 2080, time: 0.103, data: 0.011) loss: 0.349 
(epoch: 11, iters: 2160, time: 0.106, data: 0.000) loss: 0.427 
(epoch: 11, iters: 2240, time: 0.105, data: 0.011) loss: 0.416 
(epoch: 11, iters: 2320, time: 0.106, data: 0.000) loss: 0.426 
(epoch: 11, iters: 2400, time: 0.105, data: 0.000) loss: 0.690 
(epoch: 11, iters: 2480, time: 0.105, data: 0.038) loss: 0.468 
(epoch: 11, iters: 2560, time: 0.106, data: 0.000) loss: 0.480 
(epoch: 11, iters: 2640, time: 0.103, data: 0.012) loss: 0.822 
(epoch: 11, iters: 2720, time: 0.105, data: 0.000) loss: 0.428 
(epoch: 11, iters: 2800, time: 0.104, data: 0.011) loss: 0.352 
(epoch: 11, iters: 2880, time: 0.106, data: 0.000) loss: 0.726 
(epoch: 11, iters: 2960, time: 0.104, data: 0.000) loss: 0.208 
(epoch: 11, iters: 3040, time: 0.105, data: 0.038) loss: 0.928 
(epoch: 11, iters: 3120, time: 0.106, data: 0.000) loss: 0.883 
(epoch: 11, iters: 3200, time: 0.103, data: 0.011) loss: 0.275 
(epoch: 11, iters: 3280, time: 0.105, data: 0.000) loss: 0.274 
(epoch: 11, iters: 3360, time: 0.105, data: 0.011) loss: 0.429 
(epoch: 11, iters: 3440, time: 0.106, data: 0.000) loss: 0.828 
(epoch: 11, iters: 3520, time: 0.104, data: 0.000) loss: 0.743 
(epoch: 11, iters: 3600, time: 0.105, data: 0.038) loss: 0.638 
(epoch: 11, iters: 3680, time: 0.101, data: 0.000) loss: 0.532 
saving the model at the end of epoch 11, iters 41008
End of epoch 11 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 11, TEST ACC: [76.48 %]

saving the latest model (epoch 12, total_steps 41024)
(epoch: 12, iters: 32, time: 0.099, data: 0.004) loss: 0.380 
(epoch: 12, iters: 112, time: 0.105, data: 0.011) loss: 0.424 
(epoch: 12, iters: 192, time: 0.106, data: 0.000) loss: 0.605 
(epoch: 12, iters: 272, time: 0.104, data: 0.000) loss: 0.821 
(epoch: 12, iters: 352, time: 0.105, data: 0.039) loss: 0.576 
(epoch: 12, iters: 432, time: 0.105, data: 0.000) loss: 0.631 
(epoch: 12, iters: 512, time: 0.102, data: 0.012) loss: 0.524 
(epoch: 12, iters: 592, time: 0.106, data: 0.000) loss: 0.502 
(epoch: 12, iters: 672, time: 0.105, data: 0.011) loss: 0.387 
(epoch: 12, iters: 752, time: 0.106, data: 0.000) loss: 0.674 
(epoch: 12, iters: 832, time: 0.106, data: 0.000) loss: 0.382 
(epoch: 12, iters: 912, time: 0.105, data: 0.038) loss: 0.291 
(epoch: 12, iters: 992, time: 0.105, data: 0.000) loss: 0.475 
(epoch: 12, iters: 1072, time: 0.104, data: 0.011) loss: 0.341 
(epoch: 12, iters: 1152, time: 0.106, data: 0.000) loss: 0.656 
(epoch: 12, iters: 1232, time: 0.104, data: 0.012) loss: 0.737 
(epoch: 12, iters: 1312, time: 0.106, data: 0.000) loss: 0.302 
(epoch: 12, iters: 1392, time: 0.105, data: 0.000) loss: 0.476 
(epoch: 12, iters: 1472, time: 0.105, data: 0.038) loss: 0.470 
(epoch: 12, iters: 1552, time: 0.106, data: 0.000) loss: 0.265 
(epoch: 12, iters: 1632, time: 0.103, data: 0.012) loss: 0.690 
(epoch: 12, iters: 1712, time: 0.106, data: 0.000) loss: 0.355 
(epoch: 12, iters: 1792, time: 0.105, data: 0.011) loss: 0.563 
(epoch: 12, iters: 1872, time: 0.107, data: 0.000) loss: 0.582 
(epoch: 12, iters: 1952, time: 0.105, data: 0.000) loss: 0.490 
(epoch: 12, iters: 2032, time: 0.105, data: 0.038) loss: 0.685 
(epoch: 12, iters: 2112, time: 0.105, data: 0.000) loss: 0.657 
(epoch: 12, iters: 2192, time: 0.104, data: 0.011) loss: 0.376 
(epoch: 12, iters: 2272, time: 0.106, data: 0.000) loss: 0.426 
(epoch: 12, iters: 2352, time: 0.105, data: 0.011) loss: 0.517 
(epoch: 12, iters: 2432, time: 0.106, data: 0.000) loss: 0.358 
(epoch: 12, iters: 2512, time: 0.104, data: 0.000) loss: 1.424 
(epoch: 12, iters: 2592, time: 0.106, data: 0.038) loss: 0.564 
(epoch: 12, iters: 2672, time: 0.105, data: 0.000) loss: 0.353 
(epoch: 12, iters: 2752, time: 0.103, data: 0.011) loss: 0.343 
(epoch: 12, iters: 2832, time: 0.106, data: 0.000) loss: 0.521 
(epoch: 12, iters: 2912, time: 0.105, data: 0.011) loss: 0.355 
(epoch: 12, iters: 2992, time: 0.106, data: 0.000) loss: 0.459 
(epoch: 12, iters: 3072, time: 0.106, data: 0.000) loss: 0.196 
(epoch: 12, iters: 3152, time: 0.105, data: 0.039) loss: 0.548 
(epoch: 12, iters: 3232, time: 0.108, data: 0.000) loss: 0.391 
(epoch: 12, iters: 3312, time: 0.103, data: 0.011) loss: 0.375 
(epoch: 12, iters: 3392, time: 0.106, data: 0.000) loss: 0.380 
(epoch: 12, iters: 3472, time: 0.107, data: 0.012) loss: 0.286 
(epoch: 12, iters: 3552, time: 0.106, data: 0.000) loss: 0.719 
(epoch: 12, iters: 3632, time: 0.103, data: 0.000) loss: 0.677 
(epoch: 12, iters: 3712, time: 0.101, data: 0.043) loss: 0.240 
saving the model at the end of epoch 12, iters 44736
End of epoch 12 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 12, TEST ACC: [75.569 %]

saving the latest model (epoch 13, total_steps 44752)
(epoch: 13, iters: 64, time: 0.103, data: 0.000) loss: 0.354 
(epoch: 13, iters: 144, time: 0.106, data: 0.000) loss: 0.410 
(epoch: 13, iters: 224, time: 0.104, data: 0.011) loss: 0.424 
(epoch: 13, iters: 304, time: 0.106, data: 0.000) loss: 1.506 
(epoch: 13, iters: 384, time: 0.106, data: 0.000) loss: 0.292 
(epoch: 13, iters: 464, time: 0.106, data: 0.040) loss: 0.729 
(epoch: 13, iters: 544, time: 0.107, data: 0.000) loss: 0.309 
(epoch: 13, iters: 624, time: 0.103, data: 0.011) loss: 0.310 
(epoch: 13, iters: 704, time: 0.106, data: 0.000) loss: 0.548 
(epoch: 13, iters: 784, time: 0.105, data: 0.011) loss: 0.447 
(epoch: 13, iters: 864, time: 0.106, data: 0.000) loss: 0.729 
(epoch: 13, iters: 944, time: 0.105, data: 0.000) loss: 0.939 
(epoch: 13, iters: 1024, time: 0.105, data: 0.039) loss: 0.374 
(epoch: 13, iters: 1104, time: 0.106, data: 0.000) loss: 0.260 
(epoch: 13, iters: 1184, time: 0.103, data: 0.011) loss: 0.273 
(epoch: 13, iters: 1264, time: 0.105, data: 0.000) loss: 0.476 
(epoch: 13, iters: 1344, time: 0.105, data: 0.011) loss: 0.367 
(epoch: 13, iters: 1424, time: 0.106, data: 0.000) loss: 0.418 
(epoch: 13, iters: 1504, time: 0.105, data: 0.000) loss: 0.896 
(epoch: 13, iters: 1584, time: 0.105, data: 0.039) loss: 0.739 
(epoch: 13, iters: 1664, time: 0.107, data: 0.000) loss: 0.199 
(epoch: 13, iters: 1744, time: 0.103, data: 0.011) loss: 0.874 
(epoch: 13, iters: 1824, time: 0.105, data: 0.000) loss: 0.397 
(epoch: 13, iters: 1904, time: 0.105, data: 0.012) loss: 0.531 
(epoch: 13, iters: 1984, time: 0.106, data: 0.000) loss: 0.461 
(epoch: 13, iters: 2064, time: 0.106, data: 0.000) loss: 0.202 
(epoch: 13, iters: 2144, time: 0.106, data: 0.039) loss: 0.630 
(epoch: 13, iters: 2224, time: 0.105, data: 0.000) loss: 0.564 
(epoch: 13, iters: 2304, time: 0.103, data: 0.012) loss: 0.260 
(epoch: 13, iters: 2384, time: 0.106, data: 0.000) loss: 0.349 
(epoch: 13, iters: 2464, time: 0.105, data: 0.012) loss: 0.497 
(epoch: 13, iters: 2544, time: 0.107, data: 0.000) loss: 0.239 
(epoch: 13, iters: 2624, time: 0.105, data: 0.000) loss: 0.289 
(epoch: 13, iters: 2704, time: 0.107, data: 0.039) loss: 0.317 
(epoch: 13, iters: 2784, time: 0.106, data: 0.000) loss: 0.383 
(epoch: 13, iters: 2864, time: 0.104, data: 0.012) loss: 0.515 
(epoch: 13, iters: 2944, time: 0.106, data: 0.000) loss: 0.346 
(epoch: 13, iters: 3024, time: 0.105, data: 0.011) loss: 0.298 
(epoch: 13, iters: 3104, time: 0.107, data: 0.000) loss: 0.163 
(epoch: 13, iters: 3184, time: 0.104, data: 0.000) loss: 0.338 
(epoch: 13, iters: 3264, time: 0.105, data: 0.048) loss: 0.399 
(epoch: 13, iters: 3344, time: 0.106, data: 0.000) loss: 0.697 
(epoch: 13, iters: 3424, time: 0.103, data: 0.020) loss: 0.256 
(epoch: 13, iters: 3504, time: 0.106, data: 0.000) loss: 0.331 
(epoch: 13, iters: 3584, time: 0.104, data: 0.011) loss: 0.514 
(epoch: 13, iters: 3664, time: 0.101, data: 0.000) loss: 0.735 
saving the model at the end of epoch 13, iters 48464
End of epoch 13 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 13, TEST ACC: [70.561 %]

(epoch: 14, iters: 16, time: 0.119, data: 0.000) loss: 1.213 
saving the latest model (epoch 14, total_steps 48480)
(epoch: 14, iters: 96, time: 0.104, data: 0.000) loss: 0.403 
(epoch: 14, iters: 176, time: 0.105, data: 0.000) loss: 0.372 
(epoch: 14, iters: 256, time: 0.104, data: 0.012) loss: 0.399 
(epoch: 14, iters: 336, time: 0.106, data: 0.000) loss: 0.274 
(epoch: 14, iters: 416, time: 0.104, data: 0.000) loss: 0.537 
(epoch: 14, iters: 496, time: 0.105, data: 0.038) loss: 0.908 
(epoch: 14, iters: 576, time: 0.106, data: 0.000) loss: 0.269 
(epoch: 14, iters: 656, time: 0.103, data: 0.011) loss: 0.343 
(epoch: 14, iters: 736, time: 0.105, data: 0.000) loss: 0.272 
(epoch: 14, iters: 816, time: 0.104, data: 0.011) loss: 0.364 
(epoch: 14, iters: 896, time: 0.105, data: 0.000) loss: 0.396 
(epoch: 14, iters: 976, time: 0.104, data: 0.000) loss: 0.775 
(epoch: 14, iters: 1056, time: 0.105, data: 0.038) loss: 0.805 
(epoch: 14, iters: 1136, time: 0.105, data: 0.000) loss: 0.481 
(epoch: 14, iters: 1216, time: 0.103, data: 0.012) loss: 0.268 
(epoch: 14, iters: 1296, time: 0.105, data: 0.000) loss: 0.614 
(epoch: 14, iters: 1376, time: 0.105, data: 0.011) loss: 0.264 
(epoch: 14, iters: 1456, time: 0.105, data: 0.000) loss: 0.371 
(epoch: 14, iters: 1536, time: 0.104, data: 0.000) loss: 0.215 
(epoch: 14, iters: 1616, time: 0.106, data: 0.038) loss: 0.423 
(epoch: 14, iters: 1696, time: 0.105, data: 0.000) loss: 0.335 
(epoch: 14, iters: 1776, time: 0.104, data: 0.011) loss: 0.403 
(epoch: 14, iters: 1856, time: 0.104, data: 0.000) loss: 0.570 
(epoch: 14, iters: 1936, time: 0.103, data: 0.011) loss: 0.246 
(epoch: 14, iters: 2016, time: 0.106, data: 0.000) loss: 0.303 
(epoch: 14, iters: 2096, time: 0.104, data: 0.000) loss: 0.455 
(epoch: 14, iters: 2176, time: 0.105, data: 0.039) loss: 0.397 
(epoch: 14, iters: 2256, time: 0.105, data: 0.000) loss: 0.242 
(epoch: 14, iters: 2336, time: 0.104, data: 0.011) loss: 0.686 
(epoch: 14, iters: 2416, time: 0.105, data: 0.000) loss: 0.656 
(epoch: 14, iters: 2496, time: 0.104, data: 0.011) loss: 0.391 
(epoch: 14, iters: 2576, time: 0.105, data: 0.000) loss: 0.227 
(epoch: 14, iters: 2656, time: 0.104, data: 0.000) loss: 0.621 
(epoch: 14, iters: 2736, time: 0.105, data: 0.038) loss: 0.704 
(epoch: 14, iters: 2816, time: 0.106, data: 0.000) loss: 0.341 
(epoch: 14, iters: 2896, time: 0.102, data: 0.012) loss: 0.684 
(epoch: 14, iters: 2976, time: 0.106, data: 0.000) loss: 0.468 
(epoch: 14, iters: 3056, time: 0.104, data: 0.011) loss: 0.542 
(epoch: 14, iters: 3136, time: 0.105, data: 0.000) loss: 0.440 
(epoch: 14, iters: 3216, time: 0.105, data: 0.000) loss: 0.351 
(epoch: 14, iters: 3296, time: 0.106, data: 0.039) loss: 0.240 
(epoch: 14, iters: 3376, time: 0.107, data: 0.000) loss: 0.356 
(epoch: 14, iters: 3456, time: 0.103, data: 0.012) loss: 0.420 
(epoch: 14, iters: 3536, time: 0.105, data: 0.000) loss: 0.275 
(epoch: 14, iters: 3616, time: 0.106, data: 0.018) loss: 0.341 
(epoch: 14, iters: 3696, time: 0.101, data: 0.000) loss: 0.494 
saving the model at the end of epoch 14, iters 52192
End of epoch 14 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 14, TEST ACC: [79.666 %]

saving the latest model (epoch 15, total_steps 52208)
(epoch: 15, iters: 48, time: 0.107, data: 0.000) loss: 0.266 
(epoch: 15, iters: 128, time: 0.104, data: 0.000) loss: 0.451 
(epoch: 15, iters: 208, time: 0.106, data: 0.038) loss: 0.588 
(epoch: 15, iters: 288, time: 0.106, data: 0.000) loss: 0.356 
(epoch: 15, iters: 368, time: 0.103, data: 0.011) loss: 0.199 
(epoch: 15, iters: 448, time: 0.105, data: 0.000) loss: 0.451 
(epoch: 15, iters: 528, time: 0.105, data: 0.011) loss: 0.237 
(epoch: 15, iters: 608, time: 0.106, data: 0.000) loss: 0.464 
(epoch: 15, iters: 688, time: 0.104, data: 0.000) loss: 0.164 
(epoch: 15, iters: 768, time: 0.105, data: 0.038) loss: 0.252 
(epoch: 15, iters: 848, time: 0.106, data: 0.000) loss: 0.259 
(epoch: 15, iters: 928, time: 0.103, data: 0.012) loss: 0.453 
(epoch: 15, iters: 1008, time: 0.106, data: 0.000) loss: 0.264 
(epoch: 15, iters: 1088, time: 0.105, data: 0.011) loss: 0.509 
(epoch: 15, iters: 1168, time: 0.106, data: 0.000) loss: 0.183 
(epoch: 15, iters: 1248, time: 0.105, data: 0.000) loss: 0.628 
(epoch: 15, iters: 1328, time: 0.105, data: 0.038) loss: 0.380 
(epoch: 15, iters: 1408, time: 0.106, data: 0.000) loss: 0.585 
(epoch: 15, iters: 1488, time: 0.103, data: 0.012) loss: 0.419 
(epoch: 15, iters: 1568, time: 0.105, data: 0.000) loss: 0.329 
(epoch: 15, iters: 1648, time: 0.103, data: 0.011) loss: 0.337 
(epoch: 15, iters: 1728, time: 0.106, data: 0.000) loss: 0.369 
(epoch: 15, iters: 1808, time: 0.106, data: 0.000) loss: 0.221 
(epoch: 15, iters: 1888, time: 0.105, data: 0.039) loss: 0.151 
(epoch: 15, iters: 1968, time: 0.106, data: 0.000) loss: 0.689 
(epoch: 15, iters: 2048, time: 0.104, data: 0.012) loss: 0.367 
(epoch: 15, iters: 2128, time: 0.106, data: 0.000) loss: 0.190 
(epoch: 15, iters: 2208, time: 0.105, data: 0.011) loss: 0.670 
(epoch: 15, iters: 2288, time: 0.105, data: 0.000) loss: 0.424 
(epoch: 15, iters: 2368, time: 0.105, data: 0.000) loss: 0.487 
(epoch: 15, iters: 2448, time: 0.105, data: 0.039) loss: 0.296 
(epoch: 15, iters: 2528, time: 0.106, data: 0.000) loss: 0.474 
(epoch: 15, iters: 2608, time: 0.102, data: 0.011) loss: 0.396 
(epoch: 15, iters: 2688, time: 0.106, data: 0.000) loss: 0.224 
(epoch: 15, iters: 2768, time: 0.104, data: 0.012) loss: 0.799 
(epoch: 15, iters: 2848, time: 0.106, data: 0.000) loss: 0.313 
(epoch: 15, iters: 2928, time: 0.105, data: 0.000) loss: 0.254 
(epoch: 15, iters: 3008, time: 0.107, data: 0.039) loss: 0.120 
(epoch: 15, iters: 3088, time: 0.106, data: 0.000) loss: 0.386 
(epoch: 15, iters: 3168, time: 0.103, data: 0.012) loss: 0.262 
(epoch: 15, iters: 3248, time: 0.106, data: 0.000) loss: 0.355 
(epoch: 15, iters: 3328, time: 0.105, data: 0.012) loss: 0.242 
(epoch: 15, iters: 3408, time: 0.106, data: 0.000) loss: 0.647 
(epoch: 15, iters: 3488, time: 0.106, data: 0.000) loss: 0.865 
(epoch: 15, iters: 3568, time: 0.106, data: 0.039) loss: 0.222 
(epoch: 15, iters: 3648, time: 0.100, data: 0.000) loss: 0.230 
(epoch: 15, iters: 3728, time: 0.065, data: 0.011) loss: 0.607 
saving the model at the end of epoch 15, iters 55920
End of epoch 15 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 15, TEST ACC: [80.121 %]

saving the latest model (epoch 16, total_steps 55936)
(epoch: 16, iters: 80, time: 0.103, data: 0.466) loss: 0.559 
(epoch: 16, iters: 160, time: 0.104, data: 0.000) loss: 0.385 
(epoch: 16, iters: 240, time: 0.104, data: 0.011) loss: 0.336 
(epoch: 16, iters: 320, time: 0.106, data: 0.000) loss: 0.149 
(epoch: 16, iters: 400, time: 0.105, data: 0.000) loss: 0.545 
(epoch: 16, iters: 480, time: 0.105, data: 0.039) loss: 0.699 
(epoch: 16, iters: 560, time: 0.105, data: 0.000) loss: 0.796 
(epoch: 16, iters: 640, time: 0.103, data: 0.012) loss: 0.346 
(epoch: 16, iters: 720, time: 0.104, data: 0.000) loss: 0.518 
(epoch: 16, iters: 800, time: 0.105, data: 0.011) loss: 0.630 
(epoch: 16, iters: 880, time: 0.106, data: 0.000) loss: 0.155 
(epoch: 16, iters: 960, time: 0.105, data: 0.000) loss: 0.170 
(epoch: 16, iters: 1040, time: 0.105, data: 0.039) loss: 0.385 
(epoch: 16, iters: 1120, time: 0.106, data: 0.000) loss: 0.166 
(epoch: 16, iters: 1200, time: 0.103, data: 0.012) loss: 0.300 
(epoch: 16, iters: 1280, time: 0.105, data: 0.000) loss: 0.254 
(epoch: 16, iters: 1360, time: 0.104, data: 0.011) loss: 0.211 
(epoch: 16, iters: 1440, time: 0.106, data: 0.000) loss: 0.253 
(epoch: 16, iters: 1520, time: 0.105, data: 0.000) loss: 0.203 
(epoch: 16, iters: 1600, time: 0.106, data: 0.038) loss: 0.169 
(epoch: 16, iters: 1680, time: 0.105, data: 0.000) loss: 0.256 
(epoch: 16, iters: 1760, time: 0.103, data: 0.011) loss: 0.203 
(epoch: 16, iters: 1840, time: 0.107, data: 0.000) loss: 0.209 
(epoch: 16, iters: 1920, time: 0.105, data: 0.011) loss: 0.416 
(epoch: 16, iters: 2000, time: 0.106, data: 0.000) loss: 0.234 
(epoch: 16, iters: 2080, time: 0.105, data: 0.000) loss: 0.203 
(epoch: 16, iters: 2160, time: 0.106, data: 0.046) loss: 0.335 
(epoch: 16, iters: 2240, time: 0.106, data: 0.000) loss: 0.141 
(epoch: 16, iters: 2320, time: 0.103, data: 0.012) loss: 0.208 
(epoch: 16, iters: 2400, time: 0.105, data: 0.000) loss: 0.327 
(epoch: 16, iters: 2480, time: 0.105, data: 0.011) loss: 0.098 
(epoch: 16, iters: 2560, time: 0.106, data: 0.000) loss: 0.075 
(epoch: 16, iters: 2640, time: 0.104, data: 0.000) loss: 0.370 
(epoch: 16, iters: 2720, time: 0.105, data: 0.047) loss: 0.378 
(epoch: 16, iters: 2800, time: 0.106, data: 0.000) loss: 0.311 
(epoch: 16, iters: 2880, time: 0.104, data: 0.011) loss: 0.326 
(epoch: 16, iters: 2960, time: 0.105, data: 0.000) loss: 0.155 
(epoch: 16, iters: 3040, time: 0.105, data: 0.011) loss: 0.396 
(epoch: 16, iters: 3120, time: 0.105, data: 0.000) loss: 0.083 
(epoch: 16, iters: 3200, time: 0.103, data: 0.000) loss: 0.259 
(epoch: 16, iters: 3280, time: 0.104, data: 0.038) loss: 1.151 
(epoch: 16, iters: 3360, time: 0.106, data: 0.000) loss: 0.204 
(epoch: 16, iters: 3440, time: 0.103, data: 0.011) loss: 0.303 
(epoch: 16, iters: 3520, time: 0.105, data: 0.000) loss: 0.238 
(epoch: 16, iters: 3600, time: 0.104, data: 0.011) loss: 0.540 
(epoch: 16, iters: 3680, time: 0.099, data: 0.000) loss: 0.212 
saving the model at the end of epoch 16, iters 59648
End of epoch 16 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 16, TEST ACC: [72.838 %]

saving the latest model (epoch 17, total_steps 59664)
(epoch: 17, iters: 32, time: 0.099, data: 0.000) loss: 0.201 
(epoch: 17, iters: 112, time: 0.105, data: 0.012) loss: 0.134 
(epoch: 17, iters: 192, time: 0.103, data: 0.011) loss: 0.503 
(epoch: 17, iters: 272, time: 0.104, data: 0.000) loss: 0.184 
(epoch: 17, iters: 352, time: 0.105, data: 0.011) loss: 0.161 
(epoch: 17, iters: 432, time: 0.105, data: 0.000) loss: 0.325 
(epoch: 17, iters: 512, time: 0.104, data: 0.000) loss: 0.149 
(epoch: 17, iters: 592, time: 0.106, data: 0.039) loss: 0.263 
(epoch: 17, iters: 672, time: 0.107, data: 0.000) loss: 0.175 
(epoch: 17, iters: 752, time: 0.102, data: 0.012) loss: 0.453 
(epoch: 17, iters: 832, time: 0.105, data: 0.000) loss: 0.104 
(epoch: 17, iters: 912, time: 0.103, data: 0.011) loss: 0.191 
(epoch: 17, iters: 992, time: 0.105, data: 0.000) loss: 0.460 
(epoch: 17, iters: 1072, time: 0.105, data: 0.000) loss: 0.188 
(epoch: 17, iters: 1152, time: 0.107, data: 0.039) loss: 0.421 
(epoch: 17, iters: 1232, time: 0.106, data: 0.000) loss: 0.311 
(epoch: 17, iters: 1312, time: 0.102, data: 0.011) loss: 0.409 
(epoch: 17, iters: 1392, time: 0.105, data: 0.000) loss: 0.277 
(epoch: 17, iters: 1472, time: 0.106, data: 0.020) loss: 0.127 
(epoch: 17, iters: 1552, time: 0.106, data: 0.000) loss: 0.277 
(epoch: 17, iters: 1632, time: 0.104, data: 0.000) loss: 0.337 
(epoch: 17, iters: 1712, time: 0.105, data: 0.047) loss: 0.133 
(epoch: 17, iters: 1792, time: 0.106, data: 0.000) loss: 0.268 
(epoch: 17, iters: 1872, time: 0.104, data: 0.021) loss: 0.138 
(epoch: 17, iters: 1952, time: 0.106, data: 0.000) loss: 0.305 
(epoch: 17, iters: 2032, time: 0.105, data: 0.011) loss: 0.255 
(epoch: 17, iters: 2112, time: 0.106, data: 0.000) loss: 0.634 
(epoch: 17, iters: 2192, time: 0.105, data: 0.000) loss: 0.384 
(epoch: 17, iters: 2272, time: 0.104, data: 0.040) loss: 0.191 
(epoch: 17, iters: 2352, time: 0.105, data: 0.000) loss: 0.272 
(epoch: 17, iters: 2432, time: 0.104, data: 0.011) loss: 0.298 
(epoch: 17, iters: 2512, time: 0.105, data: 0.000) loss: 0.432 
(epoch: 17, iters: 2592, time: 0.104, data: 0.011) loss: 0.231 
(epoch: 17, iters: 2672, time: 0.106, data: 0.000) loss: 0.694 
(epoch: 17, iters: 2752, time: 0.104, data: 0.000) loss: 0.234 
(epoch: 17, iters: 2832, time: 0.105, data: 0.038) loss: 0.193 
(epoch: 17, iters: 2912, time: 0.105, data: 0.000) loss: 0.208 
(epoch: 17, iters: 2992, time: 0.104, data: 0.012) loss: 0.277 
(epoch: 17, iters: 3072, time: 0.105, data: 0.000) loss: 0.342 
(epoch: 17, iters: 3152, time: 0.104, data: 0.011) loss: 0.206 
(epoch: 17, iters: 3232, time: 0.107, data: 0.000) loss: 0.192 
(epoch: 17, iters: 3312, time: 0.104, data: 0.000) loss: 0.263 
(epoch: 17, iters: 3392, time: 0.105, data: 0.038) loss: 0.621 
(epoch: 17, iters: 3472, time: 0.106, data: 0.000) loss: 0.250 
(epoch: 17, iters: 3552, time: 0.103, data: 0.011) loss: 0.273 
(epoch: 17, iters: 3632, time: 0.103, data: 0.000) loss: 0.314 
(epoch: 17, iters: 3712, time: 0.100, data: 0.011) loss: 0.101 
saving the model at the end of epoch 17, iters 63376
End of epoch 17 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 17, TEST ACC: [77.997 %]

saving the latest model (epoch 18, total_steps 63392)
(epoch: 18, iters: 64, time: 0.104, data: 0.003) loss: 0.236 
(epoch: 18, iters: 144, time: 0.105, data: 0.025) loss: 0.427 
(epoch: 18, iters: 224, time: 0.106, data: 0.000) loss: 0.215 
(epoch: 18, iters: 304, time: 0.104, data: 0.011) loss: 0.163 
(epoch: 18, iters: 384, time: 0.105, data: 0.000) loss: 0.136 
(epoch: 18, iters: 464, time: 0.105, data: 0.011) loss: 0.274 
(epoch: 18, iters: 544, time: 0.105, data: 0.000) loss: 0.203 
(epoch: 18, iters: 624, time: 0.106, data: 0.000) loss: 0.459 
(epoch: 18, iters: 704, time: 0.105, data: 0.039) loss: 0.148 
(epoch: 18, iters: 784, time: 0.107, data: 0.000) loss: 0.559 
(epoch: 18, iters: 864, time: 0.104, data: 0.011) loss: 0.068 
(epoch: 18, iters: 944, time: 0.105, data: 0.000) loss: 0.154 
(epoch: 18, iters: 1024, time: 0.105, data: 0.012) loss: 0.196 
(epoch: 18, iters: 1104, time: 0.106, data: 0.000) loss: 0.248 
(epoch: 18, iters: 1184, time: 0.105, data: 0.000) loss: 0.319 
(epoch: 18, iters: 1264, time: 0.105, data: 0.038) loss: 0.238 
(epoch: 18, iters: 1344, time: 0.106, data: 0.000) loss: 0.128 
(epoch: 18, iters: 1424, time: 0.103, data: 0.011) loss: 0.447 
(epoch: 18, iters: 1504, time: 0.105, data: 0.000) loss: 1.133 
(epoch: 18, iters: 1584, time: 0.105, data: 0.011) loss: 0.217 
(epoch: 18, iters: 1664, time: 0.105, data: 0.000) loss: 0.265 
(epoch: 18, iters: 1744, time: 0.104, data: 0.000) loss: 0.047 
(epoch: 18, iters: 1824, time: 0.106, data: 0.039) loss: 0.198 
(epoch: 18, iters: 1904, time: 0.107, data: 0.000) loss: 0.232 
(epoch: 18, iters: 1984, time: 0.103, data: 0.011) loss: 0.468 
(epoch: 18, iters: 2064, time: 0.104, data: 0.000) loss: 0.528 
(epoch: 18, iters: 2144, time: 0.105, data: 0.011) loss: 0.344 
(epoch: 18, iters: 2224, time: 0.106, data: 0.000) loss: 0.426 
(epoch: 18, iters: 2304, time: 0.104, data: 0.000) loss: 0.132 
(epoch: 18, iters: 2384, time: 0.106, data: 0.038) loss: 0.464 
(epoch: 18, iters: 2464, time: 0.106, data: 0.000) loss: 0.357 
(epoch: 18, iters: 2544, time: 0.104, data: 0.012) loss: 0.338 
(epoch: 18, iters: 2624, time: 0.105, data: 0.000) loss: 0.366 
(epoch: 18, iters: 2704, time: 0.104, data: 0.012) loss: 0.287 
(epoch: 18, iters: 2784, time: 0.106, data: 0.000) loss: 0.279 
(epoch: 18, iters: 2864, time: 0.105, data: 0.000) loss: 0.087 
(epoch: 18, iters: 2944, time: 0.106, data: 0.038) loss: 0.064 
(epoch: 18, iters: 3024, time: 0.105, data: 0.000) loss: 0.104 
(epoch: 18, iters: 3104, time: 0.103, data: 0.012) loss: 0.188 
(epoch: 18, iters: 3184, time: 0.106, data: 0.000) loss: 0.254 
(epoch: 18, iters: 3264, time: 0.105, data: 0.012) loss: 0.249 
(epoch: 18, iters: 3344, time: 0.105, data: 0.000) loss: 0.166 
(epoch: 18, iters: 3424, time: 0.105, data: 0.000) loss: 0.335 
(epoch: 18, iters: 3504, time: 0.106, data: 0.039) loss: 0.086 
(epoch: 18, iters: 3584, time: 0.106, data: 0.000) loss: 0.224 
(epoch: 18, iters: 3664, time: 0.099, data: 0.012) loss: 0.123 
saving the model at the end of epoch 18, iters 67104
End of epoch 18 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 18, TEST ACC: [89.833 %]

(epoch: 19, iters: 16, time: 0.113, data: 0.012) loss: 0.139 
saving the latest model (epoch 19, total_steps 67120)
(epoch: 19, iters: 96, time: 0.105, data: 0.000) loss: 0.269 
(epoch: 19, iters: 176, time: 0.104, data: 0.000) loss: 0.072 
(epoch: 19, iters: 256, time: 0.105, data: 0.039) loss: 0.652 
(epoch: 19, iters: 336, time: 0.105, data: 0.000) loss: 0.217 
(epoch: 19, iters: 416, time: 0.102, data: 0.011) loss: 0.485 
(epoch: 19, iters: 496, time: 0.105, data: 0.000) loss: 0.299 
(epoch: 19, iters: 576, time: 0.103, data: 0.011) loss: 0.636 
(epoch: 19, iters: 656, time: 0.105, data: 0.000) loss: 0.282 
(epoch: 19, iters: 736, time: 0.105, data: 0.000) loss: 0.085 
(epoch: 19, iters: 816, time: 0.105, data: 0.040) loss: 0.187 
(epoch: 19, iters: 896, time: 0.105, data: 0.000) loss: 0.339 
(epoch: 19, iters: 976, time: 0.102, data: 0.011) loss: 0.167 
(epoch: 19, iters: 1056, time: 0.105, data: 0.000) loss: 0.062 
(epoch: 19, iters: 1136, time: 0.106, data: 0.011) loss: 0.086 
(epoch: 19, iters: 1216, time: 0.106, data: 0.000) loss: 0.243 
(epoch: 19, iters: 1296, time: 0.104, data: 0.000) loss: 0.080 
(epoch: 19, iters: 1376, time: 0.106, data: 0.039) loss: 0.242 
(epoch: 19, iters: 1456, time: 0.105, data: 0.000) loss: 0.411 
(epoch: 19, iters: 1536, time: 0.104, data: 0.012) loss: 0.209 
(epoch: 19, iters: 1616, time: 0.105, data: 0.000) loss: 0.484 
(epoch: 19, iters: 1696, time: 0.104, data: 0.011) loss: 0.238 
(epoch: 19, iters: 1776, time: 0.105, data: 0.000) loss: 0.172 
(epoch: 19, iters: 1856, time: 0.104, data: 0.000) loss: 0.245 
(epoch: 19, iters: 1936, time: 0.105, data: 0.048) loss: 0.066 
(epoch: 19, iters: 2016, time: 0.105, data: 0.000) loss: 0.544 
(epoch: 19, iters: 2096, time: 0.103, data: 0.012) loss: 0.258 
(epoch: 19, iters: 2176, time: 0.106, data: 0.000) loss: 0.320 
(epoch: 19, iters: 2256, time: 0.104, data: 0.011) loss: 0.102 
(epoch: 19, iters: 2336, time: 0.106, data: 0.000) loss: 0.307 
(epoch: 19, iters: 2416, time: 0.105, data: 0.000) loss: 0.166 
(epoch: 19, iters: 2496, time: 0.106, data: 0.038) loss: 0.068 
(epoch: 19, iters: 2576, time: 0.105, data: 0.000) loss: 0.147 
(epoch: 19, iters: 2656, time: 0.103, data: 0.011) loss: 0.137 
(epoch: 19, iters: 2736, time: 0.105, data: 0.000) loss: 0.422 
(epoch: 19, iters: 2816, time: 0.105, data: 0.011) loss: 0.225 
(epoch: 19, iters: 2896, time: 0.105, data: 0.000) loss: 0.114 
(epoch: 19, iters: 2976, time: 0.105, data: 0.000) loss: 0.206 
(epoch: 19, iters: 3056, time: 0.105, data: 0.038) loss: 0.061 
(epoch: 19, iters: 3136, time: 0.107, data: 0.000) loss: 0.202 
(epoch: 19, iters: 3216, time: 0.103, data: 0.011) loss: 0.347 
(epoch: 19, iters: 3296, time: 0.106, data: 0.000) loss: 0.018 
(epoch: 19, iters: 3376, time: 0.105, data: 0.012) loss: 0.187 
(epoch: 19, iters: 3456, time: 0.107, data: 0.000) loss: 0.111 
(epoch: 19, iters: 3536, time: 0.106, data: 0.000) loss: 0.027 
(epoch: 19, iters: 3616, time: 0.107, data: 0.039) loss: 0.146 
(epoch: 19, iters: 3696, time: 0.101, data: 0.000) loss: 0.185 
saving the model at the end of epoch 19, iters 70832
End of epoch 19 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 19, TEST ACC: [84.522 %]

saving the latest model (epoch 20, total_steps 70848)
(epoch: 20, iters: 48, time: 0.106, data: 0.000) loss: 0.082 
(epoch: 20, iters: 128, time: 0.104, data: 0.025) loss: 0.513 
(epoch: 20, iters: 208, time: 0.106, data: 0.000) loss: 0.332 
(epoch: 20, iters: 288, time: 0.104, data: 0.000) loss: 0.176 
(epoch: 20, iters: 368, time: 0.106, data: 0.039) loss: 0.099 
(epoch: 20, iters: 448, time: 0.107, data: 0.000) loss: 0.344 
(epoch: 20, iters: 528, time: 0.103, data: 0.011) loss: 0.051 
(epoch: 20, iters: 608, time: 0.105, data: 0.000) loss: 0.033 
(epoch: 20, iters: 688, time: 0.105, data: 0.011) loss: 0.227 
(epoch: 20, iters: 768, time: 0.106, data: 0.000) loss: 0.422 
(epoch: 20, iters: 848, time: 0.105, data: 0.000) loss: 0.504 
(epoch: 20, iters: 928, time: 0.105, data: 0.038) loss: 0.221 
(epoch: 20, iters: 1008, time: 0.106, data: 0.000) loss: 0.076 
(epoch: 20, iters: 1088, time: 0.103, data: 0.011) loss: 0.215 
(epoch: 20, iters: 1168, time: 0.106, data: 0.000) loss: 0.397 
(epoch: 20, iters: 1248, time: 0.105, data: 0.011) loss: 0.132 
(epoch: 20, iters: 1328, time: 0.105, data: 0.000) loss: 0.302 
(epoch: 20, iters: 1408, time: 0.105, data: 0.000) loss: 0.127 
(epoch: 20, iters: 1488, time: 0.104, data: 0.039) loss: 0.133 
(epoch: 20, iters: 1568, time: 0.106, data: 0.000) loss: 0.306 
(epoch: 20, iters: 1648, time: 0.103, data: 0.012) loss: 0.332 
(epoch: 20, iters: 1728, time: 0.105, data: 0.000) loss: 0.247 
(epoch: 20, iters: 1808, time: 0.104, data: 0.011) loss: 0.208 
(epoch: 20, iters: 1888, time: 0.107, data: 0.000) loss: 0.194 
(epoch: 20, iters: 1968, time: 0.105, data: 0.000) loss: 0.099 
(epoch: 20, iters: 2048, time: 0.105, data: 0.038) loss: 0.259 
(epoch: 20, iters: 2128, time: 0.106, data: 0.000) loss: 0.413 
(epoch: 20, iters: 2208, time: 0.102, data: 0.011) loss: 0.251 
(epoch: 20, iters: 2288, time: 0.106, data: 0.000) loss: 0.194 
(epoch: 20, iters: 2368, time: 0.105, data: 0.012) loss: 0.584 
(epoch: 20, iters: 2448, time: 0.106, data: 0.000) loss: 0.287 
(epoch: 20, iters: 2528, time: 0.106, data: 0.000) loss: 0.183 
(epoch: 20, iters: 2608, time: 0.106, data: 0.039) loss: 0.228 
(epoch: 20, iters: 2688, time: 0.107, data: 0.000) loss: 0.559 
(epoch: 20, iters: 2768, time: 0.103, data: 0.011) loss: 0.187 
(epoch: 20, iters: 2848, time: 0.105, data: 0.000) loss: 0.239 
(epoch: 20, iters: 2928, time: 0.104, data: 0.012) loss: 0.250 
(epoch: 20, iters: 3008, time: 0.106, data: 0.000) loss: 0.322 
(epoch: 20, iters: 3088, time: 0.104, data: 0.000) loss: 0.094 
(epoch: 20, iters: 3168, time: 0.106, data: 0.039) loss: 0.308 
(epoch: 20, iters: 3248, time: 0.106, data: 0.000) loss: 0.422 
(epoch: 20, iters: 3328, time: 0.103, data: 0.011) loss: 0.098 
(epoch: 20, iters: 3408, time: 0.105, data: 0.000) loss: 0.178 
(epoch: 20, iters: 3488, time: 0.106, data: 0.012) loss: 0.060 
(epoch: 20, iters: 3568, time: 0.106, data: 0.000) loss: 0.072 
(epoch: 20, iters: 3648, time: 0.100, data: 0.000) loss: 0.146 
(epoch: 20, iters: 3728, time: 0.065, data: 0.015) loss: 0.435 
saving the model at the end of epoch 20, iters 74560
End of epoch 20 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 20, TEST ACC: [80.121 %]

saving the latest model (epoch 21, total_steps 74576)
(epoch: 21, iters: 80, time: 0.106, data: 0.513) loss: 0.120 
(epoch: 21, iters: 160, time: 0.106, data: 0.039) loss: 0.139 
(epoch: 21, iters: 240, time: 0.107, data: 0.000) loss: 0.159 
(epoch: 21, iters: 320, time: 0.105, data: 0.011) loss: 0.383 
(epoch: 21, iters: 400, time: 0.106, data: 0.000) loss: 0.070 
(epoch: 21, iters: 480, time: 0.105, data: 0.011) loss: 0.090 
(epoch: 21, iters: 560, time: 0.105, data: 0.000) loss: 0.415 
(epoch: 21, iters: 640, time: 0.104, data: 0.000) loss: 0.888 
(epoch: 21, iters: 720, time: 0.106, data: 0.048) loss: 0.114 
(epoch: 21, iters: 800, time: 0.106, data: 0.000) loss: 0.205 
(epoch: 21, iters: 880, time: 0.103, data: 0.011) loss: 0.094 
(epoch: 21, iters: 960, time: 0.106, data: 0.000) loss: 0.201 
(epoch: 21, iters: 1040, time: 0.105, data: 0.011) loss: 0.182 
(epoch: 21, iters: 1120, time: 0.106, data: 0.000) loss: 0.633 
(epoch: 21, iters: 1200, time: 0.106, data: 0.000) loss: 0.110 
(epoch: 21, iters: 1280, time: 0.107, data: 0.039) loss: 0.309 
(epoch: 21, iters: 1360, time: 0.106, data: 0.000) loss: 0.247 
(epoch: 21, iters: 1440, time: 0.104, data: 0.011) loss: 0.422 
(epoch: 21, iters: 1520, time: 0.105, data: 0.000) loss: 0.161 
(epoch: 21, iters: 1600, time: 0.105, data: 0.011) loss: 0.254 
(epoch: 21, iters: 1680, time: 0.106, data: 0.000) loss: 0.296 
(epoch: 21, iters: 1760, time: 0.105, data: 0.000) loss: 0.120 
(epoch: 21, iters: 1840, time: 0.106, data: 0.038) loss: 0.178 
(epoch: 21, iters: 1920, time: 0.106, data: 0.000) loss: 0.180 
(epoch: 21, iters: 2000, time: 0.103, data: 0.011) loss: 0.170 
(epoch: 21, iters: 2080, time: 0.105, data: 0.000) loss: 0.098 
(epoch: 21, iters: 2160, time: 0.104, data: 0.011) loss: 0.660 
(epoch: 21, iters: 2240, time: 0.107, data: 0.000) loss: 0.334 
(epoch: 21, iters: 2320, time: 0.106, data: 0.000) loss: 0.357 
(epoch: 21, iters: 2400, time: 0.105, data: 0.038) loss: 0.250 
(epoch: 21, iters: 2480, time: 0.107, data: 0.000) loss: 0.075 
(epoch: 21, iters: 2560, time: 0.103, data: 0.012) loss: 0.252 
(epoch: 21, iters: 2640, time: 0.105, data: 0.000) loss: 0.239 
(epoch: 21, iters: 2720, time: 0.105, data: 0.011) loss: 0.259 
(epoch: 21, iters: 2800, time: 0.106, data: 0.000) loss: 0.044 
(epoch: 21, iters: 2880, time: 0.105, data: 0.000) loss: 0.479 
(epoch: 21, iters: 2960, time: 0.105, data: 0.038) loss: 0.048 
(epoch: 21, iters: 3040, time: 0.106, data: 0.000) loss: 0.553 
(epoch: 21, iters: 3120, time: 0.102, data: 0.011) loss: 0.333 
(epoch: 21, iters: 3200, time: 0.106, data: 0.000) loss: 0.493 
(epoch: 21, iters: 3280, time: 0.105, data: 0.011) loss: 0.102 
(epoch: 21, iters: 3360, time: 0.106, data: 0.000) loss: 0.520 
(epoch: 21, iters: 3440, time: 0.106, data: 0.000) loss: 0.096 
(epoch: 21, iters: 3520, time: 0.106, data: 0.039) loss: 0.045 
(epoch: 21, iters: 3600, time: 0.107, data: 0.000) loss: 0.131 
(epoch: 21, iters: 3680, time: 0.099, data: 0.011) loss: 0.260 
saving the model at the end of epoch 21, iters 78288
End of epoch 21 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 21, TEST ACC: [84.522 %]

saving the latest model (epoch 22, total_steps 78304)
(epoch: 22, iters: 32, time: 0.099, data: 0.015) loss: 0.090 
(epoch: 22, iters: 112, time: 0.105, data: 0.000) loss: 0.349 
(epoch: 22, iters: 192, time: 0.105, data: 0.000) loss: 0.092 
(epoch: 22, iters: 272, time: 0.105, data: 0.038) loss: 0.098 
(epoch: 22, iters: 352, time: 0.106, data: 0.000) loss: 0.098 
(epoch: 22, iters: 432, time: 0.101, data: 0.012) loss: 0.092 
(epoch: 22, iters: 512, time: 0.106, data: 0.000) loss: 0.049 
(epoch: 22, iters: 592, time: 0.104, data: 0.012) loss: 0.244 
(epoch: 22, iters: 672, time: 0.106, data: 0.000) loss: 0.024 
(epoch: 22, iters: 752, time: 0.104, data: 0.000) loss: 0.147 
(epoch: 22, iters: 832, time: 0.105, data: 0.047) loss: 0.072 
(epoch: 22, iters: 912, time: 0.106, data: 0.000) loss: 0.419 
(epoch: 22, iters: 992, time: 0.102, data: 0.020) loss: 0.030 
(epoch: 22, iters: 1072, time: 0.105, data: 0.000) loss: 0.208 
(epoch: 22, iters: 1152, time: 0.106, data: 0.011) loss: 0.251 
(epoch: 22, iters: 1232, time: 0.105, data: 0.000) loss: 0.232 
(epoch: 22, iters: 1312, time: 0.104, data: 0.000) loss: 0.379 
(epoch: 22, iters: 1392, time: 0.106, data: 0.039) loss: 0.296 
(epoch: 22, iters: 1472, time: 0.105, data: 0.000) loss: 0.495 
(epoch: 22, iters: 1552, time: 0.104, data: 0.012) loss: 0.456 
(epoch: 22, iters: 1632, time: 0.105, data: 0.000) loss: 0.271 
(epoch: 22, iters: 1712, time: 0.105, data: 0.011) loss: 0.102 
(epoch: 22, iters: 1792, time: 0.106, data: 0.000) loss: 0.049 
(epoch: 22, iters: 1872, time: 0.105, data: 0.000) loss: 0.158 
(epoch: 22, iters: 1952, time: 0.106, data: 0.039) loss: 0.505 
(epoch: 22, iters: 2032, time: 0.106, data: 0.000) loss: 0.129 
(epoch: 22, iters: 2112, time: 0.103, data: 0.011) loss: 0.081 
(epoch: 22, iters: 2192, time: 0.106, data: 0.000) loss: 0.138 
(epoch: 22, iters: 2272, time: 0.105, data: 0.012) loss: 0.355 
(epoch: 22, iters: 2352, time: 0.105, data: 0.000) loss: 0.676 
(epoch: 22, iters: 2432, time: 0.105, data: 0.000) loss: 0.341 
(epoch: 22, iters: 2512, time: 0.105, data: 0.039) loss: 0.098 
(epoch: 22, iters: 2592, time: 0.106, data: 0.000) loss: 0.106 
(epoch: 22, iters: 2672, time: 0.102, data: 0.012) loss: 0.135 
(epoch: 22, iters: 2752, time: 0.105, data: 0.000) loss: 0.064 
(epoch: 22, iters: 2832, time: 0.105, data: 0.011) loss: 0.179 
(epoch: 22, iters: 2912, time: 0.105, data: 0.000) loss: 0.178 
(epoch: 22, iters: 2992, time: 0.104, data: 0.000) loss: 0.155 
(epoch: 22, iters: 3072, time: 0.106, data: 0.039) loss: 0.540 
(epoch: 22, iters: 3152, time: 0.107, data: 0.000) loss: 0.122 
(epoch: 22, iters: 3232, time: 0.103, data: 0.011) loss: 0.072 
(epoch: 22, iters: 3312, time: 0.106, data: 0.000) loss: 0.072 
(epoch: 22, iters: 3392, time: 0.104, data: 0.011) loss: 0.013 
(epoch: 22, iters: 3472, time: 0.106, data: 0.000) loss: 0.170 
(epoch: 22, iters: 3552, time: 0.105, data: 0.000) loss: 0.473 
(epoch: 22, iters: 3632, time: 0.103, data: 0.039) loss: 0.104 
(epoch: 22, iters: 3712, time: 0.100, data: 0.000) loss: 0.337 
saving the model at the end of epoch 22, iters 82016
End of epoch 22 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 22, TEST ACC: [82.853 %]

saving the latest model (epoch 23, total_steps 82032)
(epoch: 23, iters: 64, time: 0.105, data: 0.000) loss: 0.186 
(epoch: 23, iters: 144, time: 0.104, data: 0.000) loss: 0.886 
(epoch: 23, iters: 224, time: 0.104, data: 0.011) loss: 0.170 
(epoch: 23, iters: 304, time: 0.106, data: 0.000) loss: 0.059 
(epoch: 23, iters: 384, time: 0.104, data: 0.000) loss: 0.335 
(epoch: 23, iters: 464, time: 0.106, data: 0.048) loss: 0.022 
(epoch: 23, iters: 544, time: 0.105, data: 0.000) loss: 0.043 
(epoch: 23, iters: 624, time: 0.104, data: 0.011) loss: 0.108 
(epoch: 23, iters: 704, time: 0.104, data: 0.000) loss: 0.111 
(epoch: 23, iters: 784, time: 0.105, data: 0.011) loss: 0.235 
(epoch: 23, iters: 864, time: 0.106, data: 0.000) loss: 0.314 
(epoch: 23, iters: 944, time: 0.105, data: 0.000) loss: 0.399 
(epoch: 23, iters: 1024, time: 0.105, data: 0.039) loss: 0.106 
(epoch: 23, iters: 1104, time: 0.105, data: 0.000) loss: 0.175 
(epoch: 23, iters: 1184, time: 0.104, data: 0.011) loss: 0.054 
(epoch: 23, iters: 1264, time: 0.105, data: 0.000) loss: 0.179 
(epoch: 23, iters: 1344, time: 0.104, data: 0.011) loss: 0.062 
(epoch: 23, iters: 1424, time: 0.106, data: 0.000) loss: 0.111 
(epoch: 23, iters: 1504, time: 0.104, data: 0.000) loss: 0.029 
(epoch: 23, iters: 1584, time: 0.105, data: 0.039) loss: 0.064 
(epoch: 23, iters: 1664, time: 0.106, data: 0.000) loss: 0.225 
(epoch: 23, iters: 1744, time: 0.103, data: 0.011) loss: 0.078 
(epoch: 23, iters: 1824, time: 0.105, data: 0.000) loss: 0.106 
(epoch: 23, iters: 1904, time: 0.104, data: 0.011) loss: 0.014 
(epoch: 23, iters: 1984, time: 0.105, data: 0.000) loss: 0.075 
(epoch: 23, iters: 2064, time: 0.104, data: 0.000) loss: 0.059 
(epoch: 23, iters: 2144, time: 0.105, data: 0.038) loss: 0.134 
(epoch: 23, iters: 2224, time: 0.106, data: 0.000) loss: 0.119 
(epoch: 23, iters: 2304, time: 0.102, data: 0.012) loss: 0.134 
(epoch: 23, iters: 2384, time: 0.105, data: 0.000) loss: 0.242 
(epoch: 23, iters: 2464, time: 0.104, data: 0.011) loss: 0.286 
(epoch: 23, iters: 2544, time: 0.107, data: 0.000) loss: 0.248 
(epoch: 23, iters: 2624, time: 0.105, data: 0.000) loss: 0.150 
(epoch: 23, iters: 2704, time: 0.106, data: 0.039) loss: 0.903 
(epoch: 23, iters: 2784, time: 0.107, data: 0.000) loss: 0.219 
(epoch: 23, iters: 2864, time: 0.104, data: 0.011) loss: 0.059 
(epoch: 23, iters: 2944, time: 0.106, data: 0.000) loss: 0.124 
(epoch: 23, iters: 3024, time: 0.104, data: 0.011) loss: 0.264 
(epoch: 23, iters: 3104, time: 0.106, data: 0.000) loss: 0.082 
(epoch: 23, iters: 3184, time: 0.103, data: 0.000) loss: 0.047 
(epoch: 23, iters: 3264, time: 0.105, data: 0.048) loss: 0.122 
(epoch: 23, iters: 3344, time: 0.105, data: 0.000) loss: 0.208 
(epoch: 23, iters: 3424, time: 0.102, data: 0.011) loss: 0.437 
(epoch: 23, iters: 3504, time: 0.106, data: 0.000) loss: 0.116 
(epoch: 23, iters: 3584, time: 0.105, data: 0.011) loss: 0.116 
(epoch: 23, iters: 3664, time: 0.101, data: 0.000) loss: 0.124 
saving the model at the end of epoch 23, iters 85744
End of epoch 23 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 23, TEST ACC: [87.102 %]

(epoch: 24, iters: 16, time: 0.119, data: 0.000) loss: 0.242 
saving the latest model (epoch 24, total_steps 85760)
(epoch: 24, iters: 96, time: 0.106, data: 0.000) loss: 0.088 
(epoch: 24, iters: 176, time: 0.104, data: 0.000) loss: 0.024 
(epoch: 24, iters: 256, time: 0.106, data: 0.038) loss: 0.199 
(epoch: 24, iters: 336, time: 0.105, data: 0.000) loss: 0.094 
(epoch: 24, iters: 416, time: 0.103, data: 0.012) loss: 0.129 
(epoch: 24, iters: 496, time: 0.105, data: 0.000) loss: 0.055 
(epoch: 24, iters: 576, time: 0.105, data: 0.011) loss: 0.192 
(epoch: 24, iters: 656, time: 0.105, data: 0.000) loss: 0.094 
(epoch: 24, iters: 736, time: 0.104, data: 0.000) loss: 0.432 
(epoch: 24, iters: 816, time: 0.105, data: 0.039) loss: 0.104 
(epoch: 24, iters: 896, time: 0.106, data: 0.000) loss: 0.153 
(epoch: 24, iters: 976, time: 0.103, data: 0.011) loss: 0.048 
(epoch: 24, iters: 1056, time: 0.106, data: 0.000) loss: 0.034 
(epoch: 24, iters: 1136, time: 0.104, data: 0.011) loss: 0.017 
(epoch: 24, iters: 1216, time: 0.105, data: 0.000) loss: 0.151 
(epoch: 24, iters: 1296, time: 0.105, data: 0.000) loss: 0.275 
(epoch: 24, iters: 1376, time: 0.105, data: 0.039) loss: 0.055 
(epoch: 24, iters: 1456, time: 0.106, data: 0.000) loss: 0.365 
(epoch: 24, iters: 1536, time: 0.102, data: 0.012) loss: 0.367 
(epoch: 24, iters: 1616, time: 0.105, data: 0.000) loss: 0.308 
(epoch: 24, iters: 1696, time: 0.104, data: 0.011) loss: 0.052 
(epoch: 24, iters: 1776, time: 0.105, data: 0.000) loss: 0.051 
(epoch: 24, iters: 1856, time: 0.105, data: 0.000) loss: 0.146 
(epoch: 24, iters: 1936, time: 0.106, data: 0.040) loss: 0.450 
(epoch: 24, iters: 2016, time: 0.107, data: 0.000) loss: 0.092 
(epoch: 24, iters: 2096, time: 0.103, data: 0.012) loss: 0.480 
(epoch: 24, iters: 2176, time: 0.105, data: 0.000) loss: 0.054 
(epoch: 24, iters: 2256, time: 0.105, data: 0.011) loss: 0.100 
(epoch: 24, iters: 2336, time: 0.106, data: 0.000) loss: 0.139 
(epoch: 24, iters: 2416, time: 0.103, data: 0.000) loss: 0.021 
(epoch: 24, iters: 2496, time: 0.105, data: 0.048) loss: 0.421 
(epoch: 24, iters: 2576, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 24, iters: 2656, time: 0.103, data: 0.012) loss: 0.062 
(epoch: 24, iters: 2736, time: 0.106, data: 0.000) loss: 0.197 
(epoch: 24, iters: 2816, time: 0.104, data: 0.011) loss: 0.079 
(epoch: 24, iters: 2896, time: 0.106, data: 0.000) loss: 0.325 
(epoch: 24, iters: 2976, time: 0.105, data: 0.000) loss: 0.129 
(epoch: 24, iters: 3056, time: 0.105, data: 0.039) loss: 0.204 
(epoch: 24, iters: 3136, time: 0.107, data: 0.000) loss: 0.089 
(epoch: 24, iters: 3216, time: 0.103, data: 0.011) loss: 0.244 
(epoch: 24, iters: 3296, time: 0.105, data: 0.000) loss: 0.127 
(epoch: 24, iters: 3376, time: 0.105, data: 0.011) loss: 0.062 
(epoch: 24, iters: 3456, time: 0.107, data: 0.000) loss: 0.547 
(epoch: 24, iters: 3536, time: 0.105, data: 0.000) loss: 0.085 
(epoch: 24, iters: 3616, time: 0.105, data: 0.039) loss: 0.386 
(epoch: 24, iters: 3696, time: 0.100, data: 0.000) loss: 0.197 
saving the model at the end of epoch 24, iters 89472
End of epoch 24 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 24, TEST ACC: [84.522 %]

saving the latest model (epoch 25, total_steps 89488)
(epoch: 25, iters: 48, time: 0.108, data: 0.000) loss: 0.294 
(epoch: 25, iters: 128, time: 0.105, data: 0.041) loss: 0.304 
(epoch: 25, iters: 208, time: 0.106, data: 0.000) loss: 0.207 
(epoch: 25, iters: 288, time: 0.103, data: 0.012) loss: 0.599 
(epoch: 25, iters: 368, time: 0.105, data: 0.000) loss: 0.136 
(epoch: 25, iters: 448, time: 0.105, data: 0.011) loss: 0.071 
(epoch: 25, iters: 528, time: 0.106, data: 0.000) loss: 0.119 
(epoch: 25, iters: 608, time: 0.105, data: 0.000) loss: 0.414 
(epoch: 25, iters: 688, time: 0.105, data: 0.039) loss: 0.210 
(epoch: 25, iters: 768, time: 0.106, data: 0.000) loss: 0.179 
(epoch: 25, iters: 848, time: 0.103, data: 0.011) loss: 0.401 
(epoch: 25, iters: 928, time: 0.107, data: 0.000) loss: 0.038 
(epoch: 25, iters: 1008, time: 0.105, data: 0.011) loss: 0.431 
(epoch: 25, iters: 1088, time: 0.106, data: 0.000) loss: 0.064 
(epoch: 25, iters: 1168, time: 0.105, data: 0.000) loss: 0.097 
(epoch: 25, iters: 1248, time: 0.105, data: 0.039) loss: 0.308 
(epoch: 25, iters: 1328, time: 0.106, data: 0.000) loss: 0.238 
(epoch: 25, iters: 1408, time: 0.103, data: 0.011) loss: 0.235 
(epoch: 25, iters: 1488, time: 0.106, data: 0.000) loss: 0.341 
(epoch: 25, iters: 1568, time: 0.104, data: 0.011) loss: 0.079 
(epoch: 25, iters: 1648, time: 0.105, data: 0.000) loss: 0.041 
(epoch: 25, iters: 1728, time: 0.105, data: 0.000) loss: 0.060 
(epoch: 25, iters: 1808, time: 0.106, data: 0.040) loss: 0.178 
(epoch: 25, iters: 1888, time: 0.107, data: 0.000) loss: 0.332 
(epoch: 25, iters: 1968, time: 0.103, data: 0.012) loss: 0.160 
(epoch: 25, iters: 2048, time: 0.106, data: 0.000) loss: 0.064 
(epoch: 25, iters: 2128, time: 0.105, data: 0.011) loss: 0.050 
(epoch: 25, iters: 2208, time: 0.107, data: 0.000) loss: 0.036 
(epoch: 25, iters: 2288, time: 0.105, data: 0.000) loss: 0.125 
(epoch: 25, iters: 2368, time: 0.105, data: 0.046) loss: 0.143 
(epoch: 25, iters: 2448, time: 0.105, data: 0.000) loss: 0.099 
(epoch: 25, iters: 2528, time: 0.102, data: 0.011) loss: 0.062 
(epoch: 25, iters: 2608, time: 0.105, data: 0.000) loss: 0.066 
(epoch: 25, iters: 2688, time: 0.106, data: 0.011) loss: 0.377 
(epoch: 25, iters: 2768, time: 0.106, data: 0.000) loss: 0.468 
(epoch: 25, iters: 2848, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 25, iters: 2928, time: 0.106, data: 0.040) loss: 0.115 
(epoch: 25, iters: 3008, time: 0.107, data: 0.000) loss: 0.039 
(epoch: 25, iters: 3088, time: 0.102, data: 0.011) loss: 0.107 
(epoch: 25, iters: 3168, time: 0.105, data: 0.000) loss: 0.063 
(epoch: 25, iters: 3248, time: 0.104, data: 0.011) loss: 0.446 
(epoch: 25, iters: 3328, time: 0.107, data: 0.000) loss: 0.049 
(epoch: 25, iters: 3408, time: 0.104, data: 0.000) loss: 0.048 
(epoch: 25, iters: 3488, time: 0.105, data: 0.047) loss: 0.110 
(epoch: 25, iters: 3568, time: 0.107, data: 0.000) loss: 0.189 
(epoch: 25, iters: 3648, time: 0.099, data: 0.012) loss: 0.075 
(epoch: 25, iters: 3728, time: 0.066, data: 0.000) loss: 0.055 
saving the model at the end of epoch 25, iters 93200
End of epoch 25 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 25, TEST ACC: [92.716 %]

saving the latest model (epoch 26, total_steps 93216)
(epoch: 26, iters: 80, time: 0.104, data: 0.582) loss: 0.064 
(epoch: 26, iters: 160, time: 0.105, data: 0.000) loss: 0.053 
(epoch: 26, iters: 240, time: 0.104, data: 0.011) loss: 0.135 
(epoch: 26, iters: 320, time: 0.106, data: 0.000) loss: 0.115 
(epoch: 26, iters: 400, time: 0.105, data: 0.000) loss: 0.030 
(epoch: 26, iters: 480, time: 0.105, data: 0.039) loss: 0.025 
(epoch: 26, iters: 560, time: 0.107, data: 0.000) loss: 0.218 
(epoch: 26, iters: 640, time: 0.103, data: 0.011) loss: 0.075 
(epoch: 26, iters: 720, time: 0.105, data: 0.000) loss: 0.316 
(epoch: 26, iters: 800, time: 0.106, data: 0.011) loss: 0.076 
(epoch: 26, iters: 880, time: 0.107, data: 0.000) loss: 0.290 
(epoch: 26, iters: 960, time: 0.105, data: 0.000) loss: 0.105 
(epoch: 26, iters: 1040, time: 0.106, data: 0.039) loss: 0.146 
(epoch: 26, iters: 1120, time: 0.107, data: 0.000) loss: 0.262 
(epoch: 26, iters: 1200, time: 0.104, data: 0.012) loss: 0.071 
(epoch: 26, iters: 1280, time: 0.106, data: 0.000) loss: 0.062 
(epoch: 26, iters: 1360, time: 0.105, data: 0.011) loss: 0.281 
(epoch: 26, iters: 1440, time: 0.106, data: 0.000) loss: 0.215 
(epoch: 26, iters: 1520, time: 0.105, data: 0.000) loss: 0.083 
(epoch: 26, iters: 1600, time: 0.104, data: 0.047) loss: 0.016 
(epoch: 26, iters: 1680, time: 0.105, data: 0.000) loss: 0.187 
(epoch: 26, iters: 1760, time: 0.105, data: 0.011) loss: 0.092 
(epoch: 26, iters: 1840, time: 0.106, data: 0.000) loss: 0.065 
(epoch: 26, iters: 1920, time: 0.105, data: 0.011) loss: 0.183 
(epoch: 26, iters: 2000, time: 0.105, data: 0.000) loss: 0.153 
(epoch: 26, iters: 2080, time: 0.104, data: 0.000) loss: 0.383 
(epoch: 26, iters: 2160, time: 0.106, data: 0.038) loss: 0.109 
(epoch: 26, iters: 2240, time: 0.107, data: 0.000) loss: 0.076 
(epoch: 26, iters: 2320, time: 0.103, data: 0.012) loss: 0.059 
(epoch: 26, iters: 2400, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 26, iters: 2480, time: 0.105, data: 0.011) loss: 0.367 
(epoch: 26, iters: 2560, time: 0.106, data: 0.000) loss: 0.020 
(epoch: 26, iters: 2640, time: 0.105, data: 0.000) loss: 0.032 
(epoch: 26, iters: 2720, time: 0.105, data: 0.038) loss: 0.114 
(epoch: 26, iters: 2800, time: 0.107, data: 0.000) loss: 0.078 
(epoch: 26, iters: 2880, time: 0.103, data: 0.012) loss: 0.121 
(epoch: 26, iters: 2960, time: 0.105, data: 0.000) loss: 0.036 
(epoch: 26, iters: 3040, time: 0.103, data: 0.011) loss: 0.274 
(epoch: 26, iters: 3120, time: 0.106, data: 0.000) loss: 0.093 
(epoch: 26, iters: 3200, time: 0.105, data: 0.000) loss: 0.073 
(epoch: 26, iters: 3280, time: 0.105, data: 0.039) loss: 0.208 
(epoch: 26, iters: 3360, time: 0.106, data: 0.000) loss: 0.142 
(epoch: 26, iters: 3440, time: 0.103, data: 0.011) loss: 0.047 
(epoch: 26, iters: 3520, time: 0.105, data: 0.000) loss: 0.212 
(epoch: 26, iters: 3600, time: 0.104, data: 0.011) loss: 0.190 
(epoch: 26, iters: 3680, time: 0.098, data: 0.000) loss: 0.139 
saving the model at the end of epoch 26, iters 96928
End of epoch 26 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 26, TEST ACC: [81.335 %]

saving the latest model (epoch 27, total_steps 96944)
(epoch: 27, iters: 32, time: 0.099, data: 0.000) loss: 0.097 
(epoch: 27, iters: 112, time: 0.104, data: 0.011) loss: 0.034 
(epoch: 27, iters: 192, time: 0.105, data: 0.000) loss: 0.123 
(epoch: 27, iters: 272, time: 0.104, data: 0.000) loss: 0.047 
(epoch: 27, iters: 352, time: 0.106, data: 0.039) loss: 0.058 
(epoch: 27, iters: 432, time: 0.105, data: 0.000) loss: 0.091 
(epoch: 27, iters: 512, time: 0.103, data: 0.011) loss: 0.028 
(epoch: 27, iters: 592, time: 0.105, data: 0.000) loss: 0.116 
(epoch: 27, iters: 672, time: 0.105, data: 0.012) loss: 0.022 
(epoch: 27, iters: 752, time: 0.106, data: 0.000) loss: 0.047 
(epoch: 27, iters: 832, time: 0.104, data: 0.000) loss: 0.913 
(epoch: 27, iters: 912, time: 0.105, data: 0.038) loss: 0.199 
(epoch: 27, iters: 992, time: 0.106, data: 0.000) loss: 0.022 
(epoch: 27, iters: 1072, time: 0.104, data: 0.012) loss: 0.145 
(epoch: 27, iters: 1152, time: 0.106, data: 0.000) loss: 0.128 
(epoch: 27, iters: 1232, time: 0.104, data: 0.011) loss: 0.073 
(epoch: 27, iters: 1312, time: 0.106, data: 0.000) loss: 0.031 
(epoch: 27, iters: 1392, time: 0.104, data: 0.000) loss: 0.057 
(epoch: 27, iters: 1472, time: 0.106, data: 0.039) loss: 0.040 
(epoch: 27, iters: 1552, time: 0.105, data: 0.000) loss: 0.023 
(epoch: 27, iters: 1632, time: 0.103, data: 0.011) loss: 0.171 
(epoch: 27, iters: 1712, time: 0.105, data: 0.000) loss: 0.076 
(epoch: 27, iters: 1792, time: 0.105, data: 0.011) loss: 0.324 
(epoch: 27, iters: 1872, time: 0.105, data: 0.000) loss: 0.047 
(epoch: 27, iters: 1952, time: 0.104, data: 0.000) loss: 0.182 
(epoch: 27, iters: 2032, time: 0.105, data: 0.039) loss: 0.055 
(epoch: 27, iters: 2112, time: 0.106, data: 0.000) loss: 0.107 
(epoch: 27, iters: 2192, time: 0.104, data: 0.011) loss: 0.192 
(epoch: 27, iters: 2272, time: 0.106, data: 0.000) loss: 0.066 
(epoch: 27, iters: 2352, time: 0.106, data: 0.011) loss: 0.073 
(epoch: 27, iters: 2432, time: 0.107, data: 0.000) loss: 0.109 
(epoch: 27, iters: 2512, time: 0.106, data: 0.000) loss: 0.043 
(epoch: 27, iters: 2592, time: 0.106, data: 0.040) loss: 0.080 
(epoch: 27, iters: 2672, time: 0.108, data: 0.000) loss: 0.089 
(epoch: 27, iters: 2752, time: 0.103, data: 0.012) loss: 0.124 
(epoch: 27, iters: 2832, time: 0.105, data: 0.000) loss: 0.407 
(epoch: 27, iters: 2912, time: 0.104, data: 0.011) loss: 0.012 
(epoch: 27, iters: 2992, time: 0.106, data: 0.000) loss: 0.030 
(epoch: 27, iters: 3072, time: 0.104, data: 0.000) loss: 0.216 
(epoch: 27, iters: 3152, time: 0.106, data: 0.039) loss: 0.120 
(epoch: 27, iters: 3232, time: 0.105, data: 0.000) loss: 0.047 
(epoch: 27, iters: 3312, time: 0.104, data: 0.011) loss: 0.301 
(epoch: 27, iters: 3392, time: 0.105, data: 0.000) loss: 0.050 
(epoch: 27, iters: 3472, time: 0.105, data: 0.011) loss: 0.411 
(epoch: 27, iters: 3552, time: 0.105, data: 0.000) loss: 0.138 
(epoch: 27, iters: 3632, time: 0.103, data: 0.000) loss: 0.108 
(epoch: 27, iters: 3712, time: 0.099, data: 0.035) loss: 0.025 
saving the model at the end of epoch 27, iters 100656
End of epoch 27 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 27, TEST ACC: [89.226 %]

saving the latest model (epoch 28, total_steps 100672)
(epoch: 28, iters: 64, time: 0.105, data: 0.000) loss: 0.030 
(epoch: 28, iters: 144, time: 0.105, data: 0.037) loss: 0.038 
(epoch: 28, iters: 224, time: 0.106, data: 0.000) loss: 0.136 
(epoch: 28, iters: 304, time: 0.103, data: 0.011) loss: 0.014 
(epoch: 28, iters: 384, time: 0.105, data: 0.000) loss: 0.335 
(epoch: 28, iters: 464, time: 0.106, data: 0.011) loss: 0.058 
(epoch: 28, iters: 544, time: 0.106, data: 0.000) loss: 0.083 
(epoch: 28, iters: 624, time: 0.105, data: 0.000) loss: 0.111 
(epoch: 28, iters: 704, time: 0.105, data: 0.039) loss: 0.018 
(epoch: 28, iters: 784, time: 0.106, data: 0.000) loss: 0.064 
(epoch: 28, iters: 864, time: 0.103, data: 0.012) loss: 0.257 
(epoch: 28, iters: 944, time: 0.105, data: 0.000) loss: 0.076 
(epoch: 28, iters: 1024, time: 0.106, data: 0.011) loss: 0.025 
(epoch: 28, iters: 1104, time: 0.105, data: 0.000) loss: 0.035 
(epoch: 28, iters: 1184, time: 0.104, data: 0.000) loss: 0.080 
(epoch: 28, iters: 1264, time: 0.106, data: 0.038) loss: 0.168 
(epoch: 28, iters: 1344, time: 0.106, data: 0.000) loss: 0.033 
(epoch: 28, iters: 1424, time: 0.103, data: 0.011) loss: 0.376 
(epoch: 28, iters: 1504, time: 0.106, data: 0.000) loss: 0.119 
(epoch: 28, iters: 1584, time: 0.104, data: 0.012) loss: 0.102 
(epoch: 28, iters: 1664, time: 0.106, data: 0.000) loss: 0.078 
(epoch: 28, iters: 1744, time: 0.105, data: 0.000) loss: 0.151 
(epoch: 28, iters: 1824, time: 0.105, data: 0.039) loss: 0.009 
(epoch: 28, iters: 1904, time: 0.106, data: 0.000) loss: 0.022 
(epoch: 28, iters: 1984, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 28, iters: 2064, time: 0.105, data: 0.000) loss: 0.127 
(epoch: 28, iters: 2144, time: 0.105, data: 0.011) loss: 0.030 
(epoch: 28, iters: 2224, time: 0.107, data: 0.000) loss: 0.043 
(epoch: 28, iters: 2304, time: 0.105, data: 0.000) loss: 0.022 
(epoch: 28, iters: 2384, time: 0.106, data: 0.048) loss: 0.012 
(epoch: 28, iters: 2464, time: 0.106, data: 0.000) loss: 0.038 
(epoch: 28, iters: 2544, time: 0.104, data: 0.012) loss: 0.073 
(epoch: 28, iters: 2624, time: 0.105, data: 0.000) loss: 0.077 
(epoch: 28, iters: 2704, time: 0.105, data: 0.011) loss: 0.017 
(epoch: 28, iters: 2784, time: 0.106, data: 0.000) loss: 0.279 
(epoch: 28, iters: 2864, time: 0.105, data: 0.000) loss: 0.029 
(epoch: 28, iters: 2944, time: 0.105, data: 0.039) loss: 0.206 
(epoch: 28, iters: 3024, time: 0.106, data: 0.000) loss: 0.101 
(epoch: 28, iters: 3104, time: 0.102, data: 0.011) loss: 0.018 
(epoch: 28, iters: 3184, time: 0.105, data: 0.000) loss: 0.072 
(epoch: 28, iters: 3264, time: 0.105, data: 0.011) loss: 0.098 
(epoch: 28, iters: 3344, time: 0.107, data: 0.000) loss: 0.279 
(epoch: 28, iters: 3424, time: 0.105, data: 0.000) loss: 0.022 
(epoch: 28, iters: 3504, time: 0.106, data: 0.038) loss: 0.021 
(epoch: 28, iters: 3584, time: 0.106, data: 0.000) loss: 0.197 
(epoch: 28, iters: 3664, time: 0.099, data: 0.011) loss: 0.291 
saving the model at the end of epoch 28, iters 104384
End of epoch 28 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 28, TEST ACC: [91.958 %]

(epoch: 29, iters: 16, time: 0.115, data: 0.012) loss: 0.009 
saving the latest model (epoch 29, total_steps 104400)
(epoch: 29, iters: 96, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 29, iters: 176, time: 0.105, data: 0.000) loss: 0.119 
(epoch: 29, iters: 256, time: 0.105, data: 0.012) loss: 0.331 
(epoch: 29, iters: 336, time: 0.105, data: 0.000) loss: 0.117 
(epoch: 29, iters: 416, time: 0.105, data: 0.000) loss: 0.251 
(epoch: 29, iters: 496, time: 0.105, data: 0.038) loss: 0.257 
(epoch: 29, iters: 576, time: 0.107, data: 0.000) loss: 0.133 
(epoch: 29, iters: 656, time: 0.104, data: 0.011) loss: 0.010 
(epoch: 29, iters: 736, time: 0.106, data: 0.000) loss: 0.026 
(epoch: 29, iters: 816, time: 0.104, data: 0.011) loss: 0.057 
(epoch: 29, iters: 896, time: 0.105, data: 0.000) loss: 0.019 
(epoch: 29, iters: 976, time: 0.104, data: 0.000) loss: 0.387 
(epoch: 29, iters: 1056, time: 0.106, data: 0.039) loss: 0.160 
(epoch: 29, iters: 1136, time: 0.106, data: 0.000) loss: 0.023 
(epoch: 29, iters: 1216, time: 0.103, data: 0.012) loss: 0.114 
(epoch: 29, iters: 1296, time: 0.106, data: 0.000) loss: 0.108 
(epoch: 29, iters: 1376, time: 0.104, data: 0.011) loss: 0.034 
(epoch: 29, iters: 1456, time: 0.106, data: 0.000) loss: 0.046 
(epoch: 29, iters: 1536, time: 0.104, data: 0.000) loss: 0.159 
(epoch: 29, iters: 1616, time: 0.105, data: 0.038) loss: 0.063 
(epoch: 29, iters: 1696, time: 0.105, data: 0.000) loss: 0.124 
(epoch: 29, iters: 1776, time: 0.103, data: 0.011) loss: 0.116 
(epoch: 29, iters: 1856, time: 0.106, data: 0.000) loss: 0.104 
(epoch: 29, iters: 1936, time: 0.106, data: 0.012) loss: 0.150 
(epoch: 29, iters: 2016, time: 0.106, data: 0.000) loss: 0.032 
(epoch: 29, iters: 2096, time: 0.105, data: 0.000) loss: 0.027 
(epoch: 29, iters: 2176, time: 0.107, data: 0.040) loss: 0.325 
(epoch: 29, iters: 2256, time: 0.106, data: 0.000) loss: 0.126 
(epoch: 29, iters: 2336, time: 0.104, data: 0.012) loss: 0.519 
(epoch: 29, iters: 2416, time: 0.106, data: 0.000) loss: 0.050 
(epoch: 29, iters: 2496, time: 0.104, data: 0.011) loss: 0.284 
(epoch: 29, iters: 2576, time: 0.105, data: 0.000) loss: 0.040 
(epoch: 29, iters: 2656, time: 0.104, data: 0.000) loss: 0.058 
(epoch: 29, iters: 2736, time: 0.106, data: 0.039) loss: 0.169 
(epoch: 29, iters: 2816, time: 0.105, data: 0.000) loss: 0.086 
(epoch: 29, iters: 2896, time: 0.103, data: 0.011) loss: 0.062 
(epoch: 29, iters: 2976, time: 0.105, data: 0.000) loss: 0.054 
(epoch: 29, iters: 3056, time: 0.106, data: 0.011) loss: 0.071 
(epoch: 29, iters: 3136, time: 0.106, data: 0.000) loss: 0.408 
(epoch: 29, iters: 3216, time: 0.105, data: 0.000) loss: 0.034 
(epoch: 29, iters: 3296, time: 0.105, data: 0.038) loss: 0.065 
(epoch: 29, iters: 3376, time: 0.106, data: 0.000) loss: 0.071 
(epoch: 29, iters: 3456, time: 0.104, data: 0.012) loss: 0.120 
(epoch: 29, iters: 3536, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 29, iters: 3616, time: 0.103, data: 0.011) loss: 0.512 
(epoch: 29, iters: 3696, time: 0.099, data: 0.000) loss: 0.026 
saving the model at the end of epoch 29, iters 108112
End of epoch 29 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 29, TEST ACC: [86.798 %]

saving the latest model (epoch 30, total_steps 108128)
(epoch: 30, iters: 48, time: 0.106, data: 0.000) loss: 0.022 
(epoch: 30, iters: 128, time: 0.106, data: 0.042) loss: 0.044 
(epoch: 30, iters: 208, time: 0.106, data: 0.000) loss: 0.255 
(epoch: 30, iters: 288, time: 0.103, data: 0.012) loss: 0.006 
(epoch: 30, iters: 368, time: 0.105, data: 0.000) loss: 0.092 
(epoch: 30, iters: 448, time: 0.104, data: 0.012) loss: 0.019 
(epoch: 30, iters: 528, time: 0.106, data: 0.000) loss: 0.036 
(epoch: 30, iters: 608, time: 0.104, data: 0.000) loss: 0.027 
(epoch: 30, iters: 688, time: 0.105, data: 0.039) loss: 0.410 
(epoch: 30, iters: 768, time: 0.106, data: 0.000) loss: 0.046 
(epoch: 30, iters: 848, time: 0.102, data: 0.012) loss: 0.215 
(epoch: 30, iters: 928, time: 0.105, data: 0.000) loss: 0.043 
(epoch: 30, iters: 1008, time: 0.104, data: 0.011) loss: 0.072 
(epoch: 30, iters: 1088, time: 0.107, data: 0.000) loss: 0.232 
(epoch: 30, iters: 1168, time: 0.105, data: 0.000) loss: 0.051 
(epoch: 30, iters: 1248, time: 0.104, data: 0.048) loss: 0.225 
(epoch: 30, iters: 1328, time: 0.106, data: 0.000) loss: 0.038 
(epoch: 30, iters: 1408, time: 0.104, data: 0.012) loss: 0.219 
(epoch: 30, iters: 1488, time: 0.106, data: 0.000) loss: 0.029 
(epoch: 30, iters: 1568, time: 0.104, data: 0.011) loss: 0.036 
(epoch: 30, iters: 1648, time: 0.106, data: 0.000) loss: 0.149 
(epoch: 30, iters: 1728, time: 0.105, data: 0.000) loss: 0.069 
(epoch: 30, iters: 1808, time: 0.106, data: 0.038) loss: 0.255 
(epoch: 30, iters: 1888, time: 0.106, data: 0.000) loss: 0.090 
(epoch: 30, iters: 1968, time: 0.104, data: 0.011) loss: 0.063 
(epoch: 30, iters: 2048, time: 0.106, data: 0.000) loss: 0.320 
(epoch: 30, iters: 2128, time: 0.104, data: 0.012) loss: 0.134 
(epoch: 30, iters: 2208, time: 0.106, data: 0.000) loss: 0.183 
(epoch: 30, iters: 2288, time: 0.105, data: 0.000) loss: 0.075 
(epoch: 30, iters: 2368, time: 0.106, data: 0.038) loss: 0.138 
(epoch: 30, iters: 2448, time: 0.106, data: 0.000) loss: 0.095 
(epoch: 30, iters: 2528, time: 0.102, data: 0.011) loss: 0.041 
(epoch: 30, iters: 2608, time: 0.105, data: 0.000) loss: 0.035 
(epoch: 30, iters: 2688, time: 0.104, data: 0.011) loss: 0.175 
(epoch: 30, iters: 2768, time: 0.105, data: 0.000) loss: 0.176 
(epoch: 30, iters: 2848, time: 0.104, data: 0.000) loss: 0.186 
(epoch: 30, iters: 2928, time: 0.106, data: 0.046) loss: 0.047 
(epoch: 30, iters: 3008, time: 0.106, data: 0.000) loss: 0.079 
(epoch: 30, iters: 3088, time: 0.104, data: 0.020) loss: 0.093 
(epoch: 30, iters: 3168, time: 0.106, data: 0.000) loss: 0.025 
(epoch: 30, iters: 3248, time: 0.103, data: 0.012) loss: 0.023 
(epoch: 30, iters: 3328, time: 0.106, data: 0.000) loss: 0.057 
(epoch: 30, iters: 3408, time: 0.104, data: 0.000) loss: 0.096 
(epoch: 30, iters: 3488, time: 0.104, data: 0.038) loss: 0.028 
(epoch: 30, iters: 3568, time: 0.107, data: 0.000) loss: 0.068 
(epoch: 30, iters: 3648, time: 0.098, data: 0.012) loss: 0.090 
(epoch: 30, iters: 3728, time: 0.066, data: 0.000) loss: 0.085 
saving the model at the end of epoch 30, iters 111840
End of epoch 30 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 30, TEST ACC: [84.825 %]

saving the latest model (epoch 31, total_steps 111856)
(epoch: 31, iters: 80, time: 0.106, data: 0.507) loss: 0.102 
(epoch: 31, iters: 160, time: 0.105, data: 0.031) loss: 0.009 
(epoch: 31, iters: 240, time: 0.106, data: 0.000) loss: 0.034 
(epoch: 31, iters: 320, time: 0.102, data: 0.011) loss: 0.182 
(epoch: 31, iters: 400, time: 0.106, data: 0.000) loss: 0.121 
(epoch: 31, iters: 480, time: 0.105, data: 0.011) loss: 0.580 
(epoch: 31, iters: 560, time: 0.107, data: 0.000) loss: 0.224 
(epoch: 31, iters: 640, time: 0.105, data: 0.000) loss: 0.048 
(epoch: 31, iters: 720, time: 0.104, data: 0.048) loss: 0.075 
(epoch: 31, iters: 800, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 31, iters: 880, time: 0.104, data: 0.021) loss: 0.012 
(epoch: 31, iters: 960, time: 0.105, data: 0.000) loss: 0.019 
(epoch: 31, iters: 1040, time: 0.105, data: 0.011) loss: 0.009 
(epoch: 31, iters: 1120, time: 0.106, data: 0.000) loss: 0.067 
(epoch: 31, iters: 1200, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 31, iters: 1280, time: 0.106, data: 0.039) loss: 0.024 
(epoch: 31, iters: 1360, time: 0.105, data: 0.000) loss: 0.306 
(epoch: 31, iters: 1440, time: 0.103, data: 0.011) loss: 0.045 
(epoch: 31, iters: 1520, time: 0.106, data: 0.000) loss: 0.446 
(epoch: 31, iters: 1600, time: 0.105, data: 0.011) loss: 0.291 
(epoch: 31, iters: 1680, time: 0.107, data: 0.000) loss: 0.040 
(epoch: 31, iters: 1760, time: 0.105, data: 0.000) loss: 0.073 
(epoch: 31, iters: 1840, time: 0.106, data: 0.038) loss: 0.075 
(epoch: 31, iters: 1920, time: 0.106, data: 0.000) loss: 0.199 
(epoch: 31, iters: 2000, time: 0.104, data: 0.011) loss: 0.262 
(epoch: 31, iters: 2080, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 31, iters: 2160, time: 0.105, data: 0.012) loss: 0.076 
(epoch: 31, iters: 2240, time: 0.106, data: 0.000) loss: 0.138 
(epoch: 31, iters: 2320, time: 0.105, data: 0.000) loss: 0.037 
(epoch: 31, iters: 2400, time: 0.105, data: 0.039) loss: 0.114 
(epoch: 31, iters: 2480, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 31, iters: 2560, time: 0.104, data: 0.012) loss: 0.154 
(epoch: 31, iters: 2640, time: 0.106, data: 0.000) loss: 0.286 
(epoch: 31, iters: 2720, time: 0.104, data: 0.012) loss: 0.306 
(epoch: 31, iters: 2800, time: 0.107, data: 0.000) loss: 0.086 
(epoch: 31, iters: 2880, time: 0.105, data: 0.000) loss: 0.301 
(epoch: 31, iters: 2960, time: 0.107, data: 0.040) loss: 0.035 
(epoch: 31, iters: 3040, time: 0.107, data: 0.000) loss: 0.130 
(epoch: 31, iters: 3120, time: 0.104, data: 0.011) loss: 0.160 
(epoch: 31, iters: 3200, time: 0.105, data: 0.000) loss: 0.225 
(epoch: 31, iters: 3280, time: 0.105, data: 0.011) loss: 0.020 
(epoch: 31, iters: 3360, time: 0.106, data: 0.000) loss: 0.035 
(epoch: 31, iters: 3440, time: 0.105, data: 0.000) loss: 0.038 
(epoch: 31, iters: 3520, time: 0.105, data: 0.039) loss: 0.101 
(epoch: 31, iters: 3600, time: 0.106, data: 0.000) loss: 0.053 
(epoch: 31, iters: 3680, time: 0.100, data: 0.011) loss: 0.174 
saving the model at the end of epoch 31, iters 115568
End of epoch 31 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 31, TEST ACC: [86.798 %]

saving the latest model (epoch 32, total_steps 115584)
(epoch: 32, iters: 32, time: 0.099, data: 0.006) loss: 0.267 
(epoch: 32, iters: 112, time: 0.107, data: 0.000) loss: 0.046 
(epoch: 32, iters: 192, time: 0.105, data: 0.000) loss: 0.146 
(epoch: 32, iters: 272, time: 0.106, data: 0.047) loss: 0.224 
(epoch: 32, iters: 352, time: 0.106, data: 0.000) loss: 0.046 
(epoch: 32, iters: 432, time: 0.103, data: 0.012) loss: 0.101 
(epoch: 32, iters: 512, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 32, iters: 592, time: 0.106, data: 0.011) loss: 0.020 
(epoch: 32, iters: 672, time: 0.105, data: 0.000) loss: 0.023 
(epoch: 32, iters: 752, time: 0.105, data: 0.000) loss: 0.044 
(epoch: 32, iters: 832, time: 0.105, data: 0.039) loss: 0.013 
(epoch: 32, iters: 912, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 32, iters: 992, time: 0.103, data: 0.011) loss: 0.054 
(epoch: 32, iters: 1072, time: 0.105, data: 0.000) loss: 0.063 
(epoch: 32, iters: 1152, time: 0.104, data: 0.011) loss: 0.246 
(epoch: 32, iters: 1232, time: 0.105, data: 0.000) loss: 0.092 
(epoch: 32, iters: 1312, time: 0.105, data: 0.000) loss: 0.109 
(epoch: 32, iters: 1392, time: 0.106, data: 0.039) loss: 0.102 
(epoch: 32, iters: 1472, time: 0.106, data: 0.000) loss: 0.148 
(epoch: 32, iters: 1552, time: 0.104, data: 0.012) loss: 0.070 
(epoch: 32, iters: 1632, time: 0.105, data: 0.000) loss: 0.185 
(epoch: 32, iters: 1712, time: 0.105, data: 0.011) loss: 0.026 
(epoch: 32, iters: 1792, time: 0.106, data: 0.000) loss: 0.019 
(epoch: 32, iters: 1872, time: 0.106, data: 0.000) loss: 0.403 
(epoch: 32, iters: 1952, time: 0.105, data: 0.039) loss: 0.029 
(epoch: 32, iters: 2032, time: 0.106, data: 0.000) loss: 0.048 
(epoch: 32, iters: 2112, time: 0.103, data: 0.011) loss: 0.062 
(epoch: 32, iters: 2192, time: 0.105, data: 0.000) loss: 0.261 
(epoch: 32, iters: 2272, time: 0.105, data: 0.012) loss: 0.010 
(epoch: 32, iters: 2352, time: 0.106, data: 0.000) loss: 0.541 
(epoch: 32, iters: 2432, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 32, iters: 2512, time: 0.105, data: 0.040) loss: 0.313 
(epoch: 32, iters: 2592, time: 0.106, data: 0.000) loss: 0.071 
(epoch: 32, iters: 2672, time: 0.102, data: 0.011) loss: 0.241 
(epoch: 32, iters: 2752, time: 0.106, data: 0.000) loss: 0.018 
(epoch: 32, iters: 2832, time: 0.105, data: 0.012) loss: 0.029 
(epoch: 32, iters: 2912, time: 0.107, data: 0.000) loss: 0.033 
(epoch: 32, iters: 2992, time: 0.105, data: 0.000) loss: 0.113 
(epoch: 32, iters: 3072, time: 0.106, data: 0.048) loss: 0.084 
(epoch: 32, iters: 3152, time: 0.107, data: 0.000) loss: 0.095 
(epoch: 32, iters: 3232, time: 0.103, data: 0.021) loss: 0.094 
(epoch: 32, iters: 3312, time: 0.105, data: 0.000) loss: 0.101 
(epoch: 32, iters: 3392, time: 0.104, data: 0.011) loss: 0.013 
(epoch: 32, iters: 3472, time: 0.106, data: 0.000) loss: 0.416 
(epoch: 32, iters: 3552, time: 0.104, data: 0.000) loss: 0.371 
(epoch: 32, iters: 3632, time: 0.103, data: 0.039) loss: 0.333 
(epoch: 32, iters: 3712, time: 0.102, data: 0.000) loss: 0.179 
saving the model at the end of epoch 32, iters 119296
End of epoch 32 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 32, TEST ACC: [83.612 %]

saving the latest model (epoch 33, total_steps 119312)
(epoch: 33, iters: 64, time: 0.103, data: 0.000) loss: 0.089 
(epoch: 33, iters: 144, time: 0.106, data: 0.026) loss: 0.063 
(epoch: 33, iters: 224, time: 0.106, data: 0.000) loss: 0.036 
(epoch: 33, iters: 304, time: 0.103, data: 0.012) loss: 0.026 
(epoch: 33, iters: 384, time: 0.107, data: 0.000) loss: 0.084 
(epoch: 33, iters: 464, time: 0.105, data: 0.011) loss: 0.141 
(epoch: 33, iters: 544, time: 0.106, data: 0.000) loss: 0.037 
(epoch: 33, iters: 624, time: 0.104, data: 0.000) loss: 0.018 
(epoch: 33, iters: 704, time: 0.105, data: 0.048) loss: 0.036 
(epoch: 33, iters: 784, time: 0.105, data: 0.000) loss: 0.337 
(epoch: 33, iters: 864, time: 0.102, data: 0.011) loss: 0.021 
(epoch: 33, iters: 944, time: 0.105, data: 0.000) loss: 0.032 
(epoch: 33, iters: 1024, time: 0.105, data: 0.011) loss: 0.050 
(epoch: 33, iters: 1104, time: 0.107, data: 0.000) loss: 0.040 
(epoch: 33, iters: 1184, time: 0.105, data: 0.000) loss: 0.032 
(epoch: 33, iters: 1264, time: 0.104, data: 0.038) loss: 0.027 
(epoch: 33, iters: 1344, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 33, iters: 1424, time: 0.104, data: 0.012) loss: 0.078 
(epoch: 33, iters: 1504, time: 0.105, data: 0.000) loss: 0.037 
(epoch: 33, iters: 1584, time: 0.104, data: 0.012) loss: 0.005 
(epoch: 33, iters: 1664, time: 0.106, data: 0.000) loss: 0.048 
(epoch: 33, iters: 1744, time: 0.105, data: 0.000) loss: 0.072 
(epoch: 33, iters: 1824, time: 0.106, data: 0.038) loss: 0.071 
(epoch: 33, iters: 1904, time: 0.106, data: 0.000) loss: 0.112 
(epoch: 33, iters: 1984, time: 0.102, data: 0.012) loss: 0.032 
(epoch: 33, iters: 2064, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 33, iters: 2144, time: 0.105, data: 0.012) loss: 0.195 
(epoch: 33, iters: 2224, time: 0.106, data: 0.000) loss: 0.063 
(epoch: 33, iters: 2304, time: 0.106, data: 0.000) loss: 0.103 
(epoch: 33, iters: 2384, time: 0.107, data: 0.039) loss: 0.024 
(epoch: 33, iters: 2464, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 33, iters: 2544, time: 0.105, data: 0.012) loss: 0.042 
(epoch: 33, iters: 2624, time: 0.106, data: 0.000) loss: 0.184 
(epoch: 33, iters: 2704, time: 0.106, data: 0.011) loss: 0.050 
(epoch: 33, iters: 2784, time: 0.106, data: 0.000) loss: 0.418 
(epoch: 33, iters: 2864, time: 0.104, data: 0.000) loss: 0.091 
(epoch: 33, iters: 2944, time: 0.107, data: 0.038) loss: 0.074 
(epoch: 33, iters: 3024, time: 0.105, data: 0.000) loss: 0.433 
(epoch: 33, iters: 3104, time: 0.103, data: 0.011) loss: 0.309 
(epoch: 33, iters: 3184, time: 0.105, data: 0.000) loss: 0.042 
(epoch: 33, iters: 3264, time: 0.105, data: 0.011) loss: 0.024 
(epoch: 33, iters: 3344, time: 0.106, data: 0.000) loss: 0.122 
(epoch: 33, iters: 3424, time: 0.105, data: 0.000) loss: 0.220 
(epoch: 33, iters: 3504, time: 0.106, data: 0.039) loss: 0.010 
(epoch: 33, iters: 3584, time: 0.104, data: 0.000) loss: 0.036 
(epoch: 33, iters: 3664, time: 0.100, data: 0.011) loss: 0.009 
saving the model at the end of epoch 33, iters 123024
End of epoch 33 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 33, TEST ACC: [88.316 %]

(epoch: 34, iters: 16, time: 0.119, data: 0.013) loss: 0.045 
saving the latest model (epoch 34, total_steps 123040)
(epoch: 34, iters: 96, time: 0.104, data: 0.012) loss: 0.046 
(epoch: 34, iters: 176, time: 0.105, data: 0.000) loss: 0.259 
(epoch: 34, iters: 256, time: 0.106, data: 0.011) loss: 0.143 
(epoch: 34, iters: 336, time: 0.105, data: 0.000) loss: 0.020 
(epoch: 34, iters: 416, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 34, iters: 496, time: 0.104, data: 0.038) loss: 0.099 
(epoch: 34, iters: 576, time: 0.106, data: 0.000) loss: 0.037 
(epoch: 34, iters: 656, time: 0.104, data: 0.012) loss: 0.099 
(epoch: 34, iters: 736, time: 0.106, data: 0.000) loss: 0.015 
(epoch: 34, iters: 816, time: 0.105, data: 0.011) loss: 0.048 
(epoch: 34, iters: 896, time: 0.106, data: 0.000) loss: 0.061 
(epoch: 34, iters: 976, time: 0.104, data: 0.000) loss: 0.151 
(epoch: 34, iters: 1056, time: 0.106, data: 0.038) loss: 0.155 
(epoch: 34, iters: 1136, time: 0.106, data: 0.000) loss: 0.587 
(epoch: 34, iters: 1216, time: 0.103, data: 0.011) loss: 0.103 
(epoch: 34, iters: 1296, time: 0.105, data: 0.000) loss: 0.068 
(epoch: 34, iters: 1376, time: 0.104, data: 0.011) loss: 0.044 
(epoch: 34, iters: 1456, time: 0.106, data: 0.000) loss: 0.045 
(epoch: 34, iters: 1536, time: 0.105, data: 0.000) loss: 0.024 
(epoch: 34, iters: 1616, time: 0.106, data: 0.040) loss: 0.022 
(epoch: 34, iters: 1696, time: 0.106, data: 0.000) loss: 0.073 
(epoch: 34, iters: 1776, time: 0.104, data: 0.011) loss: 0.067 
(epoch: 34, iters: 1856, time: 0.107, data: 0.000) loss: 0.019 
(epoch: 34, iters: 1936, time: 0.106, data: 0.011) loss: 0.162 
(epoch: 34, iters: 2016, time: 0.107, data: 0.000) loss: 0.011 
(epoch: 34, iters: 2096, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 34, iters: 2176, time: 0.106, data: 0.047) loss: 0.038 
(epoch: 34, iters: 2256, time: 0.106, data: 0.000) loss: 0.022 
(epoch: 34, iters: 2336, time: 0.104, data: 0.021) loss: 0.015 
(epoch: 34, iters: 2416, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 34, iters: 2496, time: 0.105, data: 0.011) loss: 0.270 
(epoch: 34, iters: 2576, time: 0.105, data: 0.000) loss: 0.107 
(epoch: 34, iters: 2656, time: 0.104, data: 0.000) loss: 0.106 
(epoch: 34, iters: 2736, time: 0.106, data: 0.038) loss: 0.088 
(epoch: 34, iters: 2816, time: 0.106, data: 0.000) loss: 0.085 
(epoch: 34, iters: 2896, time: 0.104, data: 0.011) loss: 0.162 
(epoch: 34, iters: 2976, time: 0.105, data: 0.000) loss: 0.063 
(epoch: 34, iters: 3056, time: 0.104, data: 0.011) loss: 0.021 
(epoch: 34, iters: 3136, time: 0.107, data: 0.000) loss: 0.146 
(epoch: 34, iters: 3216, time: 0.105, data: 0.000) loss: 0.202 
(epoch: 34, iters: 3296, time: 0.105, data: 0.038) loss: 0.038 
(epoch: 34, iters: 3376, time: 0.107, data: 0.000) loss: 0.020 
(epoch: 34, iters: 3456, time: 0.103, data: 0.011) loss: 0.069 
(epoch: 34, iters: 3536, time: 0.106, data: 0.000) loss: 0.180 
(epoch: 34, iters: 3616, time: 0.105, data: 0.012) loss: 0.017 
(epoch: 34, iters: 3696, time: 0.100, data: 0.000) loss: 0.090 
saving the model at the end of epoch 34, iters 126752
End of epoch 34 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 34, TEST ACC: [79.059 %]

saving the latest model (epoch 35, total_steps 126768)
(epoch: 35, iters: 48, time: 0.106, data: 0.000) loss: 0.226 
(epoch: 35, iters: 128, time: 0.105, data: 0.026) loss: 0.082 
(epoch: 35, iters: 208, time: 0.106, data: 0.000) loss: 0.418 
(epoch: 35, iters: 288, time: 0.105, data: 0.011) loss: 0.255 
(epoch: 35, iters: 368, time: 0.105, data: 0.000) loss: 0.053 
(epoch: 35, iters: 448, time: 0.104, data: 0.011) loss: 0.172 
(epoch: 35, iters: 528, time: 0.107, data: 0.000) loss: 0.029 
(epoch: 35, iters: 608, time: 0.105, data: 0.000) loss: 0.110 
(epoch: 35, iters: 688, time: 0.106, data: 0.039) loss: 0.036 
(epoch: 35, iters: 768, time: 0.106, data: 0.000) loss: 0.294 
(epoch: 35, iters: 848, time: 0.103, data: 0.011) loss: 0.166 
(epoch: 35, iters: 928, time: 0.106, data: 0.000) loss: 0.129 
(epoch: 35, iters: 1008, time: 0.104, data: 0.011) loss: 0.188 
(epoch: 35, iters: 1088, time: 0.106, data: 0.000) loss: 0.131 
(epoch: 35, iters: 1168, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 35, iters: 1248, time: 0.106, data: 0.039) loss: 0.099 
(epoch: 35, iters: 1328, time: 0.105, data: 0.000) loss: 0.338 
(epoch: 35, iters: 1408, time: 0.102, data: 0.012) loss: 0.398 
(epoch: 35, iters: 1488, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 35, iters: 1568, time: 0.106, data: 0.020) loss: 0.303 
(epoch: 35, iters: 1648, time: 0.107, data: 0.000) loss: 0.044 
(epoch: 35, iters: 1728, time: 0.104, data: 0.000) loss: 0.286 
(epoch: 35, iters: 1808, time: 0.107, data: 0.048) loss: 0.830 
(epoch: 35, iters: 1888, time: 0.106, data: 0.000) loss: 0.118 
(epoch: 35, iters: 1968, time: 0.104, data: 0.011) loss: 0.026 
(epoch: 35, iters: 2048, time: 0.105, data: 0.000) loss: 0.024 
(epoch: 35, iters: 2128, time: 0.105, data: 0.011) loss: 0.058 
(epoch: 35, iters: 2208, time: 0.107, data: 0.000) loss: 0.271 
(epoch: 35, iters: 2288, time: 0.104, data: 0.000) loss: 0.017 
(epoch: 35, iters: 2368, time: 0.106, data: 0.038) loss: 0.012 
(epoch: 35, iters: 2448, time: 0.106, data: 0.000) loss: 0.057 
(epoch: 35, iters: 2528, time: 0.104, data: 0.011) loss: 0.019 
(epoch: 35, iters: 2608, time: 0.105, data: 0.000) loss: 0.050 
(epoch: 35, iters: 2688, time: 0.104, data: 0.011) loss: 0.009 
(epoch: 35, iters: 2768, time: 0.105, data: 0.000) loss: 0.025 
(epoch: 35, iters: 2848, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 35, iters: 2928, time: 0.105, data: 0.038) loss: 0.170 
(epoch: 35, iters: 3008, time: 0.106, data: 0.000) loss: 0.029 
(epoch: 35, iters: 3088, time: 0.103, data: 0.011) loss: 0.017 
(epoch: 35, iters: 3168, time: 0.105, data: 0.000) loss: 0.059 
(epoch: 35, iters: 3248, time: 0.104, data: 0.012) loss: 0.037 
(epoch: 35, iters: 3328, time: 0.106, data: 0.000) loss: 0.025 
(epoch: 35, iters: 3408, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 35, iters: 3488, time: 0.105, data: 0.039) loss: 0.018 
(epoch: 35, iters: 3568, time: 0.105, data: 0.000) loss: 0.222 
(epoch: 35, iters: 3648, time: 0.097, data: 0.011) loss: 0.034 
(epoch: 35, iters: 3728, time: 0.066, data: 0.000) loss: 0.562 
saving the model at the end of epoch 35, iters 130480
End of epoch 35 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 35, TEST ACC: [90.44 %]

saving the latest model (epoch 36, total_steps 130496)
(epoch: 36, iters: 80, time: 0.106, data: 0.488) loss: 0.012 
(epoch: 36, iters: 160, time: 0.105, data: 0.000) loss: 0.081 
(epoch: 36, iters: 240, time: 0.106, data: 0.040) loss: 0.013 
(epoch: 36, iters: 320, time: 0.106, data: 0.000) loss: 0.098 
(epoch: 36, iters: 400, time: 0.103, data: 0.011) loss: 0.088 
(epoch: 36, iters: 480, time: 0.104, data: 0.000) loss: 0.039 
(epoch: 36, iters: 560, time: 0.104, data: 0.012) loss: 0.079 
(epoch: 36, iters: 640, time: 0.107, data: 0.000) loss: 0.023 
(epoch: 36, iters: 720, time: 0.104, data: 0.000) loss: 0.053 
(epoch: 36, iters: 800, time: 0.105, data: 0.038) loss: 0.048 
(epoch: 36, iters: 880, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 36, iters: 960, time: 0.103, data: 0.012) loss: 0.168 
(epoch: 36, iters: 1040, time: 0.105, data: 0.000) loss: 0.244 
(epoch: 36, iters: 1120, time: 0.105, data: 0.011) loss: 0.032 
(epoch: 36, iters: 1200, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 36, iters: 1280, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 36, iters: 1360, time: 0.105, data: 0.039) loss: 0.141 
(epoch: 36, iters: 1440, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 36, iters: 1520, time: 0.103, data: 0.011) loss: 0.017 
(epoch: 36, iters: 1600, time: 0.105, data: 0.000) loss: 0.189 
(epoch: 36, iters: 1680, time: 0.104, data: 0.011) loss: 0.008 
(epoch: 36, iters: 1760, time: 0.105, data: 0.000) loss: 0.094 
(epoch: 36, iters: 1840, time: 0.104, data: 0.000) loss: 0.060 
(epoch: 36, iters: 1920, time: 0.105, data: 0.038) loss: 0.043 
(epoch: 36, iters: 2000, time: 0.106, data: 0.000) loss: 0.015 
(epoch: 36, iters: 2080, time: 0.103, data: 0.011) loss: 0.045 
(epoch: 36, iters: 2160, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 36, iters: 2240, time: 0.103, data: 0.011) loss: 0.021 
(epoch: 36, iters: 2320, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 36, iters: 2400, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 36, iters: 2480, time: 0.105, data: 0.038) loss: 0.025 
(epoch: 36, iters: 2560, time: 0.105, data: 0.000) loss: 0.024 
(epoch: 36, iters: 2640, time: 0.103, data: 0.012) loss: 0.008 
(epoch: 36, iters: 2720, time: 0.105, data: 0.000) loss: 0.033 
(epoch: 36, iters: 2800, time: 0.104, data: 0.012) loss: 0.016 
(epoch: 36, iters: 2880, time: 0.106, data: 0.000) loss: 0.124 
(epoch: 36, iters: 2960, time: 0.103, data: 0.000) loss: 0.020 
(epoch: 36, iters: 3040, time: 0.106, data: 0.039) loss: 0.107 
(epoch: 36, iters: 3120, time: 0.105, data: 0.000) loss: 0.046 
(epoch: 36, iters: 3200, time: 0.101, data: 0.011) loss: 0.057 
(epoch: 36, iters: 3280, time: 0.106, data: 0.000) loss: 0.022 
(epoch: 36, iters: 3360, time: 0.105, data: 0.012) loss: 0.138 
(epoch: 36, iters: 3440, time: 0.105, data: 0.000) loss: 0.248 
(epoch: 36, iters: 3520, time: 0.104, data: 0.000) loss: 0.145 
(epoch: 36, iters: 3600, time: 0.104, data: 0.046) loss: 0.019 
(epoch: 36, iters: 3680, time: 0.100, data: 0.000) loss: 0.174 
saving the model at the end of epoch 36, iters 134208
End of epoch 36 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 36, TEST ACC: [93.171 %]

saving the latest model (epoch 37, total_steps 134224)
(epoch: 37, iters: 32, time: 0.100, data: 0.004) loss: 0.013 
(epoch: 37, iters: 112, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 37, iters: 192, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 37, iters: 272, time: 0.104, data: 0.000) loss: 0.020 
(epoch: 37, iters: 352, time: 0.105, data: 0.040) loss: 0.005 
(epoch: 37, iters: 432, time: 0.106, data: 0.000) loss: 0.068 
(epoch: 37, iters: 512, time: 0.102, data: 0.011) loss: 0.014 
(epoch: 37, iters: 592, time: 0.106, data: 0.000) loss: 0.052 
(epoch: 37, iters: 672, time: 0.105, data: 0.012) loss: 0.038 
(epoch: 37, iters: 752, time: 0.107, data: 0.000) loss: 0.196 
(epoch: 37, iters: 832, time: 0.104, data: 0.000) loss: 0.189 
(epoch: 37, iters: 912, time: 0.105, data: 0.048) loss: 0.079 
(epoch: 37, iters: 992, time: 0.106, data: 0.000) loss: 0.045 
(epoch: 37, iters: 1072, time: 0.102, data: 0.012) loss: 0.096 
(epoch: 37, iters: 1152, time: 0.107, data: 0.000) loss: 0.014 
(epoch: 37, iters: 1232, time: 0.104, data: 0.012) loss: 0.147 
(epoch: 37, iters: 1312, time: 0.106, data: 0.000) loss: 0.015 
(epoch: 37, iters: 1392, time: 0.104, data: 0.000) loss: 0.027 
(epoch: 37, iters: 1472, time: 0.105, data: 0.039) loss: 0.007 
(epoch: 37, iters: 1552, time: 0.107, data: 0.000) loss: 0.044 
(epoch: 37, iters: 1632, time: 0.103, data: 0.011) loss: 0.292 
(epoch: 37, iters: 1712, time: 0.104, data: 0.000) loss: 0.047 
(epoch: 37, iters: 1792, time: 0.103, data: 0.011) loss: 0.063 
(epoch: 37, iters: 1872, time: 0.105, data: 0.000) loss: 0.043 
(epoch: 37, iters: 1952, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 37, iters: 2032, time: 0.105, data: 0.038) loss: 0.046 
(epoch: 37, iters: 2112, time: 0.105, data: 0.000) loss: 0.273 
(epoch: 37, iters: 2192, time: 0.103, data: 0.011) loss: 0.241 
(epoch: 37, iters: 2272, time: 0.105, data: 0.000) loss: 0.195 
(epoch: 37, iters: 2352, time: 0.105, data: 0.011) loss: 0.145 
(epoch: 37, iters: 2432, time: 0.105, data: 0.000) loss: 0.197 
(epoch: 37, iters: 2512, time: 0.104, data: 0.000) loss: 0.050 
(epoch: 37, iters: 2592, time: 0.106, data: 0.039) loss: 0.024 
(epoch: 37, iters: 2672, time: 0.106, data: 0.000) loss: 0.228 
(epoch: 37, iters: 2752, time: 0.103, data: 0.011) loss: 0.045 
(epoch: 37, iters: 2832, time: 0.105, data: 0.000) loss: 0.018 
(epoch: 37, iters: 2912, time: 0.105, data: 0.011) loss: 0.015 
(epoch: 37, iters: 2992, time: 0.105, data: 0.000) loss: 0.024 
(epoch: 37, iters: 3072, time: 0.104, data: 0.000) loss: 0.039 
(epoch: 37, iters: 3152, time: 0.105, data: 0.039) loss: 0.133 
(epoch: 37, iters: 3232, time: 0.105, data: 0.000) loss: 0.041 
(epoch: 37, iters: 3312, time: 0.104, data: 0.012) loss: 0.023 
(epoch: 37, iters: 3392, time: 0.106, data: 0.000) loss: 0.160 
(epoch: 37, iters: 3472, time: 0.106, data: 0.011) loss: 0.013 
(epoch: 37, iters: 3552, time: 0.106, data: 0.000) loss: 0.023 
(epoch: 37, iters: 3632, time: 0.102, data: 0.000) loss: 0.057 
(epoch: 37, iters: 3712, time: 0.101, data: 0.035) loss: 0.007 
saving the model at the end of epoch 37, iters 137936
End of epoch 37 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 37, TEST ACC: [94.234 %]

saving the latest model (epoch 38, total_steps 137952)
(epoch: 38, iters: 64, time: 0.105, data: 0.000) loss: 0.132 
(epoch: 38, iters: 144, time: 0.103, data: 0.011) loss: 0.005 
(epoch: 38, iters: 224, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 38, iters: 304, time: 0.105, data: 0.011) loss: 0.006 
(epoch: 38, iters: 384, time: 0.106, data: 0.000) loss: 0.015 
(epoch: 38, iters: 464, time: 0.104, data: 0.000) loss: 0.067 
(epoch: 38, iters: 544, time: 0.104, data: 0.038) loss: 0.115 
(epoch: 38, iters: 624, time: 0.105, data: 0.000) loss: 0.053 
(epoch: 38, iters: 704, time: 0.103, data: 0.012) loss: 0.041 
(epoch: 38, iters: 784, time: 0.106, data: 0.000) loss: 0.114 
(epoch: 38, iters: 864, time: 0.105, data: 0.011) loss: 0.179 
(epoch: 38, iters: 944, time: 0.107, data: 0.000) loss: 0.120 
(epoch: 38, iters: 1024, time: 0.106, data: 0.000) loss: 0.105 
(epoch: 38, iters: 1104, time: 0.106, data: 0.039) loss: 0.100 
(epoch: 38, iters: 1184, time: 0.106, data: 0.000) loss: 0.351 
(epoch: 38, iters: 1264, time: 0.102, data: 0.011) loss: 0.302 
(epoch: 38, iters: 1344, time: 0.105, data: 0.000) loss: 0.240 
(epoch: 38, iters: 1424, time: 0.105, data: 0.020) loss: 0.229 
(epoch: 38, iters: 1504, time: 0.106, data: 0.000) loss: 0.053 
(epoch: 38, iters: 1584, time: 0.104, data: 0.000) loss: 0.046 
(epoch: 38, iters: 1664, time: 0.105, data: 0.048) loss: 0.050 
(epoch: 38, iters: 1744, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 38, iters: 1824, time: 0.102, data: 0.012) loss: 0.094 
(epoch: 38, iters: 1904, time: 0.105, data: 0.000) loss: 0.047 
(epoch: 38, iters: 1984, time: 0.104, data: 0.011) loss: 0.101 
(epoch: 38, iters: 2064, time: 0.106, data: 0.000) loss: 0.043 
(epoch: 38, iters: 2144, time: 0.104, data: 0.000) loss: 0.042 
(epoch: 38, iters: 2224, time: 0.105, data: 0.039) loss: 0.034 
(epoch: 38, iters: 2304, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 38, iters: 2384, time: 0.103, data: 0.011) loss: 0.063 
(epoch: 38, iters: 2464, time: 0.105, data: 0.000) loss: 0.087 
(epoch: 38, iters: 2544, time: 0.104, data: 0.011) loss: 0.267 
(epoch: 38, iters: 2624, time: 0.106, data: 0.000) loss: 0.110 
(epoch: 38, iters: 2704, time: 0.105, data: 0.000) loss: 0.051 
(epoch: 38, iters: 2784, time: 0.106, data: 0.039) loss: 0.072 
(epoch: 38, iters: 2864, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 38, iters: 2944, time: 0.104, data: 0.011) loss: 0.098 
(epoch: 38, iters: 3024, time: 0.106, data: 0.000) loss: 0.214 
(epoch: 38, iters: 3104, time: 0.104, data: 0.011) loss: 0.109 
(epoch: 38, iters: 3184, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 38, iters: 3264, time: 0.104, data: 0.000) loss: 0.107 
(epoch: 38, iters: 3344, time: 0.104, data: 0.038) loss: 0.066 
(epoch: 38, iters: 3424, time: 0.106, data: 0.000) loss: 0.080 
(epoch: 38, iters: 3504, time: 0.104, data: 0.012) loss: 0.088 
(epoch: 38, iters: 3584, time: 0.105, data: 0.000) loss: 0.097 
(epoch: 38, iters: 3664, time: 0.100, data: 0.011) loss: 0.047 
saving the model at the end of epoch 38, iters 141664
End of epoch 38 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 38, TEST ACC: [81.639 %]

(epoch: 39, iters: 16, time: 0.115, data: 0.000) loss: 0.017 
saving the latest model (epoch 39, total_steps 141680)
(epoch: 39, iters: 96, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 39, iters: 176, time: 0.105, data: 0.000) loss: 0.047 
(epoch: 39, iters: 256, time: 0.103, data: 0.011) loss: 0.132 
(epoch: 39, iters: 336, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 39, iters: 416, time: 0.104, data: 0.000) loss: 0.431 
(epoch: 39, iters: 496, time: 0.105, data: 0.040) loss: 0.030 
(epoch: 39, iters: 576, time: 0.106, data: 0.000) loss: 0.150 
(epoch: 39, iters: 656, time: 0.105, data: 0.012) loss: 0.038 
(epoch: 39, iters: 736, time: 0.106, data: 0.000) loss: 0.017 
(epoch: 39, iters: 816, time: 0.105, data: 0.011) loss: 0.131 
(epoch: 39, iters: 896, time: 0.107, data: 0.000) loss: 0.039 
(epoch: 39, iters: 976, time: 0.105, data: 0.000) loss: 0.083 
(epoch: 39, iters: 1056, time: 0.105, data: 0.039) loss: 0.025 
(epoch: 39, iters: 1136, time: 0.106, data: 0.000) loss: 0.135 
(epoch: 39, iters: 1216, time: 0.103, data: 0.012) loss: 0.166 
(epoch: 39, iters: 1296, time: 0.106, data: 0.000) loss: 0.290 
(epoch: 39, iters: 1376, time: 0.105, data: 0.011) loss: 0.113 
(epoch: 39, iters: 1456, time: 0.106, data: 0.000) loss: 0.018 
(epoch: 39, iters: 1536, time: 0.104, data: 0.000) loss: 0.123 
(epoch: 39, iters: 1616, time: 0.105, data: 0.039) loss: 0.097 
(epoch: 39, iters: 1696, time: 0.106, data: 0.000) loss: 0.210 
(epoch: 39, iters: 1776, time: 0.103, data: 0.011) loss: 0.066 
(epoch: 39, iters: 1856, time: 0.107, data: 0.000) loss: 0.295 
(epoch: 39, iters: 1936, time: 0.105, data: 0.011) loss: 0.125 
(epoch: 39, iters: 2016, time: 0.106, data: 0.000) loss: 0.025 
(epoch: 39, iters: 2096, time: 0.104, data: 0.000) loss: 0.024 
(epoch: 39, iters: 2176, time: 0.105, data: 0.047) loss: 0.021 
(epoch: 39, iters: 2256, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 39, iters: 2336, time: 0.103, data: 0.011) loss: 0.226 
(epoch: 39, iters: 2416, time: 0.105, data: 0.000) loss: 0.127 
(epoch: 39, iters: 2496, time: 0.104, data: 0.011) loss: 0.081 
(epoch: 39, iters: 2576, time: 0.106, data: 0.000) loss: 0.173 
(epoch: 39, iters: 2656, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 39, iters: 2736, time: 0.105, data: 0.038) loss: 0.107 
(epoch: 39, iters: 2816, time: 0.105, data: 0.000) loss: 0.037 
(epoch: 39, iters: 2896, time: 0.104, data: 0.011) loss: 0.008 
(epoch: 39, iters: 2976, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 39, iters: 3056, time: 0.105, data: 0.012) loss: 0.238 
(epoch: 39, iters: 3136, time: 0.106, data: 0.000) loss: 0.066 
(epoch: 39, iters: 3216, time: 0.104, data: 0.000) loss: 0.310 
(epoch: 39, iters: 3296, time: 0.105, data: 0.038) loss: 0.018 
(epoch: 39, iters: 3376, time: 0.106, data: 0.000) loss: 0.019 
(epoch: 39, iters: 3456, time: 0.103, data: 0.012) loss: 0.046 
(epoch: 39, iters: 3536, time: 0.106, data: 0.000) loss: 0.270 
(epoch: 39, iters: 3616, time: 0.105, data: 0.012) loss: 0.059 
(epoch: 39, iters: 3696, time: 0.100, data: 0.000) loss: 0.019 
saving the model at the end of epoch 39, iters 145392
End of epoch 39 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 39, TEST ACC: [88.164 %]

saving the latest model (epoch 40, total_steps 145408)
(epoch: 40, iters: 48, time: 0.108, data: 0.000) loss: 0.138 
(epoch: 40, iters: 128, time: 0.105, data: 0.000) loss: 0.122 
(epoch: 40, iters: 208, time: 0.105, data: 0.040) loss: 0.025 
(epoch: 40, iters: 288, time: 0.106, data: 0.000) loss: 0.126 
(epoch: 40, iters: 368, time: 0.102, data: 0.011) loss: 0.014 
(epoch: 40, iters: 448, time: 0.105, data: 0.000) loss: 0.142 
(epoch: 40, iters: 528, time: 0.103, data: 0.012) loss: 0.053 
(epoch: 40, iters: 608, time: 0.106, data: 0.000) loss: 0.067 
(epoch: 40, iters: 688, time: 0.104, data: 0.000) loss: 0.021 
(epoch: 40, iters: 768, time: 0.105, data: 0.047) loss: 0.200 
(epoch: 40, iters: 848, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 40, iters: 928, time: 0.104, data: 0.021) loss: 0.127 
(epoch: 40, iters: 1008, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 40, iters: 1088, time: 0.106, data: 0.011) loss: 0.157 
(epoch: 40, iters: 1168, time: 0.108, data: 0.000) loss: 0.104 
(epoch: 40, iters: 1248, time: 0.105, data: 0.000) loss: 0.099 
(epoch: 40, iters: 1328, time: 0.105, data: 0.038) loss: 1.002 
(epoch: 40, iters: 1408, time: 0.106, data: 0.000) loss: 0.044 
(epoch: 40, iters: 1488, time: 0.103, data: 0.011) loss: 0.076 
(epoch: 40, iters: 1568, time: 0.105, data: 0.000) loss: 0.192 
(epoch: 40, iters: 1648, time: 0.105, data: 0.011) loss: 0.024 
(epoch: 40, iters: 1728, time: 0.106, data: 0.000) loss: 0.090 
(epoch: 40, iters: 1808, time: 0.105, data: 0.000) loss: 0.037 
(epoch: 40, iters: 1888, time: 0.106, data: 0.038) loss: 0.054 
(epoch: 40, iters: 1968, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 40, iters: 2048, time: 0.103, data: 0.011) loss: 0.013 
(epoch: 40, iters: 2128, time: 0.105, data: 0.000) loss: 0.238 
(epoch: 40, iters: 2208, time: 0.104, data: 0.011) loss: 0.038 
(epoch: 40, iters: 2288, time: 0.106, data: 0.000) loss: 0.021 
(epoch: 40, iters: 2368, time: 0.105, data: 0.000) loss: 0.030 
(epoch: 40, iters: 2448, time: 0.105, data: 0.039) loss: 0.026 
(epoch: 40, iters: 2528, time: 0.105, data: 0.000) loss: 0.062 
(epoch: 40, iters: 2608, time: 0.103, data: 0.011) loss: 0.101 
(epoch: 40, iters: 2688, time: 0.106, data: 0.000) loss: 0.144 
(epoch: 40, iters: 2768, time: 0.105, data: 0.011) loss: 0.007 
(epoch: 40, iters: 2848, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 40, iters: 2928, time: 0.106, data: 0.000) loss: 0.077 
(epoch: 40, iters: 3008, time: 0.105, data: 0.048) loss: 0.306 
(epoch: 40, iters: 3088, time: 0.106, data: 0.000) loss: 0.015 
(epoch: 40, iters: 3168, time: 0.103, data: 0.012) loss: 0.021 
(epoch: 40, iters: 3248, time: 0.105, data: 0.000) loss: 0.091 
(epoch: 40, iters: 3328, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 40, iters: 3408, time: 0.106, data: 0.000) loss: 0.029 
(epoch: 40, iters: 3488, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 40, iters: 3568, time: 0.106, data: 0.039) loss: 0.036 
(epoch: 40, iters: 3648, time: 0.100, data: 0.000) loss: 0.005 
(epoch: 40, iters: 3728, time: 0.065, data: 0.012) loss: 0.047 
saving the model at the end of epoch 40, iters 149120
End of epoch 40 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 40, TEST ACC: [93.627 %]

saving the latest model (epoch 41, total_steps 149136)
(epoch: 41, iters: 80, time: 0.105, data: 0.497) loss: 0.018 
(epoch: 41, iters: 160, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 41, iters: 240, time: 0.105, data: 0.011) loss: 0.143 
(epoch: 41, iters: 320, time: 0.107, data: 0.000) loss: 0.106 
(epoch: 41, iters: 400, time: 0.105, data: 0.000) loss: 0.022 
(epoch: 41, iters: 480, time: 0.106, data: 0.039) loss: 0.017 
(epoch: 41, iters: 560, time: 0.105, data: 0.000) loss: 0.132 
(epoch: 41, iters: 640, time: 0.103, data: 0.012) loss: 0.034 
(epoch: 41, iters: 720, time: 0.105, data: 0.000) loss: 0.101 
(epoch: 41, iters: 800, time: 0.104, data: 0.011) loss: 0.017 
(epoch: 41, iters: 880, time: 0.106, data: 0.000) loss: 0.032 
(epoch: 41, iters: 960, time: 0.106, data: 0.000) loss: 0.099 
(epoch: 41, iters: 1040, time: 0.106, data: 0.040) loss: 0.188 
(epoch: 41, iters: 1120, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 41, iters: 1200, time: 0.104, data: 0.011) loss: 0.153 
(epoch: 41, iters: 1280, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 41, iters: 1360, time: 0.104, data: 0.011) loss: 0.023 
(epoch: 41, iters: 1440, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 41, iters: 1520, time: 0.106, data: 0.000) loss: 0.017 
(epoch: 41, iters: 1600, time: 0.106, data: 0.039) loss: 0.035 
(epoch: 41, iters: 1680, time: 0.105, data: 0.000) loss: 0.081 
(epoch: 41, iters: 1760, time: 0.104, data: 0.012) loss: 0.004 
(epoch: 41, iters: 1840, time: 0.107, data: 0.000) loss: 0.007 
(epoch: 41, iters: 1920, time: 0.104, data: 0.011) loss: 0.037 
(epoch: 41, iters: 2000, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 41, iters: 2080, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 41, iters: 2160, time: 0.106, data: 0.039) loss: 0.095 
(epoch: 41, iters: 2240, time: 0.106, data: 0.000) loss: 0.156 
(epoch: 41, iters: 2320, time: 0.104, data: 0.012) loss: 0.072 
(epoch: 41, iters: 2400, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 41, iters: 2480, time: 0.106, data: 0.011) loss: 0.067 
(epoch: 41, iters: 2560, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 41, iters: 2640, time: 0.105, data: 0.000) loss: 0.025 
(epoch: 41, iters: 2720, time: 0.106, data: 0.040) loss: 0.020 
(epoch: 41, iters: 2800, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 41, iters: 2880, time: 0.105, data: 0.012) loss: 0.084 
(epoch: 41, iters: 2960, time: 0.106, data: 0.000) loss: 0.025 
(epoch: 41, iters: 3040, time: 0.105, data: 0.012) loss: 0.038 
(epoch: 41, iters: 3120, time: 0.106, data: 0.000) loss: 0.193 
(epoch: 41, iters: 3200, time: 0.104, data: 0.000) loss: 0.005 
(epoch: 41, iters: 3280, time: 0.105, data: 0.039) loss: 0.364 
(epoch: 41, iters: 3360, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 41, iters: 3440, time: 0.104, data: 0.011) loss: 0.036 
(epoch: 41, iters: 3520, time: 0.107, data: 0.000) loss: 0.250 
(epoch: 41, iters: 3600, time: 0.104, data: 0.011) loss: 0.031 
(epoch: 41, iters: 3680, time: 0.100, data: 0.000) loss: 0.356 
saving the model at the end of epoch 41, iters 152848
End of epoch 41 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 41, TEST ACC: [94.082 %]

saving the latest model (epoch 42, total_steps 152864)
(epoch: 42, iters: 32, time: 0.100, data: 0.000) loss: 0.121 
(epoch: 42, iters: 112, time: 0.105, data: 0.026) loss: 0.018 
(epoch: 42, iters: 192, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 42, iters: 272, time: 0.104, data: 0.000) loss: 0.130 
(epoch: 42, iters: 352, time: 0.105, data: 0.038) loss: 0.215 
(epoch: 42, iters: 432, time: 0.106, data: 0.000) loss: 0.060 
(epoch: 42, iters: 512, time: 0.103, data: 0.011) loss: 0.037 
(epoch: 42, iters: 592, time: 0.106, data: 0.000) loss: 0.095 
(epoch: 42, iters: 672, time: 0.104, data: 0.011) loss: 0.015 
(epoch: 42, iters: 752, time: 0.106, data: 0.000) loss: 0.174 
(epoch: 42, iters: 832, time: 0.104, data: 0.000) loss: 0.424 
(epoch: 42, iters: 912, time: 0.106, data: 0.039) loss: 0.102 
(epoch: 42, iters: 992, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 42, iters: 1072, time: 0.103, data: 0.011) loss: 0.043 
(epoch: 42, iters: 1152, time: 0.107, data: 0.000) loss: 0.057 
(epoch: 42, iters: 1232, time: 0.105, data: 0.011) loss: 0.039 
(epoch: 42, iters: 1312, time: 0.107, data: 0.000) loss: 0.117 
(epoch: 42, iters: 1392, time: 0.104, data: 0.000) loss: 0.012 
(epoch: 42, iters: 1472, time: 0.106, data: 0.047) loss: 0.009 
(epoch: 42, iters: 1552, time: 0.106, data: 0.000) loss: 0.134 
(epoch: 42, iters: 1632, time: 0.103, data: 0.011) loss: 0.007 
(epoch: 42, iters: 1712, time: 0.106, data: 0.000) loss: 0.074 
(epoch: 42, iters: 1792, time: 0.105, data: 0.011) loss: 0.065 
(epoch: 42, iters: 1872, time: 0.106, data: 0.000) loss: 0.022 
(epoch: 42, iters: 1952, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 42, iters: 2032, time: 0.106, data: 0.038) loss: 0.075 
(epoch: 42, iters: 2112, time: 0.106, data: 0.000) loss: 0.114 
(epoch: 42, iters: 2192, time: 0.102, data: 0.011) loss: 0.009 
(epoch: 42, iters: 2272, time: 0.105, data: 0.000) loss: 0.070 
(epoch: 42, iters: 2352, time: 0.104, data: 0.011) loss: 0.025 
(epoch: 42, iters: 2432, time: 0.106, data: 0.000) loss: 0.021 
(epoch: 42, iters: 2512, time: 0.105, data: 0.000) loss: 0.032 
(epoch: 42, iters: 2592, time: 0.105, data: 0.039) loss: 0.014 
(epoch: 42, iters: 2672, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 42, iters: 2752, time: 0.102, data: 0.012) loss: 0.061 
(epoch: 42, iters: 2832, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 42, iters: 2912, time: 0.105, data: 0.011) loss: 0.029 
(epoch: 42, iters: 2992, time: 0.106, data: 0.000) loss: 0.265 
(epoch: 42, iters: 3072, time: 0.104, data: 0.000) loss: 0.037 
(epoch: 42, iters: 3152, time: 0.105, data: 0.047) loss: 0.231 
(epoch: 42, iters: 3232, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 42, iters: 3312, time: 0.103, data: 0.021) loss: 0.011 
(epoch: 42, iters: 3392, time: 0.105, data: 0.000) loss: 0.200 
(epoch: 42, iters: 3472, time: 0.105, data: 0.011) loss: 0.029 
(epoch: 42, iters: 3552, time: 0.106, data: 0.000) loss: 0.017 
(epoch: 42, iters: 3632, time: 0.103, data: 0.000) loss: 0.075 
(epoch: 42, iters: 3712, time: 0.099, data: 0.035) loss: 0.130 
saving the model at the end of epoch 42, iters 156576
End of epoch 42 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 42, TEST ACC: [91.958 %]

saving the latest model (epoch 43, total_steps 156592)
(epoch: 43, iters: 64, time: 0.104, data: 0.000) loss: 0.082 
(epoch: 43, iters: 144, time: 0.105, data: 0.000) loss: 0.060 
(epoch: 43, iters: 224, time: 0.104, data: 0.011) loss: 0.103 
(epoch: 43, iters: 304, time: 0.107, data: 0.000) loss: 0.039 
(epoch: 43, iters: 384, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 43, iters: 464, time: 0.105, data: 0.038) loss: 0.036 
(epoch: 43, iters: 544, time: 0.106, data: 0.000) loss: 0.321 
(epoch: 43, iters: 624, time: 0.104, data: 0.011) loss: 0.042 
(epoch: 43, iters: 704, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 43, iters: 784, time: 0.105, data: 0.012) loss: 0.053 
(epoch: 43, iters: 864, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 43, iters: 944, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 43, iters: 1024, time: 0.106, data: 0.040) loss: 0.019 
(epoch: 43, iters: 1104, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 43, iters: 1184, time: 0.104, data: 0.011) loss: 0.172 
(epoch: 43, iters: 1264, time: 0.105, data: 0.000) loss: 0.032 
(epoch: 43, iters: 1344, time: 0.104, data: 0.011) loss: 0.103 
(epoch: 43, iters: 1424, time: 0.105, data: 0.000) loss: 0.046 
(epoch: 43, iters: 1504, time: 0.105, data: 0.000) loss: 0.018 
(epoch: 43, iters: 1584, time: 0.106, data: 0.038) loss: 0.049 
(epoch: 43, iters: 1664, time: 0.106, data: 0.000) loss: 0.030 
(epoch: 43, iters: 1744, time: 0.105, data: 0.011) loss: 0.058 
(epoch: 43, iters: 1824, time: 0.105, data: 0.000) loss: 0.058 
(epoch: 43, iters: 1904, time: 0.105, data: 0.011) loss: 0.030 
(epoch: 43, iters: 1984, time: 0.106, data: 0.000) loss: 0.123 
(epoch: 43, iters: 2064, time: 0.104, data: 0.000) loss: 0.021 
(epoch: 43, iters: 2144, time: 0.106, data: 0.038) loss: 0.045 
(epoch: 43, iters: 2224, time: 0.106, data: 0.000) loss: 0.127 
(epoch: 43, iters: 2304, time: 0.103, data: 0.012) loss: 0.374 
(epoch: 43, iters: 2384, time: 0.106, data: 0.000) loss: 0.104 
(epoch: 43, iters: 2464, time: 0.104, data: 0.012) loss: 0.063 
(epoch: 43, iters: 2544, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 43, iters: 2624, time: 0.105, data: 0.000) loss: 0.027 
(epoch: 43, iters: 2704, time: 0.105, data: 0.039) loss: 0.235 
(epoch: 43, iters: 2784, time: 0.106, data: 0.000) loss: 0.086 
(epoch: 43, iters: 2864, time: 0.103, data: 0.011) loss: 0.050 
(epoch: 43, iters: 2944, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 43, iters: 3024, time: 0.104, data: 0.011) loss: 0.184 
(epoch: 43, iters: 3104, time: 0.105, data: 0.000) loss: 0.018 
(epoch: 43, iters: 3184, time: 0.104, data: 0.000) loss: 0.026 
(epoch: 43, iters: 3264, time: 0.106, data: 0.039) loss: 0.074 
(epoch: 43, iters: 3344, time: 0.106, data: 0.000) loss: 0.031 
(epoch: 43, iters: 3424, time: 0.103, data: 0.011) loss: 0.156 
(epoch: 43, iters: 3504, time: 0.105, data: 0.000) loss: 0.094 
(epoch: 43, iters: 3584, time: 0.104, data: 0.012) loss: 0.010 
(epoch: 43, iters: 3664, time: 0.100, data: 0.000) loss: 0.105 
saving the model at the end of epoch 43, iters 160304
End of epoch 43 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 43, TEST ACC: [91.502 %]

(epoch: 44, iters: 16, time: 0.116, data: 0.000) loss: 0.012 
saving the latest model (epoch 44, total_steps 160320)
(epoch: 44, iters: 96, time: 0.104, data: 0.012) loss: 0.272 
(epoch: 44, iters: 176, time: 0.105, data: 0.000) loss: 0.109 
(epoch: 44, iters: 256, time: 0.104, data: 0.012) loss: 0.206 
(epoch: 44, iters: 336, time: 0.106, data: 0.000) loss: 0.054 
(epoch: 44, iters: 416, time: 0.104, data: 0.000) loss: 0.089 
(epoch: 44, iters: 496, time: 0.106, data: 0.040) loss: 0.096 
(epoch: 44, iters: 576, time: 0.106, data: 0.000) loss: 0.587 
(epoch: 44, iters: 656, time: 0.104, data: 0.011) loss: 0.073 
(epoch: 44, iters: 736, time: 0.104, data: 0.000) loss: 0.273 
(epoch: 44, iters: 816, time: 0.105, data: 0.011) loss: 0.030 
(epoch: 44, iters: 896, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 44, iters: 976, time: 0.105, data: 0.000) loss: 0.018 
(epoch: 44, iters: 1056, time: 0.104, data: 0.038) loss: 0.035 
(epoch: 44, iters: 1136, time: 0.106, data: 0.000) loss: 0.035 
(epoch: 44, iters: 1216, time: 0.104, data: 0.012) loss: 0.045 
(epoch: 44, iters: 1296, time: 0.106, data: 0.000) loss: 0.118 
(epoch: 44, iters: 1376, time: 0.104, data: 0.012) loss: 0.093 
(epoch: 44, iters: 1456, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 44, iters: 1536, time: 0.104, data: 0.000) loss: 0.174 
(epoch: 44, iters: 1616, time: 0.105, data: 0.039) loss: 0.082 
(epoch: 44, iters: 1696, time: 0.107, data: 0.000) loss: 0.004 
(epoch: 44, iters: 1776, time: 0.103, data: 0.011) loss: 0.006 
(epoch: 44, iters: 1856, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 44, iters: 1936, time: 0.104, data: 0.011) loss: 0.019 
(epoch: 44, iters: 2016, time: 0.105, data: 0.000) loss: 0.033 
(epoch: 44, iters: 2096, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 44, iters: 2176, time: 0.105, data: 0.040) loss: 0.012 
(epoch: 44, iters: 2256, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 44, iters: 2336, time: 0.102, data: 0.012) loss: 0.007 
(epoch: 44, iters: 2416, time: 0.105, data: 0.000) loss: 0.031 
(epoch: 44, iters: 2496, time: 0.105, data: 0.019) loss: 0.175 
(epoch: 44, iters: 2576, time: 0.107, data: 0.000) loss: 0.005 
(epoch: 44, iters: 2656, time: 0.104, data: 0.000) loss: 0.078 
(epoch: 44, iters: 2736, time: 0.105, data: 0.048) loss: 0.013 
(epoch: 44, iters: 2816, time: 0.105, data: 0.000) loss: 0.190 
(epoch: 44, iters: 2896, time: 0.103, data: 0.011) loss: 0.016 
(epoch: 44, iters: 2976, time: 0.106, data: 0.000) loss: 0.085 
(epoch: 44, iters: 3056, time: 0.104, data: 0.011) loss: 0.205 
(epoch: 44, iters: 3136, time: 0.105, data: 0.000) loss: 0.032 
(epoch: 44, iters: 3216, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 44, iters: 3296, time: 0.104, data: 0.038) loss: 0.055 
(epoch: 44, iters: 3376, time: 0.106, data: 0.000) loss: 0.027 
(epoch: 44, iters: 3456, time: 0.104, data: 0.012) loss: 0.007 
(epoch: 44, iters: 3536, time: 0.106, data: 0.000) loss: 0.044 
(epoch: 44, iters: 3616, time: 0.105, data: 0.012) loss: 0.008 
(epoch: 44, iters: 3696, time: 0.099, data: 0.000) loss: 0.170 
saving the model at the end of epoch 44, iters 164032
End of epoch 44 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 44, TEST ACC: [91.199 %]

saving the latest model (epoch 45, total_steps 164048)
(epoch: 45, iters: 48, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 45, iters: 128, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 45, iters: 208, time: 0.106, data: 0.040) loss: 0.059 
(epoch: 45, iters: 288, time: 0.106, data: 0.000) loss: 0.066 
(epoch: 45, iters: 368, time: 0.103, data: 0.012) loss: 0.069 
(epoch: 45, iters: 448, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 45, iters: 528, time: 0.107, data: 0.012) loss: 0.008 
(epoch: 45, iters: 608, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 45, iters: 688, time: 0.105, data: 0.000) loss: 0.119 
(epoch: 45, iters: 768, time: 0.105, data: 0.048) loss: 0.009 
(epoch: 45, iters: 848, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 45, iters: 928, time: 0.103, data: 0.011) loss: 0.085 
(epoch: 45, iters: 1008, time: 0.104, data: 0.000) loss: 0.014 
(epoch: 45, iters: 1088, time: 0.105, data: 0.012) loss: 0.006 
(epoch: 45, iters: 1168, time: 0.108, data: 0.000) loss: 0.056 
(epoch: 45, iters: 1248, time: 0.105, data: 0.000) loss: 0.028 
(epoch: 45, iters: 1328, time: 0.106, data: 0.039) loss: 0.075 
(epoch: 45, iters: 1408, time: 0.105, data: 0.000) loss: 0.096 
(epoch: 45, iters: 1488, time: 0.103, data: 0.011) loss: 0.019 
(epoch: 45, iters: 1568, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 45, iters: 1648, time: 0.105, data: 0.011) loss: 0.019 
(epoch: 45, iters: 1728, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 45, iters: 1808, time: 0.105, data: 0.000) loss: 0.018 
(epoch: 45, iters: 1888, time: 0.105, data: 0.039) loss: 0.024 
(epoch: 45, iters: 1968, time: 0.107, data: 0.000) loss: 0.007 
(epoch: 45, iters: 2048, time: 0.102, data: 0.011) loss: 0.021 
(epoch: 45, iters: 2128, time: 0.107, data: 0.000) loss: 0.037 
(epoch: 45, iters: 2208, time: 0.105, data: 0.011) loss: 0.227 
(epoch: 45, iters: 2288, time: 0.107, data: 0.000) loss: 0.005 
(epoch: 45, iters: 2368, time: 0.104, data: 0.000) loss: 0.192 
(epoch: 45, iters: 2448, time: 0.105, data: 0.047) loss: 0.015 
(epoch: 45, iters: 2528, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 45, iters: 2608, time: 0.103, data: 0.020) loss: 0.115 
(epoch: 45, iters: 2688, time: 0.105, data: 0.000) loss: 0.141 
(epoch: 45, iters: 2768, time: 0.104, data: 0.011) loss: 0.027 
(epoch: 45, iters: 2848, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 45, iters: 2928, time: 0.105, data: 0.000) loss: 0.049 
(epoch: 45, iters: 3008, time: 0.106, data: 0.049) loss: 0.004 
(epoch: 45, iters: 3088, time: 0.106, data: 0.000) loss: 0.210 
(epoch: 45, iters: 3168, time: 0.103, data: 0.011) loss: 0.259 
(epoch: 45, iters: 3248, time: 0.105, data: 0.000) loss: 0.020 
(epoch: 45, iters: 3328, time: 0.104, data: 0.011) loss: 0.025 
(epoch: 45, iters: 3408, time: 0.107, data: 0.000) loss: 0.016 
(epoch: 45, iters: 3488, time: 0.104, data: 0.000) loss: 0.185 
(epoch: 45, iters: 3568, time: 0.105, data: 0.039) loss: 0.272 
(epoch: 45, iters: 3648, time: 0.100, data: 0.000) loss: 0.069 
(epoch: 45, iters: 3728, time: 0.066, data: 0.011) loss: 0.122 
saving the model at the end of epoch 45, iters 167760
End of epoch 45 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 45, TEST ACC: [87.405 %]

saving the latest model (epoch 46, total_steps 167776)
(epoch: 46, iters: 80, time: 0.106, data: 0.516) loss: 0.011 
(epoch: 46, iters: 160, time: 0.105, data: 0.000) loss: 0.181 
(epoch: 46, iters: 240, time: 0.106, data: 0.038) loss: 0.037 
(epoch: 46, iters: 320, time: 0.105, data: 0.000) loss: 0.018 
(epoch: 46, iters: 400, time: 0.105, data: 0.011) loss: 0.096 
(epoch: 46, iters: 480, time: 0.106, data: 0.000) loss: 0.078 
(epoch: 46, iters: 560, time: 0.104, data: 0.011) loss: 0.009 
(epoch: 46, iters: 640, time: 0.106, data: 0.000) loss: 0.042 
(epoch: 46, iters: 720, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 46, iters: 800, time: 0.106, data: 0.039) loss: 0.005 
(epoch: 46, iters: 880, time: 0.107, data: 0.000) loss: 0.037 
(epoch: 46, iters: 960, time: 0.104, data: 0.012) loss: 0.006 
(epoch: 46, iters: 1040, time: 0.106, data: 0.000) loss: 0.032 
(epoch: 46, iters: 1120, time: 0.105, data: 0.012) loss: 0.061 
(epoch: 46, iters: 1200, time: 0.107, data: 0.000) loss: 0.027 
(epoch: 46, iters: 1280, time: 0.105, data: 0.000) loss: 0.085 
(epoch: 46, iters: 1360, time: 0.105, data: 0.048) loss: 0.013 
(epoch: 46, iters: 1440, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 46, iters: 1520, time: 0.104, data: 0.021) loss: 0.017 
(epoch: 46, iters: 1600, time: 0.105, data: 0.000) loss: 0.102 
(epoch: 46, iters: 1680, time: 0.104, data: 0.011) loss: 0.017 
(epoch: 46, iters: 1760, time: 0.106, data: 0.000) loss: 0.024 
(epoch: 46, iters: 1840, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 46, iters: 1920, time: 0.106, data: 0.038) loss: 0.175 
(epoch: 46, iters: 2000, time: 0.105, data: 0.000) loss: 0.022 
(epoch: 46, iters: 2080, time: 0.103, data: 0.011) loss: 0.034 
(epoch: 46, iters: 2160, time: 0.105, data: 0.000) loss: 0.058 
(epoch: 46, iters: 2240, time: 0.105, data: 0.011) loss: 0.078 
(epoch: 46, iters: 2320, time: 0.106, data: 0.000) loss: 0.347 
(epoch: 46, iters: 2400, time: 0.104, data: 0.000) loss: 0.010 
(epoch: 46, iters: 2480, time: 0.105, data: 0.038) loss: 0.016 
(epoch: 46, iters: 2560, time: 0.107, data: 0.000) loss: 0.005 
(epoch: 46, iters: 2640, time: 0.103, data: 0.011) loss: 0.099 
(epoch: 46, iters: 2720, time: 0.105, data: 0.000) loss: 0.035 
(epoch: 46, iters: 2800, time: 0.105, data: 0.012) loss: 0.006 
(epoch: 46, iters: 2880, time: 0.107, data: 0.000) loss: 0.020 
(epoch: 46, iters: 2960, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 46, iters: 3040, time: 0.105, data: 0.039) loss: 0.023 
(epoch: 46, iters: 3120, time: 0.107, data: 0.000) loss: 0.021 
(epoch: 46, iters: 3200, time: 0.105, data: 0.012) loss: 0.007 
(epoch: 46, iters: 3280, time: 0.107, data: 0.000) loss: 0.018 
(epoch: 46, iters: 3360, time: 0.105, data: 0.012) loss: 0.007 
(epoch: 46, iters: 3440, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 46, iters: 3520, time: 0.105, data: 0.000) loss: 0.137 
(epoch: 46, iters: 3600, time: 0.106, data: 0.038) loss: 0.013 
(epoch: 46, iters: 3680, time: 0.100, data: 0.000) loss: 0.120 
saving the model at the end of epoch 46, iters 171488
End of epoch 46 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 46, TEST ACC: [92.261 %]

saving the latest model (epoch 47, total_steps 171504)
(epoch: 47, iters: 32, time: 0.100, data: 0.004) loss: 0.020 
(epoch: 47, iters: 112, time: 0.105, data: 0.027) loss: 0.123 
(epoch: 47, iters: 192, time: 0.107, data: 0.000) loss: 0.012 
(epoch: 47, iters: 272, time: 0.106, data: 0.000) loss: 0.025 
(epoch: 47, iters: 352, time: 0.105, data: 0.048) loss: 0.226 
(epoch: 47, iters: 432, time: 0.106, data: 0.000) loss: 0.031 
(epoch: 47, iters: 512, time: 0.102, data: 0.012) loss: 0.119 
(epoch: 47, iters: 592, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 47, iters: 672, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 47, iters: 752, time: 0.105, data: 0.000) loss: 0.023 
(epoch: 47, iters: 832, time: 0.104, data: 0.000) loss: 0.061 
(epoch: 47, iters: 912, time: 0.105, data: 0.038) loss: 0.115 
(epoch: 47, iters: 992, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 47, iters: 1072, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 47, iters: 1152, time: 0.106, data: 0.000) loss: 0.119 
(epoch: 47, iters: 1232, time: 0.104, data: 0.011) loss: 0.101 
(epoch: 47, iters: 1312, time: 0.106, data: 0.000) loss: 0.024 
(epoch: 47, iters: 1392, time: 0.105, data: 0.000) loss: 0.338 
(epoch: 47, iters: 1472, time: 0.105, data: 0.038) loss: 0.029 
(epoch: 47, iters: 1552, time: 0.105, data: 0.000) loss: 0.036 
(epoch: 47, iters: 1632, time: 0.102, data: 0.011) loss: 0.091 
(epoch: 47, iters: 1712, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 47, iters: 1792, time: 0.103, data: 0.011) loss: 0.035 
(epoch: 47, iters: 1872, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 47, iters: 1952, time: 0.105, data: 0.000) loss: 0.262 
(epoch: 47, iters: 2032, time: 0.105, data: 0.048) loss: 0.029 
(epoch: 47, iters: 2112, time: 0.106, data: 0.000) loss: 0.037 
(epoch: 47, iters: 2192, time: 0.104, data: 0.011) loss: 0.023 
(epoch: 47, iters: 2272, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 47, iters: 2352, time: 0.106, data: 0.011) loss: 0.017 
(epoch: 47, iters: 2432, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 47, iters: 2512, time: 0.104, data: 0.000) loss: 0.014 
(epoch: 47, iters: 2592, time: 0.105, data: 0.038) loss: 0.005 
(epoch: 47, iters: 2672, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 47, iters: 2752, time: 0.102, data: 0.011) loss: 0.007 
(epoch: 47, iters: 2832, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 47, iters: 2912, time: 0.104, data: 0.011) loss: 0.054 
(epoch: 47, iters: 2992, time: 0.105, data: 0.000) loss: 0.028 
(epoch: 47, iters: 3072, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 47, iters: 3152, time: 0.107, data: 0.040) loss: 0.043 
(epoch: 47, iters: 3232, time: 0.107, data: 0.000) loss: 0.007 
(epoch: 47, iters: 3312, time: 0.105, data: 0.012) loss: 0.103 
(epoch: 47, iters: 3392, time: 0.106, data: 0.000) loss: 0.334 
(epoch: 47, iters: 3472, time: 0.105, data: 0.011) loss: 0.052 
(epoch: 47, iters: 3552, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 47, iters: 3632, time: 0.103, data: 0.000) loss: 0.011 
(epoch: 47, iters: 3712, time: 0.100, data: 0.035) loss: 0.005 
saving the model at the end of epoch 47, iters 175216
End of epoch 47 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 47, TEST ACC: [91.958 %]

saving the latest model (epoch 48, total_steps 175232)
(epoch: 48, iters: 64, time: 0.104, data: 0.000) loss: 0.238 
(epoch: 48, iters: 144, time: 0.105, data: 0.000) loss: 0.050 
(epoch: 48, iters: 224, time: 0.105, data: 0.011) loss: 0.007 
(epoch: 48, iters: 304, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 48, iters: 384, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 48, iters: 464, time: 0.106, data: 0.039) loss: 0.005 
(epoch: 48, iters: 544, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 48, iters: 624, time: 0.104, data: 0.011) loss: 0.024 
(epoch: 48, iters: 704, time: 0.105, data: 0.000) loss: 0.032 
(epoch: 48, iters: 784, time: 0.105, data: 0.011) loss: 0.018 
(epoch: 48, iters: 864, time: 0.107, data: 0.000) loss: 0.014 
(epoch: 48, iters: 944, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 48, iters: 1024, time: 0.105, data: 0.038) loss: 0.014 
(epoch: 48, iters: 1104, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 48, iters: 1184, time: 0.102, data: 0.011) loss: 0.006 
(epoch: 48, iters: 1264, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 48, iters: 1344, time: 0.104, data: 0.020) loss: 0.247 
(epoch: 48, iters: 1424, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 48, iters: 1504, time: 0.104, data: 0.000) loss: 0.071 
(epoch: 48, iters: 1584, time: 0.105, data: 0.038) loss: 0.162 
(epoch: 48, iters: 1664, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 48, iters: 1744, time: 0.103, data: 0.011) loss: 0.014 
(epoch: 48, iters: 1824, time: 0.104, data: 0.000) loss: 0.061 
(epoch: 48, iters: 1904, time: 0.104, data: 0.011) loss: 0.120 
(epoch: 48, iters: 1984, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 48, iters: 2064, time: 0.105, data: 0.000) loss: 0.028 
(epoch: 48, iters: 2144, time: 0.104, data: 0.038) loss: 0.441 
(epoch: 48, iters: 2224, time: 0.105, data: 0.000) loss: 0.029 
(epoch: 48, iters: 2304, time: 0.104, data: 0.012) loss: 0.583 
(epoch: 48, iters: 2384, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 48, iters: 2464, time: 0.104, data: 0.012) loss: 0.042 
(epoch: 48, iters: 2544, time: 0.105, data: 0.000) loss: 0.066 
(epoch: 48, iters: 2624, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 48, iters: 2704, time: 0.106, data: 0.040) loss: 0.085 
(epoch: 48, iters: 2784, time: 0.106, data: 0.000) loss: 0.032 
(epoch: 48, iters: 2864, time: 0.104, data: 0.012) loss: 0.249 
(epoch: 48, iters: 2944, time: 0.106, data: 0.000) loss: 0.075 
(epoch: 48, iters: 3024, time: 0.105, data: 0.012) loss: 0.004 
(epoch: 48, iters: 3104, time: 0.105, data: 0.000) loss: 0.117 
(epoch: 48, iters: 3184, time: 0.104, data: 0.000) loss: 0.017 
(epoch: 48, iters: 3264, time: 0.105, data: 0.038) loss: 0.009 
(epoch: 48, iters: 3344, time: 0.105, data: 0.000) loss: 0.083 
(epoch: 48, iters: 3424, time: 0.104, data: 0.011) loss: 0.069 
(epoch: 48, iters: 3504, time: 0.105, data: 0.000) loss: 0.207 
(epoch: 48, iters: 3584, time: 0.105, data: 0.012) loss: 0.003 
(epoch: 48, iters: 3664, time: 0.100, data: 0.000) loss: 0.065 
saving the model at the end of epoch 48, iters 178944
End of epoch 48 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 48, TEST ACC: [95.903 %]

(epoch: 49, iters: 16, time: 0.118, data: 0.000) loss: 0.013 
saving the latest model (epoch 49, total_steps 178960)
(epoch: 49, iters: 96, time: 0.106, data: 0.044) loss: 0.088 
(epoch: 49, iters: 176, time: 0.106, data: 0.000) loss: 0.062 
(epoch: 49, iters: 256, time: 0.102, data: 0.011) loss: 0.061 
(epoch: 49, iters: 336, time: 0.106, data: 0.000) loss: 0.017 
(epoch: 49, iters: 416, time: 0.105, data: 0.011) loss: 0.193 
(epoch: 49, iters: 496, time: 0.106, data: 0.000) loss: 0.037 
(epoch: 49, iters: 576, time: 0.105, data: 0.000) loss: 0.019 
(epoch: 49, iters: 656, time: 0.105, data: 0.048) loss: 0.573 
(epoch: 49, iters: 736, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 49, iters: 816, time: 0.104, data: 0.012) loss: 0.036 
(epoch: 49, iters: 896, time: 0.106, data: 0.000) loss: 0.051 
(epoch: 49, iters: 976, time: 0.104, data: 0.011) loss: 0.307 
(epoch: 49, iters: 1056, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 49, iters: 1136, time: 0.105, data: 0.000) loss: 0.047 
(epoch: 49, iters: 1216, time: 0.105, data: 0.038) loss: 0.021 
(epoch: 49, iters: 1296, time: 0.106, data: 0.000) loss: 0.069 
(epoch: 49, iters: 1376, time: 0.103, data: 0.011) loss: 0.023 
(epoch: 49, iters: 1456, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 49, iters: 1536, time: 0.105, data: 0.011) loss: 0.039 
(epoch: 49, iters: 1616, time: 0.106, data: 0.000) loss: 0.020 
(epoch: 49, iters: 1696, time: 0.106, data: 0.000) loss: 0.134 
(epoch: 49, iters: 1776, time: 0.106, data: 0.039) loss: 0.022 
(epoch: 49, iters: 1856, time: 0.106, data: 0.000) loss: 0.069 
(epoch: 49, iters: 1936, time: 0.104, data: 0.011) loss: 0.077 
(epoch: 49, iters: 2016, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 49, iters: 2096, time: 0.105, data: 0.012) loss: 0.013 
(epoch: 49, iters: 2176, time: 0.107, data: 0.000) loss: 0.006 
(epoch: 49, iters: 2256, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 49, iters: 2336, time: 0.106, data: 0.038) loss: 0.028 
(epoch: 49, iters: 2416, time: 0.105, data: 0.000) loss: 0.070 
(epoch: 49, iters: 2496, time: 0.103, data: 0.011) loss: 0.019 
(epoch: 49, iters: 2576, time: 0.105, data: 0.000) loss: 0.134 
(epoch: 49, iters: 2656, time: 0.105, data: 0.011) loss: 0.132 
(epoch: 49, iters: 2736, time: 0.106, data: 0.000) loss: 0.021 
(epoch: 49, iters: 2816, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 49, iters: 2896, time: 0.105, data: 0.039) loss: 0.117 
(epoch: 49, iters: 2976, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 49, iters: 3056, time: 0.104, data: 0.011) loss: 0.528 
(epoch: 49, iters: 3136, time: 0.107, data: 0.000) loss: 0.084 
(epoch: 49, iters: 3216, time: 0.106, data: 0.012) loss: 0.033 
(epoch: 49, iters: 3296, time: 0.107, data: 0.000) loss: 0.010 
(epoch: 49, iters: 3376, time: 0.105, data: 0.000) loss: 0.072 
(epoch: 49, iters: 3456, time: 0.107, data: 0.048) loss: 0.002 
(epoch: 49, iters: 3536, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 49, iters: 3616, time: 0.104, data: 0.011) loss: 0.042 
(epoch: 49, iters: 3696, time: 0.101, data: 0.000) loss: 0.005 
saving the model at the end of epoch 49, iters 182672
End of epoch 49 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 49, TEST ACC: [92.868 %]

saving the latest model (epoch 50, total_steps 182688)
(epoch: 50, iters: 48, time: 0.107, data: 0.004) loss: 0.013 
(epoch: 50, iters: 128, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 50, iters: 208, time: 0.105, data: 0.040) loss: 0.010 
(epoch: 50, iters: 288, time: 0.106, data: 0.000) loss: 0.025 
(epoch: 50, iters: 368, time: 0.103, data: 0.012) loss: 0.017 
(epoch: 50, iters: 448, time: 0.107, data: 0.000) loss: 0.043 
(epoch: 50, iters: 528, time: 0.105, data: 0.011) loss: 0.037 
(epoch: 50, iters: 608, time: 0.108, data: 0.000) loss: 0.011 
(epoch: 50, iters: 688, time: 0.104, data: 0.000) loss: 0.009 
(epoch: 50, iters: 768, time: 0.105, data: 0.049) loss: 0.007 
(epoch: 50, iters: 848, time: 0.107, data: 0.000) loss: 0.337 
(epoch: 50, iters: 928, time: 0.103, data: 0.011) loss: 0.157 
(epoch: 50, iters: 1008, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 50, iters: 1088, time: 0.104, data: 0.011) loss: 0.018 
(epoch: 50, iters: 1168, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 50, iters: 1248, time: 0.104, data: 0.000) loss: 0.051 
(epoch: 50, iters: 1328, time: 0.105, data: 0.039) loss: 0.021 
(epoch: 50, iters: 1408, time: 0.106, data: 0.000) loss: 0.161 
(epoch: 50, iters: 1488, time: 0.103, data: 0.011) loss: 0.218 
(epoch: 50, iters: 1568, time: 0.106, data: 0.000) loss: 0.139 
(epoch: 50, iters: 1648, time: 0.105, data: 0.011) loss: 0.038 
(epoch: 50, iters: 1728, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 50, iters: 1808, time: 0.106, data: 0.000) loss: 0.078 
(epoch: 50, iters: 1888, time: 0.106, data: 0.038) loss: 0.010 
(epoch: 50, iters: 1968, time: 0.106, data: 0.000) loss: 0.064 
(epoch: 50, iters: 2048, time: 0.105, data: 0.011) loss: 0.036 
(epoch: 50, iters: 2128, time: 0.105, data: 0.000) loss: 0.088 
(epoch: 50, iters: 2208, time: 0.104, data: 0.012) loss: 0.074 
(epoch: 50, iters: 2288, time: 0.106, data: 0.000) loss: 0.036 
(epoch: 50, iters: 2368, time: 0.105, data: 0.000) loss: 0.116 
(epoch: 50, iters: 2448, time: 0.106, data: 0.038) loss: 0.008 
(epoch: 50, iters: 2528, time: 0.106, data: 0.000) loss: 0.020 
(epoch: 50, iters: 2608, time: 0.102, data: 0.012) loss: 0.102 
(epoch: 50, iters: 2688, time: 0.106, data: 0.000) loss: 0.028 
(epoch: 50, iters: 2768, time: 0.106, data: 0.011) loss: 0.111 
(epoch: 50, iters: 2848, time: 0.107, data: 0.000) loss: 0.028 
(epoch: 50, iters: 2928, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 50, iters: 3008, time: 0.105, data: 0.048) loss: 0.015 
(epoch: 50, iters: 3088, time: 0.106, data: 0.000) loss: 0.258 
(epoch: 50, iters: 3168, time: 0.104, data: 0.011) loss: 0.010 
(epoch: 50, iters: 3248, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 50, iters: 3328, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 50, iters: 3408, time: 0.106, data: 0.000) loss: 0.044 
(epoch: 50, iters: 3488, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 50, iters: 3568, time: 0.107, data: 0.038) loss: 0.013 
(epoch: 50, iters: 3648, time: 0.101, data: 0.000) loss: 0.006 
(epoch: 50, iters: 3728, time: 0.066, data: 0.011) loss: 0.023 
saving the model at the end of epoch 50, iters 186400
End of epoch 50 / 2100 	 Time Taken: 396 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 50, TEST ACC: [77.39 %]

saving the latest model (epoch 51, total_steps 186416)
(epoch: 51, iters: 80, time: 0.107, data: 0.503) loss: 0.025 
(epoch: 51, iters: 160, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 51, iters: 240, time: 0.106, data: 0.038) loss: 0.043 
(epoch: 51, iters: 320, time: 0.106, data: 0.000) loss: 0.252 
(epoch: 51, iters: 400, time: 0.103, data: 0.011) loss: 0.016 
(epoch: 51, iters: 480, time: 0.106, data: 0.000) loss: 0.064 
(epoch: 51, iters: 560, time: 0.106, data: 0.011) loss: 0.008 
(epoch: 51, iters: 640, time: 0.105, data: 0.000) loss: 0.158 
(epoch: 51, iters: 720, time: 0.106, data: 0.000) loss: 0.017 
(epoch: 51, iters: 800, time: 0.105, data: 0.012) loss: 0.066 
(epoch: 51, iters: 880, time: 0.104, data: 0.025) loss: 0.002 
(epoch: 51, iters: 960, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 51, iters: 1040, time: 0.105, data: 0.000) loss: 0.080 
(epoch: 51, iters: 1120, time: 0.105, data: 0.012) loss: 0.014 
(epoch: 51, iters: 1200, time: 0.104, data: 0.024) loss: 0.017 
(epoch: 51, iters: 1280, time: 0.106, data: 0.000) loss: 0.021 
(epoch: 51, iters: 1360, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 51, iters: 1440, time: 0.104, data: 0.012) loss: 0.012 
(epoch: 51, iters: 1520, time: 0.104, data: 0.025) loss: 0.004 
(epoch: 51, iters: 1600, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 51, iters: 1680, time: 0.107, data: 0.000) loss: 0.017 
(epoch: 51, iters: 1760, time: 0.105, data: 0.011) loss: 0.111 
(epoch: 51, iters: 1840, time: 0.104, data: 0.034) loss: 0.007 
(epoch: 51, iters: 1920, time: 0.107, data: 0.000) loss: 0.092 
(epoch: 51, iters: 2000, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 51, iters: 2080, time: 0.105, data: 0.011) loss: 0.016 
(epoch: 51, iters: 2160, time: 0.104, data: 0.025) loss: 0.014 
(epoch: 51, iters: 2240, time: 0.105, data: 0.000) loss: 0.231 
(epoch: 51, iters: 2320, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 51, iters: 2400, time: 0.105, data: 0.012) loss: 0.010 
(epoch: 51, iters: 2480, time: 0.104, data: 0.024) loss: 0.013 
(epoch: 51, iters: 2560, time: 0.104, data: 0.000) loss: 0.054 
(epoch: 51, iters: 2640, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 51, iters: 2720, time: 0.105, data: 0.012) loss: 0.104 
(epoch: 51, iters: 2800, time: 0.105, data: 0.025) loss: 0.018 
(epoch: 51, iters: 2880, time: 0.107, data: 0.000) loss: 0.011 
(epoch: 51, iters: 2960, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 51, iters: 3040, time: 0.105, data: 0.011) loss: 0.007 
(epoch: 51, iters: 3120, time: 0.105, data: 0.025) loss: 0.008 
(epoch: 51, iters: 3200, time: 0.105, data: 0.000) loss: 0.128 
(epoch: 51, iters: 3280, time: 0.106, data: 0.000) loss: 0.081 
(epoch: 51, iters: 3360, time: 0.105, data: 0.011) loss: 0.010 
(epoch: 51, iters: 3440, time: 0.103, data: 0.025) loss: 0.007 
(epoch: 51, iters: 3520, time: 0.107, data: 0.000) loss: 0.008 
(epoch: 51, iters: 3600, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 51, iters: 3680, time: 0.100, data: 0.012) loss: 0.336 
saving the model at the end of epoch 51, iters 190128
End of epoch 51 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 51, TEST ACC: [91.654 %]

saving the latest model (epoch 52, total_steps 190144)
(epoch: 52, iters: 32, time: 0.101, data: 0.006) loss: 0.009 
(epoch: 52, iters: 112, time: 0.105, data: 0.000) loss: 0.111 
(epoch: 52, iters: 192, time: 0.106, data: 0.011) loss: 0.075 
(epoch: 52, iters: 272, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 52, iters: 352, time: 0.106, data: 0.000) loss: 0.086 
(epoch: 52, iters: 432, time: 0.106, data: 0.040) loss: 0.018 
(epoch: 52, iters: 512, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 52, iters: 592, time: 0.105, data: 0.011) loss: 0.121 
(epoch: 52, iters: 672, time: 0.105, data: 0.000) loss: 0.080 
(epoch: 52, iters: 752, time: 0.105, data: 0.011) loss: 0.005 
(epoch: 52, iters: 832, time: 0.106, data: 0.000) loss: 0.532 
(epoch: 52, iters: 912, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 52, iters: 992, time: 0.105, data: 0.039) loss: 0.144 
(epoch: 52, iters: 1072, time: 0.106, data: 0.000) loss: 0.173 
(epoch: 52, iters: 1152, time: 0.103, data: 0.011) loss: 0.014 
(epoch: 52, iters: 1232, time: 0.105, data: 0.000) loss: 0.026 
(epoch: 52, iters: 1312, time: 0.105, data: 0.011) loss: 0.035 
(epoch: 52, iters: 1392, time: 0.107, data: 0.000) loss: 0.007 
(epoch: 52, iters: 1472, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 52, iters: 1552, time: 0.105, data: 0.039) loss: 0.020 
(epoch: 52, iters: 1632, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 52, iters: 1712, time: 0.104, data: 0.011) loss: 0.113 
(epoch: 52, iters: 1792, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 52, iters: 1872, time: 0.105, data: 0.019) loss: 0.007 
(epoch: 52, iters: 1952, time: 0.107, data: 0.000) loss: 0.009 
(epoch: 52, iters: 2032, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 52, iters: 2112, time: 0.106, data: 0.038) loss: 0.003 
(epoch: 52, iters: 2192, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 52, iters: 2272, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 52, iters: 2352, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 52, iters: 2432, time: 0.105, data: 0.011) loss: 0.189 
(epoch: 52, iters: 2512, time: 0.106, data: 0.000) loss: 0.015 
(epoch: 52, iters: 2592, time: 0.105, data: 0.000) loss: 0.030 
(epoch: 52, iters: 2672, time: 0.106, data: 0.039) loss: 0.031 
(epoch: 52, iters: 2752, time: 0.107, data: 0.000) loss: 0.008 
(epoch: 52, iters: 2832, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 52, iters: 2912, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 52, iters: 2992, time: 0.105, data: 0.020) loss: 0.003 
(epoch: 52, iters: 3072, time: 0.107, data: 0.000) loss: 0.004 
(epoch: 52, iters: 3152, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 52, iters: 3232, time: 0.105, data: 0.039) loss: 0.018 
(epoch: 52, iters: 3312, time: 0.107, data: 0.000) loss: 0.004 
(epoch: 52, iters: 3392, time: 0.103, data: 0.011) loss: 0.021 
(epoch: 52, iters: 3472, time: 0.107, data: 0.000) loss: 0.134 
(epoch: 52, iters: 3552, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 52, iters: 3632, time: 0.102, data: 0.000) loss: 0.025 
(epoch: 52, iters: 3712, time: 0.101, data: 0.000) loss: 0.011 
saving the model at the end of epoch 52, iters 193856
End of epoch 52 / 2100 	 Time Taken: 396 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 52, TEST ACC: [92.716 %]

saving the latest model (epoch 53, total_steps 193872)
(epoch: 53, iters: 64, time: 0.106, data: 0.003) loss: 0.061 
(epoch: 53, iters: 144, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 53, iters: 224, time: 0.106, data: 0.011) loss: 0.003 
(epoch: 53, iters: 304, time: 0.107, data: 0.000) loss: 0.018 
(epoch: 53, iters: 384, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 53, iters: 464, time: 0.105, data: 0.039) loss: 0.004 
(epoch: 53, iters: 544, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 53, iters: 624, time: 0.103, data: 0.011) loss: 0.010 
(epoch: 53, iters: 704, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 53, iters: 784, time: 0.106, data: 0.012) loss: 0.003 
(epoch: 53, iters: 864, time: 0.106, data: 0.000) loss: 0.040 
(epoch: 53, iters: 944, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 53, iters: 1024, time: 0.107, data: 0.039) loss: 0.002 
(epoch: 53, iters: 1104, time: 0.107, data: 0.000) loss: 0.010 
(epoch: 53, iters: 1184, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 53, iters: 1264, time: 0.105, data: 0.000) loss: 0.035 
(epoch: 53, iters: 1344, time: 0.105, data: 0.011) loss: 0.032 
(epoch: 53, iters: 1424, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 53, iters: 1504, time: 0.106, data: 0.000) loss: 0.082 
(epoch: 53, iters: 1584, time: 0.104, data: 0.039) loss: 0.002 
(epoch: 53, iters: 1664, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 53, iters: 1744, time: 0.103, data: 0.011) loss: 0.056 
(epoch: 53, iters: 1824, time: 0.107, data: 0.000) loss: 0.017 
(epoch: 53, iters: 1904, time: 0.104, data: 0.011) loss: 0.368 
(epoch: 53, iters: 1984, time: 0.106, data: 0.000) loss: 0.017 
(epoch: 53, iters: 2064, time: 0.105, data: 0.000) loss: 0.072 
(epoch: 53, iters: 2144, time: 0.106, data: 0.039) loss: 0.547 
(epoch: 53, iters: 2224, time: 0.107, data: 0.000) loss: 0.036 
(epoch: 53, iters: 2304, time: 0.104, data: 0.011) loss: 0.236 
(epoch: 53, iters: 2384, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 53, iters: 2464, time: 0.104, data: 0.011) loss: 0.031 
(epoch: 53, iters: 2544, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 53, iters: 2624, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 53, iters: 2704, time: 0.106, data: 0.038) loss: 0.058 
(epoch: 53, iters: 2784, time: 0.106, data: 0.000) loss: 0.036 
(epoch: 53, iters: 2864, time: 0.104, data: 0.012) loss: 0.165 
(epoch: 53, iters: 2944, time: 0.106, data: 0.000) loss: 0.205 
(epoch: 53, iters: 3024, time: 0.106, data: 0.011) loss: 0.105 
(epoch: 53, iters: 3104, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 53, iters: 3184, time: 0.104, data: 0.000) loss: 0.034 
(epoch: 53, iters: 3264, time: 0.105, data: 0.038) loss: 0.009 
(epoch: 53, iters: 3344, time: 0.107, data: 0.000) loss: 0.163 
(epoch: 53, iters: 3424, time: 0.102, data: 0.011) loss: 0.170 
(epoch: 53, iters: 3504, time: 0.105, data: 0.000) loss: 0.078 
(epoch: 53, iters: 3584, time: 0.104, data: 0.011) loss: 0.126 
(epoch: 53, iters: 3664, time: 0.100, data: 0.000) loss: 0.007 
saving the model at the end of epoch 53, iters 197584
End of epoch 53 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 53, TEST ACC: [93.627 %]

(epoch: 54, iters: 16, time: 0.118, data: 0.000) loss: 0.100 
saving the latest model (epoch 54, total_steps 197600)
(epoch: 54, iters: 96, time: 0.106, data: 0.011) loss: 0.137 
(epoch: 54, iters: 176, time: 0.104, data: 0.020) loss: 0.015 
(epoch: 54, iters: 256, time: 0.105, data: 0.000) loss: 0.310 
(epoch: 54, iters: 336, time: 0.105, data: 0.011) loss: 0.053 
(epoch: 54, iters: 416, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 54, iters: 496, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 54, iters: 576, time: 0.107, data: 0.039) loss: 0.003 
(epoch: 54, iters: 656, time: 0.106, data: 0.000) loss: 0.015 
(epoch: 54, iters: 736, time: 0.104, data: 0.011) loss: 0.008 
(epoch: 54, iters: 816, time: 0.105, data: 0.000) loss: 0.106 
(epoch: 54, iters: 896, time: 0.104, data: 0.011) loss: 0.028 
(epoch: 54, iters: 976, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 54, iters: 1056, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 54, iters: 1136, time: 0.105, data: 0.039) loss: 0.077 
(epoch: 54, iters: 1216, time: 0.107, data: 0.000) loss: 0.011 
(epoch: 54, iters: 1296, time: 0.102, data: 0.011) loss: 0.035 
(epoch: 54, iters: 1376, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 54, iters: 1456, time: 0.105, data: 0.011) loss: 0.056 
(epoch: 54, iters: 1536, time: 0.107, data: 0.000) loss: 0.015 
(epoch: 54, iters: 1616, time: 0.104, data: 0.000) loss: 0.199 
(epoch: 54, iters: 1696, time: 0.105, data: 0.048) loss: 0.019 
(epoch: 54, iters: 1776, time: 0.105, data: 0.000) loss: 0.041 
(epoch: 54, iters: 1856, time: 0.104, data: 0.011) loss: 0.052 
(epoch: 54, iters: 1936, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 54, iters: 2016, time: 0.103, data: 0.011) loss: 0.095 
(epoch: 54, iters: 2096, time: 0.105, data: 0.000) loss: 0.068 
(epoch: 54, iters: 2176, time: 0.105, data: 0.000) loss: 0.276 
(epoch: 54, iters: 2256, time: 0.106, data: 0.039) loss: 0.029 
(epoch: 54, iters: 2336, time: 0.107, data: 0.000) loss: 0.009 
(epoch: 54, iters: 2416, time: 0.104, data: 0.011) loss: 0.077 
(epoch: 54, iters: 2496, time: 0.104, data: 0.000) loss: 0.013 
(epoch: 54, iters: 2576, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 54, iters: 2656, time: 0.106, data: 0.000) loss: 0.113 
(epoch: 54, iters: 2736, time: 0.105, data: 0.000) loss: 0.044 
(epoch: 54, iters: 2816, time: 0.107, data: 0.040) loss: 0.006 
(epoch: 54, iters: 2896, time: 0.107, data: 0.000) loss: 0.184 
(epoch: 54, iters: 2976, time: 0.104, data: 0.012) loss: 0.011 
(epoch: 54, iters: 3056, time: 0.105, data: 0.000) loss: 0.037 
(epoch: 54, iters: 3136, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 54, iters: 3216, time: 0.106, data: 0.000) loss: 0.032 
(epoch: 54, iters: 3296, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 54, iters: 3376, time: 0.105, data: 0.040) loss: 0.109 
(epoch: 54, iters: 3456, time: 0.105, data: 0.000) loss: 0.281 
(epoch: 54, iters: 3536, time: 0.104, data: 0.011) loss: 0.019 
(epoch: 54, iters: 3616, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 54, iters: 3696, time: 0.100, data: 0.011) loss: 0.174 
saving the model at the end of epoch 54, iters 201312
End of epoch 54 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 54, TEST ACC: [89.985 %]

saving the latest model (epoch 55, total_steps 201328)
(epoch: 55, iters: 48, time: 0.106, data: 0.000) loss: 0.073 
(epoch: 55, iters: 128, time: 0.105, data: 0.037) loss: 0.371 
(epoch: 55, iters: 208, time: 0.103, data: 0.011) loss: 0.006 
(epoch: 55, iters: 288, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 55, iters: 368, time: 0.104, data: 0.011) loss: 0.173 
(epoch: 55, iters: 448, time: 0.106, data: 0.000) loss: 0.047 
(epoch: 55, iters: 528, time: 0.104, data: 0.000) loss: 0.071 
(epoch: 55, iters: 608, time: 0.106, data: 0.038) loss: 0.035 
(epoch: 55, iters: 688, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 55, iters: 768, time: 0.103, data: 0.012) loss: 0.006 
(epoch: 55, iters: 848, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 55, iters: 928, time: 0.104, data: 0.012) loss: 0.440 
(epoch: 55, iters: 1008, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 55, iters: 1088, time: 0.105, data: 0.000) loss: 0.033 
(epoch: 55, iters: 1168, time: 0.105, data: 0.039) loss: 0.077 
(epoch: 55, iters: 1248, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 55, iters: 1328, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 55, iters: 1408, time: 0.106, data: 0.000) loss: 0.105 
(epoch: 55, iters: 1488, time: 0.107, data: 0.011) loss: 0.024 
(epoch: 55, iters: 1568, time: 0.105, data: 0.011) loss: 0.211 
(epoch: 55, iters: 1648, time: 0.105, data: 0.025) loss: 0.038 
(epoch: 55, iters: 1728, time: 0.107, data: 0.000) loss: 0.298 
(epoch: 55, iters: 1808, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 55, iters: 1888, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 55, iters: 1968, time: 0.104, data: 0.034) loss: 0.001 
(epoch: 55, iters: 2048, time: 0.105, data: 0.000) loss: 0.143 
(epoch: 55, iters: 2128, time: 0.106, data: 0.000) loss: 0.218 
(epoch: 55, iters: 2208, time: 0.104, data: 0.011) loss: 0.052 
(epoch: 55, iters: 2288, time: 0.104, data: 0.024) loss: 0.164 
(epoch: 55, iters: 2368, time: 0.105, data: 0.000) loss: 0.197 
(epoch: 55, iters: 2448, time: 0.107, data: 0.000) loss: 0.024 
(epoch: 55, iters: 2528, time: 0.104, data: 0.011) loss: 0.037 
(epoch: 55, iters: 2608, time: 0.104, data: 0.025) loss: 0.263 
(epoch: 55, iters: 2688, time: 0.106, data: 0.000) loss: 0.101 
(epoch: 55, iters: 2768, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 55, iters: 2848, time: 0.105, data: 0.011) loss: 0.290 
(epoch: 55, iters: 2928, time: 0.105, data: 0.024) loss: 0.089 
(epoch: 55, iters: 3008, time: 0.105, data: 0.000) loss: 0.053 
(epoch: 55, iters: 3088, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 55, iters: 3168, time: 0.104, data: 0.000) loss: 0.096 
(epoch: 55, iters: 3248, time: 0.105, data: 0.047) loss: 0.003 
(epoch: 55, iters: 3328, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 55, iters: 3408, time: 0.103, data: 0.011) loss: 0.025 
(epoch: 55, iters: 3488, time: 0.105, data: 0.000) loss: 0.019 
(epoch: 55, iters: 3568, time: 0.104, data: 0.011) loss: 0.024 
(epoch: 55, iters: 3648, time: 0.101, data: 0.000) loss: 0.021 
(epoch: 55, iters: 3728, time: 0.066, data: 0.000) loss: 0.033 
saving the model at the end of epoch 55, iters 205040
End of epoch 55 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 55, TEST ACC: [93.171 %]

saving the latest model (epoch 56, total_steps 205056)
(epoch: 56, iters: 80, time: 0.106, data: 0.462) loss: 0.006 
(epoch: 56, iters: 160, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 56, iters: 240, time: 0.105, data: 0.039) loss: 0.076 
(epoch: 56, iters: 320, time: 0.106, data: 0.000) loss: 0.015 
(epoch: 56, iters: 400, time: 0.103, data: 0.012) loss: 0.075 
(epoch: 56, iters: 480, time: 0.105, data: 0.000) loss: 0.030 
(epoch: 56, iters: 560, time: 0.104, data: 0.011) loss: 0.057 
(epoch: 56, iters: 640, time: 0.105, data: 0.000) loss: 0.064 
(epoch: 56, iters: 720, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 56, iters: 800, time: 0.105, data: 0.038) loss: 0.008 
(epoch: 56, iters: 880, time: 0.106, data: 0.000) loss: 0.153 
(epoch: 56, iters: 960, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 56, iters: 1040, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 56, iters: 1120, time: 0.104, data: 0.011) loss: 0.007 
(epoch: 56, iters: 1200, time: 0.106, data: 0.000) loss: 0.024 
(epoch: 56, iters: 1280, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 56, iters: 1360, time: 0.106, data: 0.039) loss: 0.006 
(epoch: 56, iters: 1440, time: 0.106, data: 0.000) loss: 0.679 
(epoch: 56, iters: 1520, time: 0.103, data: 0.012) loss: 0.007 
(epoch: 56, iters: 1600, time: 0.106, data: 0.000) loss: 0.064 
(epoch: 56, iters: 1680, time: 0.104, data: 0.011) loss: 0.008 
(epoch: 56, iters: 1760, time: 0.107, data: 0.000) loss: 0.046 
(epoch: 56, iters: 1840, time: 0.105, data: 0.000) loss: 0.158 
(epoch: 56, iters: 1920, time: 0.105, data: 0.039) loss: 0.022 
(epoch: 56, iters: 2000, time: 0.106, data: 0.000) loss: 0.359 
(epoch: 56, iters: 2080, time: 0.103, data: 0.012) loss: 0.019 
(epoch: 56, iters: 2160, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 56, iters: 2240, time: 0.105, data: 0.011) loss: 0.063 
(epoch: 56, iters: 2320, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 56, iters: 2400, time: 0.105, data: 0.000) loss: 0.057 
(epoch: 56, iters: 2480, time: 0.106, data: 0.040) loss: 0.012 
(epoch: 56, iters: 2560, time: 0.107, data: 0.000) loss: 0.018 
(epoch: 56, iters: 2640, time: 0.105, data: 0.011) loss: 0.006 
(epoch: 56, iters: 2720, time: 0.105, data: 0.000) loss: 0.115 
(epoch: 56, iters: 2800, time: 0.104, data: 0.011) loss: 0.011 
(epoch: 56, iters: 2880, time: 0.105, data: 0.000) loss: 0.270 
(epoch: 56, iters: 2960, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 56, iters: 3040, time: 0.106, data: 0.038) loss: 0.015 
(epoch: 56, iters: 3120, time: 0.106, data: 0.000) loss: 0.118 
(epoch: 56, iters: 3200, time: 0.103, data: 0.011) loss: 0.017 
(epoch: 56, iters: 3280, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 56, iters: 3360, time: 0.104, data: 0.011) loss: 0.020 
(epoch: 56, iters: 3440, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 56, iters: 3520, time: 0.103, data: 0.000) loss: 0.004 
(epoch: 56, iters: 3600, time: 0.105, data: 0.039) loss: 0.006 
(epoch: 56, iters: 3680, time: 0.101, data: 0.000) loss: 0.053 
saving the model at the end of epoch 56, iters 208768
End of epoch 56 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 56, TEST ACC: [91.199 %]

saving the latest model (epoch 57, total_steps 208784)
(epoch: 57, iters: 32, time: 0.100, data: 0.004) loss: 0.127 
(epoch: 57, iters: 112, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 57, iters: 192, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 57, iters: 272, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 57, iters: 352, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 57, iters: 432, time: 0.104, data: 0.039) loss: 0.014 
(epoch: 57, iters: 512, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 57, iters: 592, time: 0.104, data: 0.011) loss: 0.205 
(epoch: 57, iters: 672, time: 0.105, data: 0.000) loss: 0.097 
(epoch: 57, iters: 752, time: 0.105, data: 0.011) loss: 0.011 
(epoch: 57, iters: 832, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 57, iters: 912, time: 0.105, data: 0.000) loss: 0.036 
(epoch: 57, iters: 992, time: 0.105, data: 0.039) loss: 0.089 
(epoch: 57, iters: 1072, time: 0.105, data: 0.000) loss: 0.042 
(epoch: 57, iters: 1152, time: 0.102, data: 0.011) loss: 0.002 
(epoch: 57, iters: 1232, time: 0.106, data: 0.000) loss: 0.041 
(epoch: 57, iters: 1312, time: 0.105, data: 0.012) loss: 0.004 
(epoch: 57, iters: 1392, time: 0.106, data: 0.000) loss: 0.154 
(epoch: 57, iters: 1472, time: 0.103, data: 0.000) loss: 0.135 
(epoch: 57, iters: 1552, time: 0.105, data: 0.048) loss: 0.004 
(epoch: 57, iters: 1632, time: 0.106, data: 0.000) loss: 0.051 
(epoch: 57, iters: 1712, time: 0.104, data: 0.012) loss: 0.257 
(epoch: 57, iters: 1792, time: 0.105, data: 0.000) loss: 0.118 
(epoch: 57, iters: 1872, time: 0.105, data: 0.011) loss: 0.050 
(epoch: 57, iters: 1952, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 57, iters: 2032, time: 0.104, data: 0.000) loss: 0.310 
(epoch: 57, iters: 2112, time: 0.105, data: 0.039) loss: 0.003 
(epoch: 57, iters: 2192, time: 0.105, data: 0.000) loss: 0.050 
(epoch: 57, iters: 2272, time: 0.104, data: 0.012) loss: 0.219 
(epoch: 57, iters: 2352, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 57, iters: 2432, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 57, iters: 2512, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 57, iters: 2592, time: 0.104, data: 0.000) loss: 0.214 
(epoch: 57, iters: 2672, time: 0.104, data: 0.038) loss: 0.025 
(epoch: 57, iters: 2752, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 57, iters: 2832, time: 0.103, data: 0.011) loss: 0.057 
(epoch: 57, iters: 2912, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 57, iters: 2992, time: 0.105, data: 0.012) loss: 0.021 
(epoch: 57, iters: 3072, time: 0.106, data: 0.000) loss: 0.473 
(epoch: 57, iters: 3152, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 57, iters: 3232, time: 0.106, data: 0.039) loss: 0.015 
(epoch: 57, iters: 3312, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 57, iters: 3392, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 57, iters: 3472, time: 0.106, data: 0.000) loss: 0.041 
(epoch: 57, iters: 3552, time: 0.104, data: 0.011) loss: 0.031 
(epoch: 57, iters: 3632, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 57, iters: 3712, time: 0.100, data: 0.000) loss: 0.031 
saving the model at the end of epoch 57, iters 212496
End of epoch 57 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 57, TEST ACC: [92.109 %]

saving the latest model (epoch 58, total_steps 212512)
(epoch: 58, iters: 64, time: 0.103, data: 0.003) loss: 0.005 
(epoch: 58, iters: 144, time: 0.105, data: 0.000) loss: 0.105 
(epoch: 58, iters: 224, time: 0.105, data: 0.011) loss: 0.005 
(epoch: 58, iters: 304, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 58, iters: 384, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 58, iters: 464, time: 0.105, data: 0.039) loss: 0.032 
(epoch: 58, iters: 544, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 58, iters: 624, time: 0.103, data: 0.011) loss: 0.061 
(epoch: 58, iters: 704, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 58, iters: 784, time: 0.104, data: 0.011) loss: 0.008 
(epoch: 58, iters: 864, time: 0.105, data: 0.000) loss: 0.081 
(epoch: 58, iters: 944, time: 0.104, data: 0.000) loss: 0.031 
(epoch: 58, iters: 1024, time: 0.105, data: 0.048) loss: 0.010 
(epoch: 58, iters: 1104, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 58, iters: 1184, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 58, iters: 1264, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 58, iters: 1344, time: 0.103, data: 0.011) loss: 0.010 
(epoch: 58, iters: 1424, time: 0.105, data: 0.000) loss: 0.146 
(epoch: 58, iters: 1504, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 58, iters: 1584, time: 0.104, data: 0.039) loss: 0.002 
(epoch: 58, iters: 1664, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 58, iters: 1744, time: 0.104, data: 0.011) loss: 0.008 
(epoch: 58, iters: 1824, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 58, iters: 1904, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 58, iters: 1984, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 58, iters: 2064, time: 0.104, data: 0.000) loss: 0.022 
(epoch: 58, iters: 2144, time: 0.104, data: 0.038) loss: 0.004 
(epoch: 58, iters: 2224, time: 0.105, data: 0.000) loss: 0.044 
(epoch: 58, iters: 2304, time: 0.103, data: 0.011) loss: 0.014 
(epoch: 58, iters: 2384, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 58, iters: 2464, time: 0.103, data: 0.011) loss: 0.054 
(epoch: 58, iters: 2544, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 58, iters: 2624, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 58, iters: 2704, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 58, iters: 2784, time: 0.107, data: 0.000) loss: 0.006 
(epoch: 58, iters: 2864, time: 0.102, data: 0.011) loss: 0.017 
(epoch: 58, iters: 2944, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 58, iters: 3024, time: 0.104, data: 0.011) loss: 0.016 
(epoch: 58, iters: 3104, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 58, iters: 3184, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 58, iters: 3264, time: 0.105, data: 0.047) loss: 0.257 
(epoch: 58, iters: 3344, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 58, iters: 3424, time: 0.103, data: 0.011) loss: 0.005 
(epoch: 58, iters: 3504, time: 0.104, data: 0.000) loss: 0.012 
(epoch: 58, iters: 3584, time: 0.104, data: 0.011) loss: 0.130 
(epoch: 58, iters: 3664, time: 0.100, data: 0.000) loss: 0.015 
saving the model at the end of epoch 58, iters 216224
End of epoch 58 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 58, TEST ACC: [89.53 %]

(epoch: 59, iters: 16, time: 0.119, data: 0.000) loss: 0.002 
saving the latest model (epoch 59, total_steps 216240)
(epoch: 59, iters: 96, time: 0.105, data: 0.054) loss: 0.038 
(epoch: 59, iters: 176, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 59, iters: 256, time: 0.103, data: 0.012) loss: 0.034 
(epoch: 59, iters: 336, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 59, iters: 416, time: 0.103, data: 0.011) loss: 0.158 
(epoch: 59, iters: 496, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 59, iters: 576, time: 0.105, data: 0.000) loss: 0.033 
(epoch: 59, iters: 656, time: 0.105, data: 0.038) loss: 0.009 
(epoch: 59, iters: 736, time: 0.105, data: 0.000) loss: 0.078 
(epoch: 59, iters: 816, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 59, iters: 896, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 59, iters: 976, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 59, iters: 1056, time: 0.106, data: 0.000) loss: 0.020 
(epoch: 59, iters: 1136, time: 0.104, data: 0.000) loss: 0.424 
(epoch: 59, iters: 1216, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 59, iters: 1296, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 59, iters: 1376, time: 0.102, data: 0.011) loss: 0.017 
(epoch: 59, iters: 1456, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 59, iters: 1536, time: 0.104, data: 0.011) loss: 0.011 
(epoch: 59, iters: 1616, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 59, iters: 1696, time: 0.105, data: 0.000) loss: 0.108 
(epoch: 59, iters: 1776, time: 0.104, data: 0.039) loss: 0.179 
(epoch: 59, iters: 1856, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 59, iters: 1936, time: 0.103, data: 0.011) loss: 0.069 
(epoch: 59, iters: 2016, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 59, iters: 2096, time: 0.104, data: 0.012) loss: 0.123 
(epoch: 59, iters: 2176, time: 0.105, data: 0.000) loss: 0.111 
(epoch: 59, iters: 2256, time: 0.104, data: 0.000) loss: 0.011 
(epoch: 59, iters: 2336, time: 0.105, data: 0.046) loss: 0.005 
(epoch: 59, iters: 2416, time: 0.106, data: 0.000) loss: 0.325 
(epoch: 59, iters: 2496, time: 0.104, data: 0.012) loss: 0.022 
(epoch: 59, iters: 2576, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 59, iters: 2656, time: 0.104, data: 0.011) loss: 0.081 
(epoch: 59, iters: 2736, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 59, iters: 2816, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 59, iters: 2896, time: 0.104, data: 0.048) loss: 0.221 
(epoch: 59, iters: 2976, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 59, iters: 3056, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 59, iters: 3136, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 59, iters: 3216, time: 0.103, data: 0.011) loss: 0.009 
(epoch: 59, iters: 3296, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 59, iters: 3376, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 59, iters: 3456, time: 0.106, data: 0.039) loss: 0.006 
(epoch: 59, iters: 3536, time: 0.106, data: 0.000) loss: 0.031 
(epoch: 59, iters: 3616, time: 0.104, data: 0.011) loss: 0.030 
(epoch: 59, iters: 3696, time: 0.100, data: 0.000) loss: 0.042 
saving the model at the end of epoch 59, iters 219952
End of epoch 59 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 59, TEST ACC: [84.37 %]

saving the latest model (epoch 60, total_steps 219968)
(epoch: 60, iters: 48, time: 0.105, data: 0.005) loss: 0.031 
(epoch: 60, iters: 128, time: 0.105, data: 0.025) loss: 0.074 
(epoch: 60, iters: 208, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 60, iters: 288, time: 0.103, data: 0.011) loss: 0.139 
(epoch: 60, iters: 368, time: 0.105, data: 0.000) loss: 0.037 
(epoch: 60, iters: 448, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 60, iters: 528, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 60, iters: 608, time: 0.105, data: 0.000) loss: 0.029 
(epoch: 60, iters: 688, time: 0.104, data: 0.038) loss: 0.004 
(epoch: 60, iters: 768, time: 0.105, data: 0.000) loss: 0.130 
(epoch: 60, iters: 848, time: 0.103, data: 0.012) loss: 0.019 
(epoch: 60, iters: 928, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 60, iters: 1008, time: 0.104, data: 0.011) loss: 0.007 
(epoch: 60, iters: 1088, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 60, iters: 1168, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 60, iters: 1248, time: 0.106, data: 0.038) loss: 0.003 
(epoch: 60, iters: 1328, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 60, iters: 1408, time: 0.102, data: 0.012) loss: 0.006 
(epoch: 60, iters: 1488, time: 0.105, data: 0.000) loss: 0.032 
(epoch: 60, iters: 1568, time: 0.106, data: 0.011) loss: 0.060 
(epoch: 60, iters: 1648, time: 0.106, data: 0.000) loss: 0.037 
(epoch: 60, iters: 1728, time: 0.105, data: 0.000) loss: 0.154 
(epoch: 60, iters: 1808, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 60, iters: 1888, time: 0.107, data: 0.000) loss: 0.007 
(epoch: 60, iters: 1968, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 60, iters: 2048, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 60, iters: 2128, time: 0.104, data: 0.011) loss: 0.039 
(epoch: 60, iters: 2208, time: 0.106, data: 0.000) loss: 0.025 
(epoch: 60, iters: 2288, time: 0.105, data: 0.000) loss: 0.088 
(epoch: 60, iters: 2368, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 60, iters: 2448, time: 0.108, data: 0.000) loss: 0.039 
(epoch: 60, iters: 2528, time: 0.103, data: 0.011) loss: 0.012 
(epoch: 60, iters: 2608, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 60, iters: 2688, time: 0.105, data: 0.011) loss: 0.074 
(epoch: 60, iters: 2768, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 60, iters: 2848, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 60, iters: 2928, time: 0.106, data: 0.038) loss: 0.072 
(epoch: 60, iters: 3008, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 60, iters: 3088, time: 0.103, data: 0.011) loss: 0.021 
(epoch: 60, iters: 3168, time: 0.106, data: 0.000) loss: 0.144 
(epoch: 60, iters: 3248, time: 0.105, data: 0.012) loss: 0.106 
(epoch: 60, iters: 3328, time: 0.107, data: 0.000) loss: 0.143 
(epoch: 60, iters: 3408, time: 0.105, data: 0.000) loss: 0.172 
(epoch: 60, iters: 3488, time: 0.105, data: 0.038) loss: 0.093 
(epoch: 60, iters: 3568, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 60, iters: 3648, time: 0.097, data: 0.011) loss: 0.001 
(epoch: 60, iters: 3728, time: 0.066, data: 0.000) loss: 0.007 
saving the model at the end of epoch 60, iters 223680
End of epoch 60 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 60, TEST ACC: [92.413 %]

saving the latest model (epoch 61, total_steps 223696)
(epoch: 61, iters: 80, time: 0.105, data: 0.464) loss: 0.001 
(epoch: 61, iters: 160, time: 0.104, data: 0.000) loss: 0.009 
(epoch: 61, iters: 240, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 61, iters: 320, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 61, iters: 400, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 61, iters: 480, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 61, iters: 560, time: 0.104, data: 0.011) loss: 0.193 
(epoch: 61, iters: 640, time: 0.106, data: 0.000) loss: 0.047 
(epoch: 61, iters: 720, time: 0.105, data: 0.000) loss: 0.091 
(epoch: 61, iters: 800, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 61, iters: 880, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 61, iters: 960, time: 0.103, data: 0.012) loss: 0.017 
(epoch: 61, iters: 1040, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 61, iters: 1120, time: 0.104, data: 0.012) loss: 0.003 
(epoch: 61, iters: 1200, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 61, iters: 1280, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 61, iters: 1360, time: 0.105, data: 0.039) loss: 0.158 
(epoch: 61, iters: 1440, time: 0.106, data: 0.000) loss: 0.038 
(epoch: 61, iters: 1520, time: 0.101, data: 0.012) loss: 0.005 
(epoch: 61, iters: 1600, time: 0.105, data: 0.000) loss: 0.249 
(epoch: 61, iters: 1680, time: 0.105, data: 0.011) loss: 0.430 
(epoch: 61, iters: 1760, time: 0.106, data: 0.000) loss: 0.304 
(epoch: 61, iters: 1840, time: 0.104, data: 0.000) loss: 0.032 
(epoch: 61, iters: 1920, time: 0.105, data: 0.047) loss: 0.234 
(epoch: 61, iters: 2000, time: 0.105, data: 0.000) loss: 0.043 
(epoch: 61, iters: 2080, time: 0.103, data: 0.012) loss: 0.024 
(epoch: 61, iters: 2160, time: 0.105, data: 0.000) loss: 0.062 
(epoch: 61, iters: 2240, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 61, iters: 2320, time: 0.108, data: 0.000) loss: 0.007 
(epoch: 61, iters: 2400, time: 0.104, data: 0.000) loss: 0.070 
(epoch: 61, iters: 2480, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 61, iters: 2560, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 61, iters: 2640, time: 0.102, data: 0.011) loss: 0.031 
(epoch: 61, iters: 2720, time: 0.104, data: 0.000) loss: 0.037 
(epoch: 61, iters: 2800, time: 0.105, data: 0.011) loss: 0.025 
(epoch: 61, iters: 2880, time: 0.107, data: 0.000) loss: 0.008 
(epoch: 61, iters: 2960, time: 0.104, data: 0.000) loss: 0.014 
(epoch: 61, iters: 3040, time: 0.105, data: 0.048) loss: 0.002 
(epoch: 61, iters: 3120, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 61, iters: 3200, time: 0.103, data: 0.011) loss: 0.005 
(epoch: 61, iters: 3280, time: 0.105, data: 0.000) loss: 0.052 
(epoch: 61, iters: 3360, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 61, iters: 3440, time: 0.105, data: 0.000) loss: 0.177 
(epoch: 61, iters: 3520, time: 0.106, data: 0.000) loss: 0.179 
(epoch: 61, iters: 3600, time: 0.106, data: 0.048) loss: 0.091 
(epoch: 61, iters: 3680, time: 0.100, data: 0.000) loss: 0.011 
saving the model at the end of epoch 61, iters 227408
End of epoch 61 / 2100 	 Time Taken: 392 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 61, TEST ACC: [84.067 %]

saving the latest model (epoch 62, total_steps 227424)
(epoch: 62, iters: 32, time: 0.099, data: 0.004) loss: 0.021 
(epoch: 62, iters: 112, time: 0.107, data: 0.000) loss: 0.131 
(epoch: 62, iters: 192, time: 0.104, data: 0.000) loss: 0.277 
(epoch: 62, iters: 272, time: 0.105, data: 0.039) loss: 0.085 
(epoch: 62, iters: 352, time: 0.106, data: 0.000) loss: 0.049 
(epoch: 62, iters: 432, time: 0.103, data: 0.011) loss: 0.012 
(epoch: 62, iters: 512, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 62, iters: 592, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 62, iters: 672, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 62, iters: 752, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 62, iters: 832, time: 0.106, data: 0.040) loss: 0.020 
(epoch: 62, iters: 912, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 62, iters: 992, time: 0.103, data: 0.012) loss: 0.009 
(epoch: 62, iters: 1072, time: 0.105, data: 0.000) loss: 0.023 
(epoch: 62, iters: 1152, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 62, iters: 1232, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 62, iters: 1312, time: 0.104, data: 0.000) loss: 0.016 
(epoch: 62, iters: 1392, time: 0.104, data: 0.038) loss: 0.009 
(epoch: 62, iters: 1472, time: 0.106, data: 0.000) loss: 0.061 
(epoch: 62, iters: 1552, time: 0.104, data: 0.011) loss: 0.021 
(epoch: 62, iters: 1632, time: 0.105, data: 0.000) loss: 0.095 
(epoch: 62, iters: 1712, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 62, iters: 1792, time: 0.106, data: 0.000) loss: 0.085 
(epoch: 62, iters: 1872, time: 0.103, data: 0.000) loss: 0.006 
(epoch: 62, iters: 1952, time: 0.105, data: 0.039) loss: 0.004 
(epoch: 62, iters: 2032, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 62, iters: 2112, time: 0.102, data: 0.011) loss: 0.066 
(epoch: 62, iters: 2192, time: 0.105, data: 0.000) loss: 0.059 
(epoch: 62, iters: 2272, time: 0.104, data: 0.012) loss: 0.016 
(epoch: 62, iters: 2352, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 62, iters: 2432, time: 0.103, data: 0.000) loss: 0.029 
(epoch: 62, iters: 2512, time: 0.104, data: 0.038) loss: 0.006 
(epoch: 62, iters: 2592, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 62, iters: 2672, time: 0.103, data: 0.011) loss: 0.186 
(epoch: 62, iters: 2752, time: 0.105, data: 0.000) loss: 0.035 
(epoch: 62, iters: 2832, time: 0.104, data: 0.012) loss: 0.014 
(epoch: 62, iters: 2912, time: 0.106, data: 0.000) loss: 0.018 
(epoch: 62, iters: 2992, time: 0.105, data: 0.000) loss: 0.045 
(epoch: 62, iters: 3072, time: 0.106, data: 0.040) loss: 0.017 
(epoch: 62, iters: 3152, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 62, iters: 3232, time: 0.103, data: 0.012) loss: 0.006 
(epoch: 62, iters: 3312, time: 0.105, data: 0.000) loss: 0.018 
(epoch: 62, iters: 3392, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 62, iters: 3472, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 62, iters: 3552, time: 0.105, data: 0.000) loss: 0.019 
(epoch: 62, iters: 3632, time: 0.103, data: 0.039) loss: 0.001 
(epoch: 62, iters: 3712, time: 0.100, data: 0.000) loss: 0.009 
saving the model at the end of epoch 62, iters 231136
End of epoch 62 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 62, TEST ACC: [94.082 %]

saving the latest model (epoch 63, total_steps 231152)
(epoch: 63, iters: 64, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 63, iters: 144, time: 0.104, data: 0.026) loss: 0.026 
(epoch: 63, iters: 224, time: 0.106, data: 0.000) loss: 0.028 
(epoch: 63, iters: 304, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 63, iters: 384, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 63, iters: 464, time: 0.105, data: 0.011) loss: 0.222 
(epoch: 63, iters: 544, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 63, iters: 624, time: 0.104, data: 0.000) loss: 0.068 
(epoch: 63, iters: 704, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 63, iters: 784, time: 0.104, data: 0.000) loss: 0.049 
(epoch: 63, iters: 864, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 63, iters: 944, time: 0.105, data: 0.000) loss: 0.081 
(epoch: 63, iters: 1024, time: 0.104, data: 0.012) loss: 0.105 
(epoch: 63, iters: 1104, time: 0.105, data: 0.000) loss: 0.195 
(epoch: 63, iters: 1184, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 63, iters: 1264, time: 0.105, data: 0.039) loss: 0.010 
(epoch: 63, iters: 1344, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 63, iters: 1424, time: 0.102, data: 0.011) loss: 0.024 
(epoch: 63, iters: 1504, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 63, iters: 1584, time: 0.103, data: 0.011) loss: 0.021 
(epoch: 63, iters: 1664, time: 0.105, data: 0.000) loss: 0.160 
(epoch: 63, iters: 1744, time: 0.105, data: 0.000) loss: 0.287 
(epoch: 63, iters: 1824, time: 0.105, data: 0.040) loss: 0.034 
(epoch: 63, iters: 1904, time: 0.106, data: 0.000) loss: 0.032 
(epoch: 63, iters: 1984, time: 0.104, data: 0.012) loss: 0.005 
(epoch: 63, iters: 2064, time: 0.104, data: 0.000) loss: 0.124 
(epoch: 63, iters: 2144, time: 0.104, data: 0.011) loss: 0.013 
(epoch: 63, iters: 2224, time: 0.105, data: 0.000) loss: 0.054 
(epoch: 63, iters: 2304, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 63, iters: 2384, time: 0.105, data: 0.038) loss: 0.049 
(epoch: 63, iters: 2464, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 63, iters: 2544, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 63, iters: 2624, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 63, iters: 2704, time: 0.104, data: 0.011) loss: 0.026 
(epoch: 63, iters: 2784, time: 0.106, data: 0.000) loss: 0.184 
(epoch: 63, iters: 2864, time: 0.104, data: 0.000) loss: 0.049 
(epoch: 63, iters: 2944, time: 0.104, data: 0.039) loss: 0.004 
(epoch: 63, iters: 3024, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 63, iters: 3104, time: 0.103, data: 0.012) loss: 0.067 
(epoch: 63, iters: 3184, time: 0.105, data: 0.000) loss: 0.022 
(epoch: 63, iters: 3264, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 63, iters: 3344, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 63, iters: 3424, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 63, iters: 3504, time: 0.105, data: 0.040) loss: 0.023 
(epoch: 63, iters: 3584, time: 0.107, data: 0.000) loss: 0.006 
(epoch: 63, iters: 3664, time: 0.099, data: 0.011) loss: 0.025 
saving the model at the end of epoch 63, iters 234864
End of epoch 63 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 63, TEST ACC: [91.654 %]

(epoch: 64, iters: 16, time: 0.119, data: 0.012) loss: 0.036 
saving the latest model (epoch 64, total_steps 234880)
(epoch: 64, iters: 96, time: 0.105, data: 0.012) loss: 0.005 
(epoch: 64, iters: 176, time: 0.103, data: 0.011) loss: 0.054 
(epoch: 64, iters: 256, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 64, iters: 336, time: 0.105, data: 0.019) loss: 0.011 
(epoch: 64, iters: 416, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 64, iters: 496, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 64, iters: 576, time: 0.105, data: 0.048) loss: 0.156 
(epoch: 64, iters: 656, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 64, iters: 736, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 64, iters: 816, time: 0.104, data: 0.000) loss: 0.005 
(epoch: 64, iters: 896, time: 0.105, data: 0.011) loss: 0.020 
(epoch: 64, iters: 976, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 64, iters: 1056, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 64, iters: 1136, time: 0.104, data: 0.038) loss: 0.000 
(epoch: 64, iters: 1216, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 64, iters: 1296, time: 0.102, data: 0.012) loss: 0.005 
(epoch: 64, iters: 1376, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 64, iters: 1456, time: 0.104, data: 0.011) loss: 0.085 
(epoch: 64, iters: 1536, time: 0.105, data: 0.000) loss: 0.063 
(epoch: 64, iters: 1616, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 64, iters: 1696, time: 0.104, data: 0.038) loss: 0.018 
(epoch: 64, iters: 1776, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 64, iters: 1856, time: 0.103, data: 0.011) loss: 0.015 
(epoch: 64, iters: 1936, time: 0.105, data: 0.000) loss: 0.037 
(epoch: 64, iters: 2016, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 64, iters: 2096, time: 0.106, data: 0.000) loss: 0.071 
(epoch: 64, iters: 2176, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 64, iters: 2256, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 64, iters: 2336, time: 0.107, data: 0.000) loss: 0.022 
(epoch: 64, iters: 2416, time: 0.103, data: 0.011) loss: 0.025 
(epoch: 64, iters: 2496, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 64, iters: 2576, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 64, iters: 2656, time: 0.106, data: 0.000) loss: 0.049 
(epoch: 64, iters: 2736, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 64, iters: 2816, time: 0.106, data: 0.048) loss: 0.210 
(epoch: 64, iters: 2896, time: 0.106, data: 0.000) loss: 0.020 
(epoch: 64, iters: 2976, time: 0.103, data: 0.011) loss: 0.033 
(epoch: 64, iters: 3056, time: 0.104, data: 0.000) loss: 0.056 
(epoch: 64, iters: 3136, time: 0.104, data: 0.011) loss: 0.055 
(epoch: 64, iters: 3216, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 64, iters: 3296, time: 0.104, data: 0.000) loss: 0.073 
(epoch: 64, iters: 3376, time: 0.105, data: 0.038) loss: 0.012 
(epoch: 64, iters: 3456, time: 0.107, data: 0.000) loss: 0.016 
(epoch: 64, iters: 3536, time: 0.102, data: 0.012) loss: 0.016 
(epoch: 64, iters: 3616, time: 0.105, data: 0.000) loss: 0.101 
(epoch: 64, iters: 3696, time: 0.100, data: 0.012) loss: 0.006 
saving the model at the end of epoch 64, iters 238592
End of epoch 64 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 64, TEST ACC: [87.405 %]

saving the latest model (epoch 65, total_steps 238608)
(epoch: 65, iters: 48, time: 0.105, data: 0.000) loss: 0.041 
(epoch: 65, iters: 128, time: 0.104, data: 0.041) loss: 0.011 
(epoch: 65, iters: 208, time: 0.106, data: 0.000) loss: 0.510 
(epoch: 65, iters: 288, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 65, iters: 368, time: 0.107, data: 0.000) loss: 0.044 
(epoch: 65, iters: 448, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 65, iters: 528, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 65, iters: 608, time: 0.105, data: 0.000) loss: 0.034 
(epoch: 65, iters: 688, time: 0.105, data: 0.048) loss: 0.001 
(epoch: 65, iters: 768, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 65, iters: 848, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 65, iters: 928, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 65, iters: 1008, time: 0.105, data: 0.011) loss: 0.009 
(epoch: 65, iters: 1088, time: 0.105, data: 0.000) loss: 0.114 
(epoch: 65, iters: 1168, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 65, iters: 1248, time: 0.105, data: 0.038) loss: 0.007 
(epoch: 65, iters: 1328, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 65, iters: 1408, time: 0.103, data: 0.012) loss: 0.005 
(epoch: 65, iters: 1488, time: 0.105, data: 0.000) loss: 0.031 
(epoch: 65, iters: 1568, time: 0.104, data: 0.012) loss: 0.014 
(epoch: 65, iters: 1648, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 65, iters: 1728, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 65, iters: 1808, time: 0.106, data: 0.040) loss: 0.016 
(epoch: 65, iters: 1888, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 65, iters: 1968, time: 0.103, data: 0.012) loss: 0.085 
(epoch: 65, iters: 2048, time: 0.105, data: 0.000) loss: 0.053 
(epoch: 65, iters: 2128, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 65, iters: 2208, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 65, iters: 2288, time: 0.104, data: 0.000) loss: 0.021 
(epoch: 65, iters: 2368, time: 0.105, data: 0.049) loss: 0.001 
(epoch: 65, iters: 2448, time: 0.106, data: 0.000) loss: 0.025 
(epoch: 65, iters: 2528, time: 0.102, data: 0.011) loss: 0.007 
(epoch: 65, iters: 2608, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 65, iters: 2688, time: 0.104, data: 0.011) loss: 0.013 
(epoch: 65, iters: 2768, time: 0.106, data: 0.000) loss: 0.038 
(epoch: 65, iters: 2848, time: 0.105, data: 0.000) loss: 0.087 
(epoch: 65, iters: 2928, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 65, iters: 3008, time: 0.105, data: 0.000) loss: 0.068 
(epoch: 65, iters: 3088, time: 0.103, data: 0.011) loss: 0.021 
(epoch: 65, iters: 3168, time: 0.105, data: 0.000) loss: 0.253 
(epoch: 65, iters: 3248, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 65, iters: 3328, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 65, iters: 3408, time: 0.105, data: 0.000) loss: 0.028 
(epoch: 65, iters: 3488, time: 0.105, data: 0.040) loss: 0.009 
(epoch: 65, iters: 3568, time: 0.106, data: 0.000) loss: 0.023 
(epoch: 65, iters: 3648, time: 0.098, data: 0.011) loss: 0.044 
(epoch: 65, iters: 3728, time: 0.066, data: 0.000) loss: 0.054 
saving the model at the end of epoch 65, iters 242320
End of epoch 65 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 65, TEST ACC: [94.082 %]

saving the latest model (epoch 66, total_steps 242336)
(epoch: 66, iters: 80, time: 0.105, data: 0.413) loss: 0.012 
(epoch: 66, iters: 160, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 66, iters: 240, time: 0.104, data: 0.000) loss: 0.043 
(epoch: 66, iters: 320, time: 0.104, data: 0.038) loss: 0.015 
(epoch: 66, iters: 400, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 66, iters: 480, time: 0.102, data: 0.011) loss: 0.003 
(epoch: 66, iters: 560, time: 0.105, data: 0.000) loss: 0.058 
(epoch: 66, iters: 640, time: 0.105, data: 0.011) loss: 0.008 
(epoch: 66, iters: 720, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 66, iters: 800, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 66, iters: 880, time: 0.105, data: 0.049) loss: 0.001 
(epoch: 66, iters: 960, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 66, iters: 1040, time: 0.102, data: 0.011) loss: 0.054 
(epoch: 66, iters: 1120, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 66, iters: 1200, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 66, iters: 1280, time: 0.106, data: 0.000) loss: 0.048 
(epoch: 66, iters: 1360, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 66, iters: 1440, time: 0.105, data: 0.038) loss: 0.011 
(epoch: 66, iters: 1520, time: 0.105, data: 0.000) loss: 0.331 
(epoch: 66, iters: 1600, time: 0.102, data: 0.011) loss: 0.005 
(epoch: 66, iters: 1680, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 66, iters: 1760, time: 0.106, data: 0.012) loss: 0.002 
(epoch: 66, iters: 1840, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 66, iters: 1920, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 66, iters: 2000, time: 0.105, data: 0.048) loss: 0.002 
(epoch: 66, iters: 2080, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 66, iters: 2160, time: 0.103, data: 0.012) loss: 0.005 
(epoch: 66, iters: 2240, time: 0.105, data: 0.000) loss: 0.041 
(epoch: 66, iters: 2320, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 66, iters: 2400, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 66, iters: 2480, time: 0.103, data: 0.000) loss: 0.005 
(epoch: 66, iters: 2560, time: 0.105, data: 0.039) loss: 0.014 
(epoch: 66, iters: 2640, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 66, iters: 2720, time: 0.102, data: 0.011) loss: 0.003 
(epoch: 66, iters: 2800, time: 0.105, data: 0.000) loss: 0.059 
(epoch: 66, iters: 2880, time: 0.106, data: 0.012) loss: 0.008 
(epoch: 66, iters: 2960, time: 0.106, data: 0.000) loss: 0.054 
(epoch: 66, iters: 3040, time: 0.104, data: 0.000) loss: 0.015 
(epoch: 66, iters: 3120, time: 0.106, data: 0.048) loss: 0.002 
(epoch: 66, iters: 3200, time: 0.106, data: 0.000) loss: 0.099 
(epoch: 66, iters: 3280, time: 0.103, data: 0.012) loss: 0.012 
(epoch: 66, iters: 3360, time: 0.105, data: 0.000) loss: 0.073 
(epoch: 66, iters: 3440, time: 0.104, data: 0.011) loss: 0.054 
(epoch: 66, iters: 3520, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 66, iters: 3600, time: 0.104, data: 0.000) loss: 0.039 
(epoch: 66, iters: 3680, time: 0.099, data: 0.040) loss: 0.020 
saving the model at the end of epoch 66, iters 246048
End of epoch 66 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 66, TEST ACC: [90.288 %]

saving the latest model (epoch 67, total_steps 246064)
(epoch: 67, iters: 32, time: 0.097, data: 0.000) loss: 0.014 
(epoch: 67, iters: 112, time: 0.104, data: 0.025) loss: 0.302 
(epoch: 67, iters: 192, time: 0.105, data: 0.000) loss: 0.227 
(epoch: 67, iters: 272, time: 0.104, data: 0.000) loss: 0.142 
(epoch: 67, iters: 352, time: 0.104, data: 0.039) loss: 0.044 
(epoch: 67, iters: 432, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 67, iters: 512, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 67, iters: 592, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 67, iters: 672, time: 0.105, data: 0.011) loss: 0.205 
(epoch: 67, iters: 752, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 67, iters: 832, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 67, iters: 912, time: 0.104, data: 0.039) loss: 0.187 
(epoch: 67, iters: 992, time: 0.105, data: 0.000) loss: 0.075 
(epoch: 67, iters: 1072, time: 0.102, data: 0.011) loss: 0.075 
(epoch: 67, iters: 1152, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 67, iters: 1232, time: 0.105, data: 0.011) loss: 0.109 
(epoch: 67, iters: 1312, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 67, iters: 1392, time: 0.103, data: 0.000) loss: 0.126 
(epoch: 67, iters: 1472, time: 0.106, data: 0.038) loss: 0.046 
(epoch: 67, iters: 1552, time: 0.105, data: 0.000) loss: 0.232 
(epoch: 67, iters: 1632, time: 0.102, data: 0.011) loss: 0.310 
(epoch: 67, iters: 1712, time: 0.105, data: 0.000) loss: 0.019 
(epoch: 67, iters: 1792, time: 0.103, data: 0.011) loss: 0.056 
(epoch: 67, iters: 1872, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 67, iters: 1952, time: 0.104, data: 0.000) loss: 0.128 
(epoch: 67, iters: 2032, time: 0.105, data: 0.040) loss: 0.066 
(epoch: 67, iters: 2112, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 67, iters: 2192, time: 0.104, data: 0.011) loss: 0.116 
(epoch: 67, iters: 2272, time: 0.105, data: 0.000) loss: 0.044 
(epoch: 67, iters: 2352, time: 0.105, data: 0.012) loss: 0.053 
(epoch: 67, iters: 2432, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 67, iters: 2512, time: 0.104, data: 0.000) loss: 0.005 
(epoch: 67, iters: 2592, time: 0.105, data: 0.039) loss: 0.009 
(epoch: 67, iters: 2672, time: 0.106, data: 0.000) loss: 0.081 
(epoch: 67, iters: 2752, time: 0.102, data: 0.012) loss: 0.113 
(epoch: 67, iters: 2832, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 67, iters: 2912, time: 0.104, data: 0.012) loss: 0.295 
(epoch: 67, iters: 2992, time: 0.105, data: 0.000) loss: 0.066 
(epoch: 67, iters: 3072, time: 0.104, data: 0.000) loss: 0.065 
(epoch: 67, iters: 3152, time: 0.104, data: 0.038) loss: 0.008 
(epoch: 67, iters: 3232, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 67, iters: 3312, time: 0.102, data: 0.012) loss: 0.004 
(epoch: 67, iters: 3392, time: 0.104, data: 0.000) loss: 0.015 
(epoch: 67, iters: 3472, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 67, iters: 3552, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 67, iters: 3632, time: 0.103, data: 0.000) loss: 0.002 
(epoch: 67, iters: 3712, time: 0.100, data: 0.036) loss: 0.006 
saving the model at the end of epoch 67, iters 249776
End of epoch 67 / 2100 	 Time Taken: 392 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 67, TEST ACC: [94.537 %]

saving the latest model (epoch 68, total_steps 249792)
(epoch: 68, iters: 64, time: 0.104, data: 0.000) loss: 0.435 
(epoch: 68, iters: 144, time: 0.106, data: 0.000) loss: 0.186 
(epoch: 68, iters: 224, time: 0.104, data: 0.011) loss: 0.016 
(epoch: 68, iters: 304, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 68, iters: 384, time: 0.103, data: 0.000) loss: 0.007 
(epoch: 68, iters: 464, time: 0.105, data: 0.038) loss: 0.009 
(epoch: 68, iters: 544, time: 0.105, data: 0.000) loss: 0.050 
(epoch: 68, iters: 624, time: 0.103, data: 0.011) loss: 0.079 
(epoch: 68, iters: 704, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 68, iters: 784, time: 0.104, data: 0.012) loss: 0.025 
(epoch: 68, iters: 864, time: 0.105, data: 0.000) loss: 0.031 
(epoch: 68, iters: 944, time: 0.104, data: 0.000) loss: 0.013 
(epoch: 68, iters: 1024, time: 0.106, data: 0.040) loss: 0.008 
(epoch: 68, iters: 1104, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 68, iters: 1184, time: 0.104, data: 0.011) loss: 0.008 
(epoch: 68, iters: 1264, time: 0.105, data: 0.000) loss: 0.111 
(epoch: 68, iters: 1344, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 68, iters: 1424, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 68, iters: 1504, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 68, iters: 1584, time: 0.106, data: 0.038) loss: 0.005 
(epoch: 68, iters: 1664, time: 0.106, data: 0.000) loss: 0.073 
(epoch: 68, iters: 1744, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 68, iters: 1824, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 68, iters: 1904, time: 0.105, data: 0.012) loss: 0.006 
(epoch: 68, iters: 1984, time: 0.105, data: 0.000) loss: 0.053 
(epoch: 68, iters: 2064, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 68, iters: 2144, time: 0.104, data: 0.038) loss: 0.001 
(epoch: 68, iters: 2224, time: 0.106, data: 0.000) loss: 0.074 
(epoch: 68, iters: 2304, time: 0.103, data: 0.011) loss: 0.024 
(epoch: 68, iters: 2384, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 68, iters: 2464, time: 0.105, data: 0.012) loss: 0.440 
(epoch: 68, iters: 2544, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 68, iters: 2624, time: 0.104, data: 0.000) loss: 0.018 
(epoch: 68, iters: 2704, time: 0.105, data: 0.038) loss: 0.107 
(epoch: 68, iters: 2784, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 68, iters: 2864, time: 0.102, data: 0.011) loss: 0.010 
(epoch: 68, iters: 2944, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 68, iters: 3024, time: 0.105, data: 0.012) loss: 0.053 
(epoch: 68, iters: 3104, time: 0.106, data: 0.000) loss: 0.100 
(epoch: 68, iters: 3184, time: 0.104, data: 0.000) loss: 0.014 
(epoch: 68, iters: 3264, time: 0.106, data: 0.039) loss: 0.060 
(epoch: 68, iters: 3344, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 68, iters: 3424, time: 0.102, data: 0.012) loss: 0.008 
(epoch: 68, iters: 3504, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 68, iters: 3584, time: 0.105, data: 0.011) loss: 0.014 
(epoch: 68, iters: 3664, time: 0.100, data: 0.000) loss: 0.014 
saving the model at the end of epoch 68, iters 253504
End of epoch 68 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 68, TEST ACC: [94.234 %]

(epoch: 69, iters: 16, time: 0.119, data: 0.000) loss: 0.006 
saving the latest model (epoch 69, total_steps 253520)
(epoch: 69, iters: 96, time: 0.105, data: 0.011) loss: 0.009 
(epoch: 69, iters: 176, time: 0.103, data: 0.012) loss: 0.032 
(epoch: 69, iters: 256, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 69, iters: 336, time: 0.105, data: 0.011) loss: 0.011 
(epoch: 69, iters: 416, time: 0.105, data: 0.000) loss: 0.114 
(epoch: 69, iters: 496, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 69, iters: 576, time: 0.107, data: 0.039) loss: 0.111 
(epoch: 69, iters: 656, time: 0.107, data: 0.000) loss: 0.023 
(epoch: 69, iters: 736, time: 0.103, data: 0.011) loss: 0.099 
(epoch: 69, iters: 816, time: 0.104, data: 0.000) loss: 0.012 
(epoch: 69, iters: 896, time: 0.105, data: 0.011) loss: 0.098 
(epoch: 69, iters: 976, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 69, iters: 1056, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 69, iters: 1136, time: 0.105, data: 0.048) loss: 0.304 
(epoch: 69, iters: 1216, time: 0.106, data: 0.000) loss: 0.065 
(epoch: 69, iters: 1296, time: 0.102, data: 0.011) loss: 0.013 
(epoch: 69, iters: 1376, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 69, iters: 1456, time: 0.104, data: 0.011) loss: 0.019 
(epoch: 69, iters: 1536, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 69, iters: 1616, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 69, iters: 1696, time: 0.104, data: 0.038) loss: 0.065 
(epoch: 69, iters: 1776, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 69, iters: 1856, time: 0.103, data: 0.011) loss: 0.007 
(epoch: 69, iters: 1936, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 69, iters: 2016, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 69, iters: 2096, time: 0.105, data: 0.000) loss: 0.031 
(epoch: 69, iters: 2176, time: 0.103, data: 0.000) loss: 0.053 
(epoch: 69, iters: 2256, time: 0.106, data: 0.038) loss: 0.027 
(epoch: 69, iters: 2336, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 69, iters: 2416, time: 0.102, data: 0.012) loss: 0.076 
(epoch: 69, iters: 2496, time: 0.104, data: 0.000) loss: 0.014 
(epoch: 69, iters: 2576, time: 0.104, data: 0.011) loss: 0.102 
(epoch: 69, iters: 2656, time: 0.105, data: 0.000) loss: 0.022 
(epoch: 69, iters: 2736, time: 0.104, data: 0.000) loss: 0.146 
(epoch: 69, iters: 2816, time: 0.105, data: 0.039) loss: 0.004 
(epoch: 69, iters: 2896, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 69, iters: 2976, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 69, iters: 3056, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 69, iters: 3136, time: 0.105, data: 0.012) loss: 0.058 
(epoch: 69, iters: 3216, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 69, iters: 3296, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 69, iters: 3376, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 69, iters: 3456, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 69, iters: 3536, time: 0.102, data: 0.011) loss: 0.007 
(epoch: 69, iters: 3616, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 69, iters: 3696, time: 0.100, data: 0.011) loss: 0.022 
saving the model at the end of epoch 69, iters 257232
End of epoch 69 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 69, TEST ACC: [95.296 %]

saving the latest model (epoch 70, total_steps 257248)
(epoch: 70, iters: 48, time: 0.107, data: 0.000) loss: 0.014 
(epoch: 70, iters: 128, time: 0.103, data: 0.000) loss: 0.002 
(epoch: 70, iters: 208, time: 0.105, data: 0.038) loss: 0.003 
(epoch: 70, iters: 288, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 70, iters: 368, time: 0.102, data: 0.012) loss: 0.007 
(epoch: 70, iters: 448, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 70, iters: 528, time: 0.105, data: 0.012) loss: 0.081 
(epoch: 70, iters: 608, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 70, iters: 688, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 70, iters: 768, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 70, iters: 848, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 70, iters: 928, time: 0.103, data: 0.011) loss: 0.014 
(epoch: 70, iters: 1008, time: 0.105, data: 0.000) loss: 0.020 
(epoch: 70, iters: 1088, time: 0.104, data: 0.011) loss: 0.219 
(epoch: 70, iters: 1168, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 70, iters: 1248, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 70, iters: 1328, time: 0.105, data: 0.048) loss: 0.061 
(epoch: 70, iters: 1408, time: 0.106, data: 0.000) loss: 0.038 
(epoch: 70, iters: 1488, time: 0.102, data: 0.011) loss: 0.004 
(epoch: 70, iters: 1568, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 70, iters: 1648, time: 0.104, data: 0.011) loss: 0.010 
(epoch: 70, iters: 1728, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 70, iters: 1808, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 70, iters: 1888, time: 0.105, data: 0.038) loss: 0.025 
(epoch: 70, iters: 1968, time: 0.106, data: 0.000) loss: 0.137 
(epoch: 70, iters: 2048, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 70, iters: 2128, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 70, iters: 2208, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 70, iters: 2288, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 70, iters: 2368, time: 0.103, data: 0.000) loss: 0.003 
(epoch: 70, iters: 2448, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 70, iters: 2528, time: 0.105, data: 0.000) loss: 0.279 
(epoch: 70, iters: 2608, time: 0.105, data: 0.000) loss: 0.203 
(epoch: 70, iters: 2688, time: 0.104, data: 0.042) loss: 0.405 
(epoch: 70, iters: 2768, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 70, iters: 2848, time: 0.102, data: 0.011) loss: 0.039 
(epoch: 70, iters: 2928, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 70, iters: 3008, time: 0.104, data: 0.012) loss: 0.099 
(epoch: 70, iters: 3088, time: 0.105, data: 0.000) loss: 0.020 
(epoch: 70, iters: 3168, time: 0.104, data: 0.000) loss: 0.029 
(epoch: 70, iters: 3248, time: 0.105, data: 0.039) loss: 0.024 
(epoch: 70, iters: 3328, time: 0.105, data: 0.000) loss: 0.107 
(epoch: 70, iters: 3408, time: 0.103, data: 0.012) loss: 0.024 
(epoch: 70, iters: 3488, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 70, iters: 3568, time: 0.105, data: 0.012) loss: 0.022 
(epoch: 70, iters: 3648, time: 0.100, data: 0.000) loss: 0.301 
(epoch: 70, iters: 3728, time: 0.065, data: 0.000) loss: 0.007 
saving the model at the end of epoch 70, iters 260960
End of epoch 70 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 70, TEST ACC: [95.903 %]

saving the latest model (epoch 71, total_steps 260976)
(epoch: 71, iters: 80, time: 0.106, data: 0.460) loss: 0.024 
(epoch: 71, iters: 160, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 71, iters: 240, time: 0.106, data: 0.038) loss: 0.005 
(epoch: 71, iters: 320, time: 0.105, data: 0.000) loss: 0.082 
(epoch: 71, iters: 400, time: 0.103, data: 0.012) loss: 0.004 
(epoch: 71, iters: 480, time: 0.104, data: 0.000) loss: 0.005 
(epoch: 71, iters: 560, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 71, iters: 640, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 71, iters: 720, time: 0.104, data: 0.000) loss: 0.087 
(epoch: 71, iters: 800, time: 0.105, data: 0.038) loss: 0.064 
(epoch: 71, iters: 880, time: 0.105, data: 0.000) loss: 0.111 
(epoch: 71, iters: 960, time: 0.102, data: 0.011) loss: 0.199 
(epoch: 71, iters: 1040, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 71, iters: 1120, time: 0.105, data: 0.011) loss: 0.006 
(epoch: 71, iters: 1200, time: 0.107, data: 0.000) loss: 0.011 
(epoch: 71, iters: 1280, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 71, iters: 1360, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 71, iters: 1440, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 71, iters: 1520, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 71, iters: 1600, time: 0.107, data: 0.000) loss: 0.006 
(epoch: 71, iters: 1680, time: 0.104, data: 0.011) loss: 0.011 
(epoch: 71, iters: 1760, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 71, iters: 1840, time: 0.104, data: 0.000) loss: 0.093 
(epoch: 71, iters: 1920, time: 0.104, data: 0.047) loss: 0.077 
(epoch: 71, iters: 2000, time: 0.105, data: 0.000) loss: 0.026 
(epoch: 71, iters: 2080, time: 0.102, data: 0.012) loss: 0.069 
(epoch: 71, iters: 2160, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 71, iters: 2240, time: 0.104, data: 0.011) loss: 0.028 
(epoch: 71, iters: 2320, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 71, iters: 2400, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 71, iters: 2480, time: 0.104, data: 0.038) loss: 0.044 
(epoch: 71, iters: 2560, time: 0.105, data: 0.000) loss: 0.443 
(epoch: 71, iters: 2640, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 71, iters: 2720, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 71, iters: 2800, time: 0.105, data: 0.012) loss: 0.028 
(epoch: 71, iters: 2880, time: 0.107, data: 0.000) loss: 0.433 
(epoch: 71, iters: 2960, time: 0.105, data: 0.000) loss: 0.468 
(epoch: 71, iters: 3040, time: 0.105, data: 0.039) loss: 0.328 
(epoch: 71, iters: 3120, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 71, iters: 3200, time: 0.103, data: 0.011) loss: 0.032 
(epoch: 71, iters: 3280, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 71, iters: 3360, time: 0.104, data: 0.011) loss: 0.232 
(epoch: 71, iters: 3440, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 71, iters: 3520, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 71, iters: 3600, time: 0.104, data: 0.038) loss: 0.002 
(epoch: 71, iters: 3680, time: 0.099, data: 0.000) loss: 0.072 
saving the model at the end of epoch 71, iters 264688
End of epoch 71 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 71, TEST ACC: [92.868 %]

saving the latest model (epoch 72, total_steps 264704)
(epoch: 72, iters: 32, time: 0.098, data: 0.004) loss: 0.001 
(epoch: 72, iters: 112, time: 0.104, data: 0.025) loss: 0.132 
(epoch: 72, iters: 192, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 72, iters: 272, time: 0.104, data: 0.000) loss: 0.009 
(epoch: 72, iters: 352, time: 0.106, data: 0.039) loss: 0.051 
(epoch: 72, iters: 432, time: 0.107, data: 0.000) loss: 0.200 
(epoch: 72, iters: 512, time: 0.103, data: 0.012) loss: 0.004 
(epoch: 72, iters: 592, time: 0.105, data: 0.000) loss: 0.022 
(epoch: 72, iters: 672, time: 0.104, data: 0.012) loss: 0.069 
(epoch: 72, iters: 752, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 72, iters: 832, time: 0.104, data: 0.000) loss: 0.072 
(epoch: 72, iters: 912, time: 0.105, data: 0.038) loss: 0.016 
(epoch: 72, iters: 992, time: 0.105, data: 0.000) loss: 0.141 
(epoch: 72, iters: 1072, time: 0.104, data: 0.012) loss: 0.002 
(epoch: 72, iters: 1152, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 72, iters: 1232, time: 0.105, data: 0.012) loss: 0.251 
(epoch: 72, iters: 1312, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 72, iters: 1392, time: 0.105, data: 0.000) loss: 0.042 
(epoch: 72, iters: 1472, time: 0.106, data: 0.040) loss: 0.016 
(epoch: 72, iters: 1552, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 72, iters: 1632, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 72, iters: 1712, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 72, iters: 1792, time: 0.104, data: 0.011) loss: 0.012 
(epoch: 72, iters: 1872, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 72, iters: 1952, time: 0.103, data: 0.000) loss: 0.005 
(epoch: 72, iters: 2032, time: 0.105, data: 0.038) loss: 0.014 
(epoch: 72, iters: 2112, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 72, iters: 2192, time: 0.104, data: 0.012) loss: 0.013 
(epoch: 72, iters: 2272, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 72, iters: 2352, time: 0.105, data: 0.011) loss: 0.038 
(epoch: 72, iters: 2432, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 72, iters: 2512, time: 0.104, data: 0.000) loss: 0.070 
(epoch: 72, iters: 2592, time: 0.106, data: 0.039) loss: 0.062 
(epoch: 72, iters: 2672, time: 0.105, data: 0.000) loss: 0.123 
(epoch: 72, iters: 2752, time: 0.103, data: 0.012) loss: 0.019 
(epoch: 72, iters: 2832, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 72, iters: 2912, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 72, iters: 2992, time: 0.106, data: 0.000) loss: 0.189 
(epoch: 72, iters: 3072, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 72, iters: 3152, time: 0.106, data: 0.038) loss: 0.032 
(epoch: 72, iters: 3232, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 72, iters: 3312, time: 0.103, data: 0.012) loss: 0.170 
(epoch: 72, iters: 3392, time: 0.105, data: 0.000) loss: 0.019 
(epoch: 72, iters: 3472, time: 0.105, data: 0.011) loss: 0.065 
(epoch: 72, iters: 3552, time: 0.106, data: 0.000) loss: 0.516 
(epoch: 72, iters: 3632, time: 0.102, data: 0.000) loss: 0.007 
(epoch: 72, iters: 3712, time: 0.100, data: 0.043) loss: 0.074 
saving the model at the end of epoch 72, iters 268416
End of epoch 72 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 72, TEST ACC: [90.592 %]

saving the latest model (epoch 73, total_steps 268432)
(epoch: 73, iters: 64, time: 0.104, data: 0.000) loss: 0.038 
(epoch: 73, iters: 144, time: 0.104, data: 0.000) loss: 0.153 
(epoch: 73, iters: 224, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 73, iters: 304, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 73, iters: 384, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 73, iters: 464, time: 0.104, data: 0.040) loss: 0.080 
(epoch: 73, iters: 544, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 73, iters: 624, time: 0.103, data: 0.011) loss: 0.011 
(epoch: 73, iters: 704, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 73, iters: 784, time: 0.104, data: 0.011) loss: 0.011 
(epoch: 73, iters: 864, time: 0.106, data: 0.000) loss: 0.017 
(epoch: 73, iters: 944, time: 0.104, data: 0.000) loss: 0.021 
(epoch: 73, iters: 1024, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 73, iters: 1104, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 73, iters: 1184, time: 0.104, data: 0.012) loss: 0.005 
(epoch: 73, iters: 1264, time: 0.105, data: 0.000) loss: 0.169 
(epoch: 73, iters: 1344, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 73, iters: 1424, time: 0.107, data: 0.000) loss: 0.006 
(epoch: 73, iters: 1504, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 73, iters: 1584, time: 0.105, data: 0.038) loss: 0.012 
(epoch: 73, iters: 1664, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 73, iters: 1744, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 73, iters: 1824, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 73, iters: 1904, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 73, iters: 1984, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 73, iters: 2064, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 73, iters: 2144, time: 0.106, data: 0.038) loss: 0.105 
(epoch: 73, iters: 2224, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 73, iters: 2304, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 73, iters: 2384, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 73, iters: 2464, time: 0.105, data: 0.011) loss: 0.039 
(epoch: 73, iters: 2544, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 73, iters: 2624, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 73, iters: 2704, time: 0.105, data: 0.039) loss: 0.013 
(epoch: 73, iters: 2784, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 73, iters: 2864, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 73, iters: 2944, time: 0.106, data: 0.000) loss: 0.018 
(epoch: 73, iters: 3024, time: 0.104, data: 0.011) loss: 0.011 
(epoch: 73, iters: 3104, time: 0.107, data: 0.000) loss: 0.127 
(epoch: 73, iters: 3184, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 73, iters: 3264, time: 0.105, data: 0.048) loss: 0.003 
(epoch: 73, iters: 3344, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 73, iters: 3424, time: 0.102, data: 0.012) loss: 0.001 
(epoch: 73, iters: 3504, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 73, iters: 3584, time: 0.105, data: 0.011) loss: 0.412 
(epoch: 73, iters: 3664, time: 0.100, data: 0.000) loss: 0.016 
saving the model at the end of epoch 73, iters 272144
End of epoch 73 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 73, TEST ACC: [93.475 %]

(epoch: 74, iters: 16, time: 0.120, data: 0.000) loss: 0.027 
saving the latest model (epoch 74, total_steps 272160)
(epoch: 74, iters: 96, time: 0.106, data: 0.012) loss: 0.003 
(epoch: 74, iters: 176, time: 0.102, data: 0.012) loss: 0.002 
(epoch: 74, iters: 256, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 74, iters: 336, time: 0.104, data: 0.012) loss: 0.012 
(epoch: 74, iters: 416, time: 0.106, data: 0.000) loss: 0.018 
(epoch: 74, iters: 496, time: 0.104, data: 0.000) loss: 0.075 
(epoch: 74, iters: 576, time: 0.105, data: 0.039) loss: 0.005 
(epoch: 74, iters: 656, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 74, iters: 736, time: 0.102, data: 0.012) loss: 0.003 
(epoch: 74, iters: 816, time: 0.105, data: 0.000) loss: 0.051 
(epoch: 74, iters: 896, time: 0.104, data: 0.012) loss: 0.006 
(epoch: 74, iters: 976, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 74, iters: 1056, time: 0.105, data: 0.000) loss: 0.023 
(epoch: 74, iters: 1136, time: 0.106, data: 0.039) loss: 0.005 
(epoch: 74, iters: 1216, time: 0.107, data: 0.000) loss: 0.021 
(epoch: 74, iters: 1296, time: 0.103, data: 0.011) loss: 0.013 
(epoch: 74, iters: 1376, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 74, iters: 1456, time: 0.105, data: 0.020) loss: 0.026 
(epoch: 74, iters: 1536, time: 0.107, data: 0.000) loss: 0.006 
(epoch: 74, iters: 1616, time: 0.104, data: 0.000) loss: 0.010 
(epoch: 74, iters: 1696, time: 0.104, data: 0.048) loss: 0.002 
(epoch: 74, iters: 1776, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 74, iters: 1856, time: 0.104, data: 0.011) loss: 0.276 
(epoch: 74, iters: 1936, time: 0.105, data: 0.000) loss: 0.025 
(epoch: 74, iters: 2016, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 74, iters: 2096, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 74, iters: 2176, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 74, iters: 2256, time: 0.105, data: 0.038) loss: 0.030 
(epoch: 74, iters: 2336, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 74, iters: 2416, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 74, iters: 2496, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 74, iters: 2576, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 74, iters: 2656, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 74, iters: 2736, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 74, iters: 2816, time: 0.105, data: 0.039) loss: 0.076 
(epoch: 74, iters: 2896, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 74, iters: 2976, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 74, iters: 3056, time: 0.106, data: 0.000) loss: 0.023 
(epoch: 74, iters: 3136, time: 0.104, data: 0.011) loss: 0.128 
(epoch: 74, iters: 3216, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 74, iters: 3296, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 74, iters: 3376, time: 0.105, data: 0.039) loss: 0.457 
(epoch: 74, iters: 3456, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 74, iters: 3536, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 74, iters: 3616, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 74, iters: 3696, time: 0.099, data: 0.011) loss: 0.005 
saving the model at the end of epoch 74, iters 275872
End of epoch 74 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 74, TEST ACC: [90.895 %]

saving the latest model (epoch 75, total_steps 275888)
(epoch: 75, iters: 48, time: 0.103, data: 0.000) loss: 0.004 
(epoch: 75, iters: 128, time: 0.105, data: 0.025) loss: 0.003 
(epoch: 75, iters: 208, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 75, iters: 288, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 75, iters: 368, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 75, iters: 448, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 75, iters: 528, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 75, iters: 608, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 75, iters: 688, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 75, iters: 768, time: 0.106, data: 0.000) loss: 0.028 
(epoch: 75, iters: 848, time: 0.104, data: 0.012) loss: 0.195 
(epoch: 75, iters: 928, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 75, iters: 1008, time: 0.104, data: 0.011) loss: 0.019 
(epoch: 75, iters: 1088, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 75, iters: 1168, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 75, iters: 1248, time: 0.105, data: 0.038) loss: 0.009 
(epoch: 75, iters: 1328, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 75, iters: 1408, time: 0.102, data: 0.012) loss: 0.000 
(epoch: 75, iters: 1488, time: 0.105, data: 0.000) loss: 0.029 
(epoch: 75, iters: 1568, time: 0.105, data: 0.011) loss: 0.008 
(epoch: 75, iters: 1648, time: 0.105, data: 0.000) loss: 0.071 
(epoch: 75, iters: 1728, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 75, iters: 1808, time: 0.104, data: 0.039) loss: 0.016 
(epoch: 75, iters: 1888, time: 0.105, data: 0.000) loss: 0.069 
(epoch: 75, iters: 1968, time: 0.103, data: 0.011) loss: 0.050 
(epoch: 75, iters: 2048, time: 0.104, data: 0.000) loss: 0.037 
(epoch: 75, iters: 2128, time: 0.104, data: 0.011) loss: 0.026 
(epoch: 75, iters: 2208, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 75, iters: 2288, time: 0.104, data: 0.000) loss: 0.005 
(epoch: 75, iters: 2368, time: 0.105, data: 0.039) loss: 0.005 
(epoch: 75, iters: 2448, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 75, iters: 2528, time: 0.102, data: 0.012) loss: 0.255 
(epoch: 75, iters: 2608, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 75, iters: 2688, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 75, iters: 2768, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 75, iters: 2848, time: 0.104, data: 0.000) loss: 0.035 
(epoch: 75, iters: 2928, time: 0.105, data: 0.046) loss: 0.005 
(epoch: 75, iters: 3008, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 75, iters: 3088, time: 0.104, data: 0.011) loss: 0.012 
(epoch: 75, iters: 3168, time: 0.105, data: 0.000) loss: 0.068 
(epoch: 75, iters: 3248, time: 0.103, data: 0.011) loss: 0.013 
(epoch: 75, iters: 3328, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 75, iters: 3408, time: 0.103, data: 0.000) loss: 0.019 
(epoch: 75, iters: 3488, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 75, iters: 3568, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 75, iters: 3648, time: 0.098, data: 0.012) loss: 0.003 
(epoch: 75, iters: 3728, time: 0.066, data: 0.000) loss: 0.001 
saving the model at the end of epoch 75, iters 279600
End of epoch 75 / 2100 	 Time Taken: 392 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 75, TEST ACC: [89.53 %]

saving the latest model (epoch 76, total_steps 279616)
(epoch: 76, iters: 80, time: 0.105, data: 0.496) loss: 0.337 
(epoch: 76, iters: 160, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 76, iters: 240, time: 0.105, data: 0.039) loss: 0.013 
(epoch: 76, iters: 320, time: 0.105, data: 0.000) loss: 0.025 
(epoch: 76, iters: 400, time: 0.102, data: 0.012) loss: 0.004 
(epoch: 76, iters: 480, time: 0.105, data: 0.000) loss: 0.023 
(epoch: 76, iters: 560, time: 0.105, data: 0.012) loss: 0.004 
(epoch: 76, iters: 640, time: 0.106, data: 0.000) loss: 0.228 
(epoch: 76, iters: 720, time: 0.104, data: 0.000) loss: 0.067 
(epoch: 76, iters: 800, time: 0.105, data: 0.047) loss: 0.005 
(epoch: 76, iters: 880, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 76, iters: 960, time: 0.102, data: 0.012) loss: 0.021 
(epoch: 76, iters: 1040, time: 0.105, data: 0.000) loss: 0.158 
(epoch: 76, iters: 1120, time: 0.104, data: 0.011) loss: 0.239 
(epoch: 76, iters: 1200, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 76, iters: 1280, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 76, iters: 1360, time: 0.106, data: 0.038) loss: 0.054 
(epoch: 76, iters: 1440, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 76, iters: 1520, time: 0.103, data: 0.011) loss: 0.150 
(epoch: 76, iters: 1600, time: 0.105, data: 0.000) loss: 0.032 
(epoch: 76, iters: 1680, time: 0.104, data: 0.011) loss: 0.013 
(epoch: 76, iters: 1760, time: 0.106, data: 0.000) loss: 0.062 
(epoch: 76, iters: 1840, time: 0.104, data: 0.000) loss: 0.012 
(epoch: 76, iters: 1920, time: 0.104, data: 0.038) loss: 0.006 
(epoch: 76, iters: 2000, time: 0.106, data: 0.000) loss: 0.137 
(epoch: 76, iters: 2080, time: 0.103, data: 0.011) loss: 0.018 
(epoch: 76, iters: 2160, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 76, iters: 2240, time: 0.103, data: 0.011) loss: 0.023 
(epoch: 76, iters: 2320, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 76, iters: 2400, time: 0.104, data: 0.000) loss: 0.055 
(epoch: 76, iters: 2480, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 76, iters: 2560, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 76, iters: 2640, time: 0.102, data: 0.012) loss: 0.242 
(epoch: 76, iters: 2720, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 76, iters: 2800, time: 0.104, data: 0.011) loss: 0.015 
(epoch: 76, iters: 2880, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 76, iters: 2960, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 76, iters: 3040, time: 0.104, data: 0.047) loss: 0.015 
(epoch: 76, iters: 3120, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 76, iters: 3200, time: 0.102, data: 0.011) loss: 0.174 
(epoch: 76, iters: 3280, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 76, iters: 3360, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 76, iters: 3440, time: 0.105, data: 0.000) loss: 0.299 
(epoch: 76, iters: 3520, time: 0.104, data: 0.000) loss: 0.018 
(epoch: 76, iters: 3600, time: 0.105, data: 0.047) loss: 0.115 
(epoch: 76, iters: 3680, time: 0.100, data: 0.000) loss: 0.004 
saving the model at the end of epoch 76, iters 283328
End of epoch 76 / 2100 	 Time Taken: 392 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 76, TEST ACC: [91.958 %]

saving the latest model (epoch 77, total_steps 283344)
(epoch: 77, iters: 32, time: 0.100, data: 0.004) loss: 0.001 
(epoch: 77, iters: 112, time: 0.104, data: 0.012) loss: 0.025 
(epoch: 77, iters: 192, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 77, iters: 272, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 77, iters: 352, time: 0.106, data: 0.039) loss: 0.005 
(epoch: 77, iters: 432, time: 0.105, data: 0.000) loss: 0.050 
(epoch: 77, iters: 512, time: 0.102, data: 0.012) loss: 0.004 
(epoch: 77, iters: 592, time: 0.105, data: 0.000) loss: 0.025 
(epoch: 77, iters: 672, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 77, iters: 752, time: 0.106, data: 0.000) loss: 0.019 
(epoch: 77, iters: 832, time: 0.104, data: 0.000) loss: 0.032 
(epoch: 77, iters: 912, time: 0.105, data: 0.047) loss: 0.020 
(epoch: 77, iters: 992, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 77, iters: 1072, time: 0.102, data: 0.011) loss: 0.106 
(epoch: 77, iters: 1152, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 77, iters: 1232, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 77, iters: 1312, time: 0.105, data: 0.000) loss: 0.143 
(epoch: 77, iters: 1392, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 77, iters: 1472, time: 0.105, data: 0.038) loss: 0.139 
(epoch: 77, iters: 1552, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 77, iters: 1632, time: 0.103, data: 0.012) loss: 0.007 
(epoch: 77, iters: 1712, time: 0.105, data: 0.000) loss: 0.131 
(epoch: 77, iters: 1792, time: 0.104, data: 0.011) loss: 0.020 
(epoch: 77, iters: 1872, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 77, iters: 1952, time: 0.104, data: 0.000) loss: 0.009 
(epoch: 77, iters: 2032, time: 0.105, data: 0.038) loss: 0.091 
(epoch: 77, iters: 2112, time: 0.106, data: 0.000) loss: 0.040 
(epoch: 77, iters: 2192, time: 0.103, data: 0.011) loss: 0.048 
(epoch: 77, iters: 2272, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 77, iters: 2352, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 77, iters: 2432, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 77, iters: 2512, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 77, iters: 2592, time: 0.106, data: 0.039) loss: 0.003 
(epoch: 77, iters: 2672, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 77, iters: 2752, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 77, iters: 2832, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 77, iters: 2912, time: 0.105, data: 0.011) loss: 0.029 
(epoch: 77, iters: 2992, time: 0.107, data: 0.000) loss: 0.084 
(epoch: 77, iters: 3072, time: 0.104, data: 0.000) loss: 0.072 
(epoch: 77, iters: 3152, time: 0.105, data: 0.047) loss: 0.011 
(epoch: 77, iters: 3232, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 77, iters: 3312, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 77, iters: 3392, time: 0.105, data: 0.000) loss: 0.128 
(epoch: 77, iters: 3472, time: 0.103, data: 0.011) loss: 0.023 
(epoch: 77, iters: 3552, time: 0.106, data: 0.000) loss: 0.244 
(epoch: 77, iters: 3632, time: 0.103, data: 0.000) loss: 0.043 
(epoch: 77, iters: 3712, time: 0.100, data: 0.036) loss: 0.000 
saving the model at the end of epoch 77, iters 287056
End of epoch 77 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 77, TEST ACC: [92.564 %]

saving the latest model (epoch 78, total_steps 287072)
(epoch: 78, iters: 64, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 78, iters: 144, time: 0.105, data: 0.025) loss: 0.011 
(epoch: 78, iters: 224, time: 0.105, data: 0.000) loss: 0.031 
(epoch: 78, iters: 304, time: 0.103, data: 0.011) loss: 0.008 
(epoch: 78, iters: 384, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 78, iters: 464, time: 0.104, data: 0.011) loss: 0.013 
(epoch: 78, iters: 544, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 78, iters: 624, time: 0.103, data: 0.000) loss: 0.005 
(epoch: 78, iters: 704, time: 0.104, data: 0.038) loss: 0.012 
(epoch: 78, iters: 784, time: 0.104, data: 0.000) loss: 0.106 
(epoch: 78, iters: 864, time: 0.103, data: 0.011) loss: 0.046 
(epoch: 78, iters: 944, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 78, iters: 1024, time: 0.103, data: 0.012) loss: 0.007 
(epoch: 78, iters: 1104, time: 0.105, data: 0.000) loss: 0.125 
(epoch: 78, iters: 1184, time: 0.105, data: 0.000) loss: 0.220 
(epoch: 78, iters: 1264, time: 0.104, data: 0.038) loss: 0.582 
(epoch: 78, iters: 1344, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 78, iters: 1424, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 78, iters: 1504, time: 0.105, data: 0.000) loss: 0.039 
(epoch: 78, iters: 1584, time: 0.103, data: 0.011) loss: 0.057 
(epoch: 78, iters: 1664, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 78, iters: 1744, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 78, iters: 1824, time: 0.105, data: 0.039) loss: 0.028 
(epoch: 78, iters: 1904, time: 0.106, data: 0.000) loss: 0.019 
(epoch: 78, iters: 1984, time: 0.102, data: 0.011) loss: 0.006 
(epoch: 78, iters: 2064, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 78, iters: 2144, time: 0.104, data: 0.020) loss: 0.042 
(epoch: 78, iters: 2224, time: 0.106, data: 0.000) loss: 0.028 
(epoch: 78, iters: 2304, time: 0.103, data: 0.000) loss: 0.127 
(epoch: 78, iters: 2384, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 78, iters: 2464, time: 0.106, data: 0.000) loss: 0.078 
(epoch: 78, iters: 2544, time: 0.103, data: 0.011) loss: 0.158 
(epoch: 78, iters: 2624, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 78, iters: 2704, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 78, iters: 2784, time: 0.105, data: 0.000) loss: 0.025 
(epoch: 78, iters: 2864, time: 0.104, data: 0.000) loss: 0.328 
(epoch: 78, iters: 2944, time: 0.104, data: 0.038) loss: 0.003 
(epoch: 78, iters: 3024, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 78, iters: 3104, time: 0.103, data: 0.011) loss: 0.033 
(epoch: 78, iters: 3184, time: 0.105, data: 0.000) loss: 0.131 
(epoch: 78, iters: 3264, time: 0.105, data: 0.011) loss: 0.070 
(epoch: 78, iters: 3344, time: 0.106, data: 0.000) loss: 0.115 
(epoch: 78, iters: 3424, time: 0.103, data: 0.000) loss: 0.002 
(epoch: 78, iters: 3504, time: 0.104, data: 0.038) loss: 0.002 
(epoch: 78, iters: 3584, time: 0.105, data: 0.000) loss: 0.134 
(epoch: 78, iters: 3664, time: 0.098, data: 0.011) loss: 0.002 
saving the model at the end of epoch 78, iters 290784
End of epoch 78 / 2100 	 Time Taken: 392 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 78, TEST ACC: [89.833 %]

(epoch: 79, iters: 16, time: 0.119, data: 0.012) loss: 0.191 
saving the latest model (epoch 79, total_steps 290800)
(epoch: 79, iters: 96, time: 0.105, data: 0.055) loss: 0.001 
(epoch: 79, iters: 176, time: 0.105, data: 0.000) loss: 0.077 
(epoch: 79, iters: 256, time: 0.104, data: 0.011) loss: 0.009 
(epoch: 79, iters: 336, time: 0.104, data: 0.000) loss: 0.060 
(epoch: 79, iters: 416, time: 0.104, data: 0.011) loss: 0.027 
(epoch: 79, iters: 496, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 79, iters: 576, time: 0.103, data: 0.000) loss: 0.003 
(epoch: 79, iters: 656, time: 0.104, data: 0.039) loss: 0.004 
(epoch: 79, iters: 736, time: 0.105, data: 0.000) loss: 0.024 
(epoch: 79, iters: 816, time: 0.103, data: 0.012) loss: 0.004 
(epoch: 79, iters: 896, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 79, iters: 976, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 79, iters: 1056, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 79, iters: 1136, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 79, iters: 1216, time: 0.106, data: 0.038) loss: 0.021 
(epoch: 79, iters: 1296, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 79, iters: 1376, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 79, iters: 1456, time: 0.104, data: 0.000) loss: 0.025 
(epoch: 79, iters: 1536, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 79, iters: 1616, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 79, iters: 1696, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 79, iters: 1776, time: 0.105, data: 0.038) loss: 0.010 
(epoch: 79, iters: 1856, time: 0.105, data: 0.000) loss: 0.056 
(epoch: 79, iters: 1936, time: 0.103, data: 0.011) loss: 0.005 
(epoch: 79, iters: 2016, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 79, iters: 2096, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 79, iters: 2176, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 79, iters: 2256, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 79, iters: 2336, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 79, iters: 2416, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 79, iters: 2496, time: 0.103, data: 0.011) loss: 0.010 
(epoch: 79, iters: 2576, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 79, iters: 2656, time: 0.104, data: 0.012) loss: 0.002 
(epoch: 79, iters: 2736, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 79, iters: 2816, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 79, iters: 2896, time: 0.106, data: 0.039) loss: 0.043 
(epoch: 79, iters: 2976, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 79, iters: 3056, time: 0.102, data: 0.011) loss: 0.032 
(epoch: 79, iters: 3136, time: 0.105, data: 0.000) loss: 0.099 
(epoch: 79, iters: 3216, time: 0.105, data: 0.011) loss: 0.007 
(epoch: 79, iters: 3296, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 79, iters: 3376, time: 0.104, data: 0.000) loss: 0.012 
(epoch: 79, iters: 3456, time: 0.104, data: 0.046) loss: 0.020 
(epoch: 79, iters: 3536, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 79, iters: 3616, time: 0.104, data: 0.020) loss: 0.003 
(epoch: 79, iters: 3696, time: 0.099, data: 0.000) loss: 0.002 
saving the model at the end of epoch 79, iters 294512
End of epoch 79 / 2100 	 Time Taken: 392 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 79, TEST ACC: [96.662 %]

saving the latest model (epoch 80, total_steps 294528)
(epoch: 80, iters: 48, time: 0.106, data: 0.004) loss: 0.001 
(epoch: 80, iters: 128, time: 0.105, data: 0.025) loss: 0.001 
(epoch: 80, iters: 208, time: 0.102, data: 0.012) loss: 0.001 
(epoch: 80, iters: 288, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 80, iters: 368, time: 0.105, data: 0.020) loss: 0.004 
(epoch: 80, iters: 448, time: 0.105, data: 0.000) loss: 0.072 
(epoch: 80, iters: 528, time: 0.103, data: 0.000) loss: 0.004 
(epoch: 80, iters: 608, time: 0.105, data: 0.048) loss: 0.005 
(epoch: 80, iters: 688, time: 0.105, data: 0.000) loss: 0.019 
(epoch: 80, iters: 768, time: 0.103, data: 0.012) loss: 0.003 
(epoch: 80, iters: 848, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 80, iters: 928, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 80, iters: 1008, time: 0.105, data: 0.000) loss: 0.018 
(epoch: 80, iters: 1088, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 80, iters: 1168, time: 0.106, data: 0.038) loss: 0.004 
(epoch: 80, iters: 1248, time: 0.104, data: 0.000) loss: 0.014 
(epoch: 80, iters: 1328, time: 0.103, data: 0.012) loss: 0.004 
(epoch: 80, iters: 1408, time: 0.104, data: 0.000) loss: 0.033 
(epoch: 80, iters: 1488, time: 0.104, data: 0.012) loss: 0.016 
(epoch: 80, iters: 1568, time: 0.105, data: 0.000) loss: 0.032 
(epoch: 80, iters: 1648, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 80, iters: 1728, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 80, iters: 1808, time: 0.107, data: 0.000) loss: 0.004 
(epoch: 80, iters: 1888, time: 0.102, data: 0.012) loss: 0.023 
(epoch: 80, iters: 1968, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 80, iters: 2048, time: 0.105, data: 0.011) loss: 0.006 
(epoch: 80, iters: 2128, time: 0.106, data: 0.000) loss: 0.038 
(epoch: 80, iters: 2208, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 80, iters: 2288, time: 0.105, data: 0.048) loss: 0.000 
(epoch: 80, iters: 2368, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 80, iters: 2448, time: 0.103, data: 0.011) loss: 0.018 
(epoch: 80, iters: 2528, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 80, iters: 2608, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 80, iters: 2688, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 80, iters: 2768, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 80, iters: 2848, time: 0.105, data: 0.038) loss: 0.004 
(epoch: 80, iters: 2928, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 80, iters: 3008, time: 0.103, data: 0.011) loss: 0.010 
(epoch: 80, iters: 3088, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 80, iters: 3168, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 80, iters: 3248, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 80, iters: 3328, time: 0.104, data: 0.000) loss: 0.014 
(epoch: 80, iters: 3408, time: 0.105, data: 0.038) loss: 0.035 
(epoch: 80, iters: 3488, time: 0.105, data: 0.000) loss: 0.034 
(epoch: 80, iters: 3568, time: 0.102, data: 0.012) loss: 0.005 
(epoch: 80, iters: 3648, time: 0.101, data: 0.000) loss: 0.010 
(epoch: 80, iters: 3728, time: 0.066, data: 0.011) loss: 0.006 
saving the model at the end of epoch 80, iters 298240
End of epoch 80 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 80, TEST ACC: [94.689 %]

saving the latest model (epoch 81, total_steps 298256)
(epoch: 81, iters: 80, time: 0.106, data: 0.437) loss: 0.004 
(epoch: 81, iters: 160, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 81, iters: 240, time: 0.104, data: 0.039) loss: 0.001 
(epoch: 81, iters: 320, time: 0.106, data: 0.000) loss: 0.038 
(epoch: 81, iters: 400, time: 0.104, data: 0.012) loss: 0.008 
(epoch: 81, iters: 480, time: 0.105, data: 0.000) loss: 0.117 
(epoch: 81, iters: 560, time: 0.103, data: 0.012) loss: 0.011 
(epoch: 81, iters: 640, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 81, iters: 720, time: 0.105, data: 0.000) loss: 0.207 
(epoch: 81, iters: 800, time: 0.104, data: 0.038) loss: 0.029 
(epoch: 81, iters: 880, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 81, iters: 960, time: 0.104, data: 0.011) loss: 0.028 
(epoch: 81, iters: 1040, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 81, iters: 1120, time: 0.104, data: 0.011) loss: 0.036 
(epoch: 81, iters: 1200, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 81, iters: 1280, time: 0.103, data: 0.000) loss: 0.005 
(epoch: 81, iters: 1360, time: 0.105, data: 0.038) loss: 0.008 
(epoch: 81, iters: 1440, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 81, iters: 1520, time: 0.102, data: 0.012) loss: 0.003 
(epoch: 81, iters: 1600, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 81, iters: 1680, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 81, iters: 1760, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 81, iters: 1840, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 81, iters: 1920, time: 0.105, data: 0.039) loss: 0.021 
(epoch: 81, iters: 2000, time: 0.106, data: 0.000) loss: 0.015 
(epoch: 81, iters: 2080, time: 0.102, data: 0.011) loss: 0.006 
(epoch: 81, iters: 2160, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 81, iters: 2240, time: 0.105, data: 0.019) loss: 0.001 
(epoch: 81, iters: 2320, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 81, iters: 2400, time: 0.105, data: 0.000) loss: 0.090 
(epoch: 81, iters: 2480, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 81, iters: 2560, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 81, iters: 2640, time: 0.102, data: 0.012) loss: 0.005 
(epoch: 81, iters: 2720, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 81, iters: 2800, time: 0.103, data: 0.011) loss: 0.078 
(epoch: 81, iters: 2880, time: 0.105, data: 0.000) loss: 0.041 
(epoch: 81, iters: 2960, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 81, iters: 3040, time: 0.104, data: 0.039) loss: 0.006 
(epoch: 81, iters: 3120, time: 0.105, data: 0.000) loss: 0.064 
(epoch: 81, iters: 3200, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 81, iters: 3280, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 81, iters: 3360, time: 0.104, data: 0.012) loss: 0.003 
(epoch: 81, iters: 3440, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 81, iters: 3520, time: 0.104, data: 0.000) loss: 0.028 
(epoch: 81, iters: 3600, time: 0.104, data: 0.038) loss: 0.002 
(epoch: 81, iters: 3680, time: 0.100, data: 0.000) loss: 0.004 
saving the model at the end of epoch 81, iters 301968
End of epoch 81 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 81, TEST ACC: [95.448 %]

saving the latest model (epoch 82, total_steps 301984)
(epoch: 82, iters: 32, time: 0.099, data: 0.004) loss: 0.006 
(epoch: 82, iters: 112, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 82, iters: 192, time: 0.103, data: 0.011) loss: 0.005 
(epoch: 82, iters: 272, time: 0.105, data: 0.000) loss: 0.230 
(epoch: 82, iters: 352, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 82, iters: 432, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 82, iters: 512, time: 0.104, data: 0.000) loss: 0.199 
(epoch: 82, iters: 592, time: 0.107, data: 0.040) loss: 0.005 
(epoch: 82, iters: 672, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 82, iters: 752, time: 0.105, data: 0.012) loss: 0.209 
(epoch: 82, iters: 832, time: 0.105, data: 0.000) loss: 0.031 
(epoch: 82, iters: 912, time: 0.104, data: 0.011) loss: 0.009 
(epoch: 82, iters: 992, time: 0.105, data: 0.000) loss: 0.273 
(epoch: 82, iters: 1072, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 82, iters: 1152, time: 0.105, data: 0.039) loss: 0.005 
(epoch: 82, iters: 1232, time: 0.107, data: 0.000) loss: 0.004 
(epoch: 82, iters: 1312, time: 0.102, data: 0.012) loss: 0.008 
(epoch: 82, iters: 1392, time: 0.105, data: 0.000) loss: 0.036 
(epoch: 82, iters: 1472, time: 0.105, data: 0.011) loss: 0.099 
(epoch: 82, iters: 1552, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 82, iters: 1632, time: 0.104, data: 0.000) loss: 0.133 
(epoch: 82, iters: 1712, time: 0.105, data: 0.038) loss: 0.232 
(epoch: 82, iters: 1792, time: 0.106, data: 0.000) loss: 0.334 
(epoch: 82, iters: 1872, time: 0.103, data: 0.011) loss: 0.008 
(epoch: 82, iters: 1952, time: 0.105, data: 0.000) loss: 0.158 
(epoch: 82, iters: 2032, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 82, iters: 2112, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 82, iters: 2192, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 82, iters: 2272, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 82, iters: 2352, time: 0.107, data: 0.000) loss: 0.006 
(epoch: 82, iters: 2432, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 82, iters: 2512, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 82, iters: 2592, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 82, iters: 2672, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 82, iters: 2752, time: 0.104, data: 0.000) loss: 0.014 
(epoch: 82, iters: 2832, time: 0.105, data: 0.039) loss: 0.015 
(epoch: 82, iters: 2912, time: 0.107, data: 0.000) loss: 0.135 
(epoch: 82, iters: 2992, time: 0.102, data: 0.011) loss: 0.089 
(epoch: 82, iters: 3072, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 82, iters: 3152, time: 0.105, data: 0.011) loss: 0.031 
(epoch: 82, iters: 3232, time: 0.107, data: 0.000) loss: 0.061 
(epoch: 82, iters: 3312, time: 0.104, data: 0.000) loss: 0.042 
(epoch: 82, iters: 3392, time: 0.106, data: 0.047) loss: 0.022 
(epoch: 82, iters: 3472, time: 0.106, data: 0.000) loss: 0.461 
(epoch: 82, iters: 3552, time: 0.104, data: 0.011) loss: 0.169 
(epoch: 82, iters: 3632, time: 0.102, data: 0.000) loss: 0.005 
(epoch: 82, iters: 3712, time: 0.100, data: 0.011) loss: 0.003 
saving the model at the end of epoch 82, iters 305696
End of epoch 82 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 82, TEST ACC: [91.654 %]

saving the latest model (epoch 83, total_steps 305712)
(epoch: 83, iters: 64, time: 0.102, data: 0.003) loss: 0.252 
(epoch: 83, iters: 144, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 83, iters: 224, time: 0.104, data: 0.011) loss: 0.010 
(epoch: 83, iters: 304, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 83, iters: 384, time: 0.104, data: 0.000) loss: 0.013 
(epoch: 83, iters: 464, time: 0.106, data: 0.047) loss: 0.047 
(epoch: 83, iters: 544, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 83, iters: 624, time: 0.103, data: 0.021) loss: 0.016 
(epoch: 83, iters: 704, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 83, iters: 784, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 83, iters: 864, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 83, iters: 944, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 83, iters: 1024, time: 0.105, data: 0.038) loss: 0.011 
(epoch: 83, iters: 1104, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 83, iters: 1184, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 83, iters: 1264, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 83, iters: 1344, time: 0.105, data: 0.011) loss: 0.032 
(epoch: 83, iters: 1424, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 83, iters: 1504, time: 0.104, data: 0.000) loss: 0.012 
(epoch: 83, iters: 1584, time: 0.105, data: 0.038) loss: 0.015 
(epoch: 83, iters: 1664, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 83, iters: 1744, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 83, iters: 1824, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 83, iters: 1904, time: 0.104, data: 0.011) loss: 0.012 
(epoch: 83, iters: 1984, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 83, iters: 2064, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 83, iters: 2144, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 83, iters: 2224, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 83, iters: 2304, time: 0.103, data: 0.012) loss: 0.004 
(epoch: 83, iters: 2384, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 83, iters: 2464, time: 0.105, data: 0.011) loss: 0.010 
(epoch: 83, iters: 2544, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 83, iters: 2624, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 83, iters: 2704, time: 0.106, data: 0.039) loss: 0.015 
(epoch: 83, iters: 2784, time: 0.106, data: 0.000) loss: 0.017 
(epoch: 83, iters: 2864, time: 0.105, data: 0.012) loss: 0.028 
(epoch: 83, iters: 2944, time: 0.106, data: 0.037) loss: 0.000 
(epoch: 83, iters: 3024, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 83, iters: 3104, time: 0.105, data: 0.011) loss: 0.040 
(epoch: 83, iters: 3184, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 83, iters: 3264, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 83, iters: 3344, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 83, iters: 3424, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 83, iters: 3504, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 83, iters: 3584, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 83, iters: 3664, time: 0.100, data: 0.011) loss: 0.005 
saving the model at the end of epoch 83, iters 309424
End of epoch 83 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 83, TEST ACC: [95.751 %]

(epoch: 84, iters: 16, time: 0.119, data: 0.012) loss: 0.012 
saving the latest model (epoch 84, total_steps 309440)
(epoch: 84, iters: 96, time: 0.106, data: 0.011) loss: 0.066 
(epoch: 84, iters: 176, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 84, iters: 256, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 84, iters: 336, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 84, iters: 416, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 84, iters: 496, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 84, iters: 576, time: 0.105, data: 0.038) loss: 0.006 
(epoch: 84, iters: 656, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 84, iters: 736, time: 0.103, data: 0.011) loss: 0.027 
(epoch: 84, iters: 816, time: 0.106, data: 0.000) loss: 0.127 
(epoch: 84, iters: 896, time: 0.104, data: 0.012) loss: 0.089 
(epoch: 84, iters: 976, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 84, iters: 1056, time: 0.104, data: 0.000) loss: 0.009 
(epoch: 84, iters: 1136, time: 0.105, data: 0.038) loss: 0.003 
(epoch: 84, iters: 1216, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 84, iters: 1296, time: 0.103, data: 0.012) loss: 0.004 
(epoch: 84, iters: 1376, time: 0.106, data: 0.000) loss: 0.019 
(epoch: 84, iters: 1456, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 84, iters: 1536, time: 0.105, data: 0.000) loss: 0.193 
(epoch: 84, iters: 1616, time: 0.106, data: 0.000) loss: 0.027 
(epoch: 84, iters: 1696, time: 0.106, data: 0.039) loss: 0.010 
(epoch: 84, iters: 1776, time: 0.107, data: 0.000) loss: 0.013 
(epoch: 84, iters: 1856, time: 0.103, data: 0.011) loss: 0.116 
(epoch: 84, iters: 1936, time: 0.106, data: 0.000) loss: 0.024 
(epoch: 84, iters: 2016, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 84, iters: 2096, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 84, iters: 2176, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 84, iters: 2256, time: 0.105, data: 0.047) loss: 0.019 
(epoch: 84, iters: 2336, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 84, iters: 2416, time: 0.105, data: 0.021) loss: 0.061 
(epoch: 84, iters: 2496, time: 0.105, data: 0.000) loss: 0.027 
(epoch: 84, iters: 2576, time: 0.104, data: 0.011) loss: 0.017 
(epoch: 84, iters: 2656, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 84, iters: 2736, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 84, iters: 2816, time: 0.105, data: 0.038) loss: 0.396 
(epoch: 84, iters: 2896, time: 0.106, data: 0.000) loss: 0.113 
(epoch: 84, iters: 2976, time: 0.103, data: 0.011) loss: 0.034 
(epoch: 84, iters: 3056, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 84, iters: 3136, time: 0.103, data: 0.011) loss: 0.049 
(epoch: 84, iters: 3216, time: 0.105, data: 0.000) loss: 0.049 
(epoch: 84, iters: 3296, time: 0.105, data: 0.000) loss: 0.061 
(epoch: 84, iters: 3376, time: 0.105, data: 0.039) loss: 0.024 
(epoch: 84, iters: 3456, time: 0.106, data: 0.000) loss: 0.022 
(epoch: 84, iters: 3536, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 84, iters: 3616, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 84, iters: 3696, time: 0.100, data: 0.011) loss: 0.000 
saving the model at the end of epoch 84, iters 313152
End of epoch 84 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 84, TEST ACC: [93.778 %]

saving the latest model (epoch 85, total_steps 313168)
(epoch: 85, iters: 48, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 85, iters: 128, time: 0.105, data: 0.052) loss: 0.040 
(epoch: 85, iters: 208, time: 0.105, data: 0.000) loss: 0.090 
(epoch: 85, iters: 288, time: 0.103, data: 0.011) loss: 0.043 
(epoch: 85, iters: 368, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 85, iters: 448, time: 0.104, data: 0.019) loss: 0.020 
(epoch: 85, iters: 528, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 85, iters: 608, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 85, iters: 688, time: 0.105, data: 0.048) loss: 0.042 
(epoch: 85, iters: 768, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 85, iters: 848, time: 0.103, data: 0.011) loss: 0.028 
(epoch: 85, iters: 928, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 85, iters: 1008, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 85, iters: 1088, time: 0.106, data: 0.000) loss: 0.096 
(epoch: 85, iters: 1168, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 85, iters: 1248, time: 0.106, data: 0.047) loss: 0.005 
(epoch: 85, iters: 1328, time: 0.106, data: 0.000) loss: 0.017 
(epoch: 85, iters: 1408, time: 0.104, data: 0.012) loss: 0.003 
(epoch: 85, iters: 1488, time: 0.105, data: 0.000) loss: 0.044 
(epoch: 85, iters: 1568, time: 0.104, data: 0.011) loss: 0.012 
(epoch: 85, iters: 1648, time: 0.106, data: 0.000) loss: 0.404 
(epoch: 85, iters: 1728, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 85, iters: 1808, time: 0.104, data: 0.038) loss: 0.584 
(epoch: 85, iters: 1888, time: 0.107, data: 0.000) loss: 0.005 
(epoch: 85, iters: 1968, time: 0.104, data: 0.011) loss: 0.023 
(epoch: 85, iters: 2048, time: 0.105, data: 0.000) loss: 0.020 
(epoch: 85, iters: 2128, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 85, iters: 2208, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 85, iters: 2288, time: 0.104, data: 0.000) loss: 0.059 
(epoch: 85, iters: 2368, time: 0.105, data: 0.038) loss: 0.033 
(epoch: 85, iters: 2448, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 85, iters: 2528, time: 0.102, data: 0.011) loss: 0.151 
(epoch: 85, iters: 2608, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 85, iters: 2688, time: 0.104, data: 0.011) loss: 0.139 
(epoch: 85, iters: 2768, time: 0.106, data: 0.000) loss: 0.080 
(epoch: 85, iters: 2848, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 85, iters: 2928, time: 0.105, data: 0.039) loss: 0.116 
(epoch: 85, iters: 3008, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 85, iters: 3088, time: 0.103, data: 0.011) loss: 0.037 
(epoch: 85, iters: 3168, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 85, iters: 3248, time: 0.104, data: 0.011) loss: 0.022 
(epoch: 85, iters: 3328, time: 0.105, data: 0.000) loss: 0.073 
(epoch: 85, iters: 3408, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 85, iters: 3488, time: 0.105, data: 0.038) loss: 0.024 
(epoch: 85, iters: 3568, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 85, iters: 3648, time: 0.097, data: 0.011) loss: 0.063 
(epoch: 85, iters: 3728, time: 0.065, data: 0.000) loss: 0.016 
saving the model at the end of epoch 85, iters 316880
End of epoch 85 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 85, TEST ACC: [92.261 %]

saving the latest model (epoch 86, total_steps 316896)
(epoch: 86, iters: 80, time: 0.106, data: 0.520) loss: 0.032 
(epoch: 86, iters: 160, time: 0.106, data: 0.030) loss: 0.013 
(epoch: 86, iters: 240, time: 0.106, data: 0.000) loss: 0.021 
(epoch: 86, iters: 320, time: 0.102, data: 0.012) loss: 0.022 
(epoch: 86, iters: 400, time: 0.106, data: 0.000) loss: 0.116 
(epoch: 86, iters: 480, time: 0.106, data: 0.011) loss: 0.015 
(epoch: 86, iters: 560, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 86, iters: 640, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 86, iters: 720, time: 0.106, data: 0.046) loss: 0.002 
(epoch: 86, iters: 800, time: 0.106, data: 0.000) loss: 0.015 
(epoch: 86, iters: 880, time: 0.103, data: 0.020) loss: 0.007 
(epoch: 86, iters: 960, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 86, iters: 1040, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 86, iters: 1120, time: 0.106, data: 0.000) loss: 0.045 
(epoch: 86, iters: 1200, time: 0.105, data: 0.000) loss: 0.115 
(epoch: 86, iters: 1280, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 86, iters: 1360, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 86, iters: 1440, time: 0.103, data: 0.011) loss: 0.022 
(epoch: 86, iters: 1520, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 86, iters: 1600, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 86, iters: 1680, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 86, iters: 1760, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 86, iters: 1840, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 86, iters: 1920, time: 0.107, data: 0.000) loss: 0.005 
(epoch: 86, iters: 2000, time: 0.103, data: 0.011) loss: 0.014 
(epoch: 86, iters: 2080, time: 0.104, data: 0.000) loss: 0.117 
(epoch: 86, iters: 2160, time: 0.105, data: 0.011) loss: 0.032 
(epoch: 86, iters: 2240, time: 0.105, data: 0.000) loss: 0.024 
(epoch: 86, iters: 2320, time: 0.105, data: 0.000) loss: 0.089 
(epoch: 86, iters: 2400, time: 0.105, data: 0.039) loss: 0.487 
(epoch: 86, iters: 2480, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 86, iters: 2560, time: 0.103, data: 0.011) loss: 0.008 
(epoch: 86, iters: 2640, time: 0.105, data: 0.000) loss: 0.034 
(epoch: 86, iters: 2720, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 86, iters: 2800, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 86, iters: 2880, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 86, iters: 2960, time: 0.105, data: 0.038) loss: 0.004 
(epoch: 86, iters: 3040, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 86, iters: 3120, time: 0.103, data: 0.011) loss: 0.037 
(epoch: 86, iters: 3200, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 86, iters: 3280, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 86, iters: 3360, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 86, iters: 3440, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 86, iters: 3520, time: 0.105, data: 0.039) loss: 0.040 
(epoch: 86, iters: 3600, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 86, iters: 3680, time: 0.099, data: 0.011) loss: 0.103 
saving the model at the end of epoch 86, iters 320608
End of epoch 86 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 86, TEST ACC: [93.93 %]

saving the latest model (epoch 87, total_steps 320624)
(epoch: 87, iters: 32, time: 0.100, data: 0.006) loss: 0.002 
(epoch: 87, iters: 112, time: 0.105, data: 0.011) loss: 0.054 
(epoch: 87, iters: 192, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 87, iters: 272, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 87, iters: 352, time: 0.105, data: 0.011) loss: 0.023 
(epoch: 87, iters: 432, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 87, iters: 512, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 87, iters: 592, time: 0.106, data: 0.039) loss: 0.017 
(epoch: 87, iters: 672, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 87, iters: 752, time: 0.103, data: 0.012) loss: 0.165 
(epoch: 87, iters: 832, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 87, iters: 912, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 87, iters: 992, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 87, iters: 1072, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 87, iters: 1152, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 87, iters: 1232, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 87, iters: 1312, time: 0.102, data: 0.011) loss: 0.056 
(epoch: 87, iters: 1392, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 87, iters: 1472, time: 0.104, data: 0.012) loss: 0.016 
(epoch: 87, iters: 1552, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 87, iters: 1632, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 87, iters: 1712, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 87, iters: 1792, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 87, iters: 1872, time: 0.102, data: 0.012) loss: 0.000 
(epoch: 87, iters: 1952, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 87, iters: 2032, time: 0.106, data: 0.018) loss: 0.195 
(epoch: 87, iters: 2112, time: 0.107, data: 0.000) loss: 0.011 
(epoch: 87, iters: 2192, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 87, iters: 2272, time: 0.106, data: 0.048) loss: 0.074 
(epoch: 87, iters: 2352, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 87, iters: 2432, time: 0.102, data: 0.011) loss: 0.004 
(epoch: 87, iters: 2512, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 87, iters: 2592, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 87, iters: 2672, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 87, iters: 2752, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 87, iters: 2832, time: 0.105, data: 0.038) loss: 0.008 
(epoch: 87, iters: 2912, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 87, iters: 2992, time: 0.103, data: 0.012) loss: 0.029 
(epoch: 87, iters: 3072, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 87, iters: 3152, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 87, iters: 3232, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 87, iters: 3312, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 87, iters: 3392, time: 0.105, data: 0.038) loss: 0.005 
(epoch: 87, iters: 3472, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 87, iters: 3552, time: 0.103, data: 0.011) loss: 0.077 
(epoch: 87, iters: 3632, time: 0.103, data: 0.000) loss: 0.026 
(epoch: 87, iters: 3712, time: 0.100, data: 0.011) loss: 0.002 
saving the model at the end of epoch 87, iters 324336
End of epoch 87 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 87, TEST ACC: [95.751 %]

saving the latest model (epoch 88, total_steps 324352)
(epoch: 88, iters: 64, time: 0.104, data: 0.003) loss: 0.007 
(epoch: 88, iters: 144, time: 0.104, data: 0.025) loss: 0.005 
(epoch: 88, iters: 224, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 88, iters: 304, time: 0.104, data: 0.000) loss: 0.209 
(epoch: 88, iters: 384, time: 0.106, data: 0.039) loss: 0.041 
(epoch: 88, iters: 464, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 88, iters: 544, time: 0.103, data: 0.012) loss: 0.053 
(epoch: 88, iters: 624, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 88, iters: 704, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 88, iters: 784, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 88, iters: 864, time: 0.104, data: 0.000) loss: 0.066 
(epoch: 88, iters: 944, time: 0.105, data: 0.039) loss: 0.003 
(epoch: 88, iters: 1024, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 88, iters: 1104, time: 0.104, data: 0.012) loss: 0.053 
(epoch: 88, iters: 1184, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 88, iters: 1264, time: 0.105, data: 0.011) loss: 0.018 
(epoch: 88, iters: 1344, time: 0.106, data: 0.000) loss: 0.039 
(epoch: 88, iters: 1424, time: 0.104, data: 0.000) loss: 0.068 
(epoch: 88, iters: 1504, time: 0.106, data: 0.038) loss: 0.006 
(epoch: 88, iters: 1584, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 88, iters: 1664, time: 0.103, data: 0.012) loss: 0.015 
(epoch: 88, iters: 1744, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 88, iters: 1824, time: 0.105, data: 0.011) loss: 0.064 
(epoch: 88, iters: 1904, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 88, iters: 1984, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 88, iters: 2064, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 88, iters: 2144, time: 0.106, data: 0.000) loss: 0.039 
(epoch: 88, iters: 2224, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 88, iters: 2304, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 88, iters: 2384, time: 0.105, data: 0.012) loss: 0.022 
(epoch: 88, iters: 2464, time: 0.105, data: 0.000) loss: 0.029 
(epoch: 88, iters: 2544, time: 0.106, data: 0.000) loss: 0.015 
(epoch: 88, iters: 2624, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 88, iters: 2704, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 88, iters: 2784, time: 0.103, data: 0.012) loss: 0.010 
(epoch: 88, iters: 2864, time: 0.106, data: 0.000) loss: 0.216 
(epoch: 88, iters: 2944, time: 0.105, data: 0.019) loss: 0.030 
(epoch: 88, iters: 3024, time: 0.108, data: 0.000) loss: 0.005 
(epoch: 88, iters: 3104, time: 0.105, data: 0.000) loss: 0.138 
(epoch: 88, iters: 3184, time: 0.106, data: 0.047) loss: 0.011 
(epoch: 88, iters: 3264, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 88, iters: 3344, time: 0.103, data: 0.012) loss: 0.022 
(epoch: 88, iters: 3424, time: 0.105, data: 0.000) loss: 0.176 
(epoch: 88, iters: 3504, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 88, iters: 3584, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 88, iters: 3664, time: 0.100, data: 0.000) loss: 0.001 
saving the model at the end of epoch 88, iters 328064
End of epoch 88 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 88, TEST ACC: [86.191 %]

(epoch: 89, iters: 16, time: 0.119, data: 0.012) loss: 0.016 
saving the latest model (epoch 89, total_steps 328080)
(epoch: 89, iters: 96, time: 0.106, data: 0.012) loss: 0.001 
(epoch: 89, iters: 176, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 89, iters: 256, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 89, iters: 336, time: 0.105, data: 0.011) loss: 0.006 
(epoch: 89, iters: 416, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 89, iters: 496, time: 0.105, data: 0.000) loss: 0.062 
(epoch: 89, iters: 576, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 89, iters: 656, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 89, iters: 736, time: 0.103, data: 0.011) loss: 0.014 
(epoch: 89, iters: 816, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 89, iters: 896, time: 0.104, data: 0.011) loss: 0.031 
(epoch: 89, iters: 976, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 89, iters: 1056, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 89, iters: 1136, time: 0.105, data: 0.039) loss: 0.136 
(epoch: 89, iters: 1216, time: 0.107, data: 0.000) loss: 0.029 
(epoch: 89, iters: 1296, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 89, iters: 1376, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 89, iters: 1456, time: 0.106, data: 0.011) loss: 0.004 
(epoch: 89, iters: 1536, time: 0.106, data: 0.000) loss: 0.224 
(epoch: 89, iters: 1616, time: 0.105, data: 0.000) loss: 0.037 
(epoch: 89, iters: 1696, time: 0.105, data: 0.038) loss: 0.009 
(epoch: 89, iters: 1776, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 89, iters: 1856, time: 0.103, data: 0.011) loss: 0.005 
(epoch: 89, iters: 1936, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 89, iters: 2016, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 89, iters: 2096, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 89, iters: 2176, time: 0.106, data: 0.000) loss: 0.465 
(epoch: 89, iters: 2256, time: 0.106, data: 0.039) loss: 0.003 
(epoch: 89, iters: 2336, time: 0.107, data: 0.000) loss: 0.006 
(epoch: 89, iters: 2416, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 89, iters: 2496, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 89, iters: 2576, time: 0.104, data: 0.012) loss: 0.011 
(epoch: 89, iters: 2656, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 89, iters: 2736, time: 0.105, data: 0.000) loss: 0.025 
(epoch: 89, iters: 2816, time: 0.106, data: 0.040) loss: 0.004 
(epoch: 89, iters: 2896, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 89, iters: 2976, time: 0.104, data: 0.011) loss: 0.484 
(epoch: 89, iters: 3056, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 89, iters: 3136, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 89, iters: 3216, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 89, iters: 3296, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 89, iters: 3376, time: 0.106, data: 0.039) loss: 0.018 
(epoch: 89, iters: 3456, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 89, iters: 3536, time: 0.104, data: 0.011) loss: 0.015 
(epoch: 89, iters: 3616, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 89, iters: 3696, time: 0.100, data: 0.011) loss: 0.001 
saving the model at the end of epoch 89, iters 331792
End of epoch 89 / 2100 	 Time Taken: 396 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 89, TEST ACC: [92.868 %]

saving the latest model (epoch 90, total_steps 331808)
(epoch: 90, iters: 48, time: 0.108, data: 0.000) loss: 0.002 
(epoch: 90, iters: 128, time: 0.104, data: 0.000) loss: 0.061 
(epoch: 90, iters: 208, time: 0.105, data: 0.039) loss: 0.046 
(epoch: 90, iters: 288, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 90, iters: 368, time: 0.103, data: 0.012) loss: 0.009 
(epoch: 90, iters: 448, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 90, iters: 528, time: 0.104, data: 0.011) loss: 0.297 
(epoch: 90, iters: 608, time: 0.106, data: 0.000) loss: 0.037 
(epoch: 90, iters: 688, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 90, iters: 768, time: 0.105, data: 0.038) loss: 0.020 
(epoch: 90, iters: 848, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 90, iters: 928, time: 0.102, data: 0.011) loss: 0.027 
(epoch: 90, iters: 1008, time: 0.107, data: 0.000) loss: 0.033 
(epoch: 90, iters: 1088, time: 0.106, data: 0.012) loss: 0.067 
(epoch: 90, iters: 1168, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 90, iters: 1248, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 90, iters: 1328, time: 0.106, data: 0.046) loss: 0.000 
(epoch: 90, iters: 1408, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 90, iters: 1488, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 90, iters: 1568, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 90, iters: 1648, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 90, iters: 1728, time: 0.107, data: 0.000) loss: 0.106 
(epoch: 90, iters: 1808, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 90, iters: 1888, time: 0.105, data: 0.038) loss: 0.006 
(epoch: 90, iters: 1968, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 90, iters: 2048, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 90, iters: 2128, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 90, iters: 2208, time: 0.105, data: 0.011) loss: 0.010 
(epoch: 90, iters: 2288, time: 0.106, data: 0.000) loss: 0.683 
(epoch: 90, iters: 2368, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 90, iters: 2448, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 90, iters: 2528, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 90, iters: 2608, time: 0.103, data: 0.011) loss: 0.013 
(epoch: 90, iters: 2688, time: 0.104, data: 0.000) loss: 0.010 
(epoch: 90, iters: 2768, time: 0.104, data: 0.011) loss: 0.140 
(epoch: 90, iters: 2848, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 90, iters: 2928, time: 0.105, data: 0.000) loss: 0.171 
(epoch: 90, iters: 3008, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 90, iters: 3088, time: 0.107, data: 0.000) loss: 0.014 
(epoch: 90, iters: 3168, time: 0.104, data: 0.012) loss: 0.003 
(epoch: 90, iters: 3248, time: 0.106, data: 0.000) loss: 0.044 
(epoch: 90, iters: 3328, time: 0.104, data: 0.012) loss: 0.006 
(epoch: 90, iters: 3408, time: 0.107, data: 0.000) loss: 0.008 
(epoch: 90, iters: 3488, time: 0.107, data: 0.000) loss: 0.021 
(epoch: 90, iters: 3568, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 90, iters: 3648, time: 0.101, data: 0.000) loss: 0.001 
(epoch: 90, iters: 3728, time: 0.066, data: 0.011) loss: 0.086 
saving the model at the end of epoch 90, iters 335520
End of epoch 90 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 90, TEST ACC: [89.833 %]

saving the latest model (epoch 91, total_steps 335536)
(epoch: 91, iters: 80, time: 0.107, data: 0.487) loss: 0.005 
(epoch: 91, iters: 160, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 91, iters: 240, time: 0.104, data: 0.047) loss: 0.007 
(epoch: 91, iters: 320, time: 0.106, data: 0.000) loss: 0.126 
(epoch: 91, iters: 400, time: 0.105, data: 0.021) loss: 0.032 
(epoch: 91, iters: 480, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 91, iters: 560, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 91, iters: 640, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 91, iters: 720, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 91, iters: 800, time: 0.105, data: 0.038) loss: 0.011 
(epoch: 91, iters: 880, time: 0.107, data: 0.000) loss: 0.041 
(epoch: 91, iters: 960, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 91, iters: 1040, time: 0.107, data: 0.000) loss: 0.021 
(epoch: 91, iters: 1120, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 91, iters: 1200, time: 0.105, data: 0.000) loss: 0.125 
(epoch: 91, iters: 1280, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 91, iters: 1360, time: 0.104, data: 0.038) loss: 0.004 
(epoch: 91, iters: 1440, time: 0.105, data: 0.000) loss: 0.101 
(epoch: 91, iters: 1520, time: 0.103, data: 0.012) loss: 0.217 
(epoch: 91, iters: 1600, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 91, iters: 1680, time: 0.105, data: 0.011) loss: 0.116 
(epoch: 91, iters: 1760, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 91, iters: 1840, time: 0.104, data: 0.000) loss: 0.009 
(epoch: 91, iters: 1920, time: 0.105, data: 0.039) loss: 0.059 
(epoch: 91, iters: 2000, time: 0.106, data: 0.000) loss: 0.019 
(epoch: 91, iters: 2080, time: 0.102, data: 0.011) loss: 0.004 
(epoch: 91, iters: 2160, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 91, iters: 2240, time: 0.106, data: 0.011) loss: 0.004 
(epoch: 91, iters: 2320, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 91, iters: 2400, time: 0.105, data: 0.000) loss: 0.025 
(epoch: 91, iters: 2480, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 91, iters: 2560, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 91, iters: 2640, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 91, iters: 2720, time: 0.105, data: 0.000) loss: 0.064 
(epoch: 91, iters: 2800, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 91, iters: 2880, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 91, iters: 2960, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 91, iters: 3040, time: 0.105, data: 0.048) loss: 0.005 
(epoch: 91, iters: 3120, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 91, iters: 3200, time: 0.103, data: 0.012) loss: 0.005 
(epoch: 91, iters: 3280, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 91, iters: 3360, time: 0.104, data: 0.011) loss: 0.009 
(epoch: 91, iters: 3440, time: 0.106, data: 0.000) loss: 0.168 
(epoch: 91, iters: 3520, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 91, iters: 3600, time: 0.104, data: 0.038) loss: 0.002 
(epoch: 91, iters: 3680, time: 0.099, data: 0.000) loss: 0.036 
saving the model at the end of epoch 91, iters 339248
End of epoch 91 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 91, TEST ACC: [94.385 %]

saving the latest model (epoch 92, total_steps 339264)
(epoch: 92, iters: 32, time: 0.099, data: 0.004) loss: 0.004 
(epoch: 92, iters: 112, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 92, iters: 192, time: 0.106, data: 0.000) loss: 0.033 
(epoch: 92, iters: 272, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 92, iters: 352, time: 0.106, data: 0.038) loss: 0.005 
(epoch: 92, iters: 432, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 92, iters: 512, time: 0.103, data: 0.011) loss: 0.010 
(epoch: 92, iters: 592, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 92, iters: 672, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 92, iters: 752, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 92, iters: 832, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 92, iters: 912, time: 0.104, data: 0.038) loss: 0.101 
(epoch: 92, iters: 992, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 92, iters: 1072, time: 0.103, data: 0.011) loss: 0.024 
(epoch: 92, iters: 1152, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 92, iters: 1232, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 92, iters: 1312, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 92, iters: 1392, time: 0.106, data: 0.000) loss: 0.021 
(epoch: 92, iters: 1472, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 92, iters: 1552, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 92, iters: 1632, time: 0.103, data: 0.011) loss: 0.086 
(epoch: 92, iters: 1712, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 92, iters: 1792, time: 0.105, data: 0.011) loss: 0.005 
(epoch: 92, iters: 1872, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 92, iters: 1952, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 92, iters: 2032, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 92, iters: 2112, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 92, iters: 2192, time: 0.104, data: 0.011) loss: 0.017 
(epoch: 92, iters: 2272, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 92, iters: 2352, time: 0.104, data: 0.011) loss: 0.012 
(epoch: 92, iters: 2432, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 92, iters: 2512, time: 0.104, data: 0.000) loss: 0.074 
(epoch: 92, iters: 2592, time: 0.105, data: 0.048) loss: 0.019 
(epoch: 92, iters: 2672, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 92, iters: 2752, time: 0.103, data: 0.011) loss: 0.009 
(epoch: 92, iters: 2832, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 92, iters: 2912, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 92, iters: 2992, time: 0.105, data: 0.000) loss: 0.058 
(epoch: 92, iters: 3072, time: 0.103, data: 0.000) loss: 0.005 
(epoch: 92, iters: 3152, time: 0.105, data: 0.038) loss: 0.086 
(epoch: 92, iters: 3232, time: 0.104, data: 0.000) loss: 0.011 
(epoch: 92, iters: 3312, time: 0.102, data: 0.011) loss: 0.004 
(epoch: 92, iters: 3392, time: 0.104, data: 0.000) loss: 0.013 
(epoch: 92, iters: 3472, time: 0.106, data: 0.011) loss: 0.211 
(epoch: 92, iters: 3552, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 92, iters: 3632, time: 0.102, data: 0.000) loss: 0.000 
(epoch: 92, iters: 3712, time: 0.101, data: 0.035) loss: 0.075 
saving the model at the end of epoch 92, iters 342976
End of epoch 92 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 92, TEST ACC: [94.992 %]

saving the latest model (epoch 93, total_steps 342992)
(epoch: 93, iters: 64, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 93, iters: 144, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 93, iters: 224, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 93, iters: 304, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 93, iters: 384, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 93, iters: 464, time: 0.104, data: 0.039) loss: 0.008 
(epoch: 93, iters: 544, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 93, iters: 624, time: 0.103, data: 0.011) loss: 0.017 
(epoch: 93, iters: 704, time: 0.105, data: 0.000) loss: 0.029 
(epoch: 93, iters: 784, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 93, iters: 864, time: 0.105, data: 0.000) loss: 0.022 
(epoch: 93, iters: 944, time: 0.104, data: 0.000) loss: 0.017 
(epoch: 93, iters: 1024, time: 0.107, data: 0.038) loss: 0.001 
(epoch: 93, iters: 1104, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 93, iters: 1184, time: 0.102, data: 0.012) loss: 0.001 
(epoch: 93, iters: 1264, time: 0.107, data: 0.000) loss: 0.008 
(epoch: 93, iters: 1344, time: 0.105, data: 0.011) loss: 0.088 
(epoch: 93, iters: 1424, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 93, iters: 1504, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 93, iters: 1584, time: 0.106, data: 0.048) loss: 0.002 
(epoch: 93, iters: 1664, time: 0.105, data: 0.000) loss: 0.056 
(epoch: 93, iters: 1744, time: 0.103, data: 0.011) loss: 0.007 
(epoch: 93, iters: 1824, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 93, iters: 1904, time: 0.104, data: 0.011) loss: 0.010 
(epoch: 93, iters: 1984, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 93, iters: 2064, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 93, iters: 2144, time: 0.105, data: 0.038) loss: 0.069 
(epoch: 93, iters: 2224, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 93, iters: 2304, time: 0.103, data: 0.011) loss: 0.005 
(epoch: 93, iters: 2384, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 93, iters: 2464, time: 0.105, data: 0.011) loss: 0.094 
(epoch: 93, iters: 2544, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 93, iters: 2624, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 93, iters: 2704, time: 0.105, data: 0.038) loss: 0.004 
(epoch: 93, iters: 2784, time: 0.105, data: 0.000) loss: 0.035 
(epoch: 93, iters: 2864, time: 0.103, data: 0.012) loss: 0.026 
(epoch: 93, iters: 2944, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 93, iters: 3024, time: 0.105, data: 0.019) loss: 0.003 
(epoch: 93, iters: 3104, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 93, iters: 3184, time: 0.104, data: 0.000) loss: 0.032 
(epoch: 93, iters: 3264, time: 0.105, data: 0.048) loss: 0.345 
(epoch: 93, iters: 3344, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 93, iters: 3424, time: 0.103, data: 0.012) loss: 0.027 
(epoch: 93, iters: 3504, time: 0.106, data: 0.000) loss: 0.167 
(epoch: 93, iters: 3584, time: 0.105, data: 0.011) loss: 0.014 
(epoch: 93, iters: 3664, time: 0.100, data: 0.000) loss: 0.219 
saving the model at the end of epoch 93, iters 346704
End of epoch 93 / 2100 	 Time Taken: 393 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 93, TEST ACC: [86.798 %]

(epoch: 94, iters: 16, time: 0.120, data: 0.000) loss: 0.003 
saving the latest model (epoch 94, total_steps 346720)
(epoch: 94, iters: 96, time: 0.106, data: 0.012) loss: 0.008 
(epoch: 94, iters: 176, time: 0.103, data: 0.011) loss: 0.024 
(epoch: 94, iters: 256, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 94, iters: 336, time: 0.105, data: 0.011) loss: 0.071 
(epoch: 94, iters: 416, time: 0.106, data: 0.000) loss: 0.021 
(epoch: 94, iters: 496, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 94, iters: 576, time: 0.105, data: 0.038) loss: 0.005 
(epoch: 94, iters: 656, time: 0.106, data: 0.000) loss: 0.020 
(epoch: 94, iters: 736, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 94, iters: 816, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 94, iters: 896, time: 0.105, data: 0.012) loss: 0.056 
(epoch: 94, iters: 976, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 94, iters: 1056, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 94, iters: 1136, time: 0.105, data: 0.039) loss: 0.010 
(epoch: 94, iters: 1216, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 94, iters: 1296, time: 0.104, data: 0.011) loss: 0.016 
(epoch: 94, iters: 1376, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 94, iters: 1456, time: 0.105, data: 0.011) loss: 0.016 
(epoch: 94, iters: 1536, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 94, iters: 1616, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 94, iters: 1696, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 94, iters: 1776, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 94, iters: 1856, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 94, iters: 1936, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 94, iters: 2016, time: 0.106, data: 0.011) loss: 0.001 
(epoch: 94, iters: 2096, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 94, iters: 2176, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 94, iters: 2256, time: 0.105, data: 0.038) loss: 0.010 
(epoch: 94, iters: 2336, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 94, iters: 2416, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 94, iters: 2496, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 94, iters: 2576, time: 0.105, data: 0.011) loss: 0.282 
(epoch: 94, iters: 2656, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 94, iters: 2736, time: 0.105, data: 0.000) loss: 0.019 
(epoch: 94, iters: 2816, time: 0.105, data: 0.039) loss: 0.012 
(epoch: 94, iters: 2896, time: 0.107, data: 0.000) loss: 0.055 
(epoch: 94, iters: 2976, time: 0.103, data: 0.011) loss: 0.018 
(epoch: 94, iters: 3056, time: 0.105, data: 0.000) loss: 0.033 
(epoch: 94, iters: 3136, time: 0.104, data: 0.011) loss: 0.020 
(epoch: 94, iters: 3216, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 94, iters: 3296, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 94, iters: 3376, time: 0.105, data: 0.038) loss: 0.078 
(epoch: 94, iters: 3456, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 94, iters: 3536, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 94, iters: 3616, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 94, iters: 3696, time: 0.100, data: 0.011) loss: 0.004 
saving the model at the end of epoch 94, iters 350432
End of epoch 94 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 94, TEST ACC: [91.351 %]

saving the latest model (epoch 95, total_steps 350448)
(epoch: 95, iters: 48, time: 0.107, data: 0.000) loss: 0.008 
(epoch: 95, iters: 128, time: 0.105, data: 0.025) loss: 0.023 
(epoch: 95, iters: 208, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 95, iters: 288, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 95, iters: 368, time: 0.106, data: 0.039) loss: 0.008 
(epoch: 95, iters: 448, time: 0.106, data: 0.000) loss: 0.032 
(epoch: 95, iters: 528, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 95, iters: 608, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 95, iters: 688, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 95, iters: 768, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 95, iters: 848, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 95, iters: 928, time: 0.105, data: 0.038) loss: 0.031 
(epoch: 95, iters: 1008, time: 0.107, data: 0.000) loss: 0.055 
(epoch: 95, iters: 1088, time: 0.103, data: 0.011) loss: 0.156 
(epoch: 95, iters: 1168, time: 0.106, data: 0.000) loss: 0.030 
(epoch: 95, iters: 1248, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 95, iters: 1328, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 95, iters: 1408, time: 0.105, data: 0.000) loss: 0.084 
(epoch: 95, iters: 1488, time: 0.106, data: 0.038) loss: 0.005 
(epoch: 95, iters: 1568, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 95, iters: 1648, time: 0.103, data: 0.012) loss: 0.025 
(epoch: 95, iters: 1728, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 95, iters: 1808, time: 0.105, data: 0.011) loss: 0.065 
(epoch: 95, iters: 1888, time: 0.108, data: 0.000) loss: 0.001 
(epoch: 95, iters: 1968, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 95, iters: 2048, time: 0.105, data: 0.047) loss: 0.007 
(epoch: 95, iters: 2128, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 95, iters: 2208, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 95, iters: 2288, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 95, iters: 2368, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 95, iters: 2448, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 95, iters: 2528, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 95, iters: 2608, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 95, iters: 2688, time: 0.106, data: 0.000) loss: 0.029 
(epoch: 95, iters: 2768, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 95, iters: 2848, time: 0.105, data: 0.012) loss: 0.024 
(epoch: 95, iters: 2928, time: 0.104, data: 0.024) loss: 0.002 
(epoch: 95, iters: 3008, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 95, iters: 3088, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 95, iters: 3168, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 95, iters: 3248, time: 0.105, data: 0.033) loss: 0.003 
(epoch: 95, iters: 3328, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 95, iters: 3408, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 95, iters: 3488, time: 0.104, data: 0.011) loss: 0.020 
(epoch: 95, iters: 3568, time: 0.104, data: 0.025) loss: 0.007 
(epoch: 95, iters: 3648, time: 0.101, data: 0.000) loss: 0.003 
(epoch: 95, iters: 3728, time: 0.066, data: 0.000) loss: 0.001 
saving the model at the end of epoch 95, iters 354160
End of epoch 95 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 95, TEST ACC: [91.958 %]

saving the latest model (epoch 96, total_steps 354176)
(epoch: 96, iters: 80, time: 0.105, data: 0.500) loss: 0.001 
(epoch: 96, iters: 160, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 96, iters: 240, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 96, iters: 320, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 96, iters: 400, time: 0.104, data: 0.000) loss: 0.005 
(epoch: 96, iters: 480, time: 0.106, data: 0.039) loss: 0.036 
(epoch: 96, iters: 560, time: 0.107, data: 0.000) loss: 0.317 
(epoch: 96, iters: 640, time: 0.103, data: 0.011) loss: 0.150 
(epoch: 96, iters: 720, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 96, iters: 800, time: 0.105, data: 0.019) loss: 0.004 
(epoch: 96, iters: 880, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 96, iters: 960, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 96, iters: 1040, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 96, iters: 1120, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 96, iters: 1200, time: 0.103, data: 0.011) loss: 0.030 
(epoch: 96, iters: 1280, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 96, iters: 1360, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 96, iters: 1440, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 96, iters: 1520, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 96, iters: 1600, time: 0.105, data: 0.039) loss: 0.008 
(epoch: 96, iters: 1680, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 96, iters: 1760, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 96, iters: 1840, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 96, iters: 1920, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 96, iters: 2000, time: 0.106, data: 0.000) loss: 0.017 
(epoch: 96, iters: 2080, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 96, iters: 2160, time: 0.106, data: 0.040) loss: 0.006 
(epoch: 96, iters: 2240, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 96, iters: 2320, time: 0.102, data: 0.012) loss: 0.000 
(epoch: 96, iters: 2400, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 96, iters: 2480, time: 0.106, data: 0.012) loss: 0.283 
(epoch: 96, iters: 2560, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 96, iters: 2640, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 96, iters: 2720, time: 0.105, data: 0.048) loss: 0.002 
(epoch: 96, iters: 2800, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 96, iters: 2880, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 96, iters: 2960, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 96, iters: 3040, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 96, iters: 3120, time: 0.106, data: 0.000) loss: 0.036 
(epoch: 96, iters: 3200, time: 0.104, data: 0.000) loss: 0.009 
(epoch: 96, iters: 3280, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 96, iters: 3360, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 96, iters: 3440, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 96, iters: 3520, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 96, iters: 3600, time: 0.105, data: 0.011) loss: 0.007 
(epoch: 96, iters: 3680, time: 0.099, data: 0.000) loss: 0.002 
saving the model at the end of epoch 96, iters 357888
End of epoch 96 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 96, TEST ACC: [94.082 %]

saving the latest model (epoch 97, total_steps 357904)
(epoch: 97, iters: 32, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 97, iters: 112, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 97, iters: 192, time: 0.103, data: 0.011) loss: 0.007 
(epoch: 97, iters: 272, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 97, iters: 352, time: 0.104, data: 0.011) loss: 0.317 
(epoch: 97, iters: 432, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 97, iters: 512, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 97, iters: 592, time: 0.105, data: 0.039) loss: 0.003 
(epoch: 97, iters: 672, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 97, iters: 752, time: 0.102, data: 0.011) loss: 0.457 
(epoch: 97, iters: 832, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 97, iters: 912, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 97, iters: 992, time: 0.105, data: 0.000) loss: 0.098 
(epoch: 97, iters: 1072, time: 0.104, data: 0.000) loss: 0.014 
(epoch: 97, iters: 1152, time: 0.105, data: 0.046) loss: 0.016 
(epoch: 97, iters: 1232, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 97, iters: 1312, time: 0.104, data: 0.020) loss: 0.051 
(epoch: 97, iters: 1392, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 97, iters: 1472, time: 0.105, data: 0.011) loss: 0.010 
(epoch: 97, iters: 1552, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 97, iters: 1632, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 97, iters: 1712, time: 0.105, data: 0.038) loss: 0.003 
(epoch: 97, iters: 1792, time: 0.106, data: 0.000) loss: 0.031 
(epoch: 97, iters: 1872, time: 0.103, data: 0.011) loss: 0.017 
(epoch: 97, iters: 1952, time: 0.105, data: 0.000) loss: 0.018 
(epoch: 97, iters: 2032, time: 0.104, data: 0.011) loss: 0.128 
(epoch: 97, iters: 2112, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 97, iters: 2192, time: 0.104, data: 0.000) loss: 0.037 
(epoch: 97, iters: 2272, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 97, iters: 2352, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 97, iters: 2432, time: 0.104, data: 0.011) loss: 0.013 
(epoch: 97, iters: 2512, time: 0.105, data: 0.000) loss: 0.247 
(epoch: 97, iters: 2592, time: 0.103, data: 0.012) loss: 0.006 
(epoch: 97, iters: 2672, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 97, iters: 2752, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 97, iters: 2832, time: 0.106, data: 0.038) loss: 0.004 
(epoch: 97, iters: 2912, time: 0.107, data: 0.000) loss: 0.069 
(epoch: 97, iters: 2992, time: 0.104, data: 0.011) loss: 0.007 
(epoch: 97, iters: 3072, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 97, iters: 3152, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 97, iters: 3232, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 97, iters: 3312, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 97, iters: 3392, time: 0.105, data: 0.039) loss: 0.400 
(epoch: 97, iters: 3472, time: 0.106, data: 0.000) loss: 0.250 
(epoch: 97, iters: 3552, time: 0.103, data: 0.011) loss: 0.376 
(epoch: 97, iters: 3632, time: 0.102, data: 0.000) loss: 0.019 
(epoch: 97, iters: 3712, time: 0.101, data: 0.011) loss: 0.003 
saving the model at the end of epoch 97, iters 361616
End of epoch 97 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 97, TEST ACC: [93.475 %]

saving the latest model (epoch 98, total_steps 361632)
(epoch: 98, iters: 64, time: 0.104, data: 0.003) loss: 0.073 
(epoch: 98, iters: 144, time: 0.105, data: 0.000) loss: 0.026 
(epoch: 98, iters: 224, time: 0.105, data: 0.011) loss: 0.035 
(epoch: 98, iters: 304, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 98, iters: 384, time: 0.104, data: 0.000) loss: 0.011 
(epoch: 98, iters: 464, time: 0.107, data: 0.040) loss: 0.004 
(epoch: 98, iters: 544, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 98, iters: 624, time: 0.102, data: 0.011) loss: 0.002 
(epoch: 98, iters: 704, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 98, iters: 784, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 98, iters: 864, time: 0.106, data: 0.000) loss: 0.040 
(epoch: 98, iters: 944, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 98, iters: 1024, time: 0.106, data: 0.047) loss: 0.002 
(epoch: 98, iters: 1104, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 98, iters: 1184, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 98, iters: 1264, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 98, iters: 1344, time: 0.105, data: 0.011) loss: 0.029 
(epoch: 98, iters: 1424, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 98, iters: 1504, time: 0.105, data: 0.000) loss: 0.067 
(epoch: 98, iters: 1584, time: 0.105, data: 0.039) loss: 0.012 
(epoch: 98, iters: 1664, time: 0.105, data: 0.000) loss: 0.087 
(epoch: 98, iters: 1744, time: 0.103, data: 0.011) loss: 0.110 
(epoch: 98, iters: 1824, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 98, iters: 1904, time: 0.105, data: 0.011) loss: 0.007 
(epoch: 98, iters: 1984, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 98, iters: 2064, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 98, iters: 2144, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 98, iters: 2224, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 98, iters: 2304, time: 0.103, data: 0.011) loss: 0.229 
(epoch: 98, iters: 2384, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 98, iters: 2464, time: 0.105, data: 0.012) loss: 0.161 
(epoch: 98, iters: 2544, time: 0.106, data: 0.000) loss: 0.027 
(epoch: 98, iters: 2624, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 98, iters: 2704, time: 0.106, data: 0.039) loss: 0.011 
(epoch: 98, iters: 2784, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 98, iters: 2864, time: 0.102, data: 0.012) loss: 0.052 
(epoch: 98, iters: 2944, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 98, iters: 3024, time: 0.105, data: 0.011) loss: 0.030 
(epoch: 98, iters: 3104, time: 0.108, data: 0.000) loss: 0.010 
(epoch: 98, iters: 3184, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 98, iters: 3264, time: 0.106, data: 0.047) loss: 0.011 
(epoch: 98, iters: 3344, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 98, iters: 3424, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 98, iters: 3504, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 98, iters: 3584, time: 0.105, data: 0.011) loss: 0.007 
(epoch: 98, iters: 3664, time: 0.100, data: 0.000) loss: 0.012 
saving the model at the end of epoch 98, iters 365344
End of epoch 98 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 98, TEST ACC: [96.055 %]

(epoch: 99, iters: 16, time: 0.117, data: 0.000) loss: 0.001 
saving the latest model (epoch 99, total_steps 365360)
(epoch: 99, iters: 96, time: 0.106, data: 0.012) loss: 0.002 
(epoch: 99, iters: 176, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 99, iters: 256, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 99, iters: 336, time: 0.104, data: 0.019) loss: 0.000 
(epoch: 99, iters: 416, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 99, iters: 496, time: 0.104, data: 0.000) loss: 0.025 
(epoch: 99, iters: 576, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 99, iters: 656, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 99, iters: 736, time: 0.103, data: 0.012) loss: 0.334 
(epoch: 99, iters: 816, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 99, iters: 896, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 99, iters: 976, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 99, iters: 1056, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 99, iters: 1136, time: 0.106, data: 0.039) loss: 0.003 
(epoch: 99, iters: 1216, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 99, iters: 1296, time: 0.104, data: 0.011) loss: 0.030 
(epoch: 99, iters: 1376, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 99, iters: 1456, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 99, iters: 1536, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 99, iters: 1616, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 99, iters: 1696, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 99, iters: 1776, time: 0.107, data: 0.000) loss: 0.042 
(epoch: 99, iters: 1856, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 99, iters: 1936, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 99, iters: 2016, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 99, iters: 2096, time: 0.106, data: 0.000) loss: 0.034 
(epoch: 99, iters: 2176, time: 0.105, data: 0.000) loss: 0.018 
(epoch: 99, iters: 2256, time: 0.106, data: 0.039) loss: 0.003 
(epoch: 99, iters: 2336, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 99, iters: 2416, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 99, iters: 2496, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 99, iters: 2576, time: 0.104, data: 0.011) loss: 0.011 
(epoch: 99, iters: 2656, time: 0.105, data: 0.000) loss: 0.101 
(epoch: 99, iters: 2736, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 99, iters: 2816, time: 0.104, data: 0.038) loss: 0.002 
(epoch: 99, iters: 2896, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 99, iters: 2976, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 99, iters: 3056, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 99, iters: 3136, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 99, iters: 3216, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 99, iters: 3296, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 99, iters: 3376, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 99, iters: 3456, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 99, iters: 3536, time: 0.102, data: 0.011) loss: 0.006 
(epoch: 99, iters: 3616, time: 0.106, data: 0.000) loss: 0.024 
(epoch: 99, iters: 3696, time: 0.100, data: 0.011) loss: 0.051 
saving the model at the end of epoch 99, iters 369072
End of epoch 99 / 2100 	 Time Taken: 394 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 99, TEST ACC: [96.206 %]

saving the latest model (epoch 100, total_steps 369088)
(epoch: 100, iters: 48, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 100, iters: 128, time: 0.105, data: 0.025) loss: 0.010 
(epoch: 100, iters: 208, time: 0.103, data: 0.011) loss: 0.027 
(epoch: 100, iters: 288, time: 0.105, data: 0.000) loss: 0.137 
(epoch: 100, iters: 368, time: 0.104, data: 0.011) loss: 0.008 
(epoch: 100, iters: 448, time: 0.106, data: 0.000) loss: 0.034 
(epoch: 100, iters: 528, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 100, iters: 608, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 100, iters: 688, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 100, iters: 768, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 100, iters: 848, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 100, iters: 928, time: 0.105, data: 0.011) loss: 0.074 
(epoch: 100, iters: 1008, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 100, iters: 1088, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 100, iters: 1168, time: 0.105, data: 0.047) loss: 0.003 
(epoch: 100, iters: 1248, time: 0.106, data: 0.000) loss: 0.034 
(epoch: 100, iters: 1328, time: 0.103, data: 0.011) loss: 0.093 
(epoch: 100, iters: 1408, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 100, iters: 1488, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 100, iters: 1568, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 100, iters: 1648, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 100, iters: 1728, time: 0.105, data: 0.038) loss: 0.004 
(epoch: 100, iters: 1808, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 100, iters: 1888, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 100, iters: 1968, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 100, iters: 2048, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 100, iters: 2128, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 100, iters: 2208, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 100, iters: 2288, time: 0.105, data: 0.038) loss: 0.180 
(epoch: 100, iters: 2368, time: 0.106, data: 0.000) loss: 0.020 
(epoch: 100, iters: 2448, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 100, iters: 2528, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 100, iters: 2608, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 100, iters: 2688, time: 0.106, data: 0.000) loss: 0.061 
(epoch: 100, iters: 2768, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 100, iters: 2848, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 100, iters: 2928, time: 0.106, data: 0.000) loss: 0.120 
(epoch: 100, iters: 3008, time: 0.102, data: 0.012) loss: 0.007 
(epoch: 100, iters: 3088, time: 0.107, data: 0.000) loss: 0.029 
(epoch: 100, iters: 3168, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 100, iters: 3248, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 100, iters: 3328, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 100, iters: 3408, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 100, iters: 3488, time: 0.107, data: 0.000) loss: 0.071 
(epoch: 100, iters: 3568, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 100, iters: 3648, time: 0.101, data: 0.000) loss: 0.005 
(epoch: 100, iters: 3728, time: 0.066, data: 0.010) loss: 0.003 
saving the model at the end of epoch 100, iters 372800
End of epoch 100 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001999
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 100, TEST ACC: [92.868 %]

saving the latest model (epoch 101, total_steps 372816)
(epoch: 101, iters: 80, time: 0.106, data: 0.441) loss: 0.004 
(epoch: 101, iters: 160, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 101, iters: 240, time: 0.104, data: 0.039) loss: 0.010 
(epoch: 101, iters: 320, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 101, iters: 400, time: 0.103, data: 0.011) loss: 0.014 
(epoch: 101, iters: 480, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 101, iters: 560, time: 0.105, data: 0.012) loss: 0.006 
(epoch: 101, iters: 640, time: 0.107, data: 0.000) loss: 0.094 
(epoch: 101, iters: 720, time: 0.103, data: 0.000) loss: 0.011 
(epoch: 101, iters: 800, time: 0.105, data: 0.040) loss: 0.016 
(epoch: 101, iters: 880, time: 0.106, data: 0.000) loss: 0.019 
(epoch: 101, iters: 960, time: 0.102, data: 0.011) loss: 0.006 
(epoch: 101, iters: 1040, time: 0.106, data: 0.000) loss: 0.044 
(epoch: 101, iters: 1120, time: 0.104, data: 0.019) loss: 0.001 
(epoch: 101, iters: 1200, time: 0.106, data: 0.000) loss: 0.017 
(epoch: 101, iters: 1280, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 101, iters: 1360, time: 0.105, data: 0.047) loss: 0.016 
(epoch: 101, iters: 1440, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 101, iters: 1520, time: 0.104, data: 0.021) loss: 0.003 
(epoch: 101, iters: 1600, time: 0.105, data: 0.000) loss: 0.196 
(epoch: 101, iters: 1680, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 101, iters: 1760, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 101, iters: 1840, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 101, iters: 1920, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 101, iters: 2000, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 101, iters: 2080, time: 0.102, data: 0.012) loss: 0.000 
(epoch: 101, iters: 2160, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 101, iters: 2240, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 101, iters: 2320, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 101, iters: 2400, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 101, iters: 2480, time: 0.104, data: 0.038) loss: 0.164 
(epoch: 101, iters: 2560, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 101, iters: 2640, time: 0.103, data: 0.011) loss: 0.014 
(epoch: 101, iters: 2720, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 101, iters: 2800, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 101, iters: 2880, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 101, iters: 2960, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 101, iters: 3040, time: 0.106, data: 0.039) loss: 0.003 
(epoch: 101, iters: 3120, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 101, iters: 3200, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 101, iters: 3280, time: 0.104, data: 0.000) loss: 0.011 
(epoch: 101, iters: 3360, time: 0.104, data: 0.020) loss: 0.003 
(epoch: 101, iters: 3440, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 101, iters: 3520, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 101, iters: 3600, time: 0.105, data: 0.048) loss: 0.003 
(epoch: 101, iters: 3680, time: 0.100, data: 0.000) loss: 0.001 
saving the model at the end of epoch 101, iters 376528
End of epoch 101 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001998
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 101, TEST ACC: [94.992 %]

saving the latest model (epoch 102, total_steps 376544)
(epoch: 102, iters: 32, time: 0.100, data: 0.004) loss: 0.004 
(epoch: 102, iters: 112, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 102, iters: 192, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 102, iters: 272, time: 0.105, data: 0.039) loss: 0.015 
(epoch: 102, iters: 352, time: 0.106, data: 0.000) loss: 0.070 
(epoch: 102, iters: 432, time: 0.104, data: 0.012) loss: 0.003 
(epoch: 102, iters: 512, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 102, iters: 592, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 102, iters: 672, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 102, iters: 752, time: 0.104, data: 0.000) loss: 0.012 
(epoch: 102, iters: 832, time: 0.105, data: 0.038) loss: 0.146 
(epoch: 102, iters: 912, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 102, iters: 992, time: 0.103, data: 0.012) loss: 0.133 
(epoch: 102, iters: 1072, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 102, iters: 1152, time: 0.105, data: 0.012) loss: 0.006 
(epoch: 102, iters: 1232, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 102, iters: 1312, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 102, iters: 1392, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 102, iters: 1472, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 102, iters: 1552, time: 0.101, data: 0.012) loss: 0.001 
(epoch: 102, iters: 1632, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 102, iters: 1712, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 102, iters: 1792, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 102, iters: 1872, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 102, iters: 1952, time: 0.105, data: 0.048) loss: 0.002 
(epoch: 102, iters: 2032, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 102, iters: 2112, time: 0.103, data: 0.012) loss: 0.013 
(epoch: 102, iters: 2192, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 102, iters: 2272, time: 0.104, data: 0.011) loss: 0.019 
(epoch: 102, iters: 2352, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 102, iters: 2432, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 102, iters: 2512, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 102, iters: 2592, time: 0.105, data: 0.000) loss: 0.061 
(epoch: 102, iters: 2672, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 102, iters: 2752, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 102, iters: 2832, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 102, iters: 2912, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 102, iters: 2992, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 102, iters: 3072, time: 0.105, data: 0.038) loss: 0.026 
(epoch: 102, iters: 3152, time: 0.106, data: 0.000) loss: 0.019 
(epoch: 102, iters: 3232, time: 0.103, data: 0.012) loss: 0.005 
(epoch: 102, iters: 3312, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 102, iters: 3392, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 102, iters: 3472, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 102, iters: 3552, time: 0.105, data: 0.000) loss: 0.018 
(epoch: 102, iters: 3632, time: 0.104, data: 0.039) loss: 0.001 
(epoch: 102, iters: 3712, time: 0.100, data: 0.000) loss: 0.026 
saving the model at the end of epoch 102, iters 380256
End of epoch 102 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001997
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 102, TEST ACC: [97.117 %]

saving the latest model (epoch 103, total_steps 380272)
(epoch: 103, iters: 64, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 103, iters: 144, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 103, iters: 224, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 103, iters: 304, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 103, iters: 384, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 103, iters: 464, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 103, iters: 544, time: 0.102, data: 0.011) loss: 0.004 
(epoch: 103, iters: 624, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 103, iters: 704, time: 0.104, data: 0.011) loss: 0.053 
(epoch: 103, iters: 784, time: 0.105, data: 0.000) loss: 0.273 
(epoch: 103, iters: 864, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 103, iters: 944, time: 0.104, data: 0.039) loss: 0.059 
(epoch: 103, iters: 1024, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 103, iters: 1104, time: 0.103, data: 0.011) loss: 0.125 
(epoch: 103, iters: 1184, time: 0.107, data: 0.000) loss: 0.135 
(epoch: 103, iters: 1264, time: 0.105, data: 0.011) loss: 0.068 
(epoch: 103, iters: 1344, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 103, iters: 1424, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 103, iters: 1504, time: 0.105, data: 0.047) loss: 0.105 
(epoch: 103, iters: 1584, time: 0.104, data: 0.000) loss: 0.018 
(epoch: 103, iters: 1664, time: 0.103, data: 0.011) loss: 0.014 
(epoch: 103, iters: 1744, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 103, iters: 1824, time: 0.104, data: 0.011) loss: 0.090 
(epoch: 103, iters: 1904, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 103, iters: 1984, time: 0.104, data: 0.000) loss: 0.072 
(epoch: 103, iters: 2064, time: 0.105, data: 0.038) loss: 0.155 
(epoch: 103, iters: 2144, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 103, iters: 2224, time: 0.103, data: 0.011) loss: 0.008 
(epoch: 103, iters: 2304, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 103, iters: 2384, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 103, iters: 2464, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 103, iters: 2544, time: 0.103, data: 0.000) loss: 0.022 
(epoch: 103, iters: 2624, time: 0.105, data: 0.038) loss: 0.648 
(epoch: 103, iters: 2704, time: 0.105, data: 0.000) loss: 0.599 
(epoch: 103, iters: 2784, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 103, iters: 2864, time: 0.105, data: 0.000) loss: 0.039 
(epoch: 103, iters: 2944, time: 0.104, data: 0.011) loss: 0.044 
(epoch: 103, iters: 3024, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 103, iters: 3104, time: 0.103, data: 0.000) loss: 0.051 
(epoch: 103, iters: 3184, time: 0.105, data: 0.038) loss: 0.009 
(epoch: 103, iters: 3264, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 103, iters: 3344, time: 0.103, data: 0.012) loss: 0.017 
(epoch: 103, iters: 3424, time: 0.105, data: 0.000) loss: 0.047 
(epoch: 103, iters: 3504, time: 0.104, data: 0.011) loss: 0.179 
(epoch: 103, iters: 3584, time: 0.105, data: 0.000) loss: 0.161 
(epoch: 103, iters: 3664, time: 0.099, data: 0.000) loss: 0.011 
saving the model at the end of epoch 103, iters 383984
End of epoch 103 / 2100 	 Time Taken: 392 sec
learning rate = 0.0001996
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 103, TEST ACC: [74.507 %]

(epoch: 104, iters: 16, time: 0.118, data: 0.012) loss: 0.002 
saving the latest model (epoch 104, total_steps 384000)
(epoch: 104, iters: 96, time: 0.105, data: 0.043) loss: 0.024 
(epoch: 104, iters: 176, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 104, iters: 256, time: 0.103, data: 0.011) loss: 0.010 
(epoch: 104, iters: 336, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 104, iters: 416, time: 0.104, data: 0.011) loss: 0.009 
(epoch: 104, iters: 496, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 104, iters: 576, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 104, iters: 656, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 104, iters: 736, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 104, iters: 816, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 104, iters: 896, time: 0.105, data: 0.000) loss: 0.026 
(epoch: 104, iters: 976, time: 0.103, data: 0.011) loss: 0.024 
(epoch: 104, iters: 1056, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 104, iters: 1136, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 104, iters: 1216, time: 0.104, data: 0.038) loss: 0.016 
(epoch: 104, iters: 1296, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 104, iters: 1376, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 104, iters: 1456, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 104, iters: 1536, time: 0.105, data: 0.011) loss: 0.007 
(epoch: 104, iters: 1616, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 104, iters: 1696, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 104, iters: 1776, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 104, iters: 1856, time: 0.106, data: 0.000) loss: 0.106 
(epoch: 104, iters: 1936, time: 0.102, data: 0.011) loss: 0.015 
(epoch: 104, iters: 2016, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 104, iters: 2096, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 104, iters: 2176, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 104, iters: 2256, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 104, iters: 2336, time: 0.105, data: 0.048) loss: 0.021 
(epoch: 104, iters: 2416, time: 0.105, data: 0.000) loss: 0.055 
(epoch: 104, iters: 2496, time: 0.103, data: 0.011) loss: 0.121 
(epoch: 104, iters: 2576, time: 0.105, data: 0.000) loss: 0.172 
(epoch: 104, iters: 2656, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 104, iters: 2736, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 104, iters: 2816, time: 0.104, data: 0.000) loss: 0.225 
(epoch: 104, iters: 2896, time: 0.105, data: 0.038) loss: 0.014 
(epoch: 104, iters: 2976, time: 0.105, data: 0.000) loss: 0.059 
(epoch: 104, iters: 3056, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 104, iters: 3136, time: 0.104, data: 0.000) loss: 0.016 
(epoch: 104, iters: 3216, time: 0.104, data: 0.011) loss: 0.056 
(epoch: 104, iters: 3296, time: 0.104, data: 0.000) loss: 0.014 
(epoch: 104, iters: 3376, time: 0.104, data: 0.000) loss: 0.019 
(epoch: 104, iters: 3456, time: 0.105, data: 0.038) loss: 0.085 
(epoch: 104, iters: 3536, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 104, iters: 3616, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 104, iters: 3696, time: 0.100, data: 0.000) loss: 0.000 
saving the model at the end of epoch 104, iters 387712
End of epoch 104 / 2100 	 Time Taken: 392 sec
learning rate = 0.0001995
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 104, TEST ACC: [92.868 %]

saving the latest model (epoch 105, total_steps 387728)
(epoch: 105, iters: 48, time: 0.106, data: 0.005) loss: 0.026 
(epoch: 105, iters: 128, time: 0.104, data: 0.026) loss: 0.075 
(epoch: 105, iters: 208, time: 0.103, data: 0.011) loss: 0.005 
(epoch: 105, iters: 288, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 105, iters: 368, time: 0.103, data: 0.011) loss: 0.006 
(epoch: 105, iters: 448, time: 0.106, data: 0.000) loss: 0.153 
(epoch: 105, iters: 528, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 105, iters: 608, time: 0.105, data: 0.038) loss: 0.003 
(epoch: 105, iters: 688, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 105, iters: 768, time: 0.104, data: 0.012) loss: 0.007 
(epoch: 105, iters: 848, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 105, iters: 928, time: 0.104, data: 0.011) loss: 0.167 
(epoch: 105, iters: 1008, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 105, iters: 1088, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 105, iters: 1168, time: 0.105, data: 0.038) loss: 0.014 
(epoch: 105, iters: 1248, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 105, iters: 1328, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 105, iters: 1408, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 105, iters: 1488, time: 0.103, data: 0.011) loss: 0.009 
(epoch: 105, iters: 1568, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 105, iters: 1648, time: 0.104, data: 0.000) loss: 0.183 
(epoch: 105, iters: 1728, time: 0.105, data: 0.038) loss: 0.020 
(epoch: 105, iters: 1808, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 105, iters: 1888, time: 0.103, data: 0.011) loss: 0.008 
(epoch: 105, iters: 1968, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 105, iters: 2048, time: 0.104, data: 0.011) loss: 0.025 
(epoch: 105, iters: 2128, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 105, iters: 2208, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 105, iters: 2288, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 105, iters: 2368, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 105, iters: 2448, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 105, iters: 2528, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 105, iters: 2608, time: 0.104, data: 0.011) loss: 0.045 
(epoch: 105, iters: 2688, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 105, iters: 2768, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 105, iters: 2848, time: 0.105, data: 0.038) loss: 0.071 
(epoch: 105, iters: 2928, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 105, iters: 3008, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 105, iters: 3088, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 105, iters: 3168, time: 0.105, data: 0.012) loss: 0.185 
(epoch: 105, iters: 3248, time: 0.107, data: 0.000) loss: 0.028 
(epoch: 105, iters: 3328, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 105, iters: 3408, time: 0.106, data: 0.039) loss: 0.021 
(epoch: 105, iters: 3488, time: 0.107, data: 0.000) loss: 0.005 
(epoch: 105, iters: 3568, time: 0.104, data: 0.012) loss: 0.002 
(epoch: 105, iters: 3648, time: 0.100, data: 0.000) loss: 0.011 
(epoch: 105, iters: 3728, time: 0.065, data: 0.010) loss: 0.019 
saving the model at the end of epoch 105, iters 391440
End of epoch 105 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001994
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 105, TEST ACC: [95.751 %]

saving the latest model (epoch 106, total_steps 391456)
(epoch: 106, iters: 80, time: 0.106, data: 0.470) loss: 0.004 
(epoch: 106, iters: 160, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 106, iters: 240, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 106, iters: 320, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 106, iters: 400, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 106, iters: 480, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 106, iters: 560, time: 0.105, data: 0.011) loss: 0.009 
(epoch: 106, iters: 640, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 106, iters: 720, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 106, iters: 800, time: 0.105, data: 0.039) loss: 0.004 
(epoch: 106, iters: 880, time: 0.107, data: 0.000) loss: 0.280 
(epoch: 106, iters: 960, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 106, iters: 1040, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 106, iters: 1120, time: 0.105, data: 0.019) loss: 0.160 
(epoch: 106, iters: 1200, time: 0.106, data: 0.000) loss: 0.214 
(epoch: 106, iters: 1280, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 106, iters: 1360, time: 0.105, data: 0.047) loss: 0.002 
(epoch: 106, iters: 1440, time: 0.107, data: 0.000) loss: 0.055 
(epoch: 106, iters: 1520, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 106, iters: 1600, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 106, iters: 1680, time: 0.104, data: 0.011) loss: 0.118 
(epoch: 106, iters: 1760, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 106, iters: 1840, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 106, iters: 1920, time: 0.105, data: 0.048) loss: 0.017 
(epoch: 106, iters: 2000, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 106, iters: 2080, time: 0.103, data: 0.012) loss: 0.466 
(epoch: 106, iters: 2160, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 106, iters: 2240, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 106, iters: 2320, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 106, iters: 2400, time: 0.105, data: 0.000) loss: 0.042 
(epoch: 106, iters: 2480, time: 0.105, data: 0.038) loss: 0.005 
(epoch: 106, iters: 2560, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 106, iters: 2640, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 106, iters: 2720, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 106, iters: 2800, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 106, iters: 2880, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 106, iters: 2960, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 106, iters: 3040, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 106, iters: 3120, time: 0.105, data: 0.000) loss: 0.026 
(epoch: 106, iters: 3200, time: 0.104, data: 0.011) loss: 0.024 
(epoch: 106, iters: 3280, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 106, iters: 3360, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 106, iters: 3440, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 106, iters: 3520, time: 0.105, data: 0.000) loss: 0.070 
(epoch: 106, iters: 3600, time: 0.105, data: 0.038) loss: 0.009 
(epoch: 106, iters: 3680, time: 0.101, data: 0.000) loss: 0.001 
saving the model at the end of epoch 106, iters 395168
End of epoch 106 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001993
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 106, TEST ACC: [90.895 %]

saving the latest model (epoch 107, total_steps 395184)
(epoch: 107, iters: 32, time: 0.100, data: 0.004) loss: 0.001 
(epoch: 107, iters: 112, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 107, iters: 192, time: 0.104, data: 0.011) loss: 0.019 
(epoch: 107, iters: 272, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 107, iters: 352, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 107, iters: 432, time: 0.106, data: 0.038) loss: 0.009 
(epoch: 107, iters: 512, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 107, iters: 592, time: 0.103, data: 0.011) loss: 0.044 
(epoch: 107, iters: 672, time: 0.105, data: 0.000) loss: 0.019 
(epoch: 107, iters: 752, time: 0.105, data: 0.012) loss: 0.012 
(epoch: 107, iters: 832, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 107, iters: 912, time: 0.105, data: 0.000) loss: 0.058 
(epoch: 107, iters: 992, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 107, iters: 1072, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 107, iters: 1152, time: 0.103, data: 0.012) loss: 0.023 
(epoch: 107, iters: 1232, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 107, iters: 1312, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 107, iters: 1392, time: 0.106, data: 0.000) loss: 0.080 
(epoch: 107, iters: 1472, time: 0.103, data: 0.000) loss: 0.004 
(epoch: 107, iters: 1552, time: 0.105, data: 0.047) loss: 0.013 
(epoch: 107, iters: 1632, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 107, iters: 1712, time: 0.103, data: 0.011) loss: 0.025 
(epoch: 107, iters: 1792, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 107, iters: 1872, time: 0.105, data: 0.011) loss: 0.005 
(epoch: 107, iters: 1952, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 107, iters: 2032, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 107, iters: 2112, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 107, iters: 2192, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 107, iters: 2272, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 107, iters: 2352, time: 0.105, data: 0.000) loss: 0.032 
(epoch: 107, iters: 2432, time: 0.105, data: 0.011) loss: 0.008 
(epoch: 107, iters: 2512, time: 0.105, data: 0.000) loss: 0.034 
(epoch: 107, iters: 2592, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 107, iters: 2672, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 107, iters: 2752, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 107, iters: 2832, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 107, iters: 2912, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 107, iters: 2992, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 107, iters: 3072, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 107, iters: 3152, time: 0.104, data: 0.000) loss: 0.050 
(epoch: 107, iters: 3232, time: 0.104, data: 0.035) loss: 0.005 
(epoch: 107, iters: 3312, time: 0.105, data: 0.000) loss: 0.058 
(epoch: 107, iters: 3392, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 107, iters: 3472, time: 0.105, data: 0.012) loss: 0.003 
(epoch: 107, iters: 3552, time: 0.104, data: 0.024) loss: 0.001 
(epoch: 107, iters: 3632, time: 0.102, data: 0.000) loss: 0.004 
(epoch: 107, iters: 3712, time: 0.101, data: 0.000) loss: 0.011 
saving the model at the end of epoch 107, iters 398896
End of epoch 107 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001992
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 107, TEST ACC: [95.903 %]

saving the latest model (epoch 108, total_steps 398912)
(epoch: 108, iters: 64, time: 0.105, data: 0.003) loss: 0.002 
(epoch: 108, iters: 144, time: 0.105, data: 0.026) loss: 0.007 
(epoch: 108, iters: 224, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 108, iters: 304, time: 0.104, data: 0.012) loss: 0.050 
(epoch: 108, iters: 384, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 108, iters: 464, time: 0.104, data: 0.011) loss: 0.046 
(epoch: 108, iters: 544, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 108, iters: 624, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 108, iters: 704, time: 0.105, data: 0.038) loss: 0.187 
(epoch: 108, iters: 784, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 108, iters: 864, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 108, iters: 944, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 108, iters: 1024, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 108, iters: 1104, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 108, iters: 1184, time: 0.104, data: 0.000) loss: 0.013 
(epoch: 108, iters: 1264, time: 0.104, data: 0.039) loss: 0.001 
(epoch: 108, iters: 1344, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 108, iters: 1424, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 108, iters: 1504, time: 0.104, data: 0.000) loss: 0.109 
(epoch: 108, iters: 1584, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 108, iters: 1664, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 108, iters: 1744, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 108, iters: 1824, time: 0.104, data: 0.038) loss: 0.002 
(epoch: 108, iters: 1904, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 108, iters: 1984, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 108, iters: 2064, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 108, iters: 2144, time: 0.104, data: 0.012) loss: 0.020 
(epoch: 108, iters: 2224, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 108, iters: 2304, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 108, iters: 2384, time: 0.105, data: 0.038) loss: 0.087 
(epoch: 108, iters: 2464, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 108, iters: 2544, time: 0.102, data: 0.011) loss: 0.007 
(epoch: 108, iters: 2624, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 108, iters: 2704, time: 0.103, data: 0.011) loss: 0.197 
(epoch: 108, iters: 2784, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 108, iters: 2864, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 108, iters: 2944, time: 0.106, data: 0.038) loss: 0.007 
(epoch: 108, iters: 3024, time: 0.105, data: 0.000) loss: 0.701 
(epoch: 108, iters: 3104, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 108, iters: 3184, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 108, iters: 3264, time: 0.105, data: 0.012) loss: 0.035 
(epoch: 108, iters: 3344, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 108, iters: 3424, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 108, iters: 3504, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 108, iters: 3584, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 108, iters: 3664, time: 0.099, data: 0.012) loss: 0.012 
saving the model at the end of epoch 108, iters 402624
End of epoch 108 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001991
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 108, TEST ACC: [90.895 %]

(epoch: 109, iters: 16, time: 0.118, data: 0.012) loss: 0.079 
saving the latest model (epoch 109, total_steps 402640)
(epoch: 109, iters: 96, time: 0.105, data: 0.012) loss: 0.005 
(epoch: 109, iters: 176, time: 0.104, data: 0.011) loss: 0.161 
(epoch: 109, iters: 256, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 109, iters: 336, time: 0.104, data: 0.012) loss: 0.002 
(epoch: 109, iters: 416, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 109, iters: 496, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 109, iters: 576, time: 0.105, data: 0.047) loss: 0.002 
(epoch: 109, iters: 656, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 109, iters: 736, time: 0.102, data: 0.011) loss: 0.427 
(epoch: 109, iters: 816, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 109, iters: 896, time: 0.105, data: 0.011) loss: 0.023 
(epoch: 109, iters: 976, time: 0.105, data: 0.000) loss: 0.030 
(epoch: 109, iters: 1056, time: 0.104, data: 0.000) loss: 0.017 
(epoch: 109, iters: 1136, time: 0.105, data: 0.048) loss: 0.035 
(epoch: 109, iters: 1216, time: 0.106, data: 0.000) loss: 0.089 
(epoch: 109, iters: 1296, time: 0.103, data: 0.012) loss: 0.010 
(epoch: 109, iters: 1376, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 109, iters: 1456, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 109, iters: 1536, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 109, iters: 1616, time: 0.103, data: 0.000) loss: 0.104 
(epoch: 109, iters: 1696, time: 0.105, data: 0.038) loss: 0.003 
(epoch: 109, iters: 1776, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 109, iters: 1856, time: 0.103, data: 0.011) loss: 0.006 
(epoch: 109, iters: 1936, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 109, iters: 2016, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 109, iters: 2096, time: 0.106, data: 0.000) loss: 0.053 
(epoch: 109, iters: 2176, time: 0.104, data: 0.000) loss: 0.031 
(epoch: 109, iters: 2256, time: 0.104, data: 0.038) loss: 0.001 
(epoch: 109, iters: 2336, time: 0.106, data: 0.000) loss: 0.088 
(epoch: 109, iters: 2416, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 109, iters: 2496, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 109, iters: 2576, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 109, iters: 2656, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 109, iters: 2736, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 109, iters: 2816, time: 0.105, data: 0.040) loss: 0.003 
(epoch: 109, iters: 2896, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 109, iters: 2976, time: 0.102, data: 0.011) loss: 0.004 
(epoch: 109, iters: 3056, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 109, iters: 3136, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 109, iters: 3216, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 109, iters: 3296, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 109, iters: 3376, time: 0.105, data: 0.048) loss: 0.003 
(epoch: 109, iters: 3456, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 109, iters: 3536, time: 0.103, data: 0.012) loss: 0.003 
(epoch: 109, iters: 3616, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 109, iters: 3696, time: 0.100, data: 0.011) loss: 0.005 
saving the model at the end of epoch 109, iters 406352
End of epoch 109 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001990
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 109, TEST ACC: [96.51 %]

saving the latest model (epoch 110, total_steps 406368)
(epoch: 110, iters: 48, time: 0.105, data: 0.000) loss: 0.089 
(epoch: 110, iters: 128, time: 0.105, data: 0.025) loss: 0.001 
(epoch: 110, iters: 208, time: 0.105, data: 0.000) loss: 0.121 
(epoch: 110, iters: 288, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 110, iters: 368, time: 0.105, data: 0.000) loss: 0.035 
(epoch: 110, iters: 448, time: 0.104, data: 0.011) loss: 0.014 
(epoch: 110, iters: 528, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 110, iters: 608, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 110, iters: 688, time: 0.104, data: 0.039) loss: 0.000 
(epoch: 110, iters: 768, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 110, iters: 848, time: 0.102, data: 0.012) loss: 0.002 
(epoch: 110, iters: 928, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 110, iters: 1008, time: 0.104, data: 0.011) loss: 0.008 
(epoch: 110, iters: 1088, time: 0.105, data: 0.000) loss: 0.057 
(epoch: 110, iters: 1168, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 110, iters: 1248, time: 0.106, data: 0.039) loss: 0.006 
(epoch: 110, iters: 1328, time: 0.105, data: 0.000) loss: 0.022 
(epoch: 110, iters: 1408, time: 0.104, data: 0.019) loss: 0.001 
(epoch: 110, iters: 1488, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 110, iters: 1568, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 110, iters: 1648, time: 0.106, data: 0.000) loss: 0.067 
(epoch: 110, iters: 1728, time: 0.104, data: 0.000) loss: 0.013 
(epoch: 110, iters: 1808, time: 0.104, data: 0.038) loss: 0.249 
(epoch: 110, iters: 1888, time: 0.107, data: 0.000) loss: 0.004 
(epoch: 110, iters: 1968, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 110, iters: 2048, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 110, iters: 2128, time: 0.104, data: 0.011) loss: 0.106 
(epoch: 110, iters: 2208, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 110, iters: 2288, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 110, iters: 2368, time: 0.105, data: 0.038) loss: 0.008 
(epoch: 110, iters: 2448, time: 0.105, data: 0.000) loss: 0.026 
(epoch: 110, iters: 2528, time: 0.102, data: 0.011) loss: 0.006 
(epoch: 110, iters: 2608, time: 0.106, data: 0.000) loss: 0.086 
(epoch: 110, iters: 2688, time: 0.104, data: 0.012) loss: 0.049 
(epoch: 110, iters: 2768, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 110, iters: 2848, time: 0.104, data: 0.000) loss: 0.010 
(epoch: 110, iters: 2928, time: 0.105, data: 0.046) loss: 0.074 
(epoch: 110, iters: 3008, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 110, iters: 3088, time: 0.105, data: 0.020) loss: 0.003 
(epoch: 110, iters: 3168, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 110, iters: 3248, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 110, iters: 3328, time: 0.106, data: 0.000) loss: 0.062 
(epoch: 110, iters: 3408, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 110, iters: 3488, time: 0.105, data: 0.038) loss: 0.326 
(epoch: 110, iters: 3568, time: 0.104, data: 0.000) loss: 0.012 
(epoch: 110, iters: 3648, time: 0.098, data: 0.011) loss: 0.001 
(epoch: 110, iters: 3728, time: 0.066, data: 0.000) loss: 0.005 
saving the model at the end of epoch 110, iters 410080
End of epoch 110 / 2100 	 Time Taken: 392 sec
learning rate = 0.0001989
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 110, TEST ACC: [91.199 %]

saving the latest model (epoch 111, total_steps 410096)
(epoch: 111, iters: 80, time: 0.103, data: 0.498) loss: 0.002 
(epoch: 111, iters: 160, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 111, iters: 240, time: 0.106, data: 0.019) loss: 0.143 
(epoch: 111, iters: 320, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 111, iters: 400, time: 0.105, data: 0.000) loss: 0.022 
(epoch: 111, iters: 480, time: 0.104, data: 0.047) loss: 0.006 
(epoch: 111, iters: 560, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 111, iters: 640, time: 0.103, data: 0.012) loss: 0.025 
(epoch: 111, iters: 720, time: 0.104, data: 0.000) loss: 0.129 
(epoch: 111, iters: 800, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 111, iters: 880, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 111, iters: 960, time: 0.104, data: 0.000) loss: 0.015 
(epoch: 111, iters: 1040, time: 0.106, data: 0.038) loss: 0.024 
(epoch: 111, iters: 1120, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 111, iters: 1200, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 111, iters: 1280, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 111, iters: 1360, time: 0.104, data: 0.011) loss: 0.009 
(epoch: 111, iters: 1440, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 111, iters: 1520, time: 0.104, data: 0.000) loss: 0.075 
(epoch: 111, iters: 1600, time: 0.105, data: 0.038) loss: 0.003 
(epoch: 111, iters: 1680, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 111, iters: 1760, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 111, iters: 1840, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 111, iters: 1920, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 111, iters: 2000, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 111, iters: 2080, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 111, iters: 2160, time: 0.105, data: 0.038) loss: 0.204 
(epoch: 111, iters: 2240, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 111, iters: 2320, time: 0.102, data: 0.011) loss: 0.010 
(epoch: 111, iters: 2400, time: 0.106, data: 0.000) loss: 0.022 
(epoch: 111, iters: 2480, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 111, iters: 2560, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 111, iters: 2640, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 111, iters: 2720, time: 0.105, data: 0.047) loss: 0.002 
(epoch: 111, iters: 2800, time: 0.105, data: 0.000) loss: 0.052 
(epoch: 111, iters: 2880, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 111, iters: 2960, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 111, iters: 3040, time: 0.105, data: 0.011) loss: 0.009 
(epoch: 111, iters: 3120, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 111, iters: 3200, time: 0.103, data: 0.000) loss: 0.073 
(epoch: 111, iters: 3280, time: 0.105, data: 0.038) loss: 0.106 
(epoch: 111, iters: 3360, time: 0.105, data: 0.000) loss: 0.066 
(epoch: 111, iters: 3440, time: 0.102, data: 0.012) loss: 0.002 
(epoch: 111, iters: 3520, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 111, iters: 3600, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 111, iters: 3680, time: 0.099, data: 0.000) loss: 0.023 
saving the model at the end of epoch 111, iters 413808
End of epoch 111 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001988
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 111, TEST ACC: [90.592 %]

saving the latest model (epoch 112, total_steps 413824)
(epoch: 112, iters: 32, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 112, iters: 112, time: 0.104, data: 0.000) loss: 0.075 
(epoch: 112, iters: 192, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 112, iters: 272, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 112, iters: 352, time: 0.105, data: 0.039) loss: 0.016 
(epoch: 112, iters: 432, time: 0.106, data: 0.000) loss: 0.037 
(epoch: 112, iters: 512, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 112, iters: 592, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 112, iters: 672, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 112, iters: 752, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 112, iters: 832, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 112, iters: 912, time: 0.104, data: 0.038) loss: 0.004 
(epoch: 112, iters: 992, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 112, iters: 1072, time: 0.101, data: 0.012) loss: 0.022 
(epoch: 112, iters: 1152, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 112, iters: 1232, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 112, iters: 1312, time: 0.106, data: 0.000) loss: 0.210 
(epoch: 112, iters: 1392, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 112, iters: 1472, time: 0.105, data: 0.039) loss: 0.035 
(epoch: 112, iters: 1552, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 112, iters: 1632, time: 0.102, data: 0.011) loss: 0.011 
(epoch: 112, iters: 1712, time: 0.104, data: 0.000) loss: 0.005 
(epoch: 112, iters: 1792, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 112, iters: 1872, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 112, iters: 1952, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 112, iters: 2032, time: 0.104, data: 0.047) loss: 0.002 
(epoch: 112, iters: 2112, time: 0.106, data: 0.000) loss: 0.165 
(epoch: 112, iters: 2192, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 112, iters: 2272, time: 0.105, data: 0.000) loss: 0.094 
(epoch: 112, iters: 2352, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 112, iters: 2432, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 112, iters: 2512, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 112, iters: 2592, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 112, iters: 2672, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 112, iters: 2752, time: 0.104, data: 0.012) loss: 0.030 
(epoch: 112, iters: 2832, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 112, iters: 2912, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 112, iters: 2992, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 112, iters: 3072, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 112, iters: 3152, time: 0.104, data: 0.038) loss: 0.001 
(epoch: 112, iters: 3232, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 112, iters: 3312, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 112, iters: 3392, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 112, iters: 3472, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 112, iters: 3552, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 112, iters: 3632, time: 0.102, data: 0.000) loss: 0.001 
(epoch: 112, iters: 3712, time: 0.100, data: 0.036) loss: 0.001 
saving the model at the end of epoch 112, iters 417536
End of epoch 112 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001987
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 112, TEST ACC: [95.751 %]

saving the latest model (epoch 113, total_steps 417552)
(epoch: 113, iters: 64, time: 0.102, data: 0.000) loss: 0.002 
(epoch: 113, iters: 144, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 113, iters: 224, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 113, iters: 304, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 113, iters: 384, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 113, iters: 464, time: 0.107, data: 0.039) loss: 0.000 
(epoch: 113, iters: 544, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 113, iters: 624, time: 0.102, data: 0.011) loss: 0.013 
(epoch: 113, iters: 704, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 113, iters: 784, time: 0.105, data: 0.020) loss: 0.000 
(epoch: 113, iters: 864, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 113, iters: 944, time: 0.104, data: 0.000) loss: 0.160 
(epoch: 113, iters: 1024, time: 0.105, data: 0.048) loss: 0.004 
(epoch: 113, iters: 1104, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 113, iters: 1184, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 113, iters: 1264, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 113, iters: 1344, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 113, iters: 1424, time: 0.105, data: 0.000) loss: 0.094 
(epoch: 113, iters: 1504, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 113, iters: 1584, time: 0.104, data: 0.040) loss: 0.005 
(epoch: 113, iters: 1664, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 113, iters: 1744, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 113, iters: 1824, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 113, iters: 1904, time: 0.104, data: 0.011) loss: 0.089 
(epoch: 113, iters: 1984, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 113, iters: 2064, time: 0.104, data: 0.000) loss: 0.005 
(epoch: 113, iters: 2144, time: 0.105, data: 0.038) loss: 0.016 
(epoch: 113, iters: 2224, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 113, iters: 2304, time: 0.104, data: 0.012) loss: 0.013 
(epoch: 113, iters: 2384, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 113, iters: 2464, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 113, iters: 2544, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 113, iters: 2624, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 113, iters: 2704, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 113, iters: 2784, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 113, iters: 2864, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 113, iters: 2944, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 113, iters: 3024, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 113, iters: 3104, time: 0.106, data: 0.000) loss: 0.015 
(epoch: 113, iters: 3184, time: 0.103, data: 0.000) loss: 0.012 
(epoch: 113, iters: 3264, time: 0.106, data: 0.048) loss: 0.015 
(epoch: 113, iters: 3344, time: 0.105, data: 0.000) loss: 0.026 
(epoch: 113, iters: 3424, time: 0.103, data: 0.012) loss: 0.036 
(epoch: 113, iters: 3504, time: 0.105, data: 0.000) loss: 0.026 
(epoch: 113, iters: 3584, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 113, iters: 3664, time: 0.100, data: 0.000) loss: 0.065 
saving the model at the end of epoch 113, iters 421264
End of epoch 113 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001986
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 113, TEST ACC: [92.868 %]

(epoch: 114, iters: 16, time: 0.118, data: 0.000) loss: 0.007 
saving the latest model (epoch 114, total_steps 421280)
(epoch: 114, iters: 96, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 114, iters: 176, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 114, iters: 256, time: 0.105, data: 0.000) loss: 0.033 
(epoch: 114, iters: 336, time: 0.105, data: 0.012) loss: 0.006 
(epoch: 114, iters: 416, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 114, iters: 496, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 114, iters: 576, time: 0.105, data: 0.038) loss: 0.004 
(epoch: 114, iters: 656, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 114, iters: 736, time: 0.103, data: 0.011) loss: 0.022 
(epoch: 114, iters: 816, time: 0.106, data: 0.000) loss: 0.270 
(epoch: 114, iters: 896, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 114, iters: 976, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 114, iters: 1056, time: 0.104, data: 0.000) loss: 0.206 
(epoch: 114, iters: 1136, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 114, iters: 1216, time: 0.105, data: 0.000) loss: 0.019 
(epoch: 114, iters: 1296, time: 0.103, data: 0.012) loss: 0.136 
(epoch: 114, iters: 1376, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 114, iters: 1456, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 114, iters: 1536, time: 0.106, data: 0.000) loss: 0.089 
(epoch: 114, iters: 1616, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 114, iters: 1696, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 114, iters: 1776, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 114, iters: 1856, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 114, iters: 1936, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 114, iters: 2016, time: 0.104, data: 0.011) loss: 0.254 
(epoch: 114, iters: 2096, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 114, iters: 2176, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 114, iters: 2256, time: 0.104, data: 0.038) loss: 0.001 
(epoch: 114, iters: 2336, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 114, iters: 2416, time: 0.102, data: 0.011) loss: 0.020 
(epoch: 114, iters: 2496, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 114, iters: 2576, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 114, iters: 2656, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 114, iters: 2736, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 114, iters: 2816, time: 0.104, data: 0.038) loss: 0.001 
(epoch: 114, iters: 2896, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 114, iters: 2976, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 114, iters: 3056, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 114, iters: 3136, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 114, iters: 3216, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 114, iters: 3296, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 114, iters: 3376, time: 0.106, data: 0.047) loss: 0.024 
(epoch: 114, iters: 3456, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 114, iters: 3536, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 114, iters: 3616, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 114, iters: 3696, time: 0.100, data: 0.011) loss: 0.001 
saving the model at the end of epoch 114, iters 424992
End of epoch 114 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001985
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 114, TEST ACC: [94.841 %]

saving the latest model (epoch 115, total_steps 425008)
(epoch: 115, iters: 48, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 115, iters: 128, time: 0.106, data: 0.025) loss: 0.005 
(epoch: 115, iters: 208, time: 0.102, data: 0.011) loss: 0.042 
(epoch: 115, iters: 288, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 115, iters: 368, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 115, iters: 448, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 115, iters: 528, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 115, iters: 608, time: 0.105, data: 0.038) loss: 0.023 
(epoch: 115, iters: 688, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 115, iters: 768, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 115, iters: 848, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 115, iters: 928, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 115, iters: 1008, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 115, iters: 1088, time: 0.104, data: 0.000) loss: 0.323 
(epoch: 115, iters: 1168, time: 0.106, data: 0.046) loss: 0.003 
(epoch: 115, iters: 1248, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 115, iters: 1328, time: 0.103, data: 0.020) loss: 0.010 
(epoch: 115, iters: 1408, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 115, iters: 1488, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 115, iters: 1568, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 115, iters: 1648, time: 0.104, data: 0.000) loss: 0.021 
(epoch: 115, iters: 1728, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 115, iters: 1808, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 115, iters: 1888, time: 0.103, data: 0.012) loss: 0.014 
(epoch: 115, iters: 1968, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 115, iters: 2048, time: 0.105, data: 0.011) loss: 0.007 
(epoch: 115, iters: 2128, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 115, iters: 2208, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 115, iters: 2288, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 115, iters: 2368, time: 0.106, data: 0.000) loss: 0.041 
(epoch: 115, iters: 2448, time: 0.101, data: 0.011) loss: 0.002 
(epoch: 115, iters: 2528, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 115, iters: 2608, time: 0.105, data: 0.019) loss: 0.010 
(epoch: 115, iters: 2688, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 115, iters: 2768, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 115, iters: 2848, time: 0.103, data: 0.047) loss: 0.000 
(epoch: 115, iters: 2928, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 115, iters: 3008, time: 0.102, data: 0.012) loss: 0.001 
(epoch: 115, iters: 3088, time: 0.105, data: 0.000) loss: 0.027 
(epoch: 115, iters: 3168, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 115, iters: 3248, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 115, iters: 3328, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 115, iters: 3408, time: 0.105, data: 0.038) loss: 0.005 
(epoch: 115, iters: 3488, time: 0.106, data: 0.000) loss: 0.129 
(epoch: 115, iters: 3568, time: 0.103, data: 0.011) loss: 0.012 
(epoch: 115, iters: 3648, time: 0.101, data: 0.000) loss: 0.423 
(epoch: 115, iters: 3728, time: 0.066, data: 0.010) loss: 0.046 
saving the model at the end of epoch 115, iters 428720
End of epoch 115 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001984
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 115, TEST ACC: [84.067 %]

saving the latest model (epoch 116, total_steps 428736)
(epoch: 116, iters: 80, time: 0.105, data: 0.505) loss: 0.000 
(epoch: 116, iters: 160, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 116, iters: 240, time: 0.106, data: 0.038) loss: 0.005 
(epoch: 116, iters: 320, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 116, iters: 400, time: 0.102, data: 0.012) loss: 0.021 
(epoch: 116, iters: 480, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 116, iters: 560, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 116, iters: 640, time: 0.107, data: 0.000) loss: 0.006 
(epoch: 116, iters: 720, time: 0.104, data: 0.000) loss: 0.084 
(epoch: 116, iters: 800, time: 0.105, data: 0.039) loss: 0.081 
(epoch: 116, iters: 880, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 116, iters: 960, time: 0.102, data: 0.012) loss: 0.028 
(epoch: 116, iters: 1040, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 116, iters: 1120, time: 0.105, data: 0.018) loss: 0.006 
(epoch: 116, iters: 1200, time: 0.106, data: 0.000) loss: 0.018 
(epoch: 116, iters: 1280, time: 0.104, data: 0.000) loss: 0.091 
(epoch: 116, iters: 1360, time: 0.106, data: 0.048) loss: 0.089 
(epoch: 116, iters: 1440, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 116, iters: 1520, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 116, iters: 1600, time: 0.106, data: 0.000) loss: 0.020 
(epoch: 116, iters: 1680, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 116, iters: 1760, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 116, iters: 1840, time: 0.104, data: 0.000) loss: 0.114 
(epoch: 116, iters: 1920, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 116, iters: 2000, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 116, iters: 2080, time: 0.103, data: 0.012) loss: 0.018 
(epoch: 116, iters: 2160, time: 0.105, data: 0.000) loss: 0.293 
(epoch: 116, iters: 2240, time: 0.104, data: 0.011) loss: 0.162 
(epoch: 116, iters: 2320, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 116, iters: 2400, time: 0.105, data: 0.000) loss: 0.024 
(epoch: 116, iters: 2480, time: 0.105, data: 0.039) loss: 0.003 
(epoch: 116, iters: 2560, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 116, iters: 2640, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 116, iters: 2720, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 116, iters: 2800, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 116, iters: 2880, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 116, iters: 2960, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 116, iters: 3040, time: 0.106, data: 0.039) loss: 0.078 
(epoch: 116, iters: 3120, time: 0.106, data: 0.000) loss: 0.046 
(epoch: 116, iters: 3200, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 116, iters: 3280, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 116, iters: 3360, time: 0.103, data: 0.011) loss: 0.009 
(epoch: 116, iters: 3440, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 116, iters: 3520, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 116, iters: 3600, time: 0.104, data: 0.038) loss: 0.002 
(epoch: 116, iters: 3680, time: 0.099, data: 0.000) loss: 0.001 
saving the model at the end of epoch 116, iters 432448
End of epoch 116 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001983
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 116, TEST ACC: [89.833 %]

saving the latest model (epoch 117, total_steps 432464)
(epoch: 117, iters: 32, time: 0.100, data: 0.004) loss: 0.134 
(epoch: 117, iters: 112, time: 0.103, data: 0.012) loss: 0.298 
(epoch: 117, iters: 192, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 117, iters: 272, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 117, iters: 352, time: 0.104, data: 0.038) loss: 0.002 
(epoch: 117, iters: 432, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 117, iters: 512, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 117, iters: 592, time: 0.106, data: 0.000) loss: 0.503 
(epoch: 117, iters: 672, time: 0.105, data: 0.011) loss: 0.059 
(epoch: 117, iters: 752, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 117, iters: 832, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 117, iters: 912, time: 0.105, data: 0.038) loss: 0.022 
(epoch: 117, iters: 992, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 117, iters: 1072, time: 0.103, data: 0.011) loss: 0.011 
(epoch: 117, iters: 1152, time: 0.106, data: 0.000) loss: 0.021 
(epoch: 117, iters: 1232, time: 0.106, data: 0.011) loss: 0.005 
(epoch: 117, iters: 1312, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 117, iters: 1392, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 117, iters: 1472, time: 0.104, data: 0.047) loss: 0.006 
(epoch: 117, iters: 1552, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 117, iters: 1632, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 117, iters: 1712, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 117, iters: 1792, time: 0.104, data: 0.011) loss: 0.135 
(epoch: 117, iters: 1872, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 117, iters: 1952, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 117, iters: 2032, time: 0.104, data: 0.039) loss: 0.000 
(epoch: 117, iters: 2112, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 117, iters: 2192, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 117, iters: 2272, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 117, iters: 2352, time: 0.105, data: 0.012) loss: 0.007 
(epoch: 117, iters: 2432, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 117, iters: 2512, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 117, iters: 2592, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 117, iters: 2672, time: 0.106, data: 0.000) loss: 0.020 
(epoch: 117, iters: 2752, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 117, iters: 2832, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 117, iters: 2912, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 117, iters: 2992, time: 0.106, data: 0.000) loss: 0.027 
(epoch: 117, iters: 3072, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 117, iters: 3152, time: 0.104, data: 0.047) loss: 0.000 
(epoch: 117, iters: 3232, time: 0.106, data: 0.000) loss: 0.020 
(epoch: 117, iters: 3312, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 117, iters: 3392, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 117, iters: 3472, time: 0.104, data: 0.011) loss: 0.036 
(epoch: 117, iters: 3552, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 117, iters: 3632, time: 0.102, data: 0.000) loss: 0.014 
(epoch: 117, iters: 3712, time: 0.100, data: 0.034) loss: 0.006 
saving the model at the end of epoch 117, iters 436176
End of epoch 117 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001982
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 117, TEST ACC: [93.475 %]

saving the latest model (epoch 118, total_steps 436192)
(epoch: 118, iters: 64, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 118, iters: 144, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 118, iters: 224, time: 0.105, data: 0.011) loss: 0.121 
(epoch: 118, iters: 304, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 118, iters: 384, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 118, iters: 464, time: 0.104, data: 0.038) loss: 0.000 
(epoch: 118, iters: 544, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 118, iters: 624, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 118, iters: 704, time: 0.104, data: 0.000) loss: 0.089 
(epoch: 118, iters: 784, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 118, iters: 864, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 118, iters: 944, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 118, iters: 1024, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 118, iters: 1104, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 118, iters: 1184, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 118, iters: 1264, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 118, iters: 1344, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 118, iters: 1424, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 118, iters: 1504, time: 0.104, data: 0.000) loss: 0.014 
(epoch: 118, iters: 1584, time: 0.104, data: 0.038) loss: 0.002 
(epoch: 118, iters: 1664, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 118, iters: 1744, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 118, iters: 1824, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 118, iters: 1904, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 118, iters: 1984, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 118, iters: 2064, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 118, iters: 2144, time: 0.105, data: 0.038) loss: 0.006 
(epoch: 118, iters: 2224, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 118, iters: 2304, time: 0.103, data: 0.012) loss: 0.003 
(epoch: 118, iters: 2384, time: 0.105, data: 0.000) loss: 0.025 
(epoch: 118, iters: 2464, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 118, iters: 2544, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 118, iters: 2624, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 118, iters: 2704, time: 0.106, data: 0.039) loss: 0.362 
(epoch: 118, iters: 2784, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 118, iters: 2864, time: 0.103, data: 0.019) loss: 0.004 
(epoch: 118, iters: 2944, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 118, iters: 3024, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 118, iters: 3104, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 118, iters: 3184, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 118, iters: 3264, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 118, iters: 3344, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 118, iters: 3424, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 118, iters: 3504, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 118, iters: 3584, time: 0.104, data: 0.012) loss: 0.002 
(epoch: 118, iters: 3664, time: 0.100, data: 0.000) loss: 0.000 
saving the model at the end of epoch 118, iters 439904
End of epoch 118 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001981
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 118, TEST ACC: [95.448 %]

(epoch: 119, iters: 16, time: 0.121, data: 0.000) loss: 0.000 
saving the latest model (epoch 119, total_steps 439920)
(epoch: 119, iters: 96, time: 0.104, data: 0.043) loss: 0.000 
(epoch: 119, iters: 176, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 119, iters: 256, time: 0.102, data: 0.012) loss: 0.000 
(epoch: 119, iters: 336, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 119, iters: 416, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 119, iters: 496, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 119, iters: 576, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 119, iters: 656, time: 0.106, data: 0.039) loss: 0.017 
(epoch: 119, iters: 736, time: 0.106, data: 0.000) loss: 0.177 
(epoch: 119, iters: 816, time: 0.103, data: 0.011) loss: 0.013 
(epoch: 119, iters: 896, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 119, iters: 976, time: 0.105, data: 0.019) loss: 0.099 
(epoch: 119, iters: 1056, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 119, iters: 1136, time: 0.104, data: 0.000) loss: 0.036 
(epoch: 119, iters: 1216, time: 0.105, data: 0.048) loss: 0.796 
(epoch: 119, iters: 1296, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 119, iters: 1376, time: 0.103, data: 0.012) loss: 0.111 
(epoch: 119, iters: 1456, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 119, iters: 1536, time: 0.104, data: 0.011) loss: 0.074 
(epoch: 119, iters: 1616, time: 0.106, data: 0.000) loss: 0.033 
(epoch: 119, iters: 1696, time: 0.105, data: 0.000) loss: 0.040 
(epoch: 119, iters: 1776, time: 0.104, data: 0.038) loss: 0.006 
(epoch: 119, iters: 1856, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 119, iters: 1936, time: 0.103, data: 0.011) loss: 0.026 
(epoch: 119, iters: 2016, time: 0.106, data: 0.000) loss: 0.083 
(epoch: 119, iters: 2096, time: 0.104, data: 0.011) loss: 0.024 
(epoch: 119, iters: 2176, time: 0.105, data: 0.000) loss: 0.247 
(epoch: 119, iters: 2256, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 119, iters: 2336, time: 0.105, data: 0.039) loss: 0.004 
(epoch: 119, iters: 2416, time: 0.106, data: 0.000) loss: 0.141 
(epoch: 119, iters: 2496, time: 0.103, data: 0.012) loss: 0.055 
(epoch: 119, iters: 2576, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 119, iters: 2656, time: 0.105, data: 0.011) loss: 0.019 
(epoch: 119, iters: 2736, time: 0.105, data: 0.000) loss: 0.026 
(epoch: 119, iters: 2816, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 119, iters: 2896, time: 0.105, data: 0.039) loss: 0.006 
(epoch: 119, iters: 2976, time: 0.105, data: 0.000) loss: 0.030 
(epoch: 119, iters: 3056, time: 0.102, data: 0.011) loss: 0.002 
(epoch: 119, iters: 3136, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 119, iters: 3216, time: 0.104, data: 0.012) loss: 0.008 
(epoch: 119, iters: 3296, time: 0.105, data: 0.000) loss: 0.025 
(epoch: 119, iters: 3376, time: 0.104, data: 0.000) loss: 0.108 
(epoch: 119, iters: 3456, time: 0.106, data: 0.047) loss: 0.032 
(epoch: 119, iters: 3536, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 119, iters: 3616, time: 0.103, data: 0.020) loss: 0.001 
(epoch: 119, iters: 3696, time: 0.101, data: 0.000) loss: 0.000 
saving the model at the end of epoch 119, iters 443632
End of epoch 119 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001980
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 119, TEST ACC: [92.109 %]

saving the latest model (epoch 120, total_steps 443648)
(epoch: 120, iters: 48, time: 0.106, data: 0.004) loss: 0.011 
(epoch: 120, iters: 128, time: 0.105, data: 0.041) loss: 0.017 
(epoch: 120, iters: 208, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 120, iters: 288, time: 0.103, data: 0.012) loss: 0.027 
(epoch: 120, iters: 368, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 120, iters: 448, time: 0.105, data: 0.012) loss: 0.007 
(epoch: 120, iters: 528, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 120, iters: 608, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 120, iters: 688, time: 0.105, data: 0.046) loss: 0.001 
(epoch: 120, iters: 768, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 120, iters: 848, time: 0.103, data: 0.012) loss: 0.025 
(epoch: 120, iters: 928, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 120, iters: 1008, time: 0.104, data: 0.011) loss: 0.297 
(epoch: 120, iters: 1088, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 120, iters: 1168, time: 0.104, data: 0.000) loss: 0.013 
(epoch: 120, iters: 1248, time: 0.105, data: 0.047) loss: 0.018 
(epoch: 120, iters: 1328, time: 0.106, data: 0.000) loss: 0.045 
(epoch: 120, iters: 1408, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 120, iters: 1488, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 120, iters: 1568, time: 0.104, data: 0.012) loss: 0.007 
(epoch: 120, iters: 1648, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 120, iters: 1728, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 120, iters: 1808, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 120, iters: 1888, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 120, iters: 1968, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 120, iters: 2048, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 120, iters: 2128, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 120, iters: 2208, time: 0.106, data: 0.000) loss: 0.029 
(epoch: 120, iters: 2288, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 120, iters: 2368, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 120, iters: 2448, time: 0.106, data: 0.000) loss: 0.289 
(epoch: 120, iters: 2528, time: 0.103, data: 0.011) loss: 0.009 
(epoch: 120, iters: 2608, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 120, iters: 2688, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 120, iters: 2768, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 120, iters: 2848, time: 0.104, data: 0.000) loss: 0.005 
(epoch: 120, iters: 2928, time: 0.105, data: 0.038) loss: 0.007 
(epoch: 120, iters: 3008, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 120, iters: 3088, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 120, iters: 3168, time: 0.105, data: 0.000) loss: 0.062 
(epoch: 120, iters: 3248, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 120, iters: 3328, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 120, iters: 3408, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 120, iters: 3488, time: 0.104, data: 0.039) loss: 0.013 
(epoch: 120, iters: 3568, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 120, iters: 3648, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 120, iters: 3728, time: 0.067, data: 0.000) loss: 0.008 
saving the model at the end of epoch 120, iters 447360
End of epoch 120 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001979
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 120, TEST ACC: [90.744 %]

saving the latest model (epoch 121, total_steps 447376)
(epoch: 121, iters: 80, time: 0.105, data: 0.503) loss: 0.000 
(epoch: 121, iters: 160, time: 0.104, data: 0.030) loss: 0.000 
(epoch: 121, iters: 240, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 121, iters: 320, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 121, iters: 400, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 121, iters: 480, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 121, iters: 560, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 121, iters: 640, time: 0.106, data: 0.000) loss: 0.026 
(epoch: 121, iters: 720, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 121, iters: 800, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 121, iters: 880, time: 0.102, data: 0.011) loss: 0.002 
(epoch: 121, iters: 960, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 121, iters: 1040, time: 0.105, data: 0.011) loss: 0.008 
(epoch: 121, iters: 1120, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 121, iters: 1200, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 121, iters: 1280, time: 0.106, data: 0.047) loss: 0.007 
(epoch: 121, iters: 1360, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 121, iters: 1440, time: 0.103, data: 0.021) loss: 0.001 
(epoch: 121, iters: 1520, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 121, iters: 1600, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 121, iters: 1680, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 121, iters: 1760, time: 0.104, data: 0.000) loss: 0.017 
(epoch: 121, iters: 1840, time: 0.104, data: 0.038) loss: 0.004 
(epoch: 121, iters: 1920, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 121, iters: 2000, time: 0.103, data: 0.011) loss: 0.027 
(epoch: 121, iters: 2080, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 121, iters: 2160, time: 0.103, data: 0.011) loss: 0.180 
(epoch: 121, iters: 2240, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 121, iters: 2320, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 121, iters: 2400, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 121, iters: 2480, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 121, iters: 2560, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 121, iters: 2640, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 121, iters: 2720, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 121, iters: 2800, time: 0.106, data: 0.000) loss: 0.032 
(epoch: 121, iters: 2880, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 121, iters: 2960, time: 0.105, data: 0.038) loss: 0.060 
(epoch: 121, iters: 3040, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 121, iters: 3120, time: 0.102, data: 0.012) loss: 0.002 
(epoch: 121, iters: 3200, time: 0.106, data: 0.000) loss: 0.050 
(epoch: 121, iters: 3280, time: 0.106, data: 0.012) loss: 0.000 
(epoch: 121, iters: 3360, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 121, iters: 3440, time: 0.104, data: 0.000) loss: 0.021 
(epoch: 121, iters: 3520, time: 0.106, data: 0.047) loss: 0.002 
(epoch: 121, iters: 3600, time: 0.105, data: 0.000) loss: 0.030 
(epoch: 121, iters: 3680, time: 0.099, data: 0.021) loss: 0.004 
saving the model at the end of epoch 121, iters 451088
End of epoch 121 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001978
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 121, TEST ACC: [91.654 %]

saving the latest model (epoch 122, total_steps 451104)
(epoch: 122, iters: 32, time: 0.099, data: 0.007) loss: 0.000 
(epoch: 122, iters: 112, time: 0.104, data: 0.036) loss: 0.009 
(epoch: 122, iters: 192, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 122, iters: 272, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 122, iters: 352, time: 0.106, data: 0.048) loss: 0.001 
(epoch: 122, iters: 432, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 122, iters: 512, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 122, iters: 592, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 122, iters: 672, time: 0.104, data: 0.011) loss: 0.430 
(epoch: 122, iters: 752, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 122, iters: 832, time: 0.104, data: 0.000) loss: 0.011 
(epoch: 122, iters: 912, time: 0.104, data: 0.038) loss: 0.002 
(epoch: 122, iters: 992, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 122, iters: 1072, time: 0.102, data: 0.011) loss: 0.005 
(epoch: 122, iters: 1152, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 122, iters: 1232, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 122, iters: 1312, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 122, iters: 1392, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 122, iters: 1472, time: 0.105, data: 0.038) loss: 0.070 
(epoch: 122, iters: 1552, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 122, iters: 1632, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 122, iters: 1712, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 122, iters: 1792, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 122, iters: 1872, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 122, iters: 1952, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 122, iters: 2032, time: 0.105, data: 0.047) loss: 0.012 
(epoch: 122, iters: 2112, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 122, iters: 2192, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 122, iters: 2272, time: 0.105, data: 0.000) loss: 0.063 
(epoch: 122, iters: 2352, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 122, iters: 2432, time: 0.104, data: 0.000) loss: 0.019 
(epoch: 122, iters: 2512, time: 0.104, data: 0.000) loss: 0.015 
(epoch: 122, iters: 2592, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 122, iters: 2672, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 122, iters: 2752, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 122, iters: 2832, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 122, iters: 2912, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 122, iters: 2992, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 122, iters: 3072, time: 0.104, data: 0.000) loss: 0.013 
(epoch: 122, iters: 3152, time: 0.106, data: 0.038) loss: 0.021 
(epoch: 122, iters: 3232, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 122, iters: 3312, time: 0.104, data: 0.012) loss: 0.005 
(epoch: 122, iters: 3392, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 122, iters: 3472, time: 0.103, data: 0.011) loss: 0.006 
(epoch: 122, iters: 3552, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 122, iters: 3632, time: 0.103, data: 0.000) loss: 0.007 
(epoch: 122, iters: 3712, time: 0.101, data: 0.035) loss: 0.000 
saving the model at the end of epoch 122, iters 454816
End of epoch 122 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001977
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 122, TEST ACC: [94.689 %]

saving the latest model (epoch 123, total_steps 454832)
(epoch: 123, iters: 64, time: 0.103, data: 0.000) loss: 0.003 
(epoch: 123, iters: 144, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 123, iters: 224, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 123, iters: 304, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 123, iters: 384, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 123, iters: 464, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 123, iters: 544, time: 0.107, data: 0.000) loss: 0.006 
(epoch: 123, iters: 624, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 123, iters: 704, time: 0.105, data: 0.000) loss: 0.077 
(epoch: 123, iters: 784, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 123, iters: 864, time: 0.107, data: 0.000) loss: 0.089 
(epoch: 123, iters: 944, time: 0.104, data: 0.000) loss: 0.016 
(epoch: 123, iters: 1024, time: 0.105, data: 0.038) loss: 0.139 
(epoch: 123, iters: 1104, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 123, iters: 1184, time: 0.102, data: 0.011) loss: 0.061 
(epoch: 123, iters: 1264, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 123, iters: 1344, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 123, iters: 1424, time: 0.105, data: 0.000) loss: 0.737 
(epoch: 123, iters: 1504, time: 0.104, data: 0.000) loss: 0.194 
(epoch: 123, iters: 1584, time: 0.104, data: 0.038) loss: 0.197 
(epoch: 123, iters: 1664, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 123, iters: 1744, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 123, iters: 1824, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 123, iters: 1904, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 123, iters: 1984, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 123, iters: 2064, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 123, iters: 2144, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 123, iters: 2224, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 123, iters: 2304, time: 0.104, data: 0.020) loss: 0.001 
(epoch: 123, iters: 2384, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 123, iters: 2464, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 123, iters: 2544, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 123, iters: 2624, time: 0.105, data: 0.000) loss: 0.139 
(epoch: 123, iters: 2704, time: 0.106, data: 0.039) loss: 0.004 
(epoch: 123, iters: 2784, time: 0.107, data: 0.000) loss: 0.182 
(epoch: 123, iters: 2864, time: 0.104, data: 0.011) loss: 0.014 
(epoch: 123, iters: 2944, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 123, iters: 3024, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 123, iters: 3104, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 123, iters: 3184, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 123, iters: 3264, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 123, iters: 3344, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 123, iters: 3424, time: 0.103, data: 0.011) loss: 0.008 
(epoch: 123, iters: 3504, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 123, iters: 3584, time: 0.105, data: 0.011) loss: 0.021 
(epoch: 123, iters: 3664, time: 0.101, data: 0.000) loss: 0.003 
saving the model at the end of epoch 123, iters 458544
End of epoch 123 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001976
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 123, TEST ACC: [94.234 %]

(epoch: 124, iters: 16, time: 0.119, data: 0.000) loss: 0.000 
saving the latest model (epoch 124, total_steps 458560)
(epoch: 124, iters: 96, time: 0.106, data: 0.012) loss: 0.003 
(epoch: 124, iters: 176, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 124, iters: 256, time: 0.105, data: 0.000) loss: 0.067 
(epoch: 124, iters: 336, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 124, iters: 416, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 124, iters: 496, time: 0.104, data: 0.000) loss: 0.154 
(epoch: 124, iters: 576, time: 0.106, data: 0.038) loss: 0.004 
(epoch: 124, iters: 656, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 124, iters: 736, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 124, iters: 816, time: 0.107, data: 0.000) loss: 0.108 
(epoch: 124, iters: 896, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 124, iters: 976, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 124, iters: 1056, time: 0.105, data: 0.000) loss: 0.043 
(epoch: 124, iters: 1136, time: 0.105, data: 0.040) loss: 0.001 
(epoch: 124, iters: 1216, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 124, iters: 1296, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 124, iters: 1376, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 124, iters: 1456, time: 0.105, data: 0.011) loss: 0.006 
(epoch: 124, iters: 1536, time: 0.106, data: 0.000) loss: 0.085 
(epoch: 124, iters: 1616, time: 0.104, data: 0.000) loss: 0.019 
(epoch: 124, iters: 1696, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 124, iters: 1776, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 124, iters: 1856, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 124, iters: 1936, time: 0.105, data: 0.000) loss: 0.055 
(epoch: 124, iters: 2016, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 124, iters: 2096, time: 0.106, data: 0.000) loss: 0.026 
(epoch: 124, iters: 2176, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 124, iters: 2256, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 124, iters: 2336, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 124, iters: 2416, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 124, iters: 2496, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 124, iters: 2576, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 124, iters: 2656, time: 0.105, data: 0.000) loss: 0.174 
(epoch: 124, iters: 2736, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 124, iters: 2816, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 124, iters: 2896, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 124, iters: 2976, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 124, iters: 3056, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 124, iters: 3136, time: 0.105, data: 0.012) loss: 0.012 
(epoch: 124, iters: 3216, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 124, iters: 3296, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 124, iters: 3376, time: 0.106, data: 0.047) loss: 0.004 
(epoch: 124, iters: 3456, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 124, iters: 3536, time: 0.104, data: 0.012) loss: 0.126 
(epoch: 124, iters: 3616, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 124, iters: 3696, time: 0.100, data: 0.011) loss: 0.010 
saving the model at the end of epoch 124, iters 462272
End of epoch 124 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001975
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 124, TEST ACC: [92.564 %]

saving the latest model (epoch 125, total_steps 462288)
(epoch: 125, iters: 48, time: 0.108, data: 0.000) loss: 0.001 
(epoch: 125, iters: 128, time: 0.104, data: 0.000) loss: 0.023 
(epoch: 125, iters: 208, time: 0.105, data: 0.038) loss: 0.044 
(epoch: 125, iters: 288, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 125, iters: 368, time: 0.103, data: 0.012) loss: 0.008 
(epoch: 125, iters: 448, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 125, iters: 528, time: 0.104, data: 0.011) loss: 0.016 
(epoch: 125, iters: 608, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 125, iters: 688, time: 0.105, data: 0.000) loss: 0.105 
(epoch: 125, iters: 768, time: 0.104, data: 0.039) loss: 0.006 
(epoch: 125, iters: 848, time: 0.106, data: 0.000) loss: 0.032 
(epoch: 125, iters: 928, time: 0.101, data: 0.011) loss: 0.025 
(epoch: 125, iters: 1008, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 125, iters: 1088, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 125, iters: 1168, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 125, iters: 1248, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 125, iters: 1328, time: 0.104, data: 0.047) loss: 0.001 
(epoch: 125, iters: 1408, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 125, iters: 1488, time: 0.103, data: 0.011) loss: 0.009 
(epoch: 125, iters: 1568, time: 0.105, data: 0.000) loss: 0.070 
(epoch: 125, iters: 1648, time: 0.104, data: 0.011) loss: 0.007 
(epoch: 125, iters: 1728, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 125, iters: 1808, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 125, iters: 1888, time: 0.104, data: 0.038) loss: 0.013 
(epoch: 125, iters: 1968, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 125, iters: 2048, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 125, iters: 2128, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 125, iters: 2208, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 125, iters: 2288, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 125, iters: 2368, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 125, iters: 2448, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 125, iters: 2528, time: 0.105, data: 0.000) loss: 0.290 
(epoch: 125, iters: 2608, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 125, iters: 2688, time: 0.105, data: 0.000) loss: 0.056 
(epoch: 125, iters: 2768, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 125, iters: 2848, time: 0.107, data: 0.000) loss: 0.058 
(epoch: 125, iters: 2928, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 125, iters: 3008, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 125, iters: 3088, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 125, iters: 3168, time: 0.103, data: 0.011) loss: 0.008 
(epoch: 125, iters: 3248, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 125, iters: 3328, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 125, iters: 3408, time: 0.105, data: 0.000) loss: 0.100 
(epoch: 125, iters: 3488, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 125, iters: 3568, time: 0.105, data: 0.038) loss: 0.036 
(epoch: 125, iters: 3648, time: 0.100, data: 0.000) loss: 0.001 
(epoch: 125, iters: 3728, time: 0.066, data: 0.011) loss: 0.003 
saving the model at the end of epoch 125, iters 466000
End of epoch 125 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001974
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 125, TEST ACC: [90.288 %]

saving the latest model (epoch 126, total_steps 466016)
(epoch: 126, iters: 80, time: 0.106, data: 0.443) loss: 0.000 
(epoch: 126, iters: 160, time: 0.106, data: 0.000) loss: 0.027 
(epoch: 126, iters: 240, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 126, iters: 320, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 126, iters: 400, time: 0.104, data: 0.012) loss: 0.003 
(epoch: 126, iters: 480, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 126, iters: 560, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 126, iters: 640, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 126, iters: 720, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 126, iters: 800, time: 0.105, data: 0.038) loss: 0.036 
(epoch: 126, iters: 880, time: 0.106, data: 0.000) loss: 0.045 
(epoch: 126, iters: 960, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 126, iters: 1040, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 126, iters: 1120, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 126, iters: 1200, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 126, iters: 1280, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 126, iters: 1360, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 126, iters: 1440, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 126, iters: 1520, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 126, iters: 1600, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 126, iters: 1680, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 126, iters: 1760, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 126, iters: 1840, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 126, iters: 1920, time: 0.106, data: 0.046) loss: 0.003 
(epoch: 126, iters: 2000, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 126, iters: 2080, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 126, iters: 2160, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 126, iters: 2240, time: 0.105, data: 0.011) loss: 0.037 
(epoch: 126, iters: 2320, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 126, iters: 2400, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 126, iters: 2480, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 126, iters: 2560, time: 0.106, data: 0.000) loss: 0.025 
(epoch: 126, iters: 2640, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 126, iters: 2720, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 126, iters: 2800, time: 0.104, data: 0.012) loss: 0.005 
(epoch: 126, iters: 2880, time: 0.107, data: 0.000) loss: 0.009 
(epoch: 126, iters: 2960, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 126, iters: 3040, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 126, iters: 3120, time: 0.107, data: 0.000) loss: 0.006 
(epoch: 126, iters: 3200, time: 0.104, data: 0.021) loss: 0.002 
(epoch: 126, iters: 3280, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 126, iters: 3360, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 126, iters: 3440, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 126, iters: 3520, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 126, iters: 3600, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 126, iters: 3680, time: 0.100, data: 0.000) loss: 0.001 
saving the model at the end of epoch 126, iters 469728
End of epoch 126 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001973
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 126, TEST ACC: [95.751 %]

saving the latest model (epoch 127, total_steps 469744)
(epoch: 127, iters: 32, time: 0.100, data: 0.004) loss: 0.087 
(epoch: 127, iters: 112, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 127, iters: 192, time: 0.103, data: 0.012) loss: 0.069 
(epoch: 127, iters: 272, time: 0.105, data: 0.000) loss: 0.042 
(epoch: 127, iters: 352, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 127, iters: 432, time: 0.106, data: 0.000) loss: 0.092 
(epoch: 127, iters: 512, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 127, iters: 592, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 127, iters: 672, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 127, iters: 752, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 127, iters: 832, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 127, iters: 912, time: 0.106, data: 0.011) loss: 0.024 
(epoch: 127, iters: 992, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 127, iters: 1072, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 127, iters: 1152, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 127, iters: 1232, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 127, iters: 1312, time: 0.104, data: 0.011) loss: 0.341 
(epoch: 127, iters: 1392, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 127, iters: 1472, time: 0.106, data: 0.011) loss: 0.036 
(epoch: 127, iters: 1552, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 127, iters: 1632, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 127, iters: 1712, time: 0.104, data: 0.038) loss: 0.004 
(epoch: 127, iters: 1792, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 127, iters: 1872, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 127, iters: 1952, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 127, iters: 2032, time: 0.106, data: 0.012) loss: 0.003 
(epoch: 127, iters: 2112, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 127, iters: 2192, time: 0.104, data: 0.000) loss: 0.143 
(epoch: 127, iters: 2272, time: 0.105, data: 0.047) loss: 0.094 
(epoch: 127, iters: 2352, time: 0.107, data: 0.000) loss: 0.004 
(epoch: 127, iters: 2432, time: 0.103, data: 0.011) loss: 0.870 
(epoch: 127, iters: 2512, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 127, iters: 2592, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 127, iters: 2672, time: 0.106, data: 0.000) loss: 0.022 
(epoch: 127, iters: 2752, time: 0.105, data: 0.000) loss: 0.054 
(epoch: 127, iters: 2832, time: 0.106, data: 0.038) loss: 0.038 
(epoch: 127, iters: 2912, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 127, iters: 2992, time: 0.101, data: 0.011) loss: 0.002 
(epoch: 127, iters: 3072, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 127, iters: 3152, time: 0.106, data: 0.011) loss: 0.000 
(epoch: 127, iters: 3232, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 127, iters: 3312, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 127, iters: 3392, time: 0.104, data: 0.047) loss: 0.001 
(epoch: 127, iters: 3472, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 127, iters: 3552, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 127, iters: 3632, time: 0.103, data: 0.000) loss: 0.029 
(epoch: 127, iters: 3712, time: 0.100, data: 0.011) loss: 0.000 
saving the model at the end of epoch 127, iters 473456
End of epoch 127 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001972
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 127, TEST ACC: [91.351 %]

saving the latest model (epoch 128, total_steps 473472)
(epoch: 128, iters: 64, time: 0.105, data: 0.002) loss: 0.072 
(epoch: 128, iters: 144, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 128, iters: 224, time: 0.104, data: 0.012) loss: 0.233 
(epoch: 128, iters: 304, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 128, iters: 384, time: 0.104, data: 0.000) loss: 0.040 
(epoch: 128, iters: 464, time: 0.104, data: 0.038) loss: 0.030 
(epoch: 128, iters: 544, time: 0.104, data: 0.000) loss: 0.011 
(epoch: 128, iters: 624, time: 0.103, data: 0.011) loss: 0.018 
(epoch: 128, iters: 704, time: 0.105, data: 0.000) loss: 0.031 
(epoch: 128, iters: 784, time: 0.104, data: 0.012) loss: 0.003 
(epoch: 128, iters: 864, time: 0.105, data: 0.000) loss: 0.158 
(epoch: 128, iters: 944, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 128, iters: 1024, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 128, iters: 1104, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 128, iters: 1184, time: 0.104, data: 0.012) loss: 0.008 
(epoch: 128, iters: 1264, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 128, iters: 1344, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 128, iters: 1424, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 128, iters: 1504, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 128, iters: 1584, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 128, iters: 1664, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 128, iters: 1744, time: 0.102, data: 0.011) loss: 0.058 
(epoch: 128, iters: 1824, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 128, iters: 1904, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 128, iters: 1984, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 128, iters: 2064, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 128, iters: 2144, time: 0.106, data: 0.039) loss: 0.003 
(epoch: 128, iters: 2224, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 128, iters: 2304, time: 0.102, data: 0.012) loss: 0.002 
(epoch: 128, iters: 2384, time: 0.105, data: 0.000) loss: 0.023 
(epoch: 128, iters: 2464, time: 0.104, data: 0.019) loss: 0.000 
(epoch: 128, iters: 2544, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 128, iters: 2624, time: 0.104, data: 0.000) loss: 0.009 
(epoch: 128, iters: 2704, time: 0.105, data: 0.048) loss: 0.005 
(epoch: 128, iters: 2784, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 128, iters: 2864, time: 0.102, data: 0.011) loss: 0.002 
(epoch: 128, iters: 2944, time: 0.105, data: 0.000) loss: 0.250 
(epoch: 128, iters: 3024, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 128, iters: 3104, time: 0.106, data: 0.000) loss: 0.018 
(epoch: 128, iters: 3184, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 128, iters: 3264, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 128, iters: 3344, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 128, iters: 3424, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 128, iters: 3504, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 128, iters: 3584, time: 0.104, data: 0.011) loss: 0.142 
(epoch: 128, iters: 3664, time: 0.100, data: 0.000) loss: 0.007 
saving the model at the end of epoch 128, iters 477184
End of epoch 128 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001971
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 128, TEST ACC: [90.744 %]

(epoch: 129, iters: 16, time: 0.117, data: 0.000) loss: 0.144 
saving the latest model (epoch 129, total_steps 477200)
(epoch: 129, iters: 96, time: 0.105, data: 0.000) loss: 0.310 
(epoch: 129, iters: 176, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 129, iters: 256, time: 0.106, data: 0.039) loss: 0.079 
(epoch: 129, iters: 336, time: 0.106, data: 0.000) loss: 0.022 
(epoch: 129, iters: 416, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 129, iters: 496, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 129, iters: 576, time: 0.104, data: 0.011) loss: 0.009 
(epoch: 129, iters: 656, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 129, iters: 736, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 129, iters: 816, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 129, iters: 896, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 129, iters: 976, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 129, iters: 1056, time: 0.106, data: 0.000) loss: 0.059 
(epoch: 129, iters: 1136, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 129, iters: 1216, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 129, iters: 1296, time: 0.104, data: 0.000) loss: 0.177 
(epoch: 129, iters: 1376, time: 0.105, data: 0.038) loss: 0.005 
(epoch: 129, iters: 1456, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 129, iters: 1536, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 129, iters: 1616, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 129, iters: 1696, time: 0.104, data: 0.012) loss: 0.003 
(epoch: 129, iters: 1776, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 129, iters: 1856, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 129, iters: 1936, time: 0.106, data: 0.040) loss: 0.001 
(epoch: 129, iters: 2016, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 129, iters: 2096, time: 0.103, data: 0.011) loss: 0.491 
(epoch: 129, iters: 2176, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 129, iters: 2256, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 129, iters: 2336, time: 0.106, data: 0.000) loss: 0.030 
(epoch: 129, iters: 2416, time: 0.103, data: 0.000) loss: 0.059 
(epoch: 129, iters: 2496, time: 0.105, data: 0.048) loss: 0.004 
(epoch: 129, iters: 2576, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 129, iters: 2656, time: 0.103, data: 0.011) loss: 0.025 
(epoch: 129, iters: 2736, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 129, iters: 2816, time: 0.104, data: 0.011) loss: 0.007 
(epoch: 129, iters: 2896, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 129, iters: 2976, time: 0.105, data: 0.000) loss: 0.035 
(epoch: 129, iters: 3056, time: 0.105, data: 0.039) loss: 0.132 
(epoch: 129, iters: 3136, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 129, iters: 3216, time: 0.103, data: 0.011) loss: 0.012 
(epoch: 129, iters: 3296, time: 0.105, data: 0.000) loss: 0.230 
(epoch: 129, iters: 3376, time: 0.103, data: 0.011) loss: 0.008 
(epoch: 129, iters: 3456, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 129, iters: 3536, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 129, iters: 3616, time: 0.106, data: 0.038) loss: 0.039 
(epoch: 129, iters: 3696, time: 0.100, data: 0.000) loss: 0.014 
saving the model at the end of epoch 129, iters 480912
End of epoch 129 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001970
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 129, TEST ACC: [92.261 %]

saving the latest model (epoch 130, total_steps 480928)
(epoch: 130, iters: 48, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 130, iters: 128, time: 0.105, data: 0.025) loss: 0.381 
(epoch: 130, iters: 208, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 130, iters: 288, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 130, iters: 368, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 130, iters: 448, time: 0.104, data: 0.011) loss: 0.027 
(epoch: 130, iters: 528, time: 0.105, data: 0.000) loss: 0.316 
(epoch: 130, iters: 608, time: 0.105, data: 0.000) loss: 0.150 
(epoch: 130, iters: 688, time: 0.104, data: 0.038) loss: 0.008 
(epoch: 130, iters: 768, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 130, iters: 848, time: 0.102, data: 0.011) loss: 0.217 
(epoch: 130, iters: 928, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 130, iters: 1008, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 130, iters: 1088, time: 0.105, data: 0.000) loss: 0.148 
(epoch: 130, iters: 1168, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 130, iters: 1248, time: 0.105, data: 0.038) loss: 0.361 
(epoch: 130, iters: 1328, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 130, iters: 1408, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 130, iters: 1488, time: 0.105, data: 0.000) loss: 0.148 
(epoch: 130, iters: 1568, time: 0.105, data: 0.011) loss: 0.119 
(epoch: 130, iters: 1648, time: 0.105, data: 0.000) loss: 0.109 
(epoch: 130, iters: 1728, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 130, iters: 1808, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 130, iters: 1888, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 130, iters: 1968, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 130, iters: 2048, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 130, iters: 2128, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 130, iters: 2208, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 130, iters: 2288, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 130, iters: 2368, time: 0.105, data: 0.047) loss: 0.007 
(epoch: 130, iters: 2448, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 130, iters: 2528, time: 0.103, data: 0.021) loss: 0.027 
(epoch: 130, iters: 2608, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 130, iters: 2688, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 130, iters: 2768, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 130, iters: 2848, time: 0.105, data: 0.000) loss: 0.031 
(epoch: 130, iters: 2928, time: 0.105, data: 0.049) loss: 0.008 
(epoch: 130, iters: 3008, time: 0.105, data: 0.000) loss: 0.018 
(epoch: 130, iters: 3088, time: 0.102, data: 0.012) loss: 0.020 
(epoch: 130, iters: 3168, time: 0.106, data: 0.000) loss: 0.019 
(epoch: 130, iters: 3248, time: 0.105, data: 0.011) loss: 0.233 
(epoch: 130, iters: 3328, time: 0.105, data: 0.000) loss: 0.125 
(epoch: 130, iters: 3408, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 130, iters: 3488, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 130, iters: 3568, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 130, iters: 3648, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 130, iters: 3728, time: 0.065, data: 0.000) loss: 0.000 
saving the model at the end of epoch 130, iters 484640
End of epoch 130 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001969
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 130, TEST ACC: [87.253 %]

saving the latest model (epoch 131, total_steps 484656)
(epoch: 131, iters: 80, time: 0.105, data: 0.523) loss: 0.001 
(epoch: 131, iters: 160, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 131, iters: 240, time: 0.105, data: 0.011) loss: 0.019 
(epoch: 131, iters: 320, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 131, iters: 400, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 131, iters: 480, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 131, iters: 560, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 131, iters: 640, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 131, iters: 720, time: 0.105, data: 0.000) loss: 0.056 
(epoch: 131, iters: 800, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 131, iters: 880, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 131, iters: 960, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 131, iters: 1040, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 131, iters: 1120, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 131, iters: 1200, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 131, iters: 1280, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 131, iters: 1360, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 131, iters: 1440, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 131, iters: 1520, time: 0.104, data: 0.000) loss: 0.032 
(epoch: 131, iters: 1600, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 131, iters: 1680, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 131, iters: 1760, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 131, iters: 1840, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 131, iters: 1920, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 131, iters: 2000, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 131, iters: 2080, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 131, iters: 2160, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 131, iters: 2240, time: 0.108, data: 0.000) loss: 0.001 
(epoch: 131, iters: 2320, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 131, iters: 2400, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 131, iters: 2480, time: 0.104, data: 0.019) loss: 0.002 
(epoch: 131, iters: 2560, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 131, iters: 2640, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 131, iters: 2720, time: 0.106, data: 0.047) loss: 0.001 
(epoch: 131, iters: 2800, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 131, iters: 2880, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 131, iters: 2960, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 131, iters: 3040, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 131, iters: 3120, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 131, iters: 3200, time: 0.104, data: 0.000) loss: 0.033 
(epoch: 131, iters: 3280, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 131, iters: 3360, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 131, iters: 3440, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 131, iters: 3520, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 131, iters: 3600, time: 0.104, data: 0.011) loss: 0.131 
(epoch: 131, iters: 3680, time: 0.100, data: 0.000) loss: 0.104 
saving the model at the end of epoch 131, iters 488368
End of epoch 131 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001968
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 131, TEST ACC: [94.234 %]

saving the latest model (epoch 132, total_steps 488384)
(epoch: 132, iters: 32, time: 0.100, data: 0.000) loss: 0.001 
(epoch: 132, iters: 112, time: 0.105, data: 0.037) loss: 0.001 
(epoch: 132, iters: 192, time: 0.106, data: 0.000) loss: 0.167 
(epoch: 132, iters: 272, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 132, iters: 352, time: 0.105, data: 0.048) loss: 0.096 
(epoch: 132, iters: 432, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 132, iters: 512, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 132, iters: 592, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 132, iters: 672, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 132, iters: 752, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 132, iters: 832, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 132, iters: 912, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 132, iters: 992, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 132, iters: 1072, time: 0.103, data: 0.011) loss: 0.093 
(epoch: 132, iters: 1152, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 132, iters: 1232, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 132, iters: 1312, time: 0.105, data: 0.000) loss: 0.065 
(epoch: 132, iters: 1392, time: 0.104, data: 0.000) loss: 0.010 
(epoch: 132, iters: 1472, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 132, iters: 1552, time: 0.105, data: 0.000) loss: 0.046 
(epoch: 132, iters: 1632, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 132, iters: 1712, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 132, iters: 1792, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 132, iters: 1872, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 132, iters: 1952, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 132, iters: 2032, time: 0.104, data: 0.039) loss: 0.018 
(epoch: 132, iters: 2112, time: 0.105, data: 0.000) loss: 0.027 
(epoch: 132, iters: 2192, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 132, iters: 2272, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 132, iters: 2352, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 132, iters: 2432, time: 0.105, data: 0.000) loss: 0.027 
(epoch: 132, iters: 2512, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 132, iters: 2592, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 132, iters: 2672, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 132, iters: 2752, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 132, iters: 2832, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 132, iters: 2912, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 132, iters: 2992, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 132, iters: 3072, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 132, iters: 3152, time: 0.105, data: 0.039) loss: 0.005 
(epoch: 132, iters: 3232, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 132, iters: 3312, time: 0.102, data: 0.012) loss: 0.068 
(epoch: 132, iters: 3392, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 132, iters: 3472, time: 0.104, data: 0.019) loss: 0.001 
(epoch: 132, iters: 3552, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 132, iters: 3632, time: 0.102, data: 0.000) loss: 0.009 
(epoch: 132, iters: 3712, time: 0.099, data: 0.043) loss: 0.016 
saving the model at the end of epoch 132, iters 492096
End of epoch 132 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001967
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 132, TEST ACC: [91.502 %]

saving the latest model (epoch 133, total_steps 492112)
(epoch: 133, iters: 64, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 133, iters: 144, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 133, iters: 224, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 133, iters: 304, time: 0.105, data: 0.000) loss: 0.048 
(epoch: 133, iters: 384, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 133, iters: 464, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 133, iters: 544, time: 0.102, data: 0.012) loss: 0.003 
(epoch: 133, iters: 624, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 133, iters: 704, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 133, iters: 784, time: 0.107, data: 0.000) loss: 0.004 
(epoch: 133, iters: 864, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 133, iters: 944, time: 0.104, data: 0.038) loss: 0.002 
(epoch: 133, iters: 1024, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 133, iters: 1104, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 133, iters: 1184, time: 0.106, data: 0.000) loss: 0.024 
(epoch: 133, iters: 1264, time: 0.105, data: 0.012) loss: 0.003 
(epoch: 133, iters: 1344, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 133, iters: 1424, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 133, iters: 1504, time: 0.105, data: 0.039) loss: 0.011 
(epoch: 133, iters: 1584, time: 0.107, data: 0.000) loss: 0.039 
(epoch: 133, iters: 1664, time: 0.102, data: 0.012) loss: 0.004 
(epoch: 133, iters: 1744, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 133, iters: 1824, time: 0.105, data: 0.019) loss: 0.000 
(epoch: 133, iters: 1904, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 133, iters: 1984, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 133, iters: 2064, time: 0.105, data: 0.047) loss: 0.002 
(epoch: 133, iters: 2144, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 133, iters: 2224, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 133, iters: 2304, time: 0.106, data: 0.000) loss: 0.079 
(epoch: 133, iters: 2384, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 133, iters: 2464, time: 0.105, data: 0.000) loss: 0.024 
(epoch: 133, iters: 2544, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 133, iters: 2624, time: 0.106, data: 0.038) loss: 0.120 
(epoch: 133, iters: 2704, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 133, iters: 2784, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 133, iters: 2864, time: 0.104, data: 0.000) loss: 0.013 
(epoch: 133, iters: 2944, time: 0.106, data: 0.011) loss: 0.008 
(epoch: 133, iters: 3024, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 133, iters: 3104, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 133, iters: 3184, time: 0.105, data: 0.040) loss: 0.001 
(epoch: 133, iters: 3264, time: 0.106, data: 0.000) loss: 0.032 
(epoch: 133, iters: 3344, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 133, iters: 3424, time: 0.105, data: 0.000) loss: 0.045 
(epoch: 133, iters: 3504, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 133, iters: 3584, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 133, iters: 3664, time: 0.098, data: 0.000) loss: 0.008 
saving the model at the end of epoch 133, iters 495824
End of epoch 133 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001966
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 133, TEST ACC: [94.992 %]

(epoch: 134, iters: 16, time: 0.116, data: 0.012) loss: 0.001 
saving the latest model (epoch 134, total_steps 495840)
(epoch: 134, iters: 96, time: 0.103, data: 0.000) loss: 0.004 
(epoch: 134, iters: 176, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 134, iters: 256, time: 0.105, data: 0.011) loss: 0.113 
(epoch: 134, iters: 336, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 134, iters: 416, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 134, iters: 496, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 134, iters: 576, time: 0.106, data: 0.000) loss: 0.026 
(epoch: 134, iters: 656, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 134, iters: 736, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 134, iters: 816, time: 0.104, data: 0.011) loss: 0.008 
(epoch: 134, iters: 896, time: 0.106, data: 0.000) loss: 0.277 
(epoch: 134, iters: 976, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 134, iters: 1056, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 134, iters: 1136, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 134, iters: 1216, time: 0.103, data: 0.011) loss: 0.018 
(epoch: 134, iters: 1296, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 134, iters: 1376, time: 0.105, data: 0.011) loss: 0.007 
(epoch: 134, iters: 1456, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 134, iters: 1536, time: 0.104, data: 0.000) loss: 0.024 
(epoch: 134, iters: 1616, time: 0.105, data: 0.038) loss: 0.011 
(epoch: 134, iters: 1696, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 134, iters: 1776, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 134, iters: 1856, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 134, iters: 1936, time: 0.104, data: 0.011) loss: 0.007 
(epoch: 134, iters: 2016, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 134, iters: 2096, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 134, iters: 2176, time: 0.104, data: 0.047) loss: 0.001 
(epoch: 134, iters: 2256, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 134, iters: 2336, time: 0.103, data: 0.011) loss: 0.025 
(epoch: 134, iters: 2416, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 134, iters: 2496, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 134, iters: 2576, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 134, iters: 2656, time: 0.104, data: 0.000) loss: 0.039 
(epoch: 134, iters: 2736, time: 0.106, data: 0.038) loss: 0.003 
(epoch: 134, iters: 2816, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 134, iters: 2896, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 134, iters: 2976, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 134, iters: 3056, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 134, iters: 3136, time: 0.105, data: 0.000) loss: 0.039 
(epoch: 134, iters: 3216, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 134, iters: 3296, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 134, iters: 3376, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 134, iters: 3456, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 134, iters: 3536, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 134, iters: 3616, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 134, iters: 3696, time: 0.101, data: 0.000) loss: 0.004 
saving the model at the end of epoch 134, iters 499552
End of epoch 134 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001965
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 134, TEST ACC: [91.047 %]

saving the latest model (epoch 135, total_steps 499568)
(epoch: 135, iters: 48, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 135, iters: 128, time: 0.105, data: 0.025) loss: 0.003 
(epoch: 135, iters: 208, time: 0.106, data: 0.000) loss: 0.020 
(epoch: 135, iters: 288, time: 0.102, data: 0.011) loss: 0.002 
(epoch: 135, iters: 368, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 135, iters: 448, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 135, iters: 528, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 135, iters: 608, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 135, iters: 688, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 135, iters: 768, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 135, iters: 848, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 135, iters: 928, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 135, iters: 1008, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 135, iters: 1088, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 135, iters: 1168, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 135, iters: 1248, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 135, iters: 1328, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 135, iters: 1408, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 135, iters: 1488, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 135, iters: 1568, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 135, iters: 1648, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 135, iters: 1728, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 135, iters: 1808, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 135, iters: 1888, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 135, iters: 1968, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 135, iters: 2048, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 135, iters: 2128, time: 0.106, data: 0.012) loss: 0.001 
(epoch: 135, iters: 2208, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 135, iters: 2288, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 135, iters: 2368, time: 0.106, data: 0.047) loss: 0.001 
(epoch: 135, iters: 2448, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 135, iters: 2528, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 135, iters: 2608, time: 0.106, data: 0.000) loss: 0.028 
(epoch: 135, iters: 2688, time: 0.105, data: 0.011) loss: 0.016 
(epoch: 135, iters: 2768, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 135, iters: 2848, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 135, iters: 2928, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 135, iters: 3008, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 135, iters: 3088, time: 0.103, data: 0.011) loss: 0.017 
(epoch: 135, iters: 3168, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 135, iters: 3248, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 135, iters: 3328, time: 0.105, data: 0.000) loss: 0.033 
(epoch: 135, iters: 3408, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 135, iters: 3488, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 135, iters: 3568, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 135, iters: 3648, time: 0.098, data: 0.011) loss: 0.000 
(epoch: 135, iters: 3728, time: 0.065, data: 0.000) loss: 0.061 
saving the model at the end of epoch 135, iters 503280
End of epoch 135 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001964
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 135, TEST ACC: [91.654 %]

saving the latest model (epoch 136, total_steps 503296)
(epoch: 136, iters: 80, time: 0.105, data: 0.432) loss: 0.001 
(epoch: 136, iters: 160, time: 0.105, data: 0.000) loss: 0.091 
(epoch: 136, iters: 240, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 136, iters: 320, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 136, iters: 400, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 136, iters: 480, time: 0.102, data: 0.012) loss: 0.002 
(epoch: 136, iters: 560, time: 0.105, data: 0.000) loss: 0.042 
(epoch: 136, iters: 640, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 136, iters: 720, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 136, iters: 800, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 136, iters: 880, time: 0.104, data: 0.047) loss: 0.001 
(epoch: 136, iters: 960, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 136, iters: 1040, time: 0.103, data: 0.011) loss: 0.154 
(epoch: 136, iters: 1120, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 136, iters: 1200, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 136, iters: 1280, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 136, iters: 1360, time: 0.103, data: 0.000) loss: 0.003 
(epoch: 136, iters: 1440, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 136, iters: 1520, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 136, iters: 1600, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 136, iters: 1680, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 136, iters: 1760, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 136, iters: 1840, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 136, iters: 1920, time: 0.105, data: 0.000) loss: 0.052 
(epoch: 136, iters: 2000, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 136, iters: 2080, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 136, iters: 2160, time: 0.103, data: 0.011) loss: 0.048 
(epoch: 136, iters: 2240, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 136, iters: 2320, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 136, iters: 2400, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 136, iters: 2480, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 136, iters: 2560, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 136, iters: 2640, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 136, iters: 2720, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 136, iters: 2800, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 136, iters: 2880, time: 0.105, data: 0.012) loss: 0.034 
(epoch: 136, iters: 2960, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 136, iters: 3040, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 136, iters: 3120, time: 0.105, data: 0.039) loss: 0.008 
(epoch: 136, iters: 3200, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 136, iters: 3280, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 136, iters: 3360, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 136, iters: 3440, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 136, iters: 3520, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 136, iters: 3600, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 136, iters: 3680, time: 0.100, data: 0.039) loss: 0.000 
saving the model at the end of epoch 136, iters 507008
End of epoch 136 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001963
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 136, TEST ACC: [93.627 %]

saving the latest model (epoch 137, total_steps 507024)
(epoch: 137, iters: 32, time: 0.100, data: 0.000) loss: 0.000 
(epoch: 137, iters: 112, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 137, iters: 192, time: 0.105, data: 0.011) loss: 0.005 
(epoch: 137, iters: 272, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 137, iters: 352, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 137, iters: 432, time: 0.105, data: 0.048) loss: 0.000 
(epoch: 137, iters: 512, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 137, iters: 592, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 137, iters: 672, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 137, iters: 752, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 137, iters: 832, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 137, iters: 912, time: 0.104, data: 0.000) loss: 0.013 
(epoch: 137, iters: 992, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 137, iters: 1072, time: 0.105, data: 0.000) loss: 0.936 
(epoch: 137, iters: 1152, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 137, iters: 1232, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 137, iters: 1312, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 137, iters: 1392, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 137, iters: 1472, time: 0.105, data: 0.000) loss: 0.023 
(epoch: 137, iters: 1552, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 137, iters: 1632, time: 0.107, data: 0.000) loss: 0.008 
(epoch: 137, iters: 1712, time: 0.104, data: 0.012) loss: 0.012 
(epoch: 137, iters: 1792, time: 0.105, data: 0.000) loss: 0.125 
(epoch: 137, iters: 1872, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 137, iters: 1952, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 137, iters: 2032, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 137, iters: 2112, time: 0.105, data: 0.039) loss: 0.005 
(epoch: 137, iters: 2192, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 137, iters: 2272, time: 0.104, data: 0.012) loss: 0.003 
(epoch: 137, iters: 2352, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 137, iters: 2432, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 137, iters: 2512, time: 0.106, data: 0.000) loss: 0.071 
(epoch: 137, iters: 2592, time: 0.104, data: 0.000) loss: 0.015 
(epoch: 137, iters: 2672, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 137, iters: 2752, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 137, iters: 2832, time: 0.102, data: 0.011) loss: 0.084 
(epoch: 137, iters: 2912, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 137, iters: 2992, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 137, iters: 3072, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 137, iters: 3152, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 137, iters: 3232, time: 0.106, data: 0.039) loss: 0.006 
(epoch: 137, iters: 3312, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 137, iters: 3392, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 137, iters: 3472, time: 0.105, data: 0.000) loss: 0.035 
(epoch: 137, iters: 3552, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 137, iters: 3632, time: 0.102, data: 0.000) loss: 0.001 
(epoch: 137, iters: 3712, time: 0.100, data: 0.000) loss: 0.000 
saving the model at the end of epoch 137, iters 510736
End of epoch 137 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001962
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 137, TEST ACC: [94.385 %]

saving the latest model (epoch 138, total_steps 510752)
(epoch: 138, iters: 64, time: 0.104, data: 0.002) loss: 0.000 
(epoch: 138, iters: 144, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 138, iters: 224, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 138, iters: 304, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 138, iters: 384, time: 0.104, data: 0.000) loss: 0.018 
(epoch: 138, iters: 464, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 138, iters: 544, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 138, iters: 624, time: 0.103, data: 0.011) loss: 0.007 
(epoch: 138, iters: 704, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 138, iters: 784, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 138, iters: 864, time: 0.107, data: 0.000) loss: 0.009 
(epoch: 138, iters: 944, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 138, iters: 1024, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 138, iters: 1104, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 138, iters: 1184, time: 0.104, data: 0.011) loss: 0.028 
(epoch: 138, iters: 1264, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 138, iters: 1344, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 138, iters: 1424, time: 0.106, data: 0.000) loss: 0.195 
(epoch: 138, iters: 1504, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 138, iters: 1584, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 138, iters: 1664, time: 0.107, data: 0.000) loss: 0.047 
(epoch: 138, iters: 1744, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 138, iters: 1824, time: 0.106, data: 0.000) loss: 0.035 
(epoch: 138, iters: 1904, time: 0.106, data: 0.019) loss: 0.005 
(epoch: 138, iters: 1984, time: 0.107, data: 0.000) loss: 0.015 
(epoch: 138, iters: 2064, time: 0.105, data: 0.000) loss: 0.019 
(epoch: 138, iters: 2144, time: 0.105, data: 0.048) loss: 0.046 
(epoch: 138, iters: 2224, time: 0.107, data: 0.000) loss: 0.019 
(epoch: 138, iters: 2304, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 138, iters: 2384, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 138, iters: 2464, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 138, iters: 2544, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 138, iters: 2624, time: 0.105, data: 0.000) loss: 0.019 
(epoch: 138, iters: 2704, time: 0.105, data: 0.038) loss: 0.006 
(epoch: 138, iters: 2784, time: 0.105, data: 0.000) loss: 0.133 
(epoch: 138, iters: 2864, time: 0.103, data: 0.011) loss: 0.014 
(epoch: 138, iters: 2944, time: 0.107, data: 0.000) loss: 0.059 
(epoch: 138, iters: 3024, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 138, iters: 3104, time: 0.107, data: 0.000) loss: 0.008 
(epoch: 138, iters: 3184, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 138, iters: 3264, time: 0.106, data: 0.047) loss: 0.001 
(epoch: 138, iters: 3344, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 138, iters: 3424, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 138, iters: 3504, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 138, iters: 3584, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 138, iters: 3664, time: 0.101, data: 0.000) loss: 0.000 
saving the model at the end of epoch 138, iters 514464
End of epoch 138 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001961
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 138, TEST ACC: [94.234 %]

(epoch: 139, iters: 16, time: 0.117, data: 0.000) loss: 0.002 
saving the latest model (epoch 139, total_steps 514480)
(epoch: 139, iters: 96, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 139, iters: 176, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 139, iters: 256, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 139, iters: 336, time: 0.106, data: 0.011) loss: 0.014 
(epoch: 139, iters: 416, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 139, iters: 496, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 139, iters: 576, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 139, iters: 656, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 139, iters: 736, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 139, iters: 816, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 139, iters: 896, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 139, iters: 976, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 139, iters: 1056, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 139, iters: 1136, time: 0.107, data: 0.039) loss: 0.001 
(epoch: 139, iters: 1216, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 139, iters: 1296, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 139, iters: 1376, time: 0.105, data: 0.000) loss: 0.035 
(epoch: 139, iters: 1456, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 139, iters: 1536, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 139, iters: 1616, time: 0.105, data: 0.000) loss: 0.033 
(epoch: 139, iters: 1696, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 139, iters: 1776, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 139, iters: 1856, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 139, iters: 1936, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 139, iters: 2016, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 139, iters: 2096, time: 0.105, data: 0.000) loss: 0.144 
(epoch: 139, iters: 2176, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 139, iters: 2256, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 139, iters: 2336, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 139, iters: 2416, time: 0.103, data: 0.012) loss: 0.228 
(epoch: 139, iters: 2496, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 139, iters: 2576, time: 0.105, data: 0.012) loss: 0.106 
(epoch: 139, iters: 2656, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 139, iters: 2736, time: 0.105, data: 0.000) loss: 0.165 
(epoch: 139, iters: 2816, time: 0.106, data: 0.047) loss: 0.000 
(epoch: 139, iters: 2896, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 139, iters: 2976, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 139, iters: 3056, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 139, iters: 3136, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 139, iters: 3216, time: 0.107, data: 0.000) loss: 0.157 
(epoch: 139, iters: 3296, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 139, iters: 3376, time: 0.105, data: 0.038) loss: 0.037 
(epoch: 139, iters: 3456, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 139, iters: 3536, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 139, iters: 3616, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 139, iters: 3696, time: 0.100, data: 0.011) loss: 0.000 
saving the model at the end of epoch 139, iters 518192
End of epoch 139 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001960
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 139, TEST ACC: [95.599 %]

saving the latest model (epoch 140, total_steps 518208)
(epoch: 140, iters: 48, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 140, iters: 128, time: 0.104, data: 0.026) loss: 0.000 
(epoch: 140, iters: 208, time: 0.106, data: 0.000) loss: 0.178 
(epoch: 140, iters: 288, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 140, iters: 368, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 140, iters: 448, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 140, iters: 528, time: 0.104, data: 0.011) loss: 0.030 
(epoch: 140, iters: 608, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 140, iters: 688, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 140, iters: 768, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 140, iters: 848, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 140, iters: 928, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 140, iters: 1008, time: 0.105, data: 0.000) loss: 0.040 
(epoch: 140, iters: 1088, time: 0.103, data: 0.011) loss: 0.010 
(epoch: 140, iters: 1168, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 140, iters: 1248, time: 0.105, data: 0.011) loss: 0.056 
(epoch: 140, iters: 1328, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 140, iters: 1408, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 140, iters: 1488, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 140, iters: 1568, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 140, iters: 1648, time: 0.102, data: 0.012) loss: 0.003 
(epoch: 140, iters: 1728, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 140, iters: 1808, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 140, iters: 1888, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 140, iters: 1968, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 140, iters: 2048, time: 0.106, data: 0.040) loss: 0.007 
(epoch: 140, iters: 2128, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 140, iters: 2208, time: 0.104, data: 0.012) loss: 0.005 
(epoch: 140, iters: 2288, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 140, iters: 2368, time: 0.106, data: 0.011) loss: 0.069 
(epoch: 140, iters: 2448, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 140, iters: 2528, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 140, iters: 2608, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 140, iters: 2688, time: 0.105, data: 0.000) loss: 0.040 
(epoch: 140, iters: 2768, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 140, iters: 2848, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 140, iters: 2928, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 140, iters: 3008, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 140, iters: 3088, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 140, iters: 3168, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 140, iters: 3248, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 140, iters: 3328, time: 0.103, data: 0.012) loss: 0.012 
(epoch: 140, iters: 3408, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 140, iters: 3488, time: 0.105, data: 0.012) loss: 0.035 
(epoch: 140, iters: 3568, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 140, iters: 3648, time: 0.100, data: 0.000) loss: 0.002 
(epoch: 140, iters: 3728, time: 0.066, data: 0.015) loss: 0.108 
saving the model at the end of epoch 140, iters 521920
End of epoch 140 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001959
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 140, TEST ACC: [93.93 %]

saving the latest model (epoch 141, total_steps 521936)
(epoch: 141, iters: 80, time: 0.107, data: 0.516) loss: 0.000 
(epoch: 141, iters: 160, time: 0.106, data: 0.030) loss: 0.001 
(epoch: 141, iters: 240, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 141, iters: 320, time: 0.102, data: 0.012) loss: 0.003 
(epoch: 141, iters: 400, time: 0.106, data: 0.000) loss: 0.015 
(epoch: 141, iters: 480, time: 0.104, data: 0.019) loss: 0.004 
(epoch: 141, iters: 560, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 141, iters: 640, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 141, iters: 720, time: 0.106, data: 0.048) loss: 0.000 
(epoch: 141, iters: 800, time: 0.107, data: 0.000) loss: 0.025 
(epoch: 141, iters: 880, time: 0.104, data: 0.012) loss: 0.020 
(epoch: 141, iters: 960, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 141, iters: 1040, time: 0.105, data: 0.011) loss: 0.007 
(epoch: 141, iters: 1120, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 141, iters: 1200, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 141, iters: 1280, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 141, iters: 1360, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 141, iters: 1440, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 141, iters: 1520, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 141, iters: 1600, time: 0.105, data: 0.012) loss: 0.094 
(epoch: 141, iters: 1680, time: 0.106, data: 0.000) loss: 0.828 
(epoch: 141, iters: 1760, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 141, iters: 1840, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 141, iters: 1920, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 141, iters: 2000, time: 0.102, data: 0.012) loss: 0.010 
(epoch: 141, iters: 2080, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 141, iters: 2160, time: 0.106, data: 0.012) loss: 0.002 
(epoch: 141, iters: 2240, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 141, iters: 2320, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 141, iters: 2400, time: 0.106, data: 0.047) loss: 0.024 
(epoch: 141, iters: 2480, time: 0.107, data: 0.000) loss: 0.013 
(epoch: 141, iters: 2560, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 141, iters: 2640, time: 0.106, data: 0.000) loss: 0.223 
(epoch: 141, iters: 2720, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 141, iters: 2800, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 141, iters: 2880, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 141, iters: 2960, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 141, iters: 3040, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 141, iters: 3120, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 141, iters: 3200, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 141, iters: 3280, time: 0.104, data: 0.012) loss: 0.036 
(epoch: 141, iters: 3360, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 141, iters: 3440, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 141, iters: 3520, time: 0.107, data: 0.039) loss: 0.003 
(epoch: 141, iters: 3600, time: 0.107, data: 0.000) loss: 0.013 
(epoch: 141, iters: 3680, time: 0.100, data: 0.011) loss: 0.053 
saving the model at the end of epoch 141, iters 525648
End of epoch 141 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001958
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 141, TEST ACC: [92.716 %]

saving the latest model (epoch 142, total_steps 525664)
(epoch: 142, iters: 32, time: 0.101, data: 0.006) loss: 0.001 
(epoch: 142, iters: 112, time: 0.105, data: 0.011) loss: 0.020 
(epoch: 142, iters: 192, time: 0.104, data: 0.021) loss: 0.004 
(epoch: 142, iters: 272, time: 0.104, data: 0.000) loss: 0.015 
(epoch: 142, iters: 352, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 142, iters: 432, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 142, iters: 512, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 142, iters: 592, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 142, iters: 672, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 142, iters: 752, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 142, iters: 832, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 142, iters: 912, time: 0.106, data: 0.012) loss: 0.041 
(epoch: 142, iters: 992, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 142, iters: 1072, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 142, iters: 1152, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 142, iters: 1232, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 142, iters: 1312, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 142, iters: 1392, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 142, iters: 1472, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 142, iters: 1552, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 142, iters: 1632, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 142, iters: 1712, time: 0.106, data: 0.039) loss: 0.003 
(epoch: 142, iters: 1792, time: 0.106, data: 0.000) loss: 0.236 
(epoch: 142, iters: 1872, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 142, iters: 1952, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 142, iters: 2032, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 142, iters: 2112, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 142, iters: 2192, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 142, iters: 2272, time: 0.105, data: 0.038) loss: 0.011 
(epoch: 142, iters: 2352, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 142, iters: 2432, time: 0.103, data: 0.011) loss: 0.036 
(epoch: 142, iters: 2512, time: 0.105, data: 0.000) loss: 0.045 
(epoch: 142, iters: 2592, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 142, iters: 2672, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 142, iters: 2752, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 142, iters: 2832, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 142, iters: 2912, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 142, iters: 2992, time: 0.104, data: 0.011) loss: 0.018 
(epoch: 142, iters: 3072, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 142, iters: 3152, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 142, iters: 3232, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 142, iters: 3312, time: 0.104, data: 0.000) loss: 0.045 
(epoch: 142, iters: 3392, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 142, iters: 3472, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 142, iters: 3552, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 142, iters: 3632, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 142, iters: 3712, time: 0.101, data: 0.011) loss: 0.000 
saving the model at the end of epoch 142, iters 529376
End of epoch 142 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001957
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 142, TEST ACC: [94.689 %]

saving the latest model (epoch 143, total_steps 529392)
(epoch: 143, iters: 64, time: 0.105, data: 0.002) loss: 0.023 
(epoch: 143, iters: 144, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 143, iters: 224, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 143, iters: 304, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 143, iters: 384, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 143, iters: 464, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 143, iters: 544, time: 0.104, data: 0.011) loss: 0.007 
(epoch: 143, iters: 624, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 143, iters: 704, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 143, iters: 784, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 143, iters: 864, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 143, iters: 944, time: 0.104, data: 0.038) loss: 0.009 
(epoch: 143, iters: 1024, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 143, iters: 1104, time: 0.103, data: 0.011) loss: 0.107 
(epoch: 143, iters: 1184, time: 0.106, data: 0.000) loss: 0.091 
(epoch: 143, iters: 1264, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 143, iters: 1344, time: 0.108, data: 0.000) loss: 0.002 
(epoch: 143, iters: 1424, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 143, iters: 1504, time: 0.106, data: 0.047) loss: 0.001 
(epoch: 143, iters: 1584, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 143, iters: 1664, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 143, iters: 1744, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 143, iters: 1824, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 143, iters: 1904, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 143, iters: 1984, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 143, iters: 2064, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 143, iters: 2144, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 143, iters: 2224, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 143, iters: 2304, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 143, iters: 2384, time: 0.105, data: 0.011) loss: 0.077 
(epoch: 143, iters: 2464, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 143, iters: 2544, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 143, iters: 2624, time: 0.106, data: 0.039) loss: 0.079 
(epoch: 143, iters: 2704, time: 0.107, data: 0.000) loss: 0.005 
(epoch: 143, iters: 2784, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 143, iters: 2864, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 143, iters: 2944, time: 0.106, data: 0.011) loss: 0.000 
(epoch: 143, iters: 3024, time: 0.105, data: 0.000) loss: 0.627 
(epoch: 143, iters: 3104, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 143, iters: 3184, time: 0.105, data: 0.049) loss: 0.016 
(epoch: 143, iters: 3264, time: 0.106, data: 0.000) loss: 0.080 
(epoch: 143, iters: 3344, time: 0.104, data: 0.012) loss: 0.002 
(epoch: 143, iters: 3424, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 143, iters: 3504, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 143, iters: 3584, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 143, iters: 3664, time: 0.099, data: 0.000) loss: 0.004 
saving the model at the end of epoch 143, iters 533104
End of epoch 143 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001956
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 143, TEST ACC: [94.689 %]

(epoch: 144, iters: 16, time: 0.116, data: 0.012) loss: 0.000 
saving the latest model (epoch 144, total_steps 533120)
(epoch: 144, iters: 96, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 144, iters: 176, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 144, iters: 256, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 144, iters: 336, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 144, iters: 416, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 144, iters: 496, time: 0.104, data: 0.039) loss: 0.000 
(epoch: 144, iters: 576, time: 0.107, data: 0.000) loss: 0.015 
(epoch: 144, iters: 656, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 144, iters: 736, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 144, iters: 816, time: 0.106, data: 0.011) loss: 0.001 
(epoch: 144, iters: 896, time: 0.105, data: 0.000) loss: 0.457 
(epoch: 144, iters: 976, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 144, iters: 1056, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 144, iters: 1136, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 144, iters: 1216, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 144, iters: 1296, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 144, iters: 1376, time: 0.106, data: 0.011) loss: 0.018 
(epoch: 144, iters: 1456, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 144, iters: 1536, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 144, iters: 1616, time: 0.106, data: 0.047) loss: 0.000 
(epoch: 144, iters: 1696, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 144, iters: 1776, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 144, iters: 1856, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 144, iters: 1936, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 144, iters: 2016, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 144, iters: 2096, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 144, iters: 2176, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 144, iters: 2256, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 144, iters: 2336, time: 0.103, data: 0.011) loss: 0.172 
(epoch: 144, iters: 2416, time: 0.105, data: 0.000) loss: 0.034 
(epoch: 144, iters: 2496, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 144, iters: 2576, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 144, iters: 2656, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 144, iters: 2736, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 144, iters: 2816, time: 0.106, data: 0.000) loss: 0.028 
(epoch: 144, iters: 2896, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 144, iters: 2976, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 144, iters: 3056, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 144, iters: 3136, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 144, iters: 3216, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 144, iters: 3296, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 144, iters: 3376, time: 0.106, data: 0.000) loss: 0.015 
(epoch: 144, iters: 3456, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 144, iters: 3536, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 144, iters: 3616, time: 0.105, data: 0.011) loss: 0.008 
(epoch: 144, iters: 3696, time: 0.099, data: 0.000) loss: 0.001 
saving the model at the end of epoch 144, iters 536832
End of epoch 144 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001955
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 144, TEST ACC: [95.599 %]

saving the latest model (epoch 145, total_steps 536848)
(epoch: 145, iters: 48, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 145, iters: 128, time: 0.105, data: 0.037) loss: 0.008 
(epoch: 145, iters: 208, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 145, iters: 288, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 145, iters: 368, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 145, iters: 448, time: 0.104, data: 0.011) loss: 0.111 
(epoch: 145, iters: 528, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 145, iters: 608, time: 0.105, data: 0.000) loss: 0.124 
(epoch: 145, iters: 688, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 145, iters: 768, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 145, iters: 848, time: 0.102, data: 0.011) loss: 0.003 
(epoch: 145, iters: 928, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 145, iters: 1008, time: 0.104, data: 0.011) loss: 0.025 
(epoch: 145, iters: 1088, time: 0.104, data: 0.000) loss: 0.036 
(epoch: 145, iters: 1168, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 145, iters: 1248, time: 0.104, data: 0.039) loss: 0.018 
(epoch: 145, iters: 1328, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 145, iters: 1408, time: 0.102, data: 0.011) loss: 0.024 
(epoch: 145, iters: 1488, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 145, iters: 1568, time: 0.103, data: 0.012) loss: 0.012 
(epoch: 145, iters: 1648, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 145, iters: 1728, time: 0.103, data: 0.000) loss: 0.013 
(epoch: 145, iters: 1808, time: 0.104, data: 0.039) loss: 0.008 
(epoch: 145, iters: 1888, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 145, iters: 1968, time: 0.102, data: 0.011) loss: 0.002 
(epoch: 145, iters: 2048, time: 0.106, data: 0.000) loss: 0.023 
(epoch: 145, iters: 2128, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 145, iters: 2208, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 145, iters: 2288, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 145, iters: 2368, time: 0.105, data: 0.047) loss: 0.119 
(epoch: 145, iters: 2448, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 145, iters: 2528, time: 0.103, data: 0.021) loss: 0.001 
(epoch: 145, iters: 2608, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 145, iters: 2688, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 145, iters: 2768, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 145, iters: 2848, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 145, iters: 2928, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 145, iters: 3008, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 145, iters: 3088, time: 0.102, data: 0.011) loss: 0.022 
(epoch: 145, iters: 3168, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 145, iters: 3248, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 145, iters: 3328, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 145, iters: 3408, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 145, iters: 3488, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 145, iters: 3568, time: 0.105, data: 0.000) loss: 0.035 
(epoch: 145, iters: 3648, time: 0.098, data: 0.011) loss: 0.032 
(epoch: 145, iters: 3728, time: 0.066, data: 0.000) loss: 0.003 
saving the model at the end of epoch 145, iters 540560
End of epoch 145 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001954
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 145, TEST ACC: [94.689 %]

saving the latest model (epoch 146, total_steps 540576)
(epoch: 146, iters: 80, time: 0.107, data: 0.484) loss: 0.002 
(epoch: 146, iters: 160, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 146, iters: 240, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 146, iters: 320, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 146, iters: 400, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 146, iters: 480, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 146, iters: 560, time: 0.104, data: 0.011) loss: 0.020 
(epoch: 146, iters: 640, time: 0.106, data: 0.000) loss: 0.028 
(epoch: 146, iters: 720, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 146, iters: 800, time: 0.105, data: 0.048) loss: 0.007 
(epoch: 146, iters: 880, time: 0.106, data: 0.000) loss: 0.143 
(epoch: 146, iters: 960, time: 0.103, data: 0.011) loss: 0.060 
(epoch: 146, iters: 1040, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 146, iters: 1120, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 146, iters: 1200, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 146, iters: 1280, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 146, iters: 1360, time: 0.104, data: 0.038) loss: 0.000 
(epoch: 146, iters: 1440, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 146, iters: 1520, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 146, iters: 1600, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 146, iters: 1680, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 146, iters: 1760, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 146, iters: 1840, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 146, iters: 1920, time: 0.107, data: 0.039) loss: 0.009 
(epoch: 146, iters: 2000, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 146, iters: 2080, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 146, iters: 2160, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 146, iters: 2240, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 146, iters: 2320, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 146, iters: 2400, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 146, iters: 2480, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 146, iters: 2560, time: 0.105, data: 0.000) loss: 0.107 
(epoch: 146, iters: 2640, time: 0.103, data: 0.012) loss: 0.094 
(epoch: 146, iters: 2720, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 146, iters: 2800, time: 0.105, data: 0.012) loss: 0.018 
(epoch: 146, iters: 2880, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 146, iters: 2960, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 146, iters: 3040, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 146, iters: 3120, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 146, iters: 3200, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 146, iters: 3280, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 146, iters: 3360, time: 0.105, data: 0.011) loss: 0.008 
(epoch: 146, iters: 3440, time: 0.107, data: 0.000) loss: 0.010 
(epoch: 146, iters: 3520, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 146, iters: 3600, time: 0.106, data: 0.048) loss: 0.146 
(epoch: 146, iters: 3680, time: 0.100, data: 0.000) loss: 0.001 
saving the model at the end of epoch 146, iters 544288
End of epoch 146 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001953
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 146, TEST ACC: [94.841 %]

saving the latest model (epoch 147, total_steps 544304)
(epoch: 147, iters: 32, time: 0.099, data: 0.004) loss: 0.016 
(epoch: 147, iters: 112, time: 0.105, data: 0.011) loss: 0.005 
(epoch: 147, iters: 192, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 147, iters: 272, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 147, iters: 352, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 147, iters: 432, time: 0.105, data: 0.000) loss: 0.097 
(epoch: 147, iters: 512, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 147, iters: 592, time: 0.106, data: 0.038) loss: 0.004 
(epoch: 147, iters: 672, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 147, iters: 752, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 147, iters: 832, time: 0.105, data: 0.000) loss: 0.149 
(epoch: 147, iters: 912, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 147, iters: 992, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 147, iters: 1072, time: 0.105, data: 0.000) loss: 0.018 
(epoch: 147, iters: 1152, time: 0.106, data: 0.039) loss: 0.321 
(epoch: 147, iters: 1232, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 147, iters: 1312, time: 0.103, data: 0.012) loss: 0.008 
(epoch: 147, iters: 1392, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 147, iters: 1472, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 147, iters: 1552, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 147, iters: 1632, time: 0.104, data: 0.000) loss: 0.030 
(epoch: 147, iters: 1712, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 147, iters: 1792, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 147, iters: 1872, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 147, iters: 1952, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 147, iters: 2032, time: 0.105, data: 0.011) loss: 0.074 
(epoch: 147, iters: 2112, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 147, iters: 2192, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 147, iters: 2272, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 147, iters: 2352, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 147, iters: 2432, time: 0.102, data: 0.012) loss: 0.000 
(epoch: 147, iters: 2512, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 147, iters: 2592, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 147, iters: 2672, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 147, iters: 2752, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 147, iters: 2832, time: 0.105, data: 0.039) loss: 0.012 
(epoch: 147, iters: 2912, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 147, iters: 2992, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 147, iters: 3072, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 147, iters: 3152, time: 0.104, data: 0.011) loss: 0.012 
(epoch: 147, iters: 3232, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 147, iters: 3312, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 147, iters: 3392, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 147, iters: 3472, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 147, iters: 3552, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 147, iters: 3632, time: 0.103, data: 0.000) loss: 0.003 
(epoch: 147, iters: 3712, time: 0.100, data: 0.011) loss: 0.004 
saving the model at the end of epoch 147, iters 548016
End of epoch 147 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001952
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 147, TEST ACC: [95.296 %]

saving the latest model (epoch 148, total_steps 548032)
(epoch: 148, iters: 64, time: 0.103, data: 0.003) loss: 0.000 
(epoch: 148, iters: 144, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 148, iters: 224, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 148, iters: 304, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 148, iters: 384, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 148, iters: 464, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 148, iters: 544, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 148, iters: 624, time: 0.103, data: 0.011) loss: 0.086 
(epoch: 148, iters: 704, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 148, iters: 784, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 148, iters: 864, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 148, iters: 944, time: 0.104, data: 0.000) loss: 0.023 
(epoch: 148, iters: 1024, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 148, iters: 1104, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 148, iters: 1184, time: 0.105, data: 0.011) loss: 0.017 
(epoch: 148, iters: 1264, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 148, iters: 1344, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 148, iters: 1424, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 148, iters: 1504, time: 0.104, data: 0.000) loss: 0.240 
(epoch: 148, iters: 1584, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 148, iters: 1664, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 148, iters: 1744, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 148, iters: 1824, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 148, iters: 1904, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 148, iters: 1984, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 148, iters: 2064, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 148, iters: 2144, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 148, iters: 2224, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 148, iters: 2304, time: 0.103, data: 0.011) loss: 0.010 
(epoch: 148, iters: 2384, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 148, iters: 2464, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 148, iters: 2544, time: 0.106, data: 0.000) loss: 0.126 
(epoch: 148, iters: 2624, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 148, iters: 2704, time: 0.106, data: 0.039) loss: 0.014 
(epoch: 148, iters: 2784, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 148, iters: 2864, time: 0.103, data: 0.012) loss: 0.012 
(epoch: 148, iters: 2944, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 148, iters: 3024, time: 0.105, data: 0.011) loss: 0.103 
(epoch: 148, iters: 3104, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 148, iters: 3184, time: 0.103, data: 0.000) loss: 0.004 
(epoch: 148, iters: 3264, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 148, iters: 3344, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 148, iters: 3424, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 148, iters: 3504, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 148, iters: 3584, time: 0.105, data: 0.011) loss: 0.030 
(epoch: 148, iters: 3664, time: 0.100, data: 0.000) loss: 0.002 
saving the model at the end of epoch 148, iters 551744
End of epoch 148 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001951
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 148, TEST ACC: [95.903 %]

(epoch: 149, iters: 16, time: 0.116, data: 0.000) loss: 0.006 
saving the latest model (epoch 149, total_steps 551760)
(epoch: 149, iters: 96, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 149, iters: 176, time: 0.102, data: 0.012) loss: 0.000 
(epoch: 149, iters: 256, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 149, iters: 336, time: 0.106, data: 0.011) loss: 0.001 
(epoch: 149, iters: 416, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 149, iters: 496, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 149, iters: 576, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 149, iters: 656, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 149, iters: 736, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 149, iters: 816, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 149, iters: 896, time: 0.103, data: 0.011) loss: 0.027 
(epoch: 149, iters: 976, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 149, iters: 1056, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 149, iters: 1136, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 149, iters: 1216, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 149, iters: 1296, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 149, iters: 1376, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 149, iters: 1456, time: 0.105, data: 0.011) loss: 0.416 
(epoch: 149, iters: 1536, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 149, iters: 1616, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 149, iters: 1696, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 149, iters: 1776, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 149, iters: 1856, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 149, iters: 1936, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 149, iters: 2016, time: 0.105, data: 0.011) loss: 0.005 
(epoch: 149, iters: 2096, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 149, iters: 2176, time: 0.104, data: 0.000) loss: 0.086 
(epoch: 149, iters: 2256, time: 0.105, data: 0.038) loss: 0.079 
(epoch: 149, iters: 2336, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 149, iters: 2416, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 149, iters: 2496, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 149, iters: 2576, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 149, iters: 2656, time: 0.105, data: 0.000) loss: 0.086 
(epoch: 149, iters: 2736, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 149, iters: 2816, time: 0.105, data: 0.038) loss: 0.021 
(epoch: 149, iters: 2896, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 149, iters: 2976, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 149, iters: 3056, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 149, iters: 3136, time: 0.104, data: 0.019) loss: 0.001 
(epoch: 149, iters: 3216, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 149, iters: 3296, time: 0.105, data: 0.000) loss: 0.140 
(epoch: 149, iters: 3376, time: 0.105, data: 0.038) loss: 0.003 
(epoch: 149, iters: 3456, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 149, iters: 3536, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 149, iters: 3616, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 149, iters: 3696, time: 0.099, data: 0.011) loss: 0.011 
saving the model at the end of epoch 149, iters 555472
End of epoch 149 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001950
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 149, TEST ACC: [94.992 %]

saving the latest model (epoch 150, total_steps 555488)
(epoch: 150, iters: 48, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 150, iters: 128, time: 0.105, data: 0.026) loss: 0.000 
(epoch: 150, iters: 208, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 150, iters: 288, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 150, iters: 368, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 150, iters: 448, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 150, iters: 528, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 150, iters: 608, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 150, iters: 688, time: 0.106, data: 0.039) loss: 0.012 
(epoch: 150, iters: 768, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 150, iters: 848, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 150, iters: 928, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 150, iters: 1008, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 150, iters: 1088, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 150, iters: 1168, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 150, iters: 1248, time: 0.105, data: 0.049) loss: 0.016 
(epoch: 150, iters: 1328, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 150, iters: 1408, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 150, iters: 1488, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 150, iters: 1568, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 150, iters: 1648, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 150, iters: 1728, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 150, iters: 1808, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 150, iters: 1888, time: 0.105, data: 0.000) loss: 0.159 
(epoch: 150, iters: 1968, time: 0.103, data: 0.012) loss: 0.030 
(epoch: 150, iters: 2048, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 150, iters: 2128, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 150, iters: 2208, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 150, iters: 2288, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 150, iters: 2368, time: 0.106, data: 0.039) loss: 0.519 
(epoch: 150, iters: 2448, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 150, iters: 2528, time: 0.104, data: 0.012) loss: 0.057 
(epoch: 150, iters: 2608, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 150, iters: 2688, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 150, iters: 2768, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 150, iters: 2848, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 150, iters: 2928, time: 0.105, data: 0.038) loss: 0.011 
(epoch: 150, iters: 3008, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 150, iters: 3088, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 150, iters: 3168, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 150, iters: 3248, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 150, iters: 3328, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 150, iters: 3408, time: 0.104, data: 0.000) loss: 0.031 
(epoch: 150, iters: 3488, time: 0.106, data: 0.038) loss: 0.006 
(epoch: 150, iters: 3568, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 150, iters: 3648, time: 0.098, data: 0.012) loss: 0.000 
(epoch: 150, iters: 3728, time: 0.065, data: 0.000) loss: 0.254 
saving the model at the end of epoch 150, iters 559200
End of epoch 150 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001949
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 150, TEST ACC: [96.813 %]

saving the latest model (epoch 151, total_steps 559216)
(epoch: 151, iters: 80, time: 0.106, data: 0.513) loss: 0.002 
(epoch: 151, iters: 160, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 151, iters: 240, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 151, iters: 320, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 151, iters: 400, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 151, iters: 480, time: 0.105, data: 0.000) loss: 0.019 
(epoch: 151, iters: 560, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 151, iters: 640, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 151, iters: 720, time: 0.103, data: 0.000) loss: 0.005 
(epoch: 151, iters: 800, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 151, iters: 880, time: 0.106, data: 0.000) loss: 0.035 
(epoch: 151, iters: 960, time: 0.103, data: 0.011) loss: 0.024 
(epoch: 151, iters: 1040, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 151, iters: 1120, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 151, iters: 1200, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 151, iters: 1280, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 151, iters: 1360, time: 0.105, data: 0.039) loss: 0.024 
(epoch: 151, iters: 1440, time: 0.106, data: 0.000) loss: 0.040 
(epoch: 151, iters: 1520, time: 0.104, data: 0.011) loss: 0.017 
(epoch: 151, iters: 1600, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 151, iters: 1680, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 151, iters: 1760, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 151, iters: 1840, time: 0.104, data: 0.000) loss: 0.176 
(epoch: 151, iters: 1920, time: 0.104, data: 0.038) loss: 0.001 
(epoch: 151, iters: 2000, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 151, iters: 2080, time: 0.103, data: 0.011) loss: 0.377 
(epoch: 151, iters: 2160, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 151, iters: 2240, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 151, iters: 2320, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 151, iters: 2400, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 151, iters: 2480, time: 0.105, data: 0.038) loss: 0.019 
(epoch: 151, iters: 2560, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 151, iters: 2640, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 151, iters: 2720, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 151, iters: 2800, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 151, iters: 2880, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 151, iters: 2960, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 151, iters: 3040, time: 0.106, data: 0.048) loss: 0.000 
(epoch: 151, iters: 3120, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 151, iters: 3200, time: 0.103, data: 0.011) loss: 0.008 
(epoch: 151, iters: 3280, time: 0.104, data: 0.000) loss: 0.010 
(epoch: 151, iters: 3360, time: 0.105, data: 0.011) loss: 0.156 
(epoch: 151, iters: 3440, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 151, iters: 3520, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 151, iters: 3600, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 151, iters: 3680, time: 0.099, data: 0.000) loss: 0.001 
saving the model at the end of epoch 151, iters 562928
End of epoch 151 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001948
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 151, TEST ACC: [96.662 %]

saving the latest model (epoch 152, total_steps 562944)
(epoch: 152, iters: 32, time: 0.100, data: 0.004) loss: 0.000 
(epoch: 152, iters: 112, time: 0.105, data: 0.026) loss: 0.017 
(epoch: 152, iters: 192, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 152, iters: 272, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 152, iters: 352, time: 0.105, data: 0.047) loss: 0.002 
(epoch: 152, iters: 432, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 152, iters: 512, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 152, iters: 592, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 152, iters: 672, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 152, iters: 752, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 152, iters: 832, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 152, iters: 912, time: 0.105, data: 0.038) loss: 0.010 
(epoch: 152, iters: 992, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 152, iters: 1072, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 152, iters: 1152, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 152, iters: 1232, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 152, iters: 1312, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 152, iters: 1392, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 152, iters: 1472, time: 0.106, data: 0.039) loss: 0.064 
(epoch: 152, iters: 1552, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 152, iters: 1632, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 152, iters: 1712, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 152, iters: 1792, time: 0.104, data: 0.011) loss: 0.008 
(epoch: 152, iters: 1872, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 152, iters: 1952, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 152, iters: 2032, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 152, iters: 2112, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 152, iters: 2192, time: 0.103, data: 0.011) loss: 0.021 
(epoch: 152, iters: 2272, time: 0.106, data: 0.000) loss: 0.044 
(epoch: 152, iters: 2352, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 152, iters: 2432, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 152, iters: 2512, time: 0.105, data: 0.000) loss: 0.050 
(epoch: 152, iters: 2592, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 152, iters: 2672, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 152, iters: 2752, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 152, iters: 2832, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 152, iters: 2912, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 152, iters: 2992, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 152, iters: 3072, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 152, iters: 3152, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 152, iters: 3232, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 152, iters: 3312, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 152, iters: 3392, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 152, iters: 3472, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 152, iters: 3552, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 152, iters: 3632, time: 0.102, data: 0.000) loss: 0.170 
(epoch: 152, iters: 3712, time: 0.100, data: 0.035) loss: 0.001 
saving the model at the end of epoch 152, iters 566656
End of epoch 152 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001947
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 152, TEST ACC: [93.475 %]

saving the latest model (epoch 153, total_steps 566672)
(epoch: 153, iters: 64, time: 0.103, data: 0.000) loss: 0.139 
(epoch: 153, iters: 144, time: 0.105, data: 0.000) loss: 0.039 
(epoch: 153, iters: 224, time: 0.103, data: 0.012) loss: 0.111 
(epoch: 153, iters: 304, time: 0.106, data: 0.000) loss: 0.040 
(epoch: 153, iters: 384, time: 0.105, data: 0.000) loss: 0.158 
(epoch: 153, iters: 464, time: 0.106, data: 0.038) loss: 0.054 
(epoch: 153, iters: 544, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 153, iters: 624, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 153, iters: 704, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 153, iters: 784, time: 0.106, data: 0.011) loss: 0.001 
(epoch: 153, iters: 864, time: 0.106, data: 0.000) loss: 0.080 
(epoch: 153, iters: 944, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 153, iters: 1024, time: 0.105, data: 0.048) loss: 0.001 
(epoch: 153, iters: 1104, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 153, iters: 1184, time: 0.103, data: 0.012) loss: 0.007 
(epoch: 153, iters: 1264, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 153, iters: 1344, time: 0.105, data: 0.011) loss: 0.079 
(epoch: 153, iters: 1424, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 153, iters: 1504, time: 0.104, data: 0.000) loss: 0.009 
(epoch: 153, iters: 1584, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 153, iters: 1664, time: 0.106, data: 0.000) loss: 0.155 
(epoch: 153, iters: 1744, time: 0.104, data: 0.011) loss: 0.013 
(epoch: 153, iters: 1824, time: 0.105, data: 0.000) loss: 0.150 
(epoch: 153, iters: 1904, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 153, iters: 1984, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 153, iters: 2064, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 153, iters: 2144, time: 0.105, data: 0.039) loss: 0.003 
(epoch: 153, iters: 2224, time: 0.105, data: 0.000) loss: 0.048 
(epoch: 153, iters: 2304, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 153, iters: 2384, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 153, iters: 2464, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 153, iters: 2544, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 153, iters: 2624, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 153, iters: 2704, time: 0.104, data: 0.047) loss: 0.001 
(epoch: 153, iters: 2784, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 153, iters: 2864, time: 0.103, data: 0.011) loss: 0.008 
(epoch: 153, iters: 2944, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 153, iters: 3024, time: 0.103, data: 0.011) loss: 0.367 
(epoch: 153, iters: 3104, time: 0.105, data: 0.000) loss: 0.023 
(epoch: 153, iters: 3184, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 153, iters: 3264, time: 0.105, data: 0.039) loss: 0.006 
(epoch: 153, iters: 3344, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 153, iters: 3424, time: 0.103, data: 0.011) loss: 0.009 
(epoch: 153, iters: 3504, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 153, iters: 3584, time: 0.105, data: 0.011) loss: 0.494 
(epoch: 153, iters: 3664, time: 0.100, data: 0.000) loss: 0.004 
saving the model at the end of epoch 153, iters 570384
End of epoch 153 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001946
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 153, TEST ACC: [93.627 %]

(epoch: 154, iters: 16, time: 0.117, data: 0.000) loss: 0.064 
saving the latest model (epoch 154, total_steps 570400)
(epoch: 154, iters: 96, time: 0.106, data: 0.011) loss: 0.001 
(epoch: 154, iters: 176, time: 0.102, data: 0.012) loss: 0.011 
(epoch: 154, iters: 256, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 154, iters: 336, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 154, iters: 416, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 154, iters: 496, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 154, iters: 576, time: 0.104, data: 0.048) loss: 0.002 
(epoch: 154, iters: 656, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 154, iters: 736, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 154, iters: 816, time: 0.106, data: 0.000) loss: 0.177 
(epoch: 154, iters: 896, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 154, iters: 976, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 154, iters: 1056, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 154, iters: 1136, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 154, iters: 1216, time: 0.106, data: 0.000) loss: 0.082 
(epoch: 154, iters: 1296, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 154, iters: 1376, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 154, iters: 1456, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 154, iters: 1536, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 154, iters: 1616, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 154, iters: 1696, time: 0.106, data: 0.039) loss: 0.069 
(epoch: 154, iters: 1776, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 154, iters: 1856, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 154, iters: 1936, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 154, iters: 2016, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 154, iters: 2096, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 154, iters: 2176, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 154, iters: 2256, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 154, iters: 2336, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 154, iters: 2416, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 154, iters: 2496, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 154, iters: 2576, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 154, iters: 2656, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 154, iters: 2736, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 154, iters: 2816, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 154, iters: 2896, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 154, iters: 2976, time: 0.104, data: 0.012) loss: 0.002 
(epoch: 154, iters: 3056, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 154, iters: 3136, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 154, iters: 3216, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 154, iters: 3296, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 154, iters: 3376, time: 0.105, data: 0.047) loss: 0.010 
(epoch: 154, iters: 3456, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 154, iters: 3536, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 154, iters: 3616, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 154, iters: 3696, time: 0.101, data: 0.011) loss: 0.011 
saving the model at the end of epoch 154, iters 574112
End of epoch 154 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001945
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 154, TEST ACC: [92.413 %]

saving the latest model (epoch 155, total_steps 574128)
(epoch: 155, iters: 48, time: 0.107, data: 0.000) loss: 0.053 
(epoch: 155, iters: 128, time: 0.105, data: 0.040) loss: 0.000 
(epoch: 155, iters: 208, time: 0.106, data: 0.000) loss: 0.155 
(epoch: 155, iters: 288, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 155, iters: 368, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 155, iters: 448, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 155, iters: 528, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 155, iters: 608, time: 0.105, data: 0.000) loss: 0.104 
(epoch: 155, iters: 688, time: 0.106, data: 0.038) loss: 0.005 
(epoch: 155, iters: 768, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 155, iters: 848, time: 0.103, data: 0.012) loss: 0.005 
(epoch: 155, iters: 928, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 155, iters: 1008, time: 0.106, data: 0.012) loss: 0.013 
(epoch: 155, iters: 1088, time: 0.107, data: 0.000) loss: 0.008 
(epoch: 155, iters: 1168, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 155, iters: 1248, time: 0.106, data: 0.047) loss: 0.017 
(epoch: 155, iters: 1328, time: 0.106, data: 0.000) loss: 0.140 
(epoch: 155, iters: 1408, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 155, iters: 1488, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 155, iters: 1568, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 155, iters: 1648, time: 0.105, data: 0.000) loss: 0.069 
(epoch: 155, iters: 1728, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 155, iters: 1808, time: 0.106, data: 0.038) loss: 0.099 
(epoch: 155, iters: 1888, time: 0.106, data: 0.000) loss: 0.035 
(epoch: 155, iters: 1968, time: 0.102, data: 0.011) loss: 0.005 
(epoch: 155, iters: 2048, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 155, iters: 2128, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 155, iters: 2208, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 155, iters: 2288, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 155, iters: 2368, time: 0.105, data: 0.038) loss: 0.032 
(epoch: 155, iters: 2448, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 155, iters: 2528, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 155, iters: 2608, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 155, iters: 2688, time: 0.103, data: 0.011) loss: 0.092 
(epoch: 155, iters: 2768, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 155, iters: 2848, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 155, iters: 2928, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 155, iters: 3008, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 155, iters: 3088, time: 0.102, data: 0.011) loss: 0.029 
(epoch: 155, iters: 3168, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 155, iters: 3248, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 155, iters: 3328, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 155, iters: 3408, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 155, iters: 3488, time: 0.106, data: 0.038) loss: 0.003 
(epoch: 155, iters: 3568, time: 0.106, data: 0.000) loss: 0.179 
(epoch: 155, iters: 3648, time: 0.097, data: 0.011) loss: 0.002 
(epoch: 155, iters: 3728, time: 0.067, data: 0.000) loss: 0.006 
saving the model at the end of epoch 155, iters 577840
End of epoch 155 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001944
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 155, TEST ACC: [94.992 %]

saving the latest model (epoch 156, total_steps 577856)
(epoch: 156, iters: 80, time: 0.106, data: 0.463) loss: 0.001 
(epoch: 156, iters: 160, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 156, iters: 240, time: 0.105, data: 0.038) loss: 0.003 
(epoch: 156, iters: 320, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 156, iters: 400, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 156, iters: 480, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 156, iters: 560, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 156, iters: 640, time: 0.106, data: 0.000) loss: 0.038 
(epoch: 156, iters: 720, time: 0.103, data: 0.000) loss: 0.025 
(epoch: 156, iters: 800, time: 0.104, data: 0.039) loss: 0.001 
(epoch: 156, iters: 880, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 156, iters: 960, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 156, iters: 1040, time: 0.105, data: 0.000) loss: 0.032 
(epoch: 156, iters: 1120, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 156, iters: 1200, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 156, iters: 1280, time: 0.103, data: 0.000) loss: 0.014 
(epoch: 156, iters: 1360, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 156, iters: 1440, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 156, iters: 1520, time: 0.102, data: 0.011) loss: 0.008 
(epoch: 156, iters: 1600, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 156, iters: 1680, time: 0.104, data: 0.012) loss: 0.037 
(epoch: 156, iters: 1760, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 156, iters: 1840, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 156, iters: 1920, time: 0.105, data: 0.040) loss: 0.012 
(epoch: 156, iters: 2000, time: 0.107, data: 0.000) loss: 0.004 
(epoch: 156, iters: 2080, time: 0.102, data: 0.011) loss: 0.002 
(epoch: 156, iters: 2160, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 156, iters: 2240, time: 0.106, data: 0.019) loss: 0.019 
(epoch: 156, iters: 2320, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 156, iters: 2400, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 156, iters: 2480, time: 0.105, data: 0.047) loss: 0.067 
(epoch: 156, iters: 2560, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 156, iters: 2640, time: 0.105, data: 0.012) loss: 0.010 
(epoch: 156, iters: 2720, time: 0.104, data: 0.034) loss: 0.004 
(epoch: 156, iters: 2800, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 156, iters: 2880, time: 0.106, data: 0.000) loss: 0.046 
(epoch: 156, iters: 2960, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 156, iters: 3040, time: 0.104, data: 0.024) loss: 0.007 
(epoch: 156, iters: 3120, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 156, iters: 3200, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 156, iters: 3280, time: 0.104, data: 0.012) loss: 0.010 
(epoch: 156, iters: 3360, time: 0.103, data: 0.024) loss: 0.043 
(epoch: 156, iters: 3440, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 156, iters: 3520, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 156, iters: 3600, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 156, iters: 3680, time: 0.099, data: 0.024) loss: 0.001 
saving the model at the end of epoch 156, iters 581568
End of epoch 156 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001943
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 156, TEST ACC: [94.992 %]

saving the latest model (epoch 157, total_steps 581584)
(epoch: 157, iters: 32, time: 0.099, data: 0.000) loss: 0.004 
(epoch: 157, iters: 112, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 157, iters: 192, time: 0.103, data: 0.012) loss: 0.012 
(epoch: 157, iters: 272, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 157, iters: 352, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 157, iters: 432, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 157, iters: 512, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 157, iters: 592, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 157, iters: 672, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 157, iters: 752, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 157, iters: 832, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 157, iters: 912, time: 0.104, data: 0.012) loss: 0.060 
(epoch: 157, iters: 992, time: 0.105, data: 0.000) loss: 0.084 
(epoch: 157, iters: 1072, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 157, iters: 1152, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 157, iters: 1232, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 157, iters: 1312, time: 0.103, data: 0.011) loss: 0.221 
(epoch: 157, iters: 1392, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 157, iters: 1472, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 157, iters: 1552, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 157, iters: 1632, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 157, iters: 1712, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 157, iters: 1792, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 157, iters: 1872, time: 0.102, data: 0.011) loss: 0.042 
(epoch: 157, iters: 1952, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 157, iters: 2032, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 157, iters: 2112, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 157, iters: 2192, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 157, iters: 2272, time: 0.104, data: 0.047) loss: 0.004 
(epoch: 157, iters: 2352, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 157, iters: 2432, time: 0.104, data: 0.011) loss: 0.010 
(epoch: 157, iters: 2512, time: 0.105, data: 0.000) loss: 0.659 
(epoch: 157, iters: 2592, time: 0.104, data: 0.011) loss: 0.013 
(epoch: 157, iters: 2672, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 157, iters: 2752, time: 0.104, data: 0.000) loss: 0.040 
(epoch: 157, iters: 2832, time: 0.105, data: 0.049) loss: 0.024 
(epoch: 157, iters: 2912, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 157, iters: 2992, time: 0.102, data: 0.012) loss: 0.019 
(epoch: 157, iters: 3072, time: 0.104, data: 0.000) loss: 0.085 
(epoch: 157, iters: 3152, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 157, iters: 3232, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 157, iters: 3312, time: 0.104, data: 0.000) loss: 0.028 
(epoch: 157, iters: 3392, time: 0.104, data: 0.038) loss: 0.003 
(epoch: 157, iters: 3472, time: 0.104, data: 0.000) loss: 0.085 
(epoch: 157, iters: 3552, time: 0.103, data: 0.011) loss: 0.042 
(epoch: 157, iters: 3632, time: 0.102, data: 0.000) loss: 0.040 
(epoch: 157, iters: 3712, time: 0.100, data: 0.011) loss: 0.181 
saving the model at the end of epoch 157, iters 585296
End of epoch 157 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001942
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 157, TEST ACC: [93.475 %]

saving the latest model (epoch 158, total_steps 585312)
(epoch: 158, iters: 64, time: 0.104, data: 0.003) loss: 0.000 
(epoch: 158, iters: 144, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 158, iters: 224, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 158, iters: 304, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 158, iters: 384, time: 0.104, data: 0.039) loss: 0.003 
(epoch: 158, iters: 464, time: 0.105, data: 0.000) loss: 0.215 
(epoch: 158, iters: 544, time: 0.103, data: 0.012) loss: 0.005 
(epoch: 158, iters: 624, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 158, iters: 704, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 158, iters: 784, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 158, iters: 864, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 158, iters: 944, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 158, iters: 1024, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 158, iters: 1104, time: 0.102, data: 0.011) loss: 0.006 
(epoch: 158, iters: 1184, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 158, iters: 1264, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 158, iters: 1344, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 158, iters: 1424, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 158, iters: 1504, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 158, iters: 1584, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 158, iters: 1664, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 158, iters: 1744, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 158, iters: 1824, time: 0.104, data: 0.011) loss: 0.055 
(epoch: 158, iters: 1904, time: 0.106, data: 0.000) loss: 0.017 
(epoch: 158, iters: 1984, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 158, iters: 2064, time: 0.104, data: 0.039) loss: 0.002 
(epoch: 158, iters: 2144, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 158, iters: 2224, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 158, iters: 2304, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 158, iters: 2384, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 158, iters: 2464, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 158, iters: 2544, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 158, iters: 2624, time: 0.104, data: 0.039) loss: 0.032 
(epoch: 158, iters: 2704, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 158, iters: 2784, time: 0.102, data: 0.011) loss: 0.105 
(epoch: 158, iters: 2864, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 158, iters: 2944, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 158, iters: 3024, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 158, iters: 3104, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 158, iters: 3184, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 158, iters: 3264, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 158, iters: 3344, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 158, iters: 3424, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 158, iters: 3504, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 158, iters: 3584, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 158, iters: 3664, time: 0.099, data: 0.000) loss: 0.003 
saving the model at the end of epoch 158, iters 589024
End of epoch 158 / 2100 	 Time Taken: 392 sec
learning rate = 0.0001941
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 158, TEST ACC: [97.117 %]

(epoch: 159, iters: 16, time: 0.121, data: 0.012) loss: 0.073 
saving the latest model (epoch 159, total_steps 589040)
(epoch: 159, iters: 96, time: 0.106, data: 0.012) loss: 0.000 
(epoch: 159, iters: 176, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 159, iters: 256, time: 0.104, data: 0.000) loss: 0.027 
(epoch: 159, iters: 336, time: 0.105, data: 0.020) loss: 0.002 
(epoch: 159, iters: 416, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 159, iters: 496, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 159, iters: 576, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 159, iters: 656, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 159, iters: 736, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 159, iters: 816, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 159, iters: 896, time: 0.105, data: 0.011) loss: 0.038 
(epoch: 159, iters: 976, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 159, iters: 1056, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 159, iters: 1136, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 159, iters: 1216, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 159, iters: 1296, time: 0.103, data: 0.011) loss: 0.016 
(epoch: 159, iters: 1376, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 159, iters: 1456, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 159, iters: 1536, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 159, iters: 1616, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 159, iters: 1696, time: 0.104, data: 0.038) loss: 0.000 
(epoch: 159, iters: 1776, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 159, iters: 1856, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 159, iters: 1936, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 159, iters: 2016, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 159, iters: 2096, time: 0.106, data: 0.000) loss: 0.179 
(epoch: 159, iters: 2176, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 159, iters: 2256, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 159, iters: 2336, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 159, iters: 2416, time: 0.102, data: 0.011) loss: 0.004 
(epoch: 159, iters: 2496, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 159, iters: 2576, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 159, iters: 2656, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 159, iters: 2736, time: 0.105, data: 0.000) loss: 0.025 
(epoch: 159, iters: 2816, time: 0.105, data: 0.039) loss: 0.003 
(epoch: 159, iters: 2896, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 159, iters: 2976, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 159, iters: 3056, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 159, iters: 3136, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 159, iters: 3216, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 159, iters: 3296, time: 0.103, data: 0.000) loss: 0.002 
(epoch: 159, iters: 3376, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 159, iters: 3456, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 159, iters: 3536, time: 0.104, data: 0.021) loss: 0.001 
(epoch: 159, iters: 3616, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 159, iters: 3696, time: 0.099, data: 0.011) loss: 0.001 
saving the model at the end of epoch 159, iters 592752
End of epoch 159 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001940
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 159, TEST ACC: [97.572 %]

saving the latest model (epoch 160, total_steps 592768)
(epoch: 160, iters: 48, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 160, iters: 128, time: 0.105, data: 0.026) loss: 0.000 
(epoch: 160, iters: 208, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 160, iters: 288, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 160, iters: 368, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 160, iters: 448, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 160, iters: 528, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 160, iters: 608, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 160, iters: 688, time: 0.104, data: 0.039) loss: 0.001 
(epoch: 160, iters: 768, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 160, iters: 848, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 160, iters: 928, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 160, iters: 1008, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 160, iters: 1088, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 160, iters: 1168, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 160, iters: 1248, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 160, iters: 1328, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 160, iters: 1408, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 160, iters: 1488, time: 0.105, data: 0.000) loss: 0.035 
(epoch: 160, iters: 1568, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 160, iters: 1648, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 160, iters: 1728, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 160, iters: 1808, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 160, iters: 1888, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 160, iters: 1968, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 160, iters: 2048, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 160, iters: 2128, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 160, iters: 2208, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 160, iters: 2288, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 160, iters: 2368, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 160, iters: 2448, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 160, iters: 2528, time: 0.103, data: 0.020) loss: 0.000 
(epoch: 160, iters: 2608, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 160, iters: 2688, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 160, iters: 2768, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 160, iters: 2848, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 160, iters: 2928, time: 0.105, data: 0.038) loss: 0.007 
(epoch: 160, iters: 3008, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 160, iters: 3088, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 160, iters: 3168, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 160, iters: 3248, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 160, iters: 3328, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 160, iters: 3408, time: 0.104, data: 0.000) loss: 0.051 
(epoch: 160, iters: 3488, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 160, iters: 3568, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 160, iters: 3648, time: 0.099, data: 0.012) loss: 0.000 
(epoch: 160, iters: 3728, time: 0.065, data: 0.000) loss: 0.003 
saving the model at the end of epoch 160, iters 596480
End of epoch 160 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001939
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 160, TEST ACC: [96.358 %]

saving the latest model (epoch 161, total_steps 596496)
(epoch: 161, iters: 80, time: 0.104, data: 0.430) loss: 0.002 
(epoch: 161, iters: 160, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 161, iters: 240, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 161, iters: 320, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 161, iters: 400, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 161, iters: 480, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 161, iters: 560, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 161, iters: 640, time: 0.104, data: 0.011) loss: 0.078 
(epoch: 161, iters: 720, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 161, iters: 800, time: 0.104, data: 0.000) loss: 0.040 
(epoch: 161, iters: 880, time: 0.104, data: 0.038) loss: 0.002 
(epoch: 161, iters: 960, time: 0.104, data: 0.000) loss: 0.018 
(epoch: 161, iters: 1040, time: 0.102, data: 0.012) loss: 0.006 
(epoch: 161, iters: 1120, time: 0.106, data: 0.000) loss: 0.059 
(epoch: 161, iters: 1200, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 161, iters: 1280, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 161, iters: 1360, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 161, iters: 1440, time: 0.105, data: 0.048) loss: 0.000 
(epoch: 161, iters: 1520, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 161, iters: 1600, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 161, iters: 1680, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 161, iters: 1760, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 161, iters: 1840, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 161, iters: 1920, time: 0.103, data: 0.000) loss: 0.094 
(epoch: 161, iters: 2000, time: 0.104, data: 0.038) loss: 0.001 
(epoch: 161, iters: 2080, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 161, iters: 2160, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 161, iters: 2240, time: 0.106, data: 0.000) loss: 0.322 
(epoch: 161, iters: 2320, time: 0.104, data: 0.011) loss: 0.007 
(epoch: 161, iters: 2400, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 161, iters: 2480, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 161, iters: 2560, time: 0.105, data: 0.038) loss: 0.005 
(epoch: 161, iters: 2640, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 161, iters: 2720, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 161, iters: 2800, time: 0.106, data: 0.000) loss: 0.018 
(epoch: 161, iters: 2880, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 161, iters: 2960, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 161, iters: 3040, time: 0.104, data: 0.000) loss: 0.115 
(epoch: 161, iters: 3120, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 161, iters: 3200, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 161, iters: 3280, time: 0.103, data: 0.011) loss: 0.023 
(epoch: 161, iters: 3360, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 161, iters: 3440, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 161, iters: 3520, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 161, iters: 3600, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 161, iters: 3680, time: 0.100, data: 0.039) loss: 0.003 
saving the model at the end of epoch 161, iters 600208
End of epoch 161 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001938
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 161, TEST ACC: [96.206 %]

saving the latest model (epoch 162, total_steps 600224)
(epoch: 162, iters: 32, time: 0.099, data: 0.000) loss: 0.001 
(epoch: 162, iters: 112, time: 0.105, data: 0.026) loss: 0.000 
(epoch: 162, iters: 192, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 162, iters: 272, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 162, iters: 352, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 162, iters: 432, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 162, iters: 512, time: 0.102, data: 0.011) loss: 0.122 
(epoch: 162, iters: 592, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 162, iters: 672, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 162, iters: 752, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 162, iters: 832, time: 0.104, data: 0.000) loss: 0.335 
(epoch: 162, iters: 912, time: 0.106, data: 0.039) loss: 0.047 
(epoch: 162, iters: 992, time: 0.107, data: 0.000) loss: 0.012 
(epoch: 162, iters: 1072, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 162, iters: 1152, time: 0.105, data: 0.000) loss: 0.605 
(epoch: 162, iters: 1232, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 162, iters: 1312, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 162, iters: 1392, time: 0.105, data: 0.000) loss: 0.075 
(epoch: 162, iters: 1472, time: 0.105, data: 0.038) loss: 0.007 
(epoch: 162, iters: 1552, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 162, iters: 1632, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 162, iters: 1712, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 162, iters: 1792, time: 0.104, data: 0.011) loss: 0.018 
(epoch: 162, iters: 1872, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 162, iters: 1952, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 162, iters: 2032, time: 0.105, data: 0.038) loss: 0.166 
(epoch: 162, iters: 2112, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 162, iters: 2192, time: 0.102, data: 0.011) loss: 0.002 
(epoch: 162, iters: 2272, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 162, iters: 2352, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 162, iters: 2432, time: 0.105, data: 0.000) loss: 0.105 
(epoch: 162, iters: 2512, time: 0.104, data: 0.000) loss: 0.019 
(epoch: 162, iters: 2592, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 162, iters: 2672, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 162, iters: 2752, time: 0.102, data: 0.011) loss: 0.026 
(epoch: 162, iters: 2832, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 162, iters: 2912, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 162, iters: 2992, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 162, iters: 3072, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 162, iters: 3152, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 162, iters: 3232, time: 0.106, data: 0.000) loss: 0.086 
(epoch: 162, iters: 3312, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 162, iters: 3392, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 162, iters: 3472, time: 0.105, data: 0.011) loss: 0.006 
(epoch: 162, iters: 3552, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 162, iters: 3632, time: 0.102, data: 0.000) loss: 0.000 
(epoch: 162, iters: 3712, time: 0.101, data: 0.035) loss: 0.001 
saving the model at the end of epoch 162, iters 603936
End of epoch 162 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001937
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 162, TEST ACC: [94.537 %]

saving the latest model (epoch 163, total_steps 603952)
(epoch: 163, iters: 64, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 163, iters: 144, time: 0.104, data: 0.000) loss: 0.033 
(epoch: 163, iters: 224, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 163, iters: 304, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 163, iters: 384, time: 0.104, data: 0.038) loss: 0.011 
(epoch: 163, iters: 464, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 163, iters: 544, time: 0.103, data: 0.011) loss: 0.014 
(epoch: 163, iters: 624, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 163, iters: 704, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 163, iters: 784, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 163, iters: 864, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 163, iters: 944, time: 0.105, data: 0.040) loss: 0.000 
(epoch: 163, iters: 1024, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 163, iters: 1104, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 163, iters: 1184, time: 0.104, data: 0.000) loss: 0.060 
(epoch: 163, iters: 1264, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 163, iters: 1344, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 163, iters: 1424, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 163, iters: 1504, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 163, iters: 1584, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 163, iters: 1664, time: 0.101, data: 0.012) loss: 0.014 
(epoch: 163, iters: 1744, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 163, iters: 1824, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 163, iters: 1904, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 163, iters: 1984, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 163, iters: 2064, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 163, iters: 2144, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 163, iters: 2224, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 163, iters: 2304, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 163, iters: 2384, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 163, iters: 2464, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 163, iters: 2544, time: 0.104, data: 0.000) loss: 0.276 
(epoch: 163, iters: 2624, time: 0.105, data: 0.038) loss: 0.099 
(epoch: 163, iters: 2704, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 163, iters: 2784, time: 0.104, data: 0.012) loss: 0.027 
(epoch: 163, iters: 2864, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 163, iters: 2944, time: 0.105, data: 0.011) loss: 0.110 
(epoch: 163, iters: 3024, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 163, iters: 3104, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 163, iters: 3184, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 163, iters: 3264, time: 0.106, data: 0.000) loss: 0.642 
(epoch: 163, iters: 3344, time: 0.103, data: 0.012) loss: 0.022 
(epoch: 163, iters: 3424, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 163, iters: 3504, time: 0.105, data: 0.012) loss: 0.099 
(epoch: 163, iters: 3584, time: 0.105, data: 0.000) loss: 0.020 
(epoch: 163, iters: 3664, time: 0.099, data: 0.000) loss: 0.034 
saving the model at the end of epoch 163, iters 607664
End of epoch 163 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001936
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 163, TEST ACC: [92.716 %]

(epoch: 164, iters: 16, time: 0.117, data: 0.012) loss: 0.005 
saving the latest model (epoch 164, total_steps 607680)
(epoch: 164, iters: 96, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 164, iters: 176, time: 0.103, data: 0.011) loss: 0.017 
(epoch: 164, iters: 256, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 164, iters: 336, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 164, iters: 416, time: 0.105, data: 0.000) loss: 0.303 
(epoch: 164, iters: 496, time: 0.104, data: 0.000) loss: 0.102 
(epoch: 164, iters: 576, time: 0.105, data: 0.038) loss: 0.095 
(epoch: 164, iters: 656, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 164, iters: 736, time: 0.102, data: 0.012) loss: 0.003 
(epoch: 164, iters: 816, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 164, iters: 896, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 164, iters: 976, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 164, iters: 1056, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 164, iters: 1136, time: 0.106, data: 0.039) loss: 0.015 
(epoch: 164, iters: 1216, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 164, iters: 1296, time: 0.104, data: 0.012) loss: 0.029 
(epoch: 164, iters: 1376, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 164, iters: 1456, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 164, iters: 1536, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 164, iters: 1616, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 164, iters: 1696, time: 0.105, data: 0.039) loss: 0.004 
(epoch: 164, iters: 1776, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 164, iters: 1856, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 164, iters: 1936, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 164, iters: 2016, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 164, iters: 2096, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 164, iters: 2176, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 164, iters: 2256, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 164, iters: 2336, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 164, iters: 2416, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 164, iters: 2496, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 164, iters: 2576, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 164, iters: 2656, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 164, iters: 2736, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 164, iters: 2816, time: 0.106, data: 0.039) loss: 0.054 
(epoch: 164, iters: 2896, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 164, iters: 2976, time: 0.102, data: 0.011) loss: 0.002 
(epoch: 164, iters: 3056, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 164, iters: 3136, time: 0.106, data: 0.011) loss: 0.093 
(epoch: 164, iters: 3216, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 164, iters: 3296, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 164, iters: 3376, time: 0.105, data: 0.047) loss: 0.006 
(epoch: 164, iters: 3456, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 164, iters: 3536, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 164, iters: 3616, time: 0.106, data: 0.000) loss: 0.079 
(epoch: 164, iters: 3696, time: 0.100, data: 0.011) loss: 0.007 
saving the model at the end of epoch 164, iters 611392
End of epoch 164 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001935
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 164, TEST ACC: [94.082 %]

saving the latest model (epoch 165, total_steps 611408)
(epoch: 165, iters: 48, time: 0.107, data: 0.000) loss: 0.004 
(epoch: 165, iters: 128, time: 0.104, data: 0.052) loss: 0.005 
(epoch: 165, iters: 208, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 165, iters: 288, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 165, iters: 368, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 165, iters: 448, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 165, iters: 528, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 165, iters: 608, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 165, iters: 688, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 165, iters: 768, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 165, iters: 848, time: 0.103, data: 0.011) loss: 0.011 
(epoch: 165, iters: 928, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 165, iters: 1008, time: 0.104, data: 0.011) loss: 0.016 
(epoch: 165, iters: 1088, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 165, iters: 1168, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 165, iters: 1248, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 165, iters: 1328, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 165, iters: 1408, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 165, iters: 1488, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 165, iters: 1568, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 165, iters: 1648, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 165, iters: 1728, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 165, iters: 1808, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 165, iters: 1888, time: 0.105, data: 0.000) loss: 0.068 
(epoch: 165, iters: 1968, time: 0.103, data: 0.011) loss: 0.011 
(epoch: 165, iters: 2048, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 165, iters: 2128, time: 0.105, data: 0.012) loss: 0.255 
(epoch: 165, iters: 2208, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 165, iters: 2288, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 165, iters: 2368, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 165, iters: 2448, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 165, iters: 2528, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 165, iters: 2608, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 165, iters: 2688, time: 0.105, data: 0.011) loss: 0.158 
(epoch: 165, iters: 2768, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 165, iters: 2848, time: 0.104, data: 0.000) loss: 0.026 
(epoch: 165, iters: 2928, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 165, iters: 3008, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 165, iters: 3088, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 165, iters: 3168, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 165, iters: 3248, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 165, iters: 3328, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 165, iters: 3408, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 165, iters: 3488, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 165, iters: 3568, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 165, iters: 3648, time: 0.098, data: 0.011) loss: 0.002 
(epoch: 165, iters: 3728, time: 0.065, data: 0.000) loss: 0.180 
saving the model at the end of epoch 165, iters 615120
End of epoch 165 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001934
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 165, TEST ACC: [92.868 %]

saving the latest model (epoch 166, total_steps 615136)
(epoch: 166, iters: 80, time: 0.104, data: 0.482) loss: 0.001 
(epoch: 166, iters: 160, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 166, iters: 240, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 166, iters: 320, time: 0.104, data: 0.039) loss: 0.011 
(epoch: 166, iters: 400, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 166, iters: 480, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 166, iters: 560, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 166, iters: 640, time: 0.104, data: 0.011) loss: 0.010 
(epoch: 166, iters: 720, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 166, iters: 800, time: 0.105, data: 0.000) loss: 0.102 
(epoch: 166, iters: 880, time: 0.104, data: 0.038) loss: 0.015 
(epoch: 166, iters: 960, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 166, iters: 1040, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 166, iters: 1120, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 166, iters: 1200, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 166, iters: 1280, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 166, iters: 1360, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 166, iters: 1440, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 166, iters: 1520, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 166, iters: 1600, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 166, iters: 1680, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 166, iters: 1760, time: 0.105, data: 0.012) loss: 0.055 
(epoch: 166, iters: 1840, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 166, iters: 1920, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 166, iters: 2000, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 166, iters: 2080, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 166, iters: 2160, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 166, iters: 2240, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 166, iters: 2320, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 166, iters: 2400, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 166, iters: 2480, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 166, iters: 2560, time: 0.105, data: 0.040) loss: 0.001 
(epoch: 166, iters: 2640, time: 0.107, data: 0.000) loss: 0.035 
(epoch: 166, iters: 2720, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 166, iters: 2800, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 166, iters: 2880, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 166, iters: 2960, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 166, iters: 3040, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 166, iters: 3120, time: 0.106, data: 0.038) loss: 0.003 
(epoch: 166, iters: 3200, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 166, iters: 3280, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 166, iters: 3360, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 166, iters: 3440, time: 0.105, data: 0.011) loss: 0.033 
(epoch: 166, iters: 3520, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 166, iters: 3600, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 166, iters: 3680, time: 0.100, data: 0.040) loss: 0.011 
saving the model at the end of epoch 166, iters 618848
End of epoch 166 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001933
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 166, TEST ACC: [94.537 %]

saving the latest model (epoch 167, total_steps 618864)
(epoch: 167, iters: 32, time: 0.100, data: 0.000) loss: 0.000 
(epoch: 167, iters: 112, time: 0.105, data: 0.026) loss: 0.007 
(epoch: 167, iters: 192, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 167, iters: 272, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 167, iters: 352, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 167, iters: 432, time: 0.105, data: 0.000) loss: 0.111 
(epoch: 167, iters: 512, time: 0.105, data: 0.012) loss: 0.117 
(epoch: 167, iters: 592, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 167, iters: 672, time: 0.105, data: 0.011) loss: 0.019 
(epoch: 167, iters: 752, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 167, iters: 832, time: 0.104, data: 0.000) loss: 0.039 
(epoch: 167, iters: 912, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 167, iters: 992, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 167, iters: 1072, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 167, iters: 1152, time: 0.107, data: 0.000) loss: 0.083 
(epoch: 167, iters: 1232, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 167, iters: 1312, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 167, iters: 1392, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 167, iters: 1472, time: 0.105, data: 0.039) loss: 0.016 
(epoch: 167, iters: 1552, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 167, iters: 1632, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 167, iters: 1712, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 167, iters: 1792, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 167, iters: 1872, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 167, iters: 1952, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 167, iters: 2032, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 167, iters: 2112, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 167, iters: 2192, time: 0.103, data: 0.012) loss: 0.003 
(epoch: 167, iters: 2272, time: 0.105, data: 0.000) loss: 0.054 
(epoch: 167, iters: 2352, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 167, iters: 2432, time: 0.106, data: 0.000) loss: 0.300 
(epoch: 167, iters: 2512, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 167, iters: 2592, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 167, iters: 2672, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 167, iters: 2752, time: 0.102, data: 0.011) loss: 0.002 
(epoch: 167, iters: 2832, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 167, iters: 2912, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 167, iters: 2992, time: 0.106, data: 0.000) loss: 0.067 
(epoch: 167, iters: 3072, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 167, iters: 3152, time: 0.106, data: 0.039) loss: 0.031 
(epoch: 167, iters: 3232, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 167, iters: 3312, time: 0.103, data: 0.012) loss: 0.006 
(epoch: 167, iters: 3392, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 167, iters: 3472, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 167, iters: 3552, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 167, iters: 3632, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 167, iters: 3712, time: 0.101, data: 0.035) loss: 0.121 
saving the model at the end of epoch 167, iters 622576
End of epoch 167 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001932
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 167, TEST ACC: [96.055 %]

saving the latest model (epoch 168, total_steps 622592)
(epoch: 168, iters: 64, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 168, iters: 144, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 168, iters: 224, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 168, iters: 304, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 168, iters: 384, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 168, iters: 464, time: 0.105, data: 0.039) loss: 0.026 
(epoch: 168, iters: 544, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 168, iters: 624, time: 0.103, data: 0.011) loss: 0.010 
(epoch: 168, iters: 704, time: 0.105, data: 0.000) loss: 0.026 
(epoch: 168, iters: 784, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 168, iters: 864, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 168, iters: 944, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 168, iters: 1024, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 168, iters: 1104, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 168, iters: 1184, time: 0.104, data: 0.012) loss: 0.002 
(epoch: 168, iters: 1264, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 168, iters: 1344, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 168, iters: 1424, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 168, iters: 1504, time: 0.104, data: 0.000) loss: 0.011 
(epoch: 168, iters: 1584, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 168, iters: 1664, time: 0.106, data: 0.000) loss: 0.049 
(epoch: 168, iters: 1744, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 168, iters: 1824, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 168, iters: 1904, time: 0.104, data: 0.012) loss: 0.109 
(epoch: 168, iters: 1984, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 168, iters: 2064, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 168, iters: 2144, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 168, iters: 2224, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 168, iters: 2304, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 168, iters: 2384, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 168, iters: 2464, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 168, iters: 2544, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 168, iters: 2624, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 168, iters: 2704, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 168, iters: 2784, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 168, iters: 2864, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 168, iters: 2944, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 168, iters: 3024, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 168, iters: 3104, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 168, iters: 3184, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 168, iters: 3264, time: 0.105, data: 0.038) loss: 0.017 
(epoch: 168, iters: 3344, time: 0.106, data: 0.000) loss: 0.045 
(epoch: 168, iters: 3424, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 168, iters: 3504, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 168, iters: 3584, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 168, iters: 3664, time: 0.101, data: 0.000) loss: 0.001 
saving the model at the end of epoch 168, iters 626304
End of epoch 168 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001931
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 168, TEST ACC: [94.992 %]

(epoch: 169, iters: 16, time: 0.120, data: 0.000) loss: 0.000 
saving the latest model (epoch 169, total_steps 626320)
(epoch: 169, iters: 96, time: 0.106, data: 0.012) loss: 0.000 
(epoch: 169, iters: 176, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 169, iters: 256, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 169, iters: 336, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 169, iters: 416, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 169, iters: 496, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 169, iters: 576, time: 0.105, data: 0.038) loss: 0.005 
(epoch: 169, iters: 656, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 169, iters: 736, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 169, iters: 816, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 169, iters: 896, time: 0.104, data: 0.011) loss: 0.009 
(epoch: 169, iters: 976, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 169, iters: 1056, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 169, iters: 1136, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 169, iters: 1216, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 169, iters: 1296, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 169, iters: 1376, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 169, iters: 1456, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 169, iters: 1536, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 169, iters: 1616, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 169, iters: 1696, time: 0.106, data: 0.047) loss: 0.003 
(epoch: 169, iters: 1776, time: 0.107, data: 0.000) loss: 0.023 
(epoch: 169, iters: 1856, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 169, iters: 1936, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 169, iters: 2016, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 169, iters: 2096, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 169, iters: 2176, time: 0.104, data: 0.000) loss: 0.060 
(epoch: 169, iters: 2256, time: 0.105, data: 0.038) loss: 0.004 
(epoch: 169, iters: 2336, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 169, iters: 2416, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 169, iters: 2496, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 169, iters: 2576, time: 0.106, data: 0.011) loss: 0.084 
(epoch: 169, iters: 2656, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 169, iters: 2736, time: 0.105, data: 0.000) loss: 0.022 
(epoch: 169, iters: 2816, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 169, iters: 2896, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 169, iters: 2976, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 169, iters: 3056, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 169, iters: 3136, time: 0.105, data: 0.011) loss: 0.007 
(epoch: 169, iters: 3216, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 169, iters: 3296, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 169, iters: 3376, time: 0.107, data: 0.039) loss: 0.000 
(epoch: 169, iters: 3456, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 169, iters: 3536, time: 0.103, data: 0.011) loss: 0.034 
(epoch: 169, iters: 3616, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 169, iters: 3696, time: 0.100, data: 0.011) loss: 0.113 
saving the model at the end of epoch 169, iters 630032
End of epoch 169 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001930
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 169, TEST ACC: [88.619 %]

saving the latest model (epoch 170, total_steps 630048)
(epoch: 170, iters: 48, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 170, iters: 128, time: 0.105, data: 0.026) loss: 0.067 
(epoch: 170, iters: 208, time: 0.106, data: 0.000) loss: 0.024 
(epoch: 170, iters: 288, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 170, iters: 368, time: 0.105, data: 0.047) loss: 0.003 
(epoch: 170, iters: 448, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 170, iters: 528, time: 0.104, data: 0.021) loss: 0.000 
(epoch: 170, iters: 608, time: 0.105, data: 0.000) loss: 0.366 
(epoch: 170, iters: 688, time: 0.104, data: 0.011) loss: 0.022 
(epoch: 170, iters: 768, time: 0.106, data: 0.000) loss: 0.103 
(epoch: 170, iters: 848, time: 0.104, data: 0.000) loss: 0.550 
(epoch: 170, iters: 928, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 170, iters: 1008, time: 0.107, data: 0.000) loss: 0.010 
(epoch: 170, iters: 1088, time: 0.103, data: 0.011) loss: 0.009 
(epoch: 170, iters: 1168, time: 0.106, data: 0.000) loss: 0.198 
(epoch: 170, iters: 1248, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 170, iters: 1328, time: 0.106, data: 0.000) loss: 0.334 
(epoch: 170, iters: 1408, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 170, iters: 1488, time: 0.105, data: 0.038) loss: 0.035 
(epoch: 170, iters: 1568, time: 0.106, data: 0.000) loss: 0.078 
(epoch: 170, iters: 1648, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 170, iters: 1728, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 170, iters: 1808, time: 0.106, data: 0.011) loss: 0.160 
(epoch: 170, iters: 1888, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 170, iters: 1968, time: 0.105, data: 0.000) loss: 0.036 
(epoch: 170, iters: 2048, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 170, iters: 2128, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 170, iters: 2208, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 170, iters: 2288, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 170, iters: 2368, time: 0.106, data: 0.012) loss: 0.007 
(epoch: 170, iters: 2448, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 170, iters: 2528, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 170, iters: 2608, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 170, iters: 2688, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 170, iters: 2768, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 170, iters: 2848, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 170, iters: 2928, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 170, iters: 3008, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 170, iters: 3088, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 170, iters: 3168, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 170, iters: 3248, time: 0.106, data: 0.000) loss: 0.090 
(epoch: 170, iters: 3328, time: 0.103, data: 0.011) loss: 0.187 
(epoch: 170, iters: 3408, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 170, iters: 3488, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 170, iters: 3568, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 170, iters: 3648, time: 0.100, data: 0.000) loss: 0.006 
(epoch: 170, iters: 3728, time: 0.066, data: 0.015) loss: 0.001 
saving the model at the end of epoch 170, iters 633760
End of epoch 170 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001929
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 170, TEST ACC: [94.992 %]

saving the latest model (epoch 171, total_steps 633776)
(epoch: 171, iters: 80, time: 0.105, data: 0.448) loss: 0.017 
(epoch: 171, iters: 160, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 171, iters: 240, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 171, iters: 320, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 171, iters: 400, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 171, iters: 480, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 171, iters: 560, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 171, iters: 640, time: 0.105, data: 0.011) loss: 0.017 
(epoch: 171, iters: 720, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 171, iters: 800, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 171, iters: 880, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 171, iters: 960, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 171, iters: 1040, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 171, iters: 1120, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 171, iters: 1200, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 171, iters: 1280, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 171, iters: 1360, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 171, iters: 1440, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 171, iters: 1520, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 171, iters: 1600, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 171, iters: 1680, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 171, iters: 1760, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 171, iters: 1840, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 171, iters: 1920, time: 0.103, data: 0.000) loss: 0.010 
(epoch: 171, iters: 2000, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 171, iters: 2080, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 171, iters: 2160, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 171, iters: 2240, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 171, iters: 2320, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 171, iters: 2400, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 171, iters: 2480, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 171, iters: 2560, time: 0.106, data: 0.040) loss: 0.003 
(epoch: 171, iters: 2640, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 171, iters: 2720, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 171, iters: 2800, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 171, iters: 2880, time: 0.105, data: 0.011) loss: 0.037 
(epoch: 171, iters: 2960, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 171, iters: 3040, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 171, iters: 3120, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 171, iters: 3200, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 171, iters: 3280, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 171, iters: 3360, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 171, iters: 3440, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 171, iters: 3520, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 171, iters: 3600, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 171, iters: 3680, time: 0.100, data: 0.038) loss: 0.000 
saving the model at the end of epoch 171, iters 637488
End of epoch 171 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001928
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 171, TEST ACC: [97.269 %]

saving the latest model (epoch 172, total_steps 637504)
(epoch: 172, iters: 32, time: 0.100, data: 0.000) loss: 0.001 
(epoch: 172, iters: 112, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 172, iters: 192, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 172, iters: 272, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 172, iters: 352, time: 0.104, data: 0.039) loss: 0.000 
(epoch: 172, iters: 432, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 172, iters: 512, time: 0.102, data: 0.012) loss: 0.000 
(epoch: 172, iters: 592, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 172, iters: 672, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 172, iters: 752, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 172, iters: 832, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 172, iters: 912, time: 0.106, data: 0.047) loss: 0.001 
(epoch: 172, iters: 992, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 172, iters: 1072, time: 0.105, data: 0.021) loss: 0.000 
(epoch: 172, iters: 1152, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 172, iters: 1232, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 172, iters: 1312, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 172, iters: 1392, time: 0.103, data: 0.000) loss: 0.021 
(epoch: 172, iters: 1472, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 172, iters: 1552, time: 0.106, data: 0.000) loss: 0.249 
(epoch: 172, iters: 1632, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 172, iters: 1712, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 172, iters: 1792, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 172, iters: 1872, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 172, iters: 1952, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 172, iters: 2032, time: 0.105, data: 0.039) loss: 0.013 
(epoch: 172, iters: 2112, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 172, iters: 2192, time: 0.103, data: 0.011) loss: 0.005 
(epoch: 172, iters: 2272, time: 0.105, data: 0.000) loss: 0.028 
(epoch: 172, iters: 2352, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 172, iters: 2432, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 172, iters: 2512, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 172, iters: 2592, time: 0.107, data: 0.039) loss: 0.001 
(epoch: 172, iters: 2672, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 172, iters: 2752, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 172, iters: 2832, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 172, iters: 2912, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 172, iters: 2992, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 172, iters: 3072, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 172, iters: 3152, time: 0.106, data: 0.039) loss: 0.003 
(epoch: 172, iters: 3232, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 172, iters: 3312, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 172, iters: 3392, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 172, iters: 3472, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 172, iters: 3552, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 172, iters: 3632, time: 0.102, data: 0.000) loss: 0.000 
(epoch: 172, iters: 3712, time: 0.101, data: 0.035) loss: 0.000 
saving the model at the end of epoch 172, iters 641216
End of epoch 172 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001927
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 172, TEST ACC: [95.751 %]

saving the latest model (epoch 173, total_steps 641232)
(epoch: 173, iters: 64, time: 0.104, data: 0.000) loss: 0.082 
(epoch: 173, iters: 144, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 173, iters: 224, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 173, iters: 304, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 173, iters: 384, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 173, iters: 464, time: 0.105, data: 0.040) loss: 0.000 
(epoch: 173, iters: 544, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 173, iters: 624, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 173, iters: 704, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 173, iters: 784, time: 0.105, data: 0.020) loss: 0.000 
(epoch: 173, iters: 864, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 173, iters: 944, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 173, iters: 1024, time: 0.105, data: 0.048) loss: 0.000 
(epoch: 173, iters: 1104, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 173, iters: 1184, time: 0.104, data: 0.012) loss: 0.073 
(epoch: 173, iters: 1264, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 173, iters: 1344, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 173, iters: 1424, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 173, iters: 1504, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 173, iters: 1584, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 173, iters: 1664, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 173, iters: 1744, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 173, iters: 1824, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 173, iters: 1904, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 173, iters: 1984, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 173, iters: 2064, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 173, iters: 2144, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 173, iters: 2224, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 173, iters: 2304, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 173, iters: 2384, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 173, iters: 2464, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 173, iters: 2544, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 173, iters: 2624, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 173, iters: 2704, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 173, iters: 2784, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 173, iters: 2864, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 173, iters: 2944, time: 0.106, data: 0.000) loss: 0.085 
(epoch: 173, iters: 3024, time: 0.105, data: 0.011) loss: 0.006 
(epoch: 173, iters: 3104, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 173, iters: 3184, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 173, iters: 3264, time: 0.105, data: 0.038) loss: 0.191 
(epoch: 173, iters: 3344, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 173, iters: 3424, time: 0.102, data: 0.012) loss: 0.011 
(epoch: 173, iters: 3504, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 173, iters: 3584, time: 0.105, data: 0.012) loss: 0.051 
(epoch: 173, iters: 3664, time: 0.100, data: 0.000) loss: 0.000 
saving the model at the end of epoch 173, iters 644944
End of epoch 173 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001926
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 173, TEST ACC: [93.02 %]

(epoch: 174, iters: 16, time: 0.114, data: 0.000) loss: 0.001 
saving the latest model (epoch 174, total_steps 644960)
(epoch: 174, iters: 96, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 174, iters: 176, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 174, iters: 256, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 174, iters: 336, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 174, iters: 416, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 174, iters: 496, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 174, iters: 576, time: 0.105, data: 0.038) loss: 0.004 
(epoch: 174, iters: 656, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 174, iters: 736, time: 0.104, data: 0.011) loss: 0.009 
(epoch: 174, iters: 816, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 174, iters: 896, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 174, iters: 976, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 174, iters: 1056, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 174, iters: 1136, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 174, iters: 1216, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 174, iters: 1296, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 174, iters: 1376, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 174, iters: 1456, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 174, iters: 1536, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 174, iters: 1616, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 174, iters: 1696, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 174, iters: 1776, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 174, iters: 1856, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 174, iters: 1936, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 174, iters: 2016, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 174, iters: 2096, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 174, iters: 2176, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 174, iters: 2256, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 174, iters: 2336, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 174, iters: 2416, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 174, iters: 2496, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 174, iters: 2576, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 174, iters: 2656, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 174, iters: 2736, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 174, iters: 2816, time: 0.105, data: 0.048) loss: 0.004 
(epoch: 174, iters: 2896, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 174, iters: 2976, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 174, iters: 3056, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 174, iters: 3136, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 174, iters: 3216, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 174, iters: 3296, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 174, iters: 3376, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 174, iters: 3456, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 174, iters: 3536, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 174, iters: 3616, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 174, iters: 3696, time: 0.100, data: 0.011) loss: 0.000 
saving the model at the end of epoch 174, iters 648672
End of epoch 174 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001925
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 174, TEST ACC: [95.144 %]

saving the latest model (epoch 175, total_steps 648688)
(epoch: 175, iters: 48, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 175, iters: 128, time: 0.105, data: 0.026) loss: 0.001 
(epoch: 175, iters: 208, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 175, iters: 288, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 175, iters: 368, time: 0.105, data: 0.000) loss: 0.063 
(epoch: 175, iters: 448, time: 0.104, data: 0.012) loss: 0.003 
(epoch: 175, iters: 528, time: 0.106, data: 0.000) loss: 0.094 
(epoch: 175, iters: 608, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 175, iters: 688, time: 0.104, data: 0.038) loss: 0.001 
(epoch: 175, iters: 768, time: 0.106, data: 0.000) loss: 0.178 
(epoch: 175, iters: 848, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 175, iters: 928, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 175, iters: 1008, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 175, iters: 1088, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 175, iters: 1168, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 175, iters: 1248, time: 0.106, data: 0.039) loss: 0.004 
(epoch: 175, iters: 1328, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 175, iters: 1408, time: 0.104, data: 0.011) loss: 0.109 
(epoch: 175, iters: 1488, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 175, iters: 1568, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 175, iters: 1648, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 175, iters: 1728, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 175, iters: 1808, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 175, iters: 1888, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 175, iters: 1968, time: 0.103, data: 0.012) loss: 0.019 
(epoch: 175, iters: 2048, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 175, iters: 2128, time: 0.105, data: 0.011) loss: 0.017 
(epoch: 175, iters: 2208, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 175, iters: 2288, time: 0.104, data: 0.000) loss: 0.009 
(epoch: 175, iters: 2368, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 175, iters: 2448, time: 0.107, data: 0.000) loss: 0.030 
(epoch: 175, iters: 2528, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 175, iters: 2608, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 175, iters: 2688, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 175, iters: 2768, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 175, iters: 2848, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 175, iters: 2928, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 175, iters: 3008, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 175, iters: 3088, time: 0.102, data: 0.012) loss: 0.001 
(epoch: 175, iters: 3168, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 175, iters: 3248, time: 0.104, data: 0.019) loss: 0.000 
(epoch: 175, iters: 3328, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 175, iters: 3408, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 175, iters: 3488, time: 0.105, data: 0.048) loss: 0.001 
(epoch: 175, iters: 3568, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 175, iters: 3648, time: 0.097, data: 0.011) loss: 0.001 
(epoch: 175, iters: 3728, time: 0.065, data: 0.000) loss: 0.000 
saving the model at the end of epoch 175, iters 652400
End of epoch 175 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001924
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 175, TEST ACC: [94.385 %]

saving the latest model (epoch 176, total_steps 652416)
(epoch: 176, iters: 80, time: 0.106, data: 0.463) loss: 0.001 
(epoch: 176, iters: 160, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 176, iters: 240, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 176, iters: 320, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 176, iters: 400, time: 0.104, data: 0.012) loss: 0.002 
(epoch: 176, iters: 480, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 176, iters: 560, time: 0.104, data: 0.011) loss: 0.012 
(epoch: 176, iters: 640, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 176, iters: 720, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 176, iters: 800, time: 0.105, data: 0.039) loss: 0.086 
(epoch: 176, iters: 880, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 176, iters: 960, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 176, iters: 1040, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 176, iters: 1120, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 176, iters: 1200, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 176, iters: 1280, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 176, iters: 1360, time: 0.106, data: 0.038) loss: 0.003 
(epoch: 176, iters: 1440, time: 0.106, data: 0.000) loss: 0.024 
(epoch: 176, iters: 1520, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 176, iters: 1600, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 176, iters: 1680, time: 0.104, data: 0.012) loss: 0.008 
(epoch: 176, iters: 1760, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 176, iters: 1840, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 176, iters: 1920, time: 0.105, data: 0.047) loss: 0.033 
(epoch: 176, iters: 2000, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 176, iters: 2080, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 176, iters: 2160, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 176, iters: 2240, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 176, iters: 2320, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 176, iters: 2400, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 176, iters: 2480, time: 0.104, data: 0.038) loss: 0.000 
(epoch: 176, iters: 2560, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 176, iters: 2640, time: 0.102, data: 0.011) loss: 0.203 
(epoch: 176, iters: 2720, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 176, iters: 2800, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 176, iters: 2880, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 176, iters: 2960, time: 0.103, data: 0.000) loss: 0.110 
(epoch: 176, iters: 3040, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 176, iters: 3120, time: 0.105, data: 0.000) loss: 0.049 
(epoch: 176, iters: 3200, time: 0.103, data: 0.012) loss: 0.014 
(epoch: 176, iters: 3280, time: 0.104, data: 0.000) loss: 0.070 
(epoch: 176, iters: 3360, time: 0.105, data: 0.011) loss: 0.009 
(epoch: 176, iters: 3440, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 176, iters: 3520, time: 0.105, data: 0.000) loss: 0.030 
(epoch: 176, iters: 3600, time: 0.105, data: 0.038) loss: 0.140 
(epoch: 176, iters: 3680, time: 0.101, data: 0.000) loss: 0.004 
saving the model at the end of epoch 176, iters 656128
End of epoch 176 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001923
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 176, TEST ACC: [91.047 %]

saving the latest model (epoch 177, total_steps 656144)
(epoch: 177, iters: 32, time: 0.100, data: 0.004) loss: 0.000 
(epoch: 177, iters: 112, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 177, iters: 192, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 177, iters: 272, time: 0.105, data: 0.038) loss: 0.049 
(epoch: 177, iters: 352, time: 0.106, data: 0.000) loss: 0.055 
(epoch: 177, iters: 432, time: 0.103, data: 0.011) loss: 0.133 
(epoch: 177, iters: 512, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 177, iters: 592, time: 0.106, data: 0.011) loss: 0.857 
(epoch: 177, iters: 672, time: 0.107, data: 0.000) loss: 0.006 
(epoch: 177, iters: 752, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 177, iters: 832, time: 0.106, data: 0.047) loss: 0.003 
(epoch: 177, iters: 912, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 177, iters: 992, time: 0.104, data: 0.021) loss: 0.024 
(epoch: 177, iters: 1072, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 177, iters: 1152, time: 0.105, data: 0.012) loss: 0.084 
(epoch: 177, iters: 1232, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 177, iters: 1312, time: 0.105, data: 0.000) loss: 0.073 
(epoch: 177, iters: 1392, time: 0.106, data: 0.038) loss: 0.162 
(epoch: 177, iters: 1472, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 177, iters: 1552, time: 0.104, data: 0.012) loss: 0.002 
(epoch: 177, iters: 1632, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 177, iters: 1712, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 177, iters: 1792, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 177, iters: 1872, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 177, iters: 1952, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 177, iters: 2032, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 177, iters: 2112, time: 0.103, data: 0.011) loss: 0.026 
(epoch: 177, iters: 2192, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 177, iters: 2272, time: 0.106, data: 0.011) loss: 0.001 
(epoch: 177, iters: 2352, time: 0.107, data: 0.000) loss: 0.016 
(epoch: 177, iters: 2432, time: 0.104, data: 0.000) loss: 0.014 
(epoch: 177, iters: 2512, time: 0.106, data: 0.038) loss: 0.006 
(epoch: 177, iters: 2592, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 177, iters: 2672, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 177, iters: 2752, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 177, iters: 2832, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 177, iters: 2912, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 177, iters: 2992, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 177, iters: 3072, time: 0.105, data: 0.048) loss: 0.003 
(epoch: 177, iters: 3152, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 177, iters: 3232, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 177, iters: 3312, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 177, iters: 3392, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 177, iters: 3472, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 177, iters: 3552, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 177, iters: 3632, time: 0.102, data: 0.038) loss: 0.000 
(epoch: 177, iters: 3712, time: 0.101, data: 0.000) loss: 0.001 
saving the model at the end of epoch 177, iters 659856
End of epoch 177 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001922
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 177, TEST ACC: [95.599 %]

saving the latest model (epoch 178, total_steps 659872)
(epoch: 178, iters: 64, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 178, iters: 144, time: 0.105, data: 0.026) loss: 0.002 
(epoch: 178, iters: 224, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 178, iters: 304, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 178, iters: 384, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 178, iters: 464, time: 0.104, data: 0.012) loss: 0.008 
(epoch: 178, iters: 544, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 178, iters: 624, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 178, iters: 704, time: 0.104, data: 0.038) loss: 0.000 
(epoch: 178, iters: 784, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 178, iters: 864, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 178, iters: 944, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 178, iters: 1024, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 178, iters: 1104, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 178, iters: 1184, time: 0.105, data: 0.000) loss: 0.048 
(epoch: 178, iters: 1264, time: 0.106, data: 0.039) loss: 0.010 
(epoch: 178, iters: 1344, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 178, iters: 1424, time: 0.104, data: 0.012) loss: 0.060 
(epoch: 178, iters: 1504, time: 0.104, data: 0.000) loss: 0.009 
(epoch: 178, iters: 1584, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 178, iters: 1664, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 178, iters: 1744, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 178, iters: 1824, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 178, iters: 1904, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 178, iters: 1984, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 178, iters: 2064, time: 0.105, data: 0.000) loss: 0.053 
(epoch: 178, iters: 2144, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 178, iters: 2224, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 178, iters: 2304, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 178, iters: 2384, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 178, iters: 2464, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 178, iters: 2544, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 178, iters: 2624, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 178, iters: 2704, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 178, iters: 2784, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 178, iters: 2864, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 178, iters: 2944, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 178, iters: 3024, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 178, iters: 3104, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 178, iters: 3184, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 178, iters: 3264, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 178, iters: 3344, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 178, iters: 3424, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 178, iters: 3504, time: 0.106, data: 0.047) loss: 0.009 
(epoch: 178, iters: 3584, time: 0.106, data: 0.000) loss: 0.106 
(epoch: 178, iters: 3664, time: 0.100, data: 0.011) loss: 0.001 
saving the model at the end of epoch 178, iters 663584
End of epoch 178 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001921
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 178, TEST ACC: [94.841 %]

(epoch: 179, iters: 16, time: 0.117, data: 0.012) loss: 0.002 
saving the latest model (epoch 179, total_steps 663600)
(epoch: 179, iters: 96, time: 0.105, data: 0.000) loss: 0.030 
(epoch: 179, iters: 176, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 179, iters: 256, time: 0.106, data: 0.000) loss: 0.207 
(epoch: 179, iters: 336, time: 0.106, data: 0.011) loss: 0.003 
(epoch: 179, iters: 416, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 179, iters: 496, time: 0.104, data: 0.000) loss: 0.059 
(epoch: 179, iters: 576, time: 0.106, data: 0.038) loss: 0.009 
(epoch: 179, iters: 656, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 179, iters: 736, time: 0.102, data: 0.011) loss: 0.270 
(epoch: 179, iters: 816, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 179, iters: 896, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 179, iters: 976, time: 0.106, data: 0.000) loss: 0.094 
(epoch: 179, iters: 1056, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 179, iters: 1136, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 179, iters: 1216, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 179, iters: 1296, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 179, iters: 1376, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 179, iters: 1456, time: 0.103, data: 0.011) loss: 0.085 
(epoch: 179, iters: 1536, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 179, iters: 1616, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 179, iters: 1696, time: 0.106, data: 0.038) loss: 0.005 
(epoch: 179, iters: 1776, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 179, iters: 1856, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 179, iters: 1936, time: 0.105, data: 0.000) loss: 0.037 
(epoch: 179, iters: 2016, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 179, iters: 2096, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 179, iters: 2176, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 179, iters: 2256, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 179, iters: 2336, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 179, iters: 2416, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 179, iters: 2496, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 179, iters: 2576, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 179, iters: 2656, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 179, iters: 2736, time: 0.105, data: 0.000) loss: 0.094 
(epoch: 179, iters: 2816, time: 0.104, data: 0.048) loss: 0.009 
(epoch: 179, iters: 2896, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 179, iters: 2976, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 179, iters: 3056, time: 0.106, data: 0.000) loss: 0.032 
(epoch: 179, iters: 3136, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 179, iters: 3216, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 179, iters: 3296, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 179, iters: 3376, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 179, iters: 3456, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 179, iters: 3536, time: 0.103, data: 0.011) loss: 0.008 
(epoch: 179, iters: 3616, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 179, iters: 3696, time: 0.100, data: 0.011) loss: 0.002 
saving the model at the end of epoch 179, iters 667312
End of epoch 179 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001920
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 179, TEST ACC: [96.662 %]

saving the latest model (epoch 180, total_steps 667328)
(epoch: 180, iters: 48, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 180, iters: 128, time: 0.105, data: 0.026) loss: 0.000 
(epoch: 180, iters: 208, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 180, iters: 288, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 180, iters: 368, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 180, iters: 448, time: 0.106, data: 0.011) loss: 0.000 
(epoch: 180, iters: 528, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 180, iters: 608, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 180, iters: 688, time: 0.106, data: 0.038) loss: 0.070 
(epoch: 180, iters: 768, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 180, iters: 848, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 180, iters: 928, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 180, iters: 1008, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 180, iters: 1088, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 180, iters: 1168, time: 0.105, data: 0.000) loss: 0.061 
(epoch: 180, iters: 1248, time: 0.105, data: 0.039) loss: 0.003 
(epoch: 180, iters: 1328, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 180, iters: 1408, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 180, iters: 1488, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 180, iters: 1568, time: 0.106, data: 0.020) loss: 0.024 
(epoch: 180, iters: 1648, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 180, iters: 1728, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 180, iters: 1808, time: 0.106, data: 0.038) loss: 0.033 
(epoch: 180, iters: 1888, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 180, iters: 1968, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 180, iters: 2048, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 180, iters: 2128, time: 0.104, data: 0.011) loss: 0.096 
(epoch: 180, iters: 2208, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 180, iters: 2288, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 180, iters: 2368, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 180, iters: 2448, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 180, iters: 2528, time: 0.103, data: 0.012) loss: 0.003 
(epoch: 180, iters: 2608, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 180, iters: 2688, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 180, iters: 2768, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 180, iters: 2848, time: 0.104, data: 0.000) loss: 0.009 
(epoch: 180, iters: 2928, time: 0.106, data: 0.047) loss: 0.091 
(epoch: 180, iters: 3008, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 180, iters: 3088, time: 0.104, data: 0.011) loss: 0.011 
(epoch: 180, iters: 3168, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 180, iters: 3248, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 180, iters: 3328, time: 0.105, data: 0.000) loss: 0.050 
(epoch: 180, iters: 3408, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 180, iters: 3488, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 180, iters: 3568, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 180, iters: 3648, time: 0.098, data: 0.012) loss: 0.008 
(epoch: 180, iters: 3728, time: 0.066, data: 0.000) loss: 0.000 
saving the model at the end of epoch 180, iters 671040
End of epoch 180 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001919
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 180, TEST ACC: [94.689 %]

saving the latest model (epoch 181, total_steps 671056)
(epoch: 181, iters: 80, time: 0.105, data: 0.510) loss: 0.000 
(epoch: 181, iters: 160, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 181, iters: 240, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 181, iters: 320, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 181, iters: 400, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 181, iters: 480, time: 0.106, data: 0.038) loss: 0.006 
(epoch: 181, iters: 560, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 181, iters: 640, time: 0.103, data: 0.012) loss: 0.016 
(epoch: 181, iters: 720, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 181, iters: 800, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 181, iters: 880, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 181, iters: 960, time: 0.104, data: 0.000) loss: 0.037 
(epoch: 181, iters: 1040, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 181, iters: 1120, time: 0.107, data: 0.000) loss: 0.005 
(epoch: 181, iters: 1200, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 181, iters: 1280, time: 0.105, data: 0.000) loss: 0.107 
(epoch: 181, iters: 1360, time: 0.106, data: 0.020) loss: 0.000 
(epoch: 181, iters: 1440, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 181, iters: 1520, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 181, iters: 1600, time: 0.104, data: 0.048) loss: 0.002 
(epoch: 181, iters: 1680, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 181, iters: 1760, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 181, iters: 1840, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 181, iters: 1920, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 181, iters: 2000, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 181, iters: 2080, time: 0.104, data: 0.000) loss: 0.076 
(epoch: 181, iters: 2160, time: 0.105, data: 0.038) loss: 0.005 
(epoch: 181, iters: 2240, time: 0.106, data: 0.000) loss: 0.215 
(epoch: 181, iters: 2320, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 181, iters: 2400, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 181, iters: 2480, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 181, iters: 2560, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 181, iters: 2640, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 181, iters: 2720, time: 0.104, data: 0.021) loss: 0.006 
(epoch: 181, iters: 2800, time: 0.105, data: 0.034) loss: 0.000 
(epoch: 181, iters: 2880, time: 0.105, data: 0.000) loss: 0.020 
(epoch: 181, iters: 2960, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 181, iters: 3040, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 181, iters: 3120, time: 0.104, data: 0.024) loss: 0.001 
(epoch: 181, iters: 3200, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 181, iters: 3280, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 181, iters: 3360, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 181, iters: 3440, time: 0.104, data: 0.024) loss: 0.000 
(epoch: 181, iters: 3520, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 181, iters: 3600, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 181, iters: 3680, time: 0.101, data: 0.011) loss: 0.006 
saving the model at the end of epoch 181, iters 674768
End of epoch 181 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001918
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 181, TEST ACC: [96.055 %]

saving the latest model (epoch 182, total_steps 674784)
(epoch: 182, iters: 32, time: 0.101, data: 0.007) loss: 0.001 
(epoch: 182, iters: 112, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 182, iters: 192, time: 0.107, data: 0.000) loss: 0.031 
(epoch: 182, iters: 272, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 182, iters: 352, time: 0.107, data: 0.047) loss: 0.001 
(epoch: 182, iters: 432, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 182, iters: 512, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 182, iters: 592, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 182, iters: 672, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 182, iters: 752, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 182, iters: 832, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 182, iters: 912, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 182, iters: 992, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 182, iters: 1072, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 182, iters: 1152, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 182, iters: 1232, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 182, iters: 1312, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 182, iters: 1392, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 182, iters: 1472, time: 0.107, data: 0.039) loss: 0.003 
(epoch: 182, iters: 1552, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 182, iters: 1632, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 182, iters: 1712, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 182, iters: 1792, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 182, iters: 1872, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 182, iters: 1952, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 182, iters: 2032, time: 0.106, data: 0.038) loss: 0.014 
(epoch: 182, iters: 2112, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 182, iters: 2192, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 182, iters: 2272, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 182, iters: 2352, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 182, iters: 2432, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 182, iters: 2512, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 182, iters: 2592, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 182, iters: 2672, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 182, iters: 2752, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 182, iters: 2832, time: 0.104, data: 0.000) loss: 0.020 
(epoch: 182, iters: 2912, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 182, iters: 2992, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 182, iters: 3072, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 182, iters: 3152, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 182, iters: 3232, time: 0.107, data: 0.000) loss: 0.008 
(epoch: 182, iters: 3312, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 182, iters: 3392, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 182, iters: 3472, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 182, iters: 3552, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 182, iters: 3632, time: 0.103, data: 0.000) loss: 0.003 
(epoch: 182, iters: 3712, time: 0.100, data: 0.035) loss: 0.001 
saving the model at the end of epoch 182, iters 678496
End of epoch 182 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001917
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 182, TEST ACC: [93.323 %]

saving the latest model (epoch 183, total_steps 678512)
(epoch: 183, iters: 64, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 183, iters: 144, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 183, iters: 224, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 183, iters: 304, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 183, iters: 384, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 183, iters: 464, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 183, iters: 544, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 183, iters: 624, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 183, iters: 704, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 183, iters: 784, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 183, iters: 864, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 183, iters: 944, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 183, iters: 1024, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 183, iters: 1104, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 183, iters: 1184, time: 0.104, data: 0.011) loss: 0.034 
(epoch: 183, iters: 1264, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 183, iters: 1344, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 183, iters: 1424, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 183, iters: 1504, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 183, iters: 1584, time: 0.105, data: 0.038) loss: 0.044 
(epoch: 183, iters: 1664, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 183, iters: 1744, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 183, iters: 1824, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 183, iters: 1904, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 183, iters: 1984, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 183, iters: 2064, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 183, iters: 2144, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 183, iters: 2224, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 183, iters: 2304, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 183, iters: 2384, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 183, iters: 2464, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 183, iters: 2544, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 183, iters: 2624, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 183, iters: 2704, time: 0.107, data: 0.039) loss: 0.000 
(epoch: 183, iters: 2784, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 183, iters: 2864, time: 0.105, data: 0.011) loss: 0.025 
(epoch: 183, iters: 2944, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 183, iters: 3024, time: 0.104, data: 0.011) loss: 0.009 
(epoch: 183, iters: 3104, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 183, iters: 3184, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 183, iters: 3264, time: 0.105, data: 0.039) loss: 0.019 
(epoch: 183, iters: 3344, time: 0.105, data: 0.000) loss: 0.075 
(epoch: 183, iters: 3424, time: 0.103, data: 0.011) loss: 0.388 
(epoch: 183, iters: 3504, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 183, iters: 3584, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 183, iters: 3664, time: 0.101, data: 0.000) loss: 0.001 
saving the model at the end of epoch 183, iters 682224
End of epoch 183 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001916
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 183, TEST ACC: [89.53 %]

(epoch: 184, iters: 16, time: 0.120, data: 0.000) loss: 0.002 
saving the latest model (epoch 184, total_steps 682240)
(epoch: 184, iters: 96, time: 0.105, data: 0.044) loss: 0.000 
(epoch: 184, iters: 176, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 184, iters: 256, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 184, iters: 336, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 184, iters: 416, time: 0.104, data: 0.011) loss: 0.041 
(epoch: 184, iters: 496, time: 0.105, data: 0.000) loss: 0.159 
(epoch: 184, iters: 576, time: 0.105, data: 0.000) loss: 0.422 
(epoch: 184, iters: 656, time: 0.105, data: 0.038) loss: 0.003 
(epoch: 184, iters: 736, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 184, iters: 816, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 184, iters: 896, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 184, iters: 976, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 184, iters: 1056, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 184, iters: 1136, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 184, iters: 1216, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 184, iters: 1296, time: 0.106, data: 0.000) loss: 0.231 
(epoch: 184, iters: 1376, time: 0.102, data: 0.012) loss: 0.001 
(epoch: 184, iters: 1456, time: 0.106, data: 0.000) loss: 0.054 
(epoch: 184, iters: 1536, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 184, iters: 1616, time: 0.106, data: 0.000) loss: 0.177 
(epoch: 184, iters: 1696, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 184, iters: 1776, time: 0.105, data: 0.048) loss: 0.001 
(epoch: 184, iters: 1856, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 184, iters: 1936, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 184, iters: 2016, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 184, iters: 2096, time: 0.104, data: 0.011) loss: 0.031 
(epoch: 184, iters: 2176, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 184, iters: 2256, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 184, iters: 2336, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 184, iters: 2416, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 184, iters: 2496, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 184, iters: 2576, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 184, iters: 2656, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 184, iters: 2736, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 184, iters: 2816, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 184, iters: 2896, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 184, iters: 2976, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 184, iters: 3056, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 184, iters: 3136, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 184, iters: 3216, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 184, iters: 3296, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 184, iters: 3376, time: 0.104, data: 0.000) loss: 0.005 
(epoch: 184, iters: 3456, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 184, iters: 3536, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 184, iters: 3616, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 184, iters: 3696, time: 0.100, data: 0.000) loss: 0.003 
saving the model at the end of epoch 184, iters 685952
End of epoch 184 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001915
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 184, TEST ACC: [91.199 %]

saving the latest model (epoch 185, total_steps 685968)
(epoch: 185, iters: 48, time: 0.108, data: 0.004) loss: 0.002 
(epoch: 185, iters: 128, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 185, iters: 208, time: 0.105, data: 0.038) loss: 0.034 
(epoch: 185, iters: 288, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 185, iters: 368, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 185, iters: 448, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 185, iters: 528, time: 0.104, data: 0.011) loss: 0.015 
(epoch: 185, iters: 608, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 185, iters: 688, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 185, iters: 768, time: 0.105, data: 0.040) loss: 0.000 
(epoch: 185, iters: 848, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 185, iters: 928, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 185, iters: 1008, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 185, iters: 1088, time: 0.105, data: 0.011) loss: 0.012 
(epoch: 185, iters: 1168, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 185, iters: 1248, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 185, iters: 1328, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 185, iters: 1408, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 185, iters: 1488, time: 0.103, data: 0.011) loss: 0.012 
(epoch: 185, iters: 1568, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 185, iters: 1648, time: 0.104, data: 0.011) loss: 0.107 
(epoch: 185, iters: 1728, time: 0.107, data: 0.000) loss: 0.008 
(epoch: 185, iters: 1808, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 185, iters: 1888, time: 0.106, data: 0.040) loss: 0.000 
(epoch: 185, iters: 1968, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 185, iters: 2048, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 185, iters: 2128, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 185, iters: 2208, time: 0.105, data: 0.012) loss: 0.010 
(epoch: 185, iters: 2288, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 185, iters: 2368, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 185, iters: 2448, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 185, iters: 2528, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 185, iters: 2608, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 185, iters: 2688, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 185, iters: 2768, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 185, iters: 2848, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 185, iters: 2928, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 185, iters: 3008, time: 0.106, data: 0.038) loss: 0.003 
(epoch: 185, iters: 3088, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 185, iters: 3168, time: 0.103, data: 0.011) loss: 0.005 
(epoch: 185, iters: 3248, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 185, iters: 3328, time: 0.106, data: 0.012) loss: 0.002 
(epoch: 185, iters: 3408, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 185, iters: 3488, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 185, iters: 3568, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 185, iters: 3648, time: 0.101, data: 0.000) loss: 0.000 
(epoch: 185, iters: 3728, time: 0.066, data: 0.011) loss: 0.000 
saving the model at the end of epoch 185, iters 689680
End of epoch 185 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001914
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 185, TEST ACC: [94.082 %]

saving the latest model (epoch 186, total_steps 689696)
(epoch: 186, iters: 80, time: 0.105, data: 0.511) loss: 0.000 
(epoch: 186, iters: 160, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 186, iters: 240, time: 0.105, data: 0.011) loss: 0.006 
(epoch: 186, iters: 320, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 186, iters: 400, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 186, iters: 480, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 186, iters: 560, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 186, iters: 640, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 186, iters: 720, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 186, iters: 800, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 186, iters: 880, time: 0.105, data: 0.000) loss: 0.029 
(epoch: 186, iters: 960, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 186, iters: 1040, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 186, iters: 1120, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 186, iters: 1200, time: 0.103, data: 0.011) loss: 0.176 
(epoch: 186, iters: 1280, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 186, iters: 1360, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 186, iters: 1440, time: 0.105, data: 0.000) loss: 0.115 
(epoch: 186, iters: 1520, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 186, iters: 1600, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 186, iters: 1680, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 186, iters: 1760, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 186, iters: 1840, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 186, iters: 1920, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 186, iters: 2000, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 186, iters: 2080, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 186, iters: 2160, time: 0.106, data: 0.038) loss: 0.005 
(epoch: 186, iters: 2240, time: 0.105, data: 0.000) loss: 0.075 
(epoch: 186, iters: 2320, time: 0.104, data: 0.011) loss: 0.014 
(epoch: 186, iters: 2400, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 186, iters: 2480, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 186, iters: 2560, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 186, iters: 2640, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 186, iters: 2720, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 186, iters: 2800, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 186, iters: 2880, time: 0.103, data: 0.011) loss: 0.007 
(epoch: 186, iters: 2960, time: 0.106, data: 0.000) loss: 0.018 
(epoch: 186, iters: 3040, time: 0.106, data: 0.011) loss: 0.021 
(epoch: 186, iters: 3120, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 186, iters: 3200, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 186, iters: 3280, time: 0.105, data: 0.048) loss: 0.000 
(epoch: 186, iters: 3360, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 186, iters: 3440, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 186, iters: 3520, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 186, iters: 3600, time: 0.104, data: 0.011) loss: 0.010 
(epoch: 186, iters: 3680, time: 0.100, data: 0.000) loss: 0.001 
saving the model at the end of epoch 186, iters 693408
End of epoch 186 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001913
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 186, TEST ACC: [90.895 %]

saving the latest model (epoch 187, total_steps 693424)
(epoch: 187, iters: 32, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 187, iters: 112, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 187, iters: 192, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 187, iters: 272, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 187, iters: 352, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 187, iters: 432, time: 0.105, data: 0.038) loss: 0.009 
(epoch: 187, iters: 512, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 187, iters: 592, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 187, iters: 672, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 187, iters: 752, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 187, iters: 832, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 187, iters: 912, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 187, iters: 992, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 187, iters: 1072, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 187, iters: 1152, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 187, iters: 1232, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 187, iters: 1312, time: 0.103, data: 0.011) loss: 0.030 
(epoch: 187, iters: 1392, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 187, iters: 1472, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 187, iters: 1552, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 187, iters: 1632, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 187, iters: 1712, time: 0.103, data: 0.012) loss: 0.003 
(epoch: 187, iters: 1792, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 187, iters: 1872, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 187, iters: 1952, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 187, iters: 2032, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 187, iters: 2112, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 187, iters: 2192, time: 0.106, data: 0.000) loss: 0.018 
(epoch: 187, iters: 2272, time: 0.103, data: 0.011) loss: 0.171 
(epoch: 187, iters: 2352, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 187, iters: 2432, time: 0.104, data: 0.011) loss: 0.282 
(epoch: 187, iters: 2512, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 187, iters: 2592, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 187, iters: 2672, time: 0.104, data: 0.047) loss: 0.001 
(epoch: 187, iters: 2752, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 187, iters: 2832, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 187, iters: 2912, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 187, iters: 2992, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 187, iters: 3072, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 187, iters: 3152, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 187, iters: 3232, time: 0.106, data: 0.038) loss: 0.046 
(epoch: 187, iters: 3312, time: 0.107, data: 0.000) loss: 0.150 
(epoch: 187, iters: 3392, time: 0.103, data: 0.011) loss: 0.054 
(epoch: 187, iters: 3472, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 187, iters: 3552, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 187, iters: 3632, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 187, iters: 3712, time: 0.102, data: 0.000) loss: 0.004 
saving the model at the end of epoch 187, iters 697136
End of epoch 187 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001912
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 187, TEST ACC: [92.564 %]

saving the latest model (epoch 188, total_steps 697152)
(epoch: 188, iters: 64, time: 0.104, data: 0.003) loss: 0.001 
(epoch: 188, iters: 144, time: 0.106, data: 0.025) loss: 0.000 
(epoch: 188, iters: 224, time: 0.107, data: 0.000) loss: 0.105 
(epoch: 188, iters: 304, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 188, iters: 384, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 188, iters: 464, time: 0.106, data: 0.011) loss: 0.022 
(epoch: 188, iters: 544, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 188, iters: 624, time: 0.106, data: 0.000) loss: 0.089 
(epoch: 188, iters: 704, time: 0.105, data: 0.040) loss: 0.000 
(epoch: 188, iters: 784, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 188, iters: 864, time: 0.103, data: 0.011) loss: 0.236 
(epoch: 188, iters: 944, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 188, iters: 1024, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 188, iters: 1104, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 188, iters: 1184, time: 0.105, data: 0.000) loss: 0.350 
(epoch: 188, iters: 1264, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 188, iters: 1344, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 188, iters: 1424, time: 0.103, data: 0.012) loss: 0.013 
(epoch: 188, iters: 1504, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 188, iters: 1584, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 188, iters: 1664, time: 0.105, data: 0.000) loss: 0.022 
(epoch: 188, iters: 1744, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 188, iters: 1824, time: 0.105, data: 0.046) loss: 0.000 
(epoch: 188, iters: 1904, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 188, iters: 1984, time: 0.104, data: 0.021) loss: 0.000 
(epoch: 188, iters: 2064, time: 0.105, data: 0.000) loss: 0.307 
(epoch: 188, iters: 2144, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 188, iters: 2224, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 188, iters: 2304, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 188, iters: 2384, time: 0.106, data: 0.038) loss: 0.025 
(epoch: 188, iters: 2464, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 188, iters: 2544, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 188, iters: 2624, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 188, iters: 2704, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 188, iters: 2784, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 188, iters: 2864, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 188, iters: 2944, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 188, iters: 3024, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 188, iters: 3104, time: 0.102, data: 0.012) loss: 0.017 
(epoch: 188, iters: 3184, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 188, iters: 3264, time: 0.105, data: 0.011) loss: 0.011 
(epoch: 188, iters: 3344, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 188, iters: 3424, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 188, iters: 3504, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 188, iters: 3584, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 188, iters: 3664, time: 0.099, data: 0.012) loss: 0.000 
saving the model at the end of epoch 188, iters 700864
End of epoch 188 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001911
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 188, TEST ACC: [96.206 %]

(epoch: 189, iters: 16, time: 0.116, data: 0.011) loss: 0.001 
saving the latest model (epoch 189, total_steps 700880)
(epoch: 189, iters: 96, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 189, iters: 176, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 189, iters: 256, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 189, iters: 336, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 189, iters: 416, time: 0.105, data: 0.000) loss: 0.040 
(epoch: 189, iters: 496, time: 0.104, data: 0.000) loss: 0.005 
(epoch: 189, iters: 576, time: 0.105, data: 0.039) loss: 0.003 
(epoch: 189, iters: 656, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 189, iters: 736, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 189, iters: 816, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 189, iters: 896, time: 0.104, data: 0.011) loss: 1.886 
(epoch: 189, iters: 976, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 189, iters: 1056, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 189, iters: 1136, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 189, iters: 1216, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 189, iters: 1296, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 189, iters: 1376, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 189, iters: 1456, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 189, iters: 1536, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 189, iters: 1616, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 189, iters: 1696, time: 0.105, data: 0.047) loss: 0.005 
(epoch: 189, iters: 1776, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 189, iters: 1856, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 189, iters: 1936, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 189, iters: 2016, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 189, iters: 2096, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 189, iters: 2176, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 189, iters: 2256, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 189, iters: 2336, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 189, iters: 2416, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 189, iters: 2496, time: 0.107, data: 0.000) loss: 0.004 
(epoch: 189, iters: 2576, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 189, iters: 2656, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 189, iters: 2736, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 189, iters: 2816, time: 0.106, data: 0.039) loss: 0.027 
(epoch: 189, iters: 2896, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 189, iters: 2976, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 189, iters: 3056, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 189, iters: 3136, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 189, iters: 3216, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 189, iters: 3296, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 189, iters: 3376, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 189, iters: 3456, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 189, iters: 3536, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 189, iters: 3616, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 189, iters: 3696, time: 0.100, data: 0.011) loss: 0.000 
saving the model at the end of epoch 189, iters 704592
End of epoch 189 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001910
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 189, TEST ACC: [95.144 %]

saving the latest model (epoch 190, total_steps 704608)
(epoch: 190, iters: 48, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 190, iters: 128, time: 0.106, data: 0.026) loss: 0.001 
(epoch: 190, iters: 208, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 190, iters: 288, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 190, iters: 368, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 190, iters: 448, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 190, iters: 528, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 190, iters: 608, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 190, iters: 688, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 190, iters: 768, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 190, iters: 848, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 190, iters: 928, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 190, iters: 1008, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 190, iters: 1088, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 190, iters: 1168, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 190, iters: 1248, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 190, iters: 1328, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 190, iters: 1408, time: 0.102, data: 0.012) loss: 0.000 
(epoch: 190, iters: 1488, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 190, iters: 1568, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 190, iters: 1648, time: 0.107, data: 0.000) loss: 0.015 
(epoch: 190, iters: 1728, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 190, iters: 1808, time: 0.105, data: 0.048) loss: 0.001 
(epoch: 190, iters: 1888, time: 0.106, data: 0.000) loss: 0.022 
(epoch: 190, iters: 1968, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 190, iters: 2048, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 190, iters: 2128, time: 0.105, data: 0.011) loss: 0.029 
(epoch: 190, iters: 2208, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 190, iters: 2288, time: 0.104, data: 0.000) loss: 0.010 
(epoch: 190, iters: 2368, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 190, iters: 2448, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 190, iters: 2528, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 190, iters: 2608, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 190, iters: 2688, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 190, iters: 2768, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 190, iters: 2848, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 190, iters: 2928, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 190, iters: 3008, time: 0.107, data: 0.000) loss: 0.075 
(epoch: 190, iters: 3088, time: 0.103, data: 0.012) loss: 0.059 
(epoch: 190, iters: 3168, time: 0.106, data: 0.000) loss: 0.037 
(epoch: 190, iters: 3248, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 190, iters: 3328, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 190, iters: 3408, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 190, iters: 3488, time: 0.105, data: 0.039) loss: 0.003 
(epoch: 190, iters: 3568, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 190, iters: 3648, time: 0.098, data: 0.011) loss: 0.001 
(epoch: 190, iters: 3728, time: 0.067, data: 0.000) loss: 0.001 
saving the model at the end of epoch 190, iters 708320
End of epoch 190 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001909
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 190, TEST ACC: [93.778 %]

saving the latest model (epoch 191, total_steps 708336)
(epoch: 191, iters: 80, time: 0.106, data: 0.468) loss: 0.001 
(epoch: 191, iters: 160, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 191, iters: 240, time: 0.105, data: 0.039) loss: 0.033 
(epoch: 191, iters: 320, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 191, iters: 400, time: 0.104, data: 0.011) loss: 0.008 
(epoch: 191, iters: 480, time: 0.106, data: 0.000) loss: 0.143 
(epoch: 191, iters: 560, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 191, iters: 640, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 191, iters: 720, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 191, iters: 800, time: 0.106, data: 0.039) loss: 0.017 
(epoch: 191, iters: 880, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 191, iters: 960, time: 0.104, data: 0.020) loss: 0.000 
(epoch: 191, iters: 1040, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 191, iters: 1120, time: 0.106, data: 0.011) loss: 0.000 
(epoch: 191, iters: 1200, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 191, iters: 1280, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 191, iters: 1360, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 191, iters: 1440, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 191, iters: 1520, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 191, iters: 1600, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 191, iters: 1680, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 191, iters: 1760, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 191, iters: 1840, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 191, iters: 1920, time: 0.106, data: 0.039) loss: 0.024 
(epoch: 191, iters: 2000, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 191, iters: 2080, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 191, iters: 2160, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 191, iters: 2240, time: 0.105, data: 0.020) loss: 0.000 
(epoch: 191, iters: 2320, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 191, iters: 2400, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 191, iters: 2480, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 191, iters: 2560, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 191, iters: 2640, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 191, iters: 2720, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 191, iters: 2800, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 191, iters: 2880, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 191, iters: 2960, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 191, iters: 3040, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 191, iters: 3120, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 191, iters: 3200, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 191, iters: 3280, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 191, iters: 3360, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 191, iters: 3440, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 191, iters: 3520, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 191, iters: 3600, time: 0.106, data: 0.047) loss: 0.001 
(epoch: 191, iters: 3680, time: 0.101, data: 0.000) loss: 0.000 
saving the model at the end of epoch 191, iters 712048
End of epoch 191 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001908
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 191, TEST ACC: [96.206 %]

saving the latest model (epoch 192, total_steps 712064)
(epoch: 192, iters: 32, time: 0.100, data: 0.004) loss: 0.000 
(epoch: 192, iters: 112, time: 0.103, data: 0.026) loss: 0.000 
(epoch: 192, iters: 192, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 192, iters: 272, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 192, iters: 352, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 192, iters: 432, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 192, iters: 512, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 192, iters: 592, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 192, iters: 672, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 192, iters: 752, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 192, iters: 832, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 192, iters: 912, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 192, iters: 992, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 192, iters: 1072, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 192, iters: 1152, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 192, iters: 1232, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 192, iters: 1312, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 192, iters: 1392, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 192, iters: 1472, time: 0.105, data: 0.038) loss: 0.059 
(epoch: 192, iters: 1552, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 192, iters: 1632, time: 0.104, data: 0.011) loss: 0.019 
(epoch: 192, iters: 1712, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 192, iters: 1792, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 192, iters: 1872, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 192, iters: 1952, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 192, iters: 2032, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 192, iters: 2112, time: 0.105, data: 0.000) loss: 0.231 
(epoch: 192, iters: 2192, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 192, iters: 2272, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 192, iters: 2352, time: 0.104, data: 0.012) loss: 0.005 
(epoch: 192, iters: 2432, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 192, iters: 2512, time: 0.104, data: 0.000) loss: 0.014 
(epoch: 192, iters: 2592, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 192, iters: 2672, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 192, iters: 2752, time: 0.104, data: 0.020) loss: 0.000 
(epoch: 192, iters: 2832, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 192, iters: 2912, time: 0.105, data: 0.011) loss: 0.912 
(epoch: 192, iters: 2992, time: 0.107, data: 0.000) loss: 0.005 
(epoch: 192, iters: 3072, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 192, iters: 3152, time: 0.105, data: 0.038) loss: 0.012 
(epoch: 192, iters: 3232, time: 0.107, data: 0.000) loss: 0.008 
(epoch: 192, iters: 3312, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 192, iters: 3392, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 192, iters: 3472, time: 0.106, data: 0.011) loss: 0.001 
(epoch: 192, iters: 3552, time: 0.107, data: 0.000) loss: 0.015 
(epoch: 192, iters: 3632, time: 0.103, data: 0.000) loss: 0.019 
(epoch: 192, iters: 3712, time: 0.101, data: 0.035) loss: 0.000 
saving the model at the end of epoch 192, iters 715776
End of epoch 192 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001907
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 192, TEST ACC: [93.475 %]

saving the latest model (epoch 193, total_steps 715792)
(epoch: 193, iters: 64, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 193, iters: 144, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 193, iters: 224, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 193, iters: 304, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 193, iters: 384, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 193, iters: 464, time: 0.105, data: 0.046) loss: 0.001 
(epoch: 193, iters: 544, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 193, iters: 624, time: 0.104, data: 0.020) loss: 0.174 
(epoch: 193, iters: 704, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 193, iters: 784, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 193, iters: 864, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 193, iters: 944, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 193, iters: 1024, time: 0.105, data: 0.039) loss: 0.017 
(epoch: 193, iters: 1104, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 193, iters: 1184, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 193, iters: 1264, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 193, iters: 1344, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 193, iters: 1424, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 193, iters: 1504, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 193, iters: 1584, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 193, iters: 1664, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 193, iters: 1744, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 193, iters: 1824, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 193, iters: 1904, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 193, iters: 1984, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 193, iters: 2064, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 193, iters: 2144, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 193, iters: 2224, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 193, iters: 2304, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 193, iters: 2384, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 193, iters: 2464, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 193, iters: 2544, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 193, iters: 2624, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 193, iters: 2704, time: 0.106, data: 0.038) loss: 0.238 
(epoch: 193, iters: 2784, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 193, iters: 2864, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 193, iters: 2944, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 193, iters: 3024, time: 0.105, data: 0.011) loss: 0.013 
(epoch: 193, iters: 3104, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 193, iters: 3184, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 193, iters: 3264, time: 0.105, data: 0.038) loss: 0.003 
(epoch: 193, iters: 3344, time: 0.106, data: 0.000) loss: 0.071 
(epoch: 193, iters: 3424, time: 0.104, data: 0.011) loss: 0.025 
(epoch: 193, iters: 3504, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 193, iters: 3584, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 193, iters: 3664, time: 0.100, data: 0.000) loss: 0.002 
saving the model at the end of epoch 193, iters 719504
End of epoch 193 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001906
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 193, TEST ACC: [94.992 %]

(epoch: 194, iters: 16, time: 0.116, data: 0.000) loss: 0.003 
saving the latest model (epoch 194, total_steps 719520)
(epoch: 194, iters: 96, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 194, iters: 176, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 194, iters: 256, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 194, iters: 336, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 194, iters: 416, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 194, iters: 496, time: 0.106, data: 0.000) loss: 0.023 
(epoch: 194, iters: 576, time: 0.106, data: 0.011) loss: 0.001 
(epoch: 194, iters: 656, time: 0.107, data: 0.000) loss: 0.024 
(epoch: 194, iters: 736, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 194, iters: 816, time: 0.107, data: 0.047) loss: 0.000 
(epoch: 194, iters: 896, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 194, iters: 976, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 194, iters: 1056, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 194, iters: 1136, time: 0.105, data: 0.011) loss: 0.113 
(epoch: 194, iters: 1216, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 194, iters: 1296, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 194, iters: 1376, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 194, iters: 1456, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 194, iters: 1536, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 194, iters: 1616, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 194, iters: 1696, time: 0.104, data: 0.011) loss: 0.198 
(epoch: 194, iters: 1776, time: 0.107, data: 0.000) loss: 0.010 
(epoch: 194, iters: 1856, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 194, iters: 1936, time: 0.105, data: 0.040) loss: 0.002 
(epoch: 194, iters: 2016, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 194, iters: 2096, time: 0.102, data: 0.012) loss: 0.000 
(epoch: 194, iters: 2176, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 194, iters: 2256, time: 0.106, data: 0.011) loss: 0.002 
(epoch: 194, iters: 2336, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 194, iters: 2416, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 194, iters: 2496, time: 0.107, data: 0.039) loss: 0.000 
(epoch: 194, iters: 2576, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 194, iters: 2656, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 194, iters: 2736, time: 0.106, data: 0.000) loss: 0.038 
(epoch: 194, iters: 2816, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 194, iters: 2896, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 194, iters: 2976, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 194, iters: 3056, time: 0.105, data: 0.039) loss: 0.068 
(epoch: 194, iters: 3136, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 194, iters: 3216, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 194, iters: 3296, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 194, iters: 3376, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 194, iters: 3456, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 194, iters: 3536, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 194, iters: 3616, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 194, iters: 3696, time: 0.101, data: 0.000) loss: 0.000 
saving the model at the end of epoch 194, iters 723232
End of epoch 194 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001905
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 194, TEST ACC: [94.992 %]

saving the latest model (epoch 195, total_steps 723248)
(epoch: 195, iters: 48, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 195, iters: 128, time: 0.105, data: 0.026) loss: 0.000 
(epoch: 195, iters: 208, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 195, iters: 288, time: 0.103, data: 0.012) loss: 0.015 
(epoch: 195, iters: 368, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 195, iters: 448, time: 0.105, data: 0.012) loss: 0.004 
(epoch: 195, iters: 528, time: 0.105, data: 0.000) loss: 0.015 
(epoch: 195, iters: 608, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 195, iters: 688, time: 0.104, data: 0.039) loss: 0.000 
(epoch: 195, iters: 768, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 195, iters: 848, time: 0.102, data: 0.011) loss: 0.005 
(epoch: 195, iters: 928, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 195, iters: 1008, time: 0.104, data: 0.020) loss: 0.000 
(epoch: 195, iters: 1088, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 195, iters: 1168, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 195, iters: 1248, time: 0.106, data: 0.048) loss: 0.000 
(epoch: 195, iters: 1328, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 195, iters: 1408, time: 0.103, data: 0.012) loss: 0.017 
(epoch: 195, iters: 1488, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 195, iters: 1568, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 195, iters: 1648, time: 0.105, data: 0.000) loss: 0.065 
(epoch: 195, iters: 1728, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 195, iters: 1808, time: 0.105, data: 0.039) loss: 0.051 
(epoch: 195, iters: 1888, time: 0.105, data: 0.000) loss: 0.057 
(epoch: 195, iters: 1968, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 195, iters: 2048, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 195, iters: 2128, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 195, iters: 2208, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 195, iters: 2288, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 195, iters: 2368, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 195, iters: 2448, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 195, iters: 2528, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 195, iters: 2608, time: 0.106, data: 0.000) loss: 0.524 
(epoch: 195, iters: 2688, time: 0.105, data: 0.020) loss: 0.002 
(epoch: 195, iters: 2768, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 195, iters: 2848, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 195, iters: 2928, time: 0.105, data: 0.048) loss: 0.003 
(epoch: 195, iters: 3008, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 195, iters: 3088, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 195, iters: 3168, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 195, iters: 3248, time: 0.105, data: 0.011) loss: 0.020 
(epoch: 195, iters: 3328, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 195, iters: 3408, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 195, iters: 3488, time: 0.105, data: 0.038) loss: 0.028 
(epoch: 195, iters: 3568, time: 0.106, data: 0.000) loss: 0.028 
(epoch: 195, iters: 3648, time: 0.098, data: 0.012) loss: 0.001 
(epoch: 195, iters: 3728, time: 0.066, data: 0.000) loss: 0.001 
saving the model at the end of epoch 195, iters 726960
End of epoch 195 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001904
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 195, TEST ACC: [93.627 %]

saving the latest model (epoch 196, total_steps 726976)
(epoch: 196, iters: 80, time: 0.106, data: 0.492) loss: 0.000 
(epoch: 196, iters: 160, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 196, iters: 240, time: 0.105, data: 0.046) loss: 0.001 
(epoch: 196, iters: 320, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 196, iters: 400, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 196, iters: 480, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 196, iters: 560, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 196, iters: 640, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 196, iters: 720, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 196, iters: 800, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 196, iters: 880, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 196, iters: 960, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 196, iters: 1040, time: 0.106, data: 0.000) loss: 0.045 
(epoch: 196, iters: 1120, time: 0.107, data: 0.011) loss: 0.077 
(epoch: 196, iters: 1200, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 196, iters: 1280, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 196, iters: 1360, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 196, iters: 1440, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 196, iters: 1520, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 196, iters: 1600, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 196, iters: 1680, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 196, iters: 1760, time: 0.106, data: 0.000) loss: 0.222 
(epoch: 196, iters: 1840, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 196, iters: 1920, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 196, iters: 2000, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 196, iters: 2080, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 196, iters: 2160, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 196, iters: 2240, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 196, iters: 2320, time: 0.106, data: 0.000) loss: 0.488 
(epoch: 196, iters: 2400, time: 0.104, data: 0.000) loss: 0.022 
(epoch: 196, iters: 2480, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 196, iters: 2560, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 196, iters: 2640, time: 0.103, data: 0.012) loss: 0.006 
(epoch: 196, iters: 2720, time: 0.105, data: 0.000) loss: 0.638 
(epoch: 196, iters: 2800, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 196, iters: 2880, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 196, iters: 2960, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 196, iters: 3040, time: 0.105, data: 0.048) loss: 0.000 
(epoch: 196, iters: 3120, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 196, iters: 3200, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 196, iters: 3280, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 196, iters: 3360, time: 0.106, data: 0.011) loss: 0.001 
(epoch: 196, iters: 3440, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 196, iters: 3520, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 196, iters: 3600, time: 0.106, data: 0.039) loss: 0.002 
(epoch: 196, iters: 3680, time: 0.100, data: 0.000) loss: 0.000 
saving the model at the end of epoch 196, iters 730688
End of epoch 196 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001903
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 196, TEST ACC: [94.841 %]

saving the latest model (epoch 197, total_steps 730704)
(epoch: 197, iters: 32, time: 0.100, data: 0.004) loss: 0.010 
(epoch: 197, iters: 112, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 197, iters: 192, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 197, iters: 272, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 197, iters: 352, time: 0.106, data: 0.039) loss: 0.006 
(epoch: 197, iters: 432, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 197, iters: 512, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 197, iters: 592, time: 0.106, data: 0.000) loss: 0.021 
(epoch: 197, iters: 672, time: 0.104, data: 0.011) loss: 0.005 
(epoch: 197, iters: 752, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 197, iters: 832, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 197, iters: 912, time: 0.105, data: 0.038) loss: 0.007 
(epoch: 197, iters: 992, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 197, iters: 1072, time: 0.103, data: 0.011) loss: 0.005 
(epoch: 197, iters: 1152, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 197, iters: 1232, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 197, iters: 1312, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 197, iters: 1392, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 197, iters: 1472, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 197, iters: 1552, time: 0.106, data: 0.000) loss: 0.176 
(epoch: 197, iters: 1632, time: 0.103, data: 0.011) loss: 0.005 
(epoch: 197, iters: 1712, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 197, iters: 1792, time: 0.106, data: 0.020) loss: 0.000 
(epoch: 197, iters: 1872, time: 0.106, data: 0.000) loss: 0.169 
(epoch: 197, iters: 1952, time: 0.104, data: 0.000) loss: 0.050 
(epoch: 197, iters: 2032, time: 0.106, data: 0.038) loss: 0.009 
(epoch: 197, iters: 2112, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 197, iters: 2192, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 197, iters: 2272, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 197, iters: 2352, time: 0.105, data: 0.012) loss: 0.011 
(epoch: 197, iters: 2432, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 197, iters: 2512, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 197, iters: 2592, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 197, iters: 2672, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 197, iters: 2752, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 197, iters: 2832, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 197, iters: 2912, time: 0.105, data: 0.011) loss: 0.037 
(epoch: 197, iters: 2992, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 197, iters: 3072, time: 0.106, data: 0.000) loss: 0.196 
(epoch: 197, iters: 3152, time: 0.106, data: 0.047) loss: 0.009 
(epoch: 197, iters: 3232, time: 0.106, data: 0.000) loss: 0.133 
(epoch: 197, iters: 3312, time: 0.103, data: 0.012) loss: 0.101 
(epoch: 197, iters: 3392, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 197, iters: 3472, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 197, iters: 3552, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 197, iters: 3632, time: 0.102, data: 0.000) loss: 0.001 
(epoch: 197, iters: 3712, time: 0.101, data: 0.035) loss: 0.000 
saving the model at the end of epoch 197, iters 734416
End of epoch 197 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001902
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 197, TEST ACC: [91.502 %]

saving the latest model (epoch 198, total_steps 734432)
(epoch: 198, iters: 64, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 198, iters: 144, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 198, iters: 224, time: 0.106, data: 0.011) loss: 0.000 
(epoch: 198, iters: 304, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 198, iters: 384, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 198, iters: 464, time: 0.107, data: 0.047) loss: 0.000 
(epoch: 198, iters: 544, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 198, iters: 624, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 198, iters: 704, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 198, iters: 784, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 198, iters: 864, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 198, iters: 944, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 198, iters: 1024, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 198, iters: 1104, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 198, iters: 1184, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 198, iters: 1264, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 198, iters: 1344, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 198, iters: 1424, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 198, iters: 1504, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 198, iters: 1584, time: 0.106, data: 0.048) loss: 0.000 
(epoch: 198, iters: 1664, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 198, iters: 1744, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 198, iters: 1824, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 198, iters: 1904, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 198, iters: 1984, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 198, iters: 2064, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 198, iters: 2144, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 198, iters: 2224, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 198, iters: 2304, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 198, iters: 2384, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 198, iters: 2464, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 198, iters: 2544, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 198, iters: 2624, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 198, iters: 2704, time: 0.105, data: 0.040) loss: 0.000 
(epoch: 198, iters: 2784, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 198, iters: 2864, time: 0.103, data: 0.020) loss: 0.003 
(epoch: 198, iters: 2944, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 198, iters: 3024, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 198, iters: 3104, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 198, iters: 3184, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 198, iters: 3264, time: 0.105, data: 0.038) loss: 0.007 
(epoch: 198, iters: 3344, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 198, iters: 3424, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 198, iters: 3504, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 198, iters: 3584, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 198, iters: 3664, time: 0.100, data: 0.000) loss: 0.001 
saving the model at the end of epoch 198, iters 738144
End of epoch 198 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001901
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 198, TEST ACC: [92.261 %]

(epoch: 199, iters: 16, time: 0.117, data: 0.000) loss: 0.000 
saving the latest model (epoch 199, total_steps 738160)
(epoch: 199, iters: 96, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 199, iters: 176, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 199, iters: 256, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 199, iters: 336, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 199, iters: 416, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 199, iters: 496, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 199, iters: 576, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 199, iters: 656, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 199, iters: 736, time: 0.106, data: 0.000) loss: 0.052 
(epoch: 199, iters: 816, time: 0.104, data: 0.011) loss: 0.008 
(epoch: 199, iters: 896, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 199, iters: 976, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 199, iters: 1056, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 199, iters: 1136, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 199, iters: 1216, time: 0.103, data: 0.012) loss: 0.003 
(epoch: 199, iters: 1296, time: 0.105, data: 0.000) loss: 0.506 
(epoch: 199, iters: 1376, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 199, iters: 1456, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 199, iters: 1536, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 199, iters: 1616, time: 0.105, data: 0.038) loss: 0.006 
(epoch: 199, iters: 1696, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 199, iters: 1776, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 199, iters: 1856, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 199, iters: 1936, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 199, iters: 2016, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 199, iters: 2096, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 199, iters: 2176, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 199, iters: 2256, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 199, iters: 2336, time: 0.103, data: 0.011) loss: 0.027 
(epoch: 199, iters: 2416, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 199, iters: 2496, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 199, iters: 2576, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 199, iters: 2656, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 199, iters: 2736, time: 0.104, data: 0.047) loss: 0.002 
(epoch: 199, iters: 2816, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 199, iters: 2896, time: 0.104, data: 0.011) loss: 0.007 
(epoch: 199, iters: 2976, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 199, iters: 3056, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 199, iters: 3136, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 199, iters: 3216, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 199, iters: 3296, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 199, iters: 3376, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 199, iters: 3456, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 199, iters: 3536, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 199, iters: 3616, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 199, iters: 3696, time: 0.099, data: 0.000) loss: 0.000 
saving the model at the end of epoch 199, iters 741872
End of epoch 199 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001900
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 199, TEST ACC: [93.02 %]

saving the latest model (epoch 200, total_steps 741888)
(epoch: 200, iters: 48, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 200, iters: 128, time: 0.104, data: 0.025) loss: 0.000 
(epoch: 200, iters: 208, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 200, iters: 288, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 200, iters: 368, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 200, iters: 448, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 200, iters: 528, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 200, iters: 608, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 200, iters: 688, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 200, iters: 768, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 200, iters: 848, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 200, iters: 928, time: 0.105, data: 0.038) loss: 0.101 
(epoch: 200, iters: 1008, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 200, iters: 1088, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 200, iters: 1168, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 200, iters: 1248, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 200, iters: 1328, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 200, iters: 1408, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 200, iters: 1488, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 200, iters: 1568, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 200, iters: 1648, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 200, iters: 1728, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 200, iters: 1808, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 200, iters: 1888, time: 0.107, data: 0.000) loss: 0.004 
(epoch: 200, iters: 1968, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 200, iters: 2048, time: 0.105, data: 0.047) loss: 0.001 
(epoch: 200, iters: 2128, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 200, iters: 2208, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 200, iters: 2288, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 200, iters: 2368, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 200, iters: 2448, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 200, iters: 2528, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 200, iters: 2608, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 200, iters: 2688, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 200, iters: 2768, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 200, iters: 2848, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 200, iters: 2928, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 200, iters: 3008, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 200, iters: 3088, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 200, iters: 3168, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 200, iters: 3248, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 200, iters: 3328, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 200, iters: 3408, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 200, iters: 3488, time: 0.106, data: 0.011) loss: 0.000 
(epoch: 200, iters: 3568, time: 0.106, data: 0.000) loss: 0.017 
(epoch: 200, iters: 3648, time: 0.100, data: 0.000) loss: 0.000 
(epoch: 200, iters: 3728, time: 0.066, data: 0.015) loss: 0.000 
saving the model at the end of epoch 200, iters 745600
End of epoch 200 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001899
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 200, TEST ACC: [89.074 %]

saving the latest model (epoch 201, total_steps 745616)
(epoch: 201, iters: 80, time: 0.103, data: 0.510) loss: 0.000 
(epoch: 201, iters: 160, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 201, iters: 240, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 201, iters: 320, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 201, iters: 400, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 201, iters: 480, time: 0.105, data: 0.039) loss: 0.007 
(epoch: 201, iters: 560, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 201, iters: 640, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 201, iters: 720, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 201, iters: 800, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 201, iters: 880, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 201, iters: 960, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 201, iters: 1040, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 201, iters: 1120, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 201, iters: 1200, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 201, iters: 1280, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 201, iters: 1360, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 201, iters: 1440, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 201, iters: 1520, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 201, iters: 1600, time: 0.105, data: 0.048) loss: 0.002 
(epoch: 201, iters: 1680, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 201, iters: 1760, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 201, iters: 1840, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 201, iters: 1920, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 201, iters: 2000, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 201, iters: 2080, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 201, iters: 2160, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 201, iters: 2240, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 201, iters: 2320, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 201, iters: 2400, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 201, iters: 2480, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 201, iters: 2560, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 201, iters: 2640, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 201, iters: 2720, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 201, iters: 2800, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 201, iters: 2880, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 201, iters: 2960, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 201, iters: 3040, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 201, iters: 3120, time: 0.106, data: 0.000) loss: 0.018 
(epoch: 201, iters: 3200, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 201, iters: 3280, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 201, iters: 3360, time: 0.106, data: 0.000) loss: 0.531 
(epoch: 201, iters: 3440, time: 0.104, data: 0.012) loss: 0.005 
(epoch: 201, iters: 3520, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 201, iters: 3600, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 201, iters: 3680, time: 0.099, data: 0.000) loss: 0.225 
saving the model at the end of epoch 201, iters 749328
End of epoch 201 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001898
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 201, TEST ACC: [83.308 %]

saving the latest model (epoch 202, total_steps 749344)
(epoch: 202, iters: 32, time: 0.099, data: 0.000) loss: 0.001 
(epoch: 202, iters: 112, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 202, iters: 192, time: 0.104, data: 0.000) loss: 0.046 
(epoch: 202, iters: 272, time: 0.105, data: 0.038) loss: 0.017 
(epoch: 202, iters: 352, time: 0.105, data: 0.000) loss: 0.371 
(epoch: 202, iters: 432, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 202, iters: 512, time: 0.105, data: 0.000) loss: 0.012 
(epoch: 202, iters: 592, time: 0.106, data: 0.011) loss: 0.390 
(epoch: 202, iters: 672, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 202, iters: 752, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 202, iters: 832, time: 0.104, data: 0.039) loss: 0.393 
(epoch: 202, iters: 912, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 202, iters: 992, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 202, iters: 1072, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 202, iters: 1152, time: 0.106, data: 0.012) loss: 0.002 
(epoch: 202, iters: 1232, time: 0.107, data: 0.000) loss: 0.007 
(epoch: 202, iters: 1312, time: 0.104, data: 0.000) loss: 0.035 
(epoch: 202, iters: 1392, time: 0.104, data: 0.047) loss: 0.001 
(epoch: 202, iters: 1472, time: 0.107, data: 0.000) loss: 0.007 
(epoch: 202, iters: 1552, time: 0.103, data: 0.011) loss: 0.267 
(epoch: 202, iters: 1632, time: 0.106, data: 0.000) loss: 0.035 
(epoch: 202, iters: 1712, time: 0.104, data: 0.011) loss: 0.034 
(epoch: 202, iters: 1792, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 202, iters: 1872, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 202, iters: 1952, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 202, iters: 2032, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 202, iters: 2112, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 202, iters: 2192, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 202, iters: 2272, time: 0.104, data: 0.011) loss: 0.008 
(epoch: 202, iters: 2352, time: 0.107, data: 0.000) loss: 0.016 
(epoch: 202, iters: 2432, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 202, iters: 2512, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 202, iters: 2592, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 202, iters: 2672, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 202, iters: 2752, time: 0.105, data: 0.000) loss: 0.031 
(epoch: 202, iters: 2832, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 202, iters: 2912, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 202, iters: 2992, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 202, iters: 3072, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 202, iters: 3152, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 202, iters: 3232, time: 0.105, data: 0.011) loss: 0.008 
(epoch: 202, iters: 3312, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 202, iters: 3392, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 202, iters: 3472, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 202, iters: 3552, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 202, iters: 3632, time: 0.104, data: 0.038) loss: 0.000 
(epoch: 202, iters: 3712, time: 0.100, data: 0.000) loss: 0.000 
saving the model at the end of epoch 202, iters 753056
End of epoch 202 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001897
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 202, TEST ACC: [92.716 %]

saving the latest model (epoch 203, total_steps 753072)
(epoch: 203, iters: 64, time: 0.105, data: 0.000) loss: 0.040 
(epoch: 203, iters: 144, time: 0.104, data: 0.000) loss: 0.024 
(epoch: 203, iters: 224, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 203, iters: 304, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 203, iters: 384, time: 0.105, data: 0.039) loss: 0.005 
(epoch: 203, iters: 464, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 203, iters: 544, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 203, iters: 624, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 203, iters: 704, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 203, iters: 784, time: 0.105, data: 0.000) loss: 0.187 
(epoch: 203, iters: 864, time: 0.104, data: 0.000) loss: 0.188 
(epoch: 203, iters: 944, time: 0.104, data: 0.038) loss: 0.000 
(epoch: 203, iters: 1024, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 203, iters: 1104, time: 0.104, data: 0.011) loss: 0.012 
(epoch: 203, iters: 1184, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 203, iters: 1264, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 203, iters: 1344, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 203, iters: 1424, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 203, iters: 1504, time: 0.105, data: 0.038) loss: 0.006 
(epoch: 203, iters: 1584, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 203, iters: 1664, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 203, iters: 1744, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 203, iters: 1824, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 203, iters: 1904, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 203, iters: 1984, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 203, iters: 2064, time: 0.106, data: 0.039) loss: 0.026 
(epoch: 203, iters: 2144, time: 0.106, data: 0.000) loss: 0.062 
(epoch: 203, iters: 2224, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 203, iters: 2304, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 203, iters: 2384, time: 0.106, data: 0.011) loss: 0.001 
(epoch: 203, iters: 2464, time: 0.105, data: 0.000) loss: 0.062 
(epoch: 203, iters: 2544, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 203, iters: 2624, time: 0.104, data: 0.038) loss: 0.015 
(epoch: 203, iters: 2704, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 203, iters: 2784, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 203, iters: 2864, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 203, iters: 2944, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 203, iters: 3024, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 203, iters: 3104, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 203, iters: 3184, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 203, iters: 3264, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 203, iters: 3344, time: 0.103, data: 0.012) loss: 0.102 
(epoch: 203, iters: 3424, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 203, iters: 3504, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 203, iters: 3584, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 203, iters: 3664, time: 0.100, data: 0.000) loss: 0.004 
saving the model at the end of epoch 203, iters 756784
End of epoch 203 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001896
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 203, TEST ACC: [95.599 %]

(epoch: 204, iters: 16, time: 0.117, data: 0.012) loss: 0.003 
saving the latest model (epoch 204, total_steps 756800)
(epoch: 204, iters: 96, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 204, iters: 176, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 204, iters: 256, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 204, iters: 336, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 204, iters: 416, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 204, iters: 496, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 204, iters: 576, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 204, iters: 656, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 204, iters: 736, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 204, iters: 816, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 204, iters: 896, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 204, iters: 976, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 204, iters: 1056, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 204, iters: 1136, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 204, iters: 1216, time: 0.103, data: 0.012) loss: 0.008 
(epoch: 204, iters: 1296, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 204, iters: 1376, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 204, iters: 1456, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 204, iters: 1536, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 204, iters: 1616, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 204, iters: 1696, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 204, iters: 1776, time: 0.104, data: 0.011) loss: 0.054 
(epoch: 204, iters: 1856, time: 0.105, data: 0.000) loss: 0.024 
(epoch: 204, iters: 1936, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 204, iters: 2016, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 204, iters: 2096, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 204, iters: 2176, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 204, iters: 2256, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 204, iters: 2336, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 204, iters: 2416, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 204, iters: 2496, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 204, iters: 2576, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 204, iters: 2656, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 204, iters: 2736, time: 0.105, data: 0.038) loss: 0.005 
(epoch: 204, iters: 2816, time: 0.105, data: 0.000) loss: 0.060 
(epoch: 204, iters: 2896, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 204, iters: 2976, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 204, iters: 3056, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 204, iters: 3136, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 204, iters: 3216, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 204, iters: 3296, time: 0.106, data: 0.038) loss: 0.007 
(epoch: 204, iters: 3376, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 204, iters: 3456, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 204, iters: 3536, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 204, iters: 3616, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 204, iters: 3696, time: 0.098, data: 0.000) loss: 0.000 
saving the model at the end of epoch 204, iters 760512
End of epoch 204 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001895
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 204, TEST ACC: [93.475 %]

saving the latest model (epoch 205, total_steps 760528)
(epoch: 205, iters: 48, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 205, iters: 128, time: 0.105, data: 0.042) loss: 0.001 
(epoch: 205, iters: 208, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 205, iters: 288, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 205, iters: 368, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 205, iters: 448, time: 0.106, data: 0.011) loss: 0.000 
(epoch: 205, iters: 528, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 205, iters: 608, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 205, iters: 688, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 205, iters: 768, time: 0.106, data: 0.000) loss: 0.159 
(epoch: 205, iters: 848, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 205, iters: 928, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 205, iters: 1008, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 205, iters: 1088, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 205, iters: 1168, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 205, iters: 1248, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 205, iters: 1328, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 205, iters: 1408, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 205, iters: 1488, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 205, iters: 1568, time: 0.104, data: 0.011) loss: 0.086 
(epoch: 205, iters: 1648, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 205, iters: 1728, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 205, iters: 1808, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 205, iters: 1888, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 205, iters: 1968, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 205, iters: 2048, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 205, iters: 2128, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 205, iters: 2208, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 205, iters: 2288, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 205, iters: 2368, time: 0.105, data: 0.048) loss: 0.000 
(epoch: 205, iters: 2448, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 205, iters: 2528, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 205, iters: 2608, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 205, iters: 2688, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 205, iters: 2768, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 205, iters: 2848, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 205, iters: 2928, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 205, iters: 3008, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 205, iters: 3088, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 205, iters: 3168, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 205, iters: 3248, time: 0.105, data: 0.012) loss: 0.103 
(epoch: 205, iters: 3328, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 205, iters: 3408, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 205, iters: 3488, time: 0.107, data: 0.039) loss: 0.001 
(epoch: 205, iters: 3568, time: 0.107, data: 0.000) loss: 0.006 
(epoch: 205, iters: 3648, time: 0.099, data: 0.011) loss: 0.000 
(epoch: 205, iters: 3728, time: 0.066, data: 0.000) loss: 0.010 
saving the model at the end of epoch 205, iters 764240
End of epoch 205 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001894
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 205, TEST ACC: [92.564 %]

saving the latest model (epoch 206, total_steps 764256)
(epoch: 206, iters: 80, time: 0.105, data: 0.512) loss: 0.002 
(epoch: 206, iters: 160, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 206, iters: 240, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 206, iters: 320, time: 0.106, data: 0.000) loss: 0.211 
(epoch: 206, iters: 400, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 206, iters: 480, time: 0.104, data: 0.038) loss: 0.004 
(epoch: 206, iters: 560, time: 0.105, data: 0.000) loss: 0.018 
(epoch: 206, iters: 640, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 206, iters: 720, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 206, iters: 800, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 206, iters: 880, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 206, iters: 960, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 206, iters: 1040, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 206, iters: 1120, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 206, iters: 1200, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 206, iters: 1280, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 206, iters: 1360, time: 0.105, data: 0.011) loss: 0.004 
(epoch: 206, iters: 1440, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 206, iters: 1520, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 206, iters: 1600, time: 0.105, data: 0.046) loss: 0.111 
(epoch: 206, iters: 1680, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 206, iters: 1760, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 206, iters: 1840, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 206, iters: 1920, time: 0.104, data: 0.011) loss: 0.539 
(epoch: 206, iters: 2000, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 206, iters: 2080, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 206, iters: 2160, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 206, iters: 2240, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 206, iters: 2320, time: 0.102, data: 0.011) loss: 0.035 
(epoch: 206, iters: 2400, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 206, iters: 2480, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 206, iters: 2560, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 206, iters: 2640, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 206, iters: 2720, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 206, iters: 2800, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 206, iters: 2880, time: 0.103, data: 0.012) loss: 0.653 
(epoch: 206, iters: 2960, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 206, iters: 3040, time: 0.104, data: 0.012) loss: 0.052 
(epoch: 206, iters: 3120, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 206, iters: 3200, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 206, iters: 3280, time: 0.106, data: 0.040) loss: 0.154 
(epoch: 206, iters: 3360, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 206, iters: 3440, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 206, iters: 3520, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 206, iters: 3600, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 206, iters: 3680, time: 0.099, data: 0.000) loss: 0.000 
saving the model at the end of epoch 206, iters 767968
End of epoch 206 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001893
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 206, TEST ACC: [91.958 %]

saving the latest model (epoch 207, total_steps 767984)
(epoch: 207, iters: 32, time: 0.100, data: 0.000) loss: 0.099 
(epoch: 207, iters: 112, time: 0.104, data: 0.011) loss: 0.004 
(epoch: 207, iters: 192, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 207, iters: 272, time: 0.105, data: 0.000) loss: 0.162 
(epoch: 207, iters: 352, time: 0.106, data: 0.038) loss: 0.012 
(epoch: 207, iters: 432, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 207, iters: 512, time: 0.103, data: 0.011) loss: 0.240 
(epoch: 207, iters: 592, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 207, iters: 672, time: 0.105, data: 0.012) loss: 0.176 
(epoch: 207, iters: 752, time: 0.105, data: 0.000) loss: 0.107 
(epoch: 207, iters: 832, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 207, iters: 912, time: 0.105, data: 0.039) loss: 0.002 
(epoch: 207, iters: 992, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 207, iters: 1072, time: 0.103, data: 0.011) loss: 0.005 
(epoch: 207, iters: 1152, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 207, iters: 1232, time: 0.105, data: 0.019) loss: 0.011 
(epoch: 207, iters: 1312, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 207, iters: 1392, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 207, iters: 1472, time: 0.106, data: 0.047) loss: 0.018 
(epoch: 207, iters: 1552, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 207, iters: 1632, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 207, iters: 1712, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 207, iters: 1792, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 207, iters: 1872, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 207, iters: 1952, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 207, iters: 2032, time: 0.104, data: 0.039) loss: 0.004 
(epoch: 207, iters: 2112, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 207, iters: 2192, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 207, iters: 2272, time: 0.105, data: 0.000) loss: 0.027 
(epoch: 207, iters: 2352, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 207, iters: 2432, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 207, iters: 2512, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 207, iters: 2592, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 207, iters: 2672, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 207, iters: 2752, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 207, iters: 2832, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 207, iters: 2912, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 207, iters: 2992, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 207, iters: 3072, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 207, iters: 3152, time: 0.104, data: 0.048) loss: 0.000 
(epoch: 207, iters: 3232, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 207, iters: 3312, time: 0.102, data: 0.011) loss: 0.001 
(epoch: 207, iters: 3392, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 207, iters: 3472, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 207, iters: 3552, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 207, iters: 3632, time: 0.102, data: 0.000) loss: 0.001 
(epoch: 207, iters: 3712, time: 0.099, data: 0.034) loss: 0.472 
saving the model at the end of epoch 207, iters 771696
End of epoch 207 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001892
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 207, TEST ACC: [95.903 %]

saving the latest model (epoch 208, total_steps 771712)
(epoch: 208, iters: 64, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 208, iters: 144, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 208, iters: 224, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 208, iters: 304, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 208, iters: 384, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 208, iters: 464, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 208, iters: 544, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 208, iters: 624, time: 0.103, data: 0.011) loss: 0.010 
(epoch: 208, iters: 704, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 208, iters: 784, time: 0.105, data: 0.012) loss: 0.013 
(epoch: 208, iters: 864, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 208, iters: 944, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 208, iters: 1024, time: 0.106, data: 0.047) loss: 0.000 
(epoch: 208, iters: 1104, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 208, iters: 1184, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 208, iters: 1264, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 208, iters: 1344, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 208, iters: 1424, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 208, iters: 1504, time: 0.105, data: 0.000) loss: 0.022 
(epoch: 208, iters: 1584, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 208, iters: 1664, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 208, iters: 1744, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 208, iters: 1824, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 208, iters: 1904, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 208, iters: 1984, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 208, iters: 2064, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 208, iters: 2144, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 208, iters: 2224, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 208, iters: 2304, time: 0.104, data: 0.012) loss: 0.005 
(epoch: 208, iters: 2384, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 208, iters: 2464, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 208, iters: 2544, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 208, iters: 2624, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 208, iters: 2704, time: 0.105, data: 0.048) loss: 0.002 
(epoch: 208, iters: 2784, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 208, iters: 2864, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 208, iters: 2944, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 208, iters: 3024, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 208, iters: 3104, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 208, iters: 3184, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 208, iters: 3264, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 208, iters: 3344, time: 0.107, data: 0.000) loss: 0.004 
(epoch: 208, iters: 3424, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 208, iters: 3504, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 208, iters: 3584, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 208, iters: 3664, time: 0.100, data: 0.000) loss: 0.013 
saving the model at the end of epoch 208, iters 775424
End of epoch 208 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001891
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 208, TEST ACC: [93.323 %]

(epoch: 209, iters: 16, time: 0.117, data: 0.000) loss: 0.000 
saving the latest model (epoch 209, total_steps 775440)
(epoch: 209, iters: 96, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 209, iters: 176, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 209, iters: 256, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 209, iters: 336, time: 0.108, data: 0.000) loss: 0.000 
(epoch: 209, iters: 416, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 209, iters: 496, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 209, iters: 576, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 209, iters: 656, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 209, iters: 736, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 209, iters: 816, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 209, iters: 896, time: 0.106, data: 0.000) loss: 0.149 
(epoch: 209, iters: 976, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 209, iters: 1056, time: 0.105, data: 0.000) loss: 0.036 
(epoch: 209, iters: 1136, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 209, iters: 1216, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 209, iters: 1296, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 209, iters: 1376, time: 0.105, data: 0.038) loss: 0.032 
(epoch: 209, iters: 1456, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 209, iters: 1536, time: 0.103, data: 0.012) loss: 0.004 
(epoch: 209, iters: 1616, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 209, iters: 1696, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 209, iters: 1776, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 209, iters: 1856, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 209, iters: 1936, time: 0.105, data: 0.039) loss: 0.018 
(epoch: 209, iters: 2016, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 209, iters: 2096, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 209, iters: 2176, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 209, iters: 2256, time: 0.105, data: 0.011) loss: 0.026 
(epoch: 209, iters: 2336, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 209, iters: 2416, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 209, iters: 2496, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 209, iters: 2576, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 209, iters: 2656, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 209, iters: 2736, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 209, iters: 2816, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 209, iters: 2896, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 209, iters: 2976, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 209, iters: 3056, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 209, iters: 3136, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 209, iters: 3216, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 209, iters: 3296, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 209, iters: 3376, time: 0.105, data: 0.012) loss: 0.015 
(epoch: 209, iters: 3456, time: 0.107, data: 0.000) loss: 0.021 
(epoch: 209, iters: 3536, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 209, iters: 3616, time: 0.104, data: 0.047) loss: 0.000 
(epoch: 209, iters: 3696, time: 0.100, data: 0.000) loss: 0.000 
saving the model at the end of epoch 209, iters 779152
End of epoch 209 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001890
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 209, TEST ACC: [93.627 %]

saving the latest model (epoch 210, total_steps 779168)
(epoch: 210, iters: 48, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 210, iters: 128, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 210, iters: 208, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 210, iters: 288, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 210, iters: 368, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 210, iters: 448, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 210, iters: 528, time: 0.103, data: 0.011) loss: 0.030 
(epoch: 210, iters: 608, time: 0.106, data: 0.000) loss: 0.013 
(epoch: 210, iters: 688, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 210, iters: 768, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 210, iters: 848, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 210, iters: 928, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 210, iters: 1008, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 210, iters: 1088, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 210, iters: 1168, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 210, iters: 1248, time: 0.105, data: 0.011) loss: 0.012 
(epoch: 210, iters: 1328, time: 0.106, data: 0.000) loss: 0.035 
(epoch: 210, iters: 1408, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 210, iters: 1488, time: 0.105, data: 0.048) loss: 0.001 
(epoch: 210, iters: 1568, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 210, iters: 1648, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 210, iters: 1728, time: 0.106, data: 0.000) loss: 0.008 
(epoch: 210, iters: 1808, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 210, iters: 1888, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 210, iters: 1968, time: 0.106, data: 0.000) loss: 0.154 
(epoch: 210, iters: 2048, time: 0.105, data: 0.040) loss: 0.004 
(epoch: 210, iters: 2128, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 210, iters: 2208, time: 0.103, data: 0.011) loss: 0.173 
(epoch: 210, iters: 2288, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 210, iters: 2368, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 210, iters: 2448, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 210, iters: 2528, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 210, iters: 2608, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 210, iters: 2688, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 210, iters: 2768, time: 0.102, data: 0.011) loss: 0.002 
(epoch: 210, iters: 2848, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 210, iters: 2928, time: 0.106, data: 0.018) loss: 0.049 
(epoch: 210, iters: 3008, time: 0.107, data: 0.000) loss: 0.065 
(epoch: 210, iters: 3088, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 210, iters: 3168, time: 0.105, data: 0.048) loss: 0.017 
(epoch: 210, iters: 3248, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 210, iters: 3328, time: 0.103, data: 0.011) loss: 0.007 
(epoch: 210, iters: 3408, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 210, iters: 3488, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 210, iters: 3568, time: 0.105, data: 0.000) loss: 0.061 
(epoch: 210, iters: 3648, time: 0.101, data: 0.000) loss: 0.000 
(epoch: 210, iters: 3728, time: 0.065, data: 0.014) loss: 0.011 
saving the model at the end of epoch 210, iters 782880
End of epoch 210 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001889
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 210, TEST ACC: [94.234 %]

saving the latest model (epoch 211, total_steps 782896)
(epoch: 211, iters: 80, time: 0.105, data: 0.494) loss: 0.000 
(epoch: 211, iters: 160, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 211, iters: 240, time: 0.105, data: 0.039) loss: 0.003 
(epoch: 211, iters: 320, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 211, iters: 400, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 211, iters: 480, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 211, iters: 560, time: 0.104, data: 0.011) loss: 0.040 
(epoch: 211, iters: 640, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 211, iters: 720, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 211, iters: 800, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 211, iters: 880, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 211, iters: 960, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 211, iters: 1040, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 211, iters: 1120, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 211, iters: 1200, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 211, iters: 1280, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 211, iters: 1360, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 211, iters: 1440, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 211, iters: 1520, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 211, iters: 1600, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 211, iters: 1680, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 211, iters: 1760, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 211, iters: 1840, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 211, iters: 1920, time: 0.104, data: 0.047) loss: 0.000 
(epoch: 211, iters: 2000, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 211, iters: 2080, time: 0.103, data: 0.021) loss: 0.000 
(epoch: 211, iters: 2160, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 211, iters: 2240, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 211, iters: 2320, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 211, iters: 2400, time: 0.105, data: 0.000) loss: 0.023 
(epoch: 211, iters: 2480, time: 0.105, data: 0.038) loss: 0.130 
(epoch: 211, iters: 2560, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 211, iters: 2640, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 211, iters: 2720, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 211, iters: 2800, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 211, iters: 2880, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 211, iters: 2960, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 211, iters: 3040, time: 0.106, data: 0.038) loss: 0.006 
(epoch: 211, iters: 3120, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 211, iters: 3200, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 211, iters: 3280, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 211, iters: 3360, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 211, iters: 3440, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 211, iters: 3520, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 211, iters: 3600, time: 0.106, data: 0.047) loss: 0.000 
(epoch: 211, iters: 3680, time: 0.100, data: 0.000) loss: 0.013 
saving the model at the end of epoch 211, iters 786608
End of epoch 211 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001888
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 211, TEST ACC: [94.082 %]

saving the latest model (epoch 212, total_steps 786624)
(epoch: 212, iters: 32, time: 0.100, data: 0.004) loss: 0.000 
(epoch: 212, iters: 112, time: 0.103, data: 0.000) loss: 0.003 
(epoch: 212, iters: 192, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 212, iters: 272, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 212, iters: 352, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 212, iters: 432, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 212, iters: 512, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 212, iters: 592, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 212, iters: 672, time: 0.104, data: 0.011) loss: 0.030 
(epoch: 212, iters: 752, time: 0.107, data: 0.000) loss: 0.005 
(epoch: 212, iters: 832, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 212, iters: 912, time: 0.106, data: 0.038) loss: 0.139 
(epoch: 212, iters: 992, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 212, iters: 1072, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 212, iters: 1152, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 212, iters: 1232, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 212, iters: 1312, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 212, iters: 1392, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 212, iters: 1472, time: 0.104, data: 0.047) loss: 0.000 
(epoch: 212, iters: 1552, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 212, iters: 1632, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 212, iters: 1712, time: 0.106, data: 0.000) loss: 0.257 
(epoch: 212, iters: 1792, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 212, iters: 1872, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 212, iters: 1952, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 212, iters: 2032, time: 0.105, data: 0.039) loss: 0.199 
(epoch: 212, iters: 2112, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 212, iters: 2192, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 212, iters: 2272, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 212, iters: 2352, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 212, iters: 2432, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 212, iters: 2512, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 212, iters: 2592, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 212, iters: 2672, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 212, iters: 2752, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 212, iters: 2832, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 212, iters: 2912, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 212, iters: 2992, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 212, iters: 3072, time: 0.104, data: 0.000) loss: 0.028 
(epoch: 212, iters: 3152, time: 0.106, data: 0.047) loss: 0.001 
(epoch: 212, iters: 3232, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 212, iters: 3312, time: 0.102, data: 0.011) loss: 0.006 
(epoch: 212, iters: 3392, time: 0.104, data: 0.000) loss: 0.030 
(epoch: 212, iters: 3472, time: 0.105, data: 0.011) loss: 0.013 
(epoch: 212, iters: 3552, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 212, iters: 3632, time: 0.102, data: 0.000) loss: 0.000 
(epoch: 212, iters: 3712, time: 0.100, data: 0.034) loss: 0.001 
saving the model at the end of epoch 212, iters 790336
End of epoch 212 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001887
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 212, TEST ACC: [92.109 %]

saving the latest model (epoch 213, total_steps 790352)
(epoch: 213, iters: 64, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 213, iters: 144, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 213, iters: 224, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 213, iters: 304, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 213, iters: 384, time: 0.104, data: 0.000) loss: 0.013 
(epoch: 213, iters: 464, time: 0.106, data: 0.038) loss: 0.002 
(epoch: 213, iters: 544, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 213, iters: 624, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 213, iters: 704, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 213, iters: 784, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 213, iters: 864, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 213, iters: 944, time: 0.104, data: 0.000) loss: 0.009 
(epoch: 213, iters: 1024, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 213, iters: 1104, time: 0.106, data: 0.000) loss: 0.032 
(epoch: 213, iters: 1184, time: 0.102, data: 0.012) loss: 0.001 
(epoch: 213, iters: 1264, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 213, iters: 1344, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 213, iters: 1424, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 213, iters: 1504, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 213, iters: 1584, time: 0.105, data: 0.039) loss: 0.858 
(epoch: 213, iters: 1664, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 213, iters: 1744, time: 0.104, data: 0.012) loss: 0.002 
(epoch: 213, iters: 1824, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 213, iters: 1904, time: 0.105, data: 0.012) loss: 0.010 
(epoch: 213, iters: 1984, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 213, iters: 2064, time: 0.105, data: 0.000) loss: 0.020 
(epoch: 213, iters: 2144, time: 0.106, data: 0.038) loss: 0.003 
(epoch: 213, iters: 2224, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 213, iters: 2304, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 213, iters: 2384, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 213, iters: 2464, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 213, iters: 2544, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 213, iters: 2624, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 213, iters: 2704, time: 0.105, data: 0.040) loss: 0.001 
(epoch: 213, iters: 2784, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 213, iters: 2864, time: 0.103, data: 0.012) loss: 0.169 
(epoch: 213, iters: 2944, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 213, iters: 3024, time: 0.105, data: 0.019) loss: 0.003 
(epoch: 213, iters: 3104, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 213, iters: 3184, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 213, iters: 3264, time: 0.105, data: 0.047) loss: 0.067 
(epoch: 213, iters: 3344, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 213, iters: 3424, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 213, iters: 3504, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 213, iters: 3584, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 213, iters: 3664, time: 0.100, data: 0.000) loss: 0.049 
saving the model at the end of epoch 213, iters 794064
End of epoch 213 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001886
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 213, TEST ACC: [94.992 %]

(epoch: 214, iters: 16, time: 0.118, data: 0.000) loss: 0.000 
saving the latest model (epoch 214, total_steps 794080)
(epoch: 214, iters: 96, time: 0.105, data: 0.012) loss: 0.003 
(epoch: 214, iters: 176, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 214, iters: 256, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 214, iters: 336, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 214, iters: 416, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 214, iters: 496, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 214, iters: 576, time: 0.105, data: 0.039) loss: 0.064 
(epoch: 214, iters: 656, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 214, iters: 736, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 214, iters: 816, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 214, iters: 896, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 214, iters: 976, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 214, iters: 1056, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 214, iters: 1136, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 214, iters: 1216, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 214, iters: 1296, time: 0.104, data: 0.011) loss: 0.002 
(epoch: 214, iters: 1376, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 214, iters: 1456, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 214, iters: 1536, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 214, iters: 1616, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 214, iters: 1696, time: 0.105, data: 0.038) loss: 0.008 
(epoch: 214, iters: 1776, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 214, iters: 1856, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 214, iters: 1936, time: 0.105, data: 0.000) loss: 0.017 
(epoch: 214, iters: 2016, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 214, iters: 2096, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 214, iters: 2176, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 214, iters: 2256, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 214, iters: 2336, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 214, iters: 2416, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 214, iters: 2496, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 214, iters: 2576, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 214, iters: 2656, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 214, iters: 2736, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 214, iters: 2816, time: 0.106, data: 0.039) loss: 0.004 
(epoch: 214, iters: 2896, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 214, iters: 2976, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 214, iters: 3056, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 214, iters: 3136, time: 0.104, data: 0.011) loss: 0.012 
(epoch: 214, iters: 3216, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 214, iters: 3296, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 214, iters: 3376, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 214, iters: 3456, time: 0.105, data: 0.000) loss: 0.032 
(epoch: 214, iters: 3536, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 214, iters: 3616, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 214, iters: 3696, time: 0.100, data: 0.011) loss: 0.001 
saving the model at the end of epoch 214, iters 797792
End of epoch 214 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001885
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 214, TEST ACC: [95.448 %]

saving the latest model (epoch 215, total_steps 797808)
(epoch: 215, iters: 48, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 215, iters: 128, time: 0.105, data: 0.025) loss: 0.000 
(epoch: 215, iters: 208, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 215, iters: 288, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 215, iters: 368, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 215, iters: 448, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 215, iters: 528, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 215, iters: 608, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 215, iters: 688, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 215, iters: 768, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 215, iters: 848, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 215, iters: 928, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 215, iters: 1008, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 215, iters: 1088, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 215, iters: 1168, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 215, iters: 1248, time: 0.105, data: 0.020) loss: 0.000 
(epoch: 215, iters: 1328, time: 0.107, data: 0.000) loss: 0.070 
(epoch: 215, iters: 1408, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 215, iters: 1488, time: 0.105, data: 0.048) loss: 0.000 
(epoch: 215, iters: 1568, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 215, iters: 1648, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 215, iters: 1728, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 215, iters: 1808, time: 0.105, data: 0.011) loss: 0.300 
(epoch: 215, iters: 1888, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 215, iters: 1968, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 215, iters: 2048, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 215, iters: 2128, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 215, iters: 2208, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 215, iters: 2288, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 215, iters: 2368, time: 0.104, data: 0.012) loss: 0.058 
(epoch: 215, iters: 2448, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 215, iters: 2528, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 215, iters: 2608, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 215, iters: 2688, time: 0.107, data: 0.000) loss: 0.003 
(epoch: 215, iters: 2768, time: 0.103, data: 0.012) loss: 0.010 
(epoch: 215, iters: 2848, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 215, iters: 2928, time: 0.106, data: 0.011) loss: 0.001 
(epoch: 215, iters: 3008, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 215, iters: 3088, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 215, iters: 3168, time: 0.106, data: 0.048) loss: 0.147 
(epoch: 215, iters: 3248, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 215, iters: 3328, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 215, iters: 3408, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 215, iters: 3488, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 215, iters: 3568, time: 0.106, data: 0.000) loss: 0.009 
(epoch: 215, iters: 3648, time: 0.099, data: 0.000) loss: 0.024 
(epoch: 215, iters: 3728, time: 0.066, data: 0.015) loss: 0.000 
saving the model at the end of epoch 215, iters 801520
End of epoch 215 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001884
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 215, TEST ACC: [93.778 %]

saving the latest model (epoch 216, total_steps 801536)
(epoch: 216, iters: 80, time: 0.106, data: 0.456) loss: 0.000 
(epoch: 216, iters: 160, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 216, iters: 240, time: 0.105, data: 0.039) loss: 0.106 
(epoch: 216, iters: 320, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 216, iters: 400, time: 0.104, data: 0.011) loss: 0.012 
(epoch: 216, iters: 480, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 216, iters: 560, time: 0.104, data: 0.011) loss: 0.080 
(epoch: 216, iters: 640, time: 0.106, data: 0.000) loss: 0.077 
(epoch: 216, iters: 720, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 216, iters: 800, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 216, iters: 880, time: 0.105, data: 0.000) loss: 0.035 
(epoch: 216, iters: 960, time: 0.103, data: 0.011) loss: 0.109 
(epoch: 216, iters: 1040, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 216, iters: 1120, time: 0.104, data: 0.011) loss: 0.031 
(epoch: 216, iters: 1200, time: 0.106, data: 0.000) loss: 0.162 
(epoch: 216, iters: 1280, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 216, iters: 1360, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 216, iters: 1440, time: 0.104, data: 0.000) loss: 0.367 
(epoch: 216, iters: 1520, time: 0.104, data: 0.012) loss: 0.002 
(epoch: 216, iters: 1600, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 216, iters: 1680, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 216, iters: 1760, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 216, iters: 1840, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 216, iters: 1920, time: 0.105, data: 0.038) loss: 0.019 
(epoch: 216, iters: 2000, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 216, iters: 2080, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 216, iters: 2160, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 216, iters: 2240, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 216, iters: 2320, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 216, iters: 2400, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 216, iters: 2480, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 216, iters: 2560, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 216, iters: 2640, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 216, iters: 2720, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 216, iters: 2800, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 216, iters: 2880, time: 0.105, data: 0.000) loss: 0.067 
(epoch: 216, iters: 2960, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 216, iters: 3040, time: 0.105, data: 0.038) loss: 0.004 
(epoch: 216, iters: 3120, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 216, iters: 3200, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 216, iters: 3280, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 216, iters: 3360, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 216, iters: 3440, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 216, iters: 3520, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 216, iters: 3600, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 216, iters: 3680, time: 0.100, data: 0.000) loss: 0.011 
saving the model at the end of epoch 216, iters 805248
End of epoch 216 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001883
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 216, TEST ACC: [94.537 %]

saving the latest model (epoch 217, total_steps 805264)
(epoch: 217, iters: 32, time: 0.101, data: 0.005) loss: 0.001 
(epoch: 217, iters: 112, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 217, iters: 192, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 217, iters: 272, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 217, iters: 352, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 217, iters: 432, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 217, iters: 512, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 217, iters: 592, time: 0.106, data: 0.011) loss: 0.000 
(epoch: 217, iters: 672, time: 0.106, data: 0.000) loss: 0.016 
(epoch: 217, iters: 752, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 217, iters: 832, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 217, iters: 912, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 217, iters: 992, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 217, iters: 1072, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 217, iters: 1152, time: 0.106, data: 0.012) loss: 0.000 
(epoch: 217, iters: 1232, time: 0.106, data: 0.000) loss: 0.019 
(epoch: 217, iters: 1312, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 217, iters: 1392, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 217, iters: 1472, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 217, iters: 1552, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 217, iters: 1632, time: 0.106, data: 0.000) loss: 0.024 
(epoch: 217, iters: 1712, time: 0.107, data: 0.012) loss: 0.000 
(epoch: 217, iters: 1792, time: 0.107, data: 0.000) loss: 0.027 
(epoch: 217, iters: 1872, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 217, iters: 1952, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 217, iters: 2032, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 217, iters: 2112, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 217, iters: 2192, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 217, iters: 2272, time: 0.105, data: 0.011) loss: 0.011 
(epoch: 217, iters: 2352, time: 0.107, data: 0.000) loss: 0.071 
(epoch: 217, iters: 2432, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 217, iters: 2512, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 217, iters: 2592, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 217, iters: 2672, time: 0.102, data: 0.012) loss: 0.003 
(epoch: 217, iters: 2752, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 217, iters: 2832, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 217, iters: 2912, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 217, iters: 2992, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 217, iters: 3072, time: 0.106, data: 0.039) loss: 0.008 
(epoch: 217, iters: 3152, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 217, iters: 3232, time: 0.104, data: 0.020) loss: 0.001 
(epoch: 217, iters: 3312, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 217, iters: 3392, time: 0.106, data: 0.011) loss: 0.062 
(epoch: 217, iters: 3472, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 217, iters: 3552, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 217, iters: 3632, time: 0.103, data: 0.038) loss: 0.000 
(epoch: 217, iters: 3712, time: 0.101, data: 0.000) loss: 0.158 
saving the model at the end of epoch 217, iters 808976
End of epoch 217 / 2100 	 Time Taken: 395 sec
learning rate = 0.0001882
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 217, TEST ACC: [90.592 %]

saving the latest model (epoch 218, total_steps 808992)
(epoch: 218, iters: 64, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 218, iters: 144, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 218, iters: 224, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 218, iters: 304, time: 0.105, data: 0.012) loss: 0.002 
(epoch: 218, iters: 384, time: 0.106, data: 0.000) loss: 0.012 
(epoch: 218, iters: 464, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 218, iters: 544, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 218, iters: 624, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 218, iters: 704, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 218, iters: 784, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 218, iters: 864, time: 0.104, data: 0.011) loss: 0.023 
(epoch: 218, iters: 944, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 218, iters: 1024, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 218, iters: 1104, time: 0.105, data: 0.048) loss: 0.004 
(epoch: 218, iters: 1184, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 218, iters: 1264, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 218, iters: 1344, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 218, iters: 1424, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 218, iters: 1504, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 218, iters: 1584, time: 0.104, data: 0.000) loss: 0.147 
(epoch: 218, iters: 1664, time: 0.105, data: 0.038) loss: 0.005 
(epoch: 218, iters: 1744, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 218, iters: 1824, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 218, iters: 1904, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 218, iters: 1984, time: 0.105, data: 0.012) loss: 0.005 
(epoch: 218, iters: 2064, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 218, iters: 2144, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 218, iters: 2224, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 218, iters: 2304, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 218, iters: 2384, time: 0.102, data: 0.012) loss: 0.001 
(epoch: 218, iters: 2464, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 218, iters: 2544, time: 0.105, data: 0.011) loss: 0.071 
(epoch: 218, iters: 2624, time: 0.106, data: 0.000) loss: 0.024 
(epoch: 218, iters: 2704, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 218, iters: 2784, time: 0.105, data: 0.048) loss: 0.005 
(epoch: 218, iters: 2864, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 218, iters: 2944, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 218, iters: 3024, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 218, iters: 3104, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 218, iters: 3184, time: 0.106, data: 0.000) loss: 0.059 
(epoch: 218, iters: 3264, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 218, iters: 3344, time: 0.104, data: 0.038) loss: 0.000 
(epoch: 218, iters: 3424, time: 0.106, data: 0.000) loss: 0.005 
(epoch: 218, iters: 3504, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 218, iters: 3584, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 218, iters: 3664, time: 0.100, data: 0.011) loss: 0.004 
saving the model at the end of epoch 218, iters 812704
End of epoch 218 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001881
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 218, TEST ACC: [95.751 %]

(epoch: 219, iters: 16, time: 0.119, data: 0.000) loss: 0.000 
saving the latest model (epoch 219, total_steps 812720)
(epoch: 219, iters: 96, time: 0.106, data: 0.011) loss: 0.000 
(epoch: 219, iters: 176, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 219, iters: 256, time: 0.105, data: 0.000) loss: 0.060 
(epoch: 219, iters: 336, time: 0.105, data: 0.011) loss: 0.011 
(epoch: 219, iters: 416, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 219, iters: 496, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 219, iters: 576, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 219, iters: 656, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 219, iters: 736, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 219, iters: 816, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 219, iters: 896, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 219, iters: 976, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 219, iters: 1056, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 219, iters: 1136, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 219, iters: 1216, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 219, iters: 1296, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 219, iters: 1376, time: 0.105, data: 0.000) loss: 0.064 
(epoch: 219, iters: 1456, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 219, iters: 1536, time: 0.107, data: 0.000) loss: 0.019 
(epoch: 219, iters: 1616, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 219, iters: 1696, time: 0.104, data: 0.039) loss: 0.000 
(epoch: 219, iters: 1776, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 219, iters: 1856, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 219, iters: 1936, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 219, iters: 2016, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 219, iters: 2096, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 219, iters: 2176, time: 0.105, data: 0.000) loss: 0.025 
(epoch: 219, iters: 2256, time: 0.107, data: 0.039) loss: 0.000 
(epoch: 219, iters: 2336, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 219, iters: 2416, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 219, iters: 2496, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 219, iters: 2576, time: 0.105, data: 0.011) loss: 0.002 
(epoch: 219, iters: 2656, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 219, iters: 2736, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 219, iters: 2816, time: 0.106, data: 0.038) loss: 0.001 
(epoch: 219, iters: 2896, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 219, iters: 2976, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 219, iters: 3056, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 219, iters: 3136, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 219, iters: 3216, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 219, iters: 3296, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 219, iters: 3376, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 219, iters: 3456, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 219, iters: 3536, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 219, iters: 3616, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 219, iters: 3696, time: 0.100, data: 0.011) loss: 0.001 
saving the model at the end of epoch 219, iters 816432
End of epoch 219 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001880
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 219, TEST ACC: [95.296 %]

saving the latest model (epoch 220, total_steps 816448)
(epoch: 220, iters: 48, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 220, iters: 128, time: 0.105, data: 0.025) loss: 0.000 
(epoch: 220, iters: 208, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 220, iters: 288, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 220, iters: 368, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 220, iters: 448, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 220, iters: 528, time: 0.105, data: 0.000) loss: 0.024 
(epoch: 220, iters: 608, time: 0.104, data: 0.000) loss: 0.055 
(epoch: 220, iters: 688, time: 0.105, data: 0.038) loss: 0.191 
(epoch: 220, iters: 768, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 220, iters: 848, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 220, iters: 928, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 220, iters: 1008, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 220, iters: 1088, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 220, iters: 1168, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 220, iters: 1248, time: 0.106, data: 0.046) loss: 0.000 
(epoch: 220, iters: 1328, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 220, iters: 1408, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 220, iters: 1488, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 220, iters: 1568, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 220, iters: 1648, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 220, iters: 1728, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 220, iters: 1808, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 220, iters: 1888, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 220, iters: 1968, time: 0.103, data: 0.012) loss: 0.102 
(epoch: 220, iters: 2048, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 220, iters: 2128, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 220, iters: 2208, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 220, iters: 2288, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 220, iters: 2368, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 220, iters: 2448, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 220, iters: 2528, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 220, iters: 2608, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 220, iters: 2688, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 220, iters: 2768, time: 0.106, data: 0.000) loss: 0.045 
(epoch: 220, iters: 2848, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 220, iters: 2928, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 220, iters: 3008, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 220, iters: 3088, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 220, iters: 3168, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 220, iters: 3248, time: 0.103, data: 0.011) loss: 0.005 
(epoch: 220, iters: 3328, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 220, iters: 3408, time: 0.105, data: 0.000) loss: 0.041 
(epoch: 220, iters: 3488, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 220, iters: 3568, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 220, iters: 3648, time: 0.099, data: 0.011) loss: 0.000 
(epoch: 220, iters: 3728, time: 0.065, data: 0.000) loss: 0.000 
saving the model at the end of epoch 220, iters 820160
End of epoch 220 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001879
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 220, TEST ACC: [94.082 %]

saving the latest model (epoch 221, total_steps 820176)
(epoch: 221, iters: 80, time: 0.104, data: 0.434) loss: 0.006 
(epoch: 221, iters: 160, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 221, iters: 240, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 221, iters: 320, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 221, iters: 400, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 221, iters: 480, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 221, iters: 560, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 221, iters: 640, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 221, iters: 720, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 221, iters: 800, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 221, iters: 880, time: 0.105, data: 0.040) loss: 0.000 
(epoch: 221, iters: 960, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 221, iters: 1040, time: 0.104, data: 0.012) loss: 0.016 
(epoch: 221, iters: 1120, time: 0.105, data: 0.000) loss: 0.004 
(epoch: 221, iters: 1200, time: 0.106, data: 0.011) loss: 0.000 
(epoch: 221, iters: 1280, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 221, iters: 1360, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 221, iters: 1440, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 221, iters: 1520, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 221, iters: 1600, time: 0.102, data: 0.012) loss: 0.028 
(epoch: 221, iters: 1680, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 221, iters: 1760, time: 0.105, data: 0.011) loss: 0.011 
(epoch: 221, iters: 1840, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 221, iters: 1920, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 221, iters: 2000, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 221, iters: 2080, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 221, iters: 2160, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 221, iters: 2240, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 221, iters: 2320, time: 0.106, data: 0.011) loss: 0.001 
(epoch: 221, iters: 2400, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 221, iters: 2480, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 221, iters: 2560, time: 0.105, data: 0.039) loss: 0.004 
(epoch: 221, iters: 2640, time: 0.106, data: 0.000) loss: 0.019 
(epoch: 221, iters: 2720, time: 0.102, data: 0.012) loss: 0.324 
(epoch: 221, iters: 2800, time: 0.105, data: 0.000) loss: 0.038 
(epoch: 221, iters: 2880, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 221, iters: 2960, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 221, iters: 3040, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 221, iters: 3120, time: 0.105, data: 0.040) loss: 0.000 
(epoch: 221, iters: 3200, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 221, iters: 3280, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 221, iters: 3360, time: 0.104, data: 0.000) loss: 0.084 
(epoch: 221, iters: 3440, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 221, iters: 3520, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 221, iters: 3600, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 221, iters: 3680, time: 0.100, data: 0.048) loss: 0.000 
saving the model at the end of epoch 221, iters 823888
End of epoch 221 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001878
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 221, TEST ACC: [93.778 %]

saving the latest model (epoch 222, total_steps 823904)
(epoch: 222, iters: 32, time: 0.101, data: 0.000) loss: 0.000 
(epoch: 222, iters: 112, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 222, iters: 192, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 222, iters: 272, time: 0.104, data: 0.048) loss: 0.000 
(epoch: 222, iters: 352, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 222, iters: 432, time: 0.103, data: 0.011) loss: 0.152 
(epoch: 222, iters: 512, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 222, iters: 592, time: 0.106, data: 0.011) loss: 0.003 
(epoch: 222, iters: 672, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 222, iters: 752, time: 0.105, data: 0.000) loss: 0.033 
(epoch: 222, iters: 832, time: 0.104, data: 0.038) loss: 0.004 
(epoch: 222, iters: 912, time: 0.106, data: 0.000) loss: 0.108 
(epoch: 222, iters: 992, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 222, iters: 1072, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 222, iters: 1152, time: 0.106, data: 0.011) loss: 0.064 
(epoch: 222, iters: 1232, time: 0.105, data: 0.000) loss: 0.016 
(epoch: 222, iters: 1312, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 222, iters: 1392, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 222, iters: 1472, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 222, iters: 1552, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 222, iters: 1632, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 222, iters: 1712, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 222, iters: 1792, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 222, iters: 1872, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 222, iters: 1952, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 222, iters: 2032, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 222, iters: 2112, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 222, iters: 2192, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 222, iters: 2272, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 222, iters: 2352, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 222, iters: 2432, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 222, iters: 2512, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 222, iters: 2592, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 222, iters: 2672, time: 0.103, data: 0.011) loss: 0.091 
(epoch: 222, iters: 2752, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 222, iters: 2832, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 222, iters: 2912, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 222, iters: 2992, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 222, iters: 3072, time: 0.105, data: 0.038) loss: 0.002 
(epoch: 222, iters: 3152, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 222, iters: 3232, time: 0.102, data: 0.011) loss: 0.006 
(epoch: 222, iters: 3312, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 222, iters: 3392, time: 0.105, data: 0.011) loss: 0.003 
(epoch: 222, iters: 3472, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 222, iters: 3552, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 222, iters: 3632, time: 0.103, data: 0.048) loss: 0.003 
(epoch: 222, iters: 3712, time: 0.102, data: 0.000) loss: 0.000 
saving the model at the end of epoch 222, iters 827616
End of epoch 222 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001877
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 222, TEST ACC: [95.448 %]

saving the latest model (epoch 223, total_steps 827632)
(epoch: 223, iters: 64, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 223, iters: 144, time: 0.103, data: 0.012) loss: 0.001 
(epoch: 223, iters: 224, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 223, iters: 304, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 223, iters: 384, time: 0.107, data: 0.000) loss: 0.002 
(epoch: 223, iters: 464, time: 0.104, data: 0.000) loss: 0.056 
(epoch: 223, iters: 544, time: 0.104, data: 0.039) loss: 0.000 
(epoch: 223, iters: 624, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 223, iters: 704, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 223, iters: 784, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 223, iters: 864, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 223, iters: 944, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 223, iters: 1024, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 223, iters: 1104, time: 0.104, data: 0.038) loss: 0.000 
(epoch: 223, iters: 1184, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 223, iters: 1264, time: 0.102, data: 0.011) loss: 0.122 
(epoch: 223, iters: 1344, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 223, iters: 1424, time: 0.104, data: 0.011) loss: 0.006 
(epoch: 223, iters: 1504, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 223, iters: 1584, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 223, iters: 1664, time: 0.104, data: 0.047) loss: 0.000 
(epoch: 223, iters: 1744, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 223, iters: 1824, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 223, iters: 1904, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 223, iters: 1984, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 223, iters: 2064, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 223, iters: 2144, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 223, iters: 2224, time: 0.105, data: 0.038) loss: 0.315 
(epoch: 223, iters: 2304, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 223, iters: 2384, time: 0.103, data: 0.012) loss: 0.045 
(epoch: 223, iters: 2464, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 223, iters: 2544, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 223, iters: 2624, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 223, iters: 2704, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 223, iters: 2784, time: 0.106, data: 0.039) loss: 0.001 
(epoch: 223, iters: 2864, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 223, iters: 2944, time: 0.105, data: 0.011) loss: 0.008 
(epoch: 223, iters: 3024, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 223, iters: 3104, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 223, iters: 3184, time: 0.106, data: 0.000) loss: 0.050 
(epoch: 223, iters: 3264, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 223, iters: 3344, time: 0.105, data: 0.038) loss: 0.003 
(epoch: 223, iters: 3424, time: 0.106, data: 0.000) loss: 0.006 
(epoch: 223, iters: 3504, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 223, iters: 3584, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 223, iters: 3664, time: 0.099, data: 0.012) loss: 0.000 
saving the model at the end of epoch 223, iters 831344
End of epoch 223 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001876
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 223, TEST ACC: [92.261 %]

(epoch: 224, iters: 16, time: 0.115, data: 0.000) loss: 0.000 
saving the latest model (epoch 224, total_steps 831360)
(epoch: 224, iters: 96, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 224, iters: 176, time: 0.104, data: 0.011) loss: 0.017 
(epoch: 224, iters: 256, time: 0.105, data: 0.000) loss: 0.172 
(epoch: 224, iters: 336, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 224, iters: 416, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 224, iters: 496, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 224, iters: 576, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 224, iters: 656, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 224, iters: 736, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 224, iters: 816, time: 0.105, data: 0.000) loss: 0.014 
(epoch: 224, iters: 896, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 224, iters: 976, time: 0.105, data: 0.000) loss: 0.011 
(epoch: 224, iters: 1056, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 224, iters: 1136, time: 0.105, data: 0.039) loss: 0.010 
(epoch: 224, iters: 1216, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 224, iters: 1296, time: 0.103, data: 0.012) loss: 0.008 
(epoch: 224, iters: 1376, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 224, iters: 1456, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 224, iters: 1536, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 224, iters: 1616, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 224, iters: 1696, time: 0.104, data: 0.038) loss: 0.000 
(epoch: 224, iters: 1776, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 224, iters: 1856, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 224, iters: 1936, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 224, iters: 2016, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 224, iters: 2096, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 224, iters: 2176, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 224, iters: 2256, time: 0.105, data: 0.048) loss: 0.002 
(epoch: 224, iters: 2336, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 224, iters: 2416, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 224, iters: 2496, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 224, iters: 2576, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 224, iters: 2656, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 224, iters: 2736, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 224, iters: 2816, time: 0.106, data: 0.038) loss: 0.017 
(epoch: 224, iters: 2896, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 224, iters: 2976, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 224, iters: 3056, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 224, iters: 3136, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 224, iters: 3216, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 224, iters: 3296, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 224, iters: 3376, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 224, iters: 3456, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 224, iters: 3536, time: 0.103, data: 0.011) loss: 0.020 
(epoch: 224, iters: 3616, time: 0.106, data: 0.000) loss: 0.057 
(epoch: 224, iters: 3696, time: 0.099, data: 0.011) loss: 0.000 
saving the model at the end of epoch 224, iters 835072
End of epoch 224 / 2100 	 Time Taken: 393 sec
learning rate = 0.0001875
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 224, TEST ACC: [96.206 %]

saving the latest model (epoch 225, total_steps 835088)
(epoch: 225, iters: 48, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 225, iters: 128, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 225, iters: 208, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 225, iters: 288, time: 0.104, data: 0.011) loss: 0.296 
(epoch: 225, iters: 368, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 225, iters: 448, time: 0.103, data: 0.011) loss: 0.204 
(epoch: 225, iters: 528, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 225, iters: 608, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 225, iters: 688, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 225, iters: 768, time: 0.106, data: 0.000) loss: 0.003 
(epoch: 225, iters: 848, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 225, iters: 928, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 225, iters: 1008, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 225, iters: 1088, time: 0.105, data: 0.000) loss: 0.032 
(epoch: 225, iters: 1168, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 225, iters: 1248, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 225, iters: 1328, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 225, iters: 1408, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 225, iters: 1488, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 225, iters: 1568, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 225, iters: 1648, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 225, iters: 1728, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 225, iters: 1808, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 225, iters: 1888, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 225, iters: 1968, time: 0.103, data: 0.011) loss: 0.003 
(epoch: 225, iters: 2048, time: 0.105, data: 0.000) loss: 0.101 
(epoch: 225, iters: 2128, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 225, iters: 2208, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 225, iters: 2288, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 225, iters: 2368, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 225, iters: 2448, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 225, iters: 2528, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 225, iters: 2608, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 225, iters: 2688, time: 0.104, data: 0.011) loss: 0.125 
(epoch: 225, iters: 2768, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 225, iters: 2848, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 225, iters: 2928, time: 0.107, data: 0.039) loss: 0.000 
(epoch: 225, iters: 3008, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 225, iters: 3088, time: 0.103, data: 0.012) loss: 0.008 
(epoch: 225, iters: 3168, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 225, iters: 3248, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 225, iters: 3328, time: 0.106, data: 0.000) loss: 0.011 
(epoch: 225, iters: 3408, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 225, iters: 3488, time: 0.105, data: 0.038) loss: 0.010 
(epoch: 225, iters: 3568, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 225, iters: 3648, time: 0.098, data: 0.011) loss: 0.000 
(epoch: 225, iters: 3728, time: 0.066, data: 0.000) loss: 0.002 
saving the model at the end of epoch 225, iters 838800
End of epoch 225 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001874
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 225, TEST ACC: [93.93 %]

saving the latest model (epoch 226, total_steps 838816)
(epoch: 226, iters: 80, time: 0.105, data: 0.439) loss: 0.001 
(epoch: 226, iters: 160, time: 0.105, data: 0.000) loss: 0.005 
(epoch: 226, iters: 240, time: 0.105, data: 0.039) loss: 0.001 
(epoch: 226, iters: 320, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 226, iters: 400, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 226, iters: 480, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 226, iters: 560, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 226, iters: 640, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 226, iters: 720, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 226, iters: 800, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 226, iters: 880, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 226, iters: 960, time: 0.103, data: 0.011) loss: 0.016 
(epoch: 226, iters: 1040, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 226, iters: 1120, time: 0.104, data: 0.011) loss: 0.192 
(epoch: 226, iters: 1200, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 226, iters: 1280, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 226, iters: 1360, time: 0.106, data: 0.039) loss: 0.036 
(epoch: 226, iters: 1440, time: 0.106, data: 0.000) loss: 0.281 
(epoch: 226, iters: 1520, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 226, iters: 1600, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 226, iters: 1680, time: 0.104, data: 0.011) loss: 0.003 
(epoch: 226, iters: 1760, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 226, iters: 1840, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 226, iters: 1920, time: 0.105, data: 0.038) loss: 0.108 
(epoch: 226, iters: 2000, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 226, iters: 2080, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 226, iters: 2160, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 226, iters: 2240, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 226, iters: 2320, time: 0.107, data: 0.000) loss: 0.004 
(epoch: 226, iters: 2400, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 226, iters: 2480, time: 0.107, data: 0.039) loss: 0.001 
(epoch: 226, iters: 2560, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 226, iters: 2640, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 226, iters: 2720, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 226, iters: 2800, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 226, iters: 2880, time: 0.106, data: 0.000) loss: 0.007 
(epoch: 226, iters: 2960, time: 0.104, data: 0.000) loss: 0.005 
(epoch: 226, iters: 3040, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 226, iters: 3120, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 226, iters: 3200, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 226, iters: 3280, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 226, iters: 3360, time: 0.104, data: 0.011) loss: 0.011 
(epoch: 226, iters: 3440, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 226, iters: 3520, time: 0.105, data: 0.000) loss: 0.024 
(epoch: 226, iters: 3600, time: 0.105, data: 0.038) loss: 0.001 
(epoch: 226, iters: 3680, time: 0.100, data: 0.000) loss: 0.001 
saving the model at the end of epoch 226, iters 842528
End of epoch 226 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001873
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 226, TEST ACC: [94.082 %]

saving the latest model (epoch 227, total_steps 842544)
(epoch: 227, iters: 32, time: 0.099, data: 0.004) loss: 0.000 
(epoch: 227, iters: 112, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 227, iters: 192, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 227, iters: 272, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 227, iters: 352, time: 0.106, data: 0.038) loss: 0.000 
(epoch: 227, iters: 432, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 227, iters: 512, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 227, iters: 592, time: 0.105, data: 0.000) loss: 0.040 
(epoch: 227, iters: 672, time: 0.103, data: 0.011) loss: 0.001 
(epoch: 227, iters: 752, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 227, iters: 832, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 227, iters: 912, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 227, iters: 992, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 227, iters: 1072, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 227, iters: 1152, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 227, iters: 1232, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 227, iters: 1312, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 227, iters: 1392, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 227, iters: 1472, time: 0.105, data: 0.047) loss: 0.111 
(epoch: 227, iters: 1552, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 227, iters: 1632, time: 0.104, data: 0.012) loss: 0.001 
(epoch: 227, iters: 1712, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 227, iters: 1792, time: 0.105, data: 0.011) loss: 0.008 
(epoch: 227, iters: 1872, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 227, iters: 1952, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 227, iters: 2032, time: 0.106, data: 0.038) loss: 0.012 
(epoch: 227, iters: 2112, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 227, iters: 2192, time: 0.102, data: 0.011) loss: 0.002 
(epoch: 227, iters: 2272, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 227, iters: 2352, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 227, iters: 2432, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 227, iters: 2512, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 227, iters: 2592, time: 0.105, data: 0.046) loss: 0.000 
(epoch: 227, iters: 2672, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 227, iters: 2752, time: 0.104, data: 0.020) loss: 0.001 
(epoch: 227, iters: 2832, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 227, iters: 2912, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 227, iters: 2992, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 227, iters: 3072, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 227, iters: 3152, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 227, iters: 3232, time: 0.105, data: 0.000) loss: 0.021 
(epoch: 227, iters: 3312, time: 0.102, data: 0.012) loss: 0.000 
(epoch: 227, iters: 3392, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 227, iters: 3472, time: 0.105, data: 0.011) loss: 0.008 
(epoch: 227, iters: 3552, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 227, iters: 3632, time: 0.102, data: 0.000) loss: 0.006 
(epoch: 227, iters: 3712, time: 0.100, data: 0.035) loss: 0.000 
saving the model at the end of epoch 227, iters 846256
End of epoch 227 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001872
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 227, TEST ACC: [93.627 %]

saving the latest model (epoch 228, total_steps 846272)
(epoch: 228, iters: 64, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 228, iters: 144, time: 0.105, data: 0.025) loss: 0.000 
(epoch: 228, iters: 224, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 228, iters: 304, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 228, iters: 384, time: 0.106, data: 0.000) loss: 0.004 
(epoch: 228, iters: 464, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 228, iters: 544, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 228, iters: 624, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 228, iters: 704, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 228, iters: 784, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 228, iters: 864, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 228, iters: 944, time: 0.105, data: 0.000) loss: 0.134 
(epoch: 228, iters: 1024, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 228, iters: 1104, time: 0.105, data: 0.000) loss: 0.003 
(epoch: 228, iters: 1184, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 228, iters: 1264, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 228, iters: 1344, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 228, iters: 1424, time: 0.103, data: 0.011) loss: 0.006 
(epoch: 228, iters: 1504, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 228, iters: 1584, time: 0.105, data: 0.012) loss: 0.000 
(epoch: 228, iters: 1664, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 228, iters: 1744, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 228, iters: 1824, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 228, iters: 1904, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 228, iters: 1984, time: 0.102, data: 0.012) loss: 0.000 
(epoch: 228, iters: 2064, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 228, iters: 2144, time: 0.105, data: 0.012) loss: 0.001 
(epoch: 228, iters: 2224, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 228, iters: 2304, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 228, iters: 2384, time: 0.106, data: 0.047) loss: 0.000 
(epoch: 228, iters: 2464, time: 0.106, data: 0.000) loss: 0.023 
(epoch: 228, iters: 2544, time: 0.103, data: 0.011) loss: 0.004 
(epoch: 228, iters: 2624, time: 0.105, data: 0.000) loss: 0.008 
(epoch: 228, iters: 2704, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 228, iters: 2784, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 228, iters: 2864, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 228, iters: 2944, time: 0.106, data: 0.038) loss: 0.006 
(epoch: 228, iters: 3024, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 228, iters: 3104, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 228, iters: 3184, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 228, iters: 3264, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 228, iters: 3344, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 228, iters: 3424, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 228, iters: 3504, time: 0.105, data: 0.038) loss: 0.012 
(epoch: 228, iters: 3584, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 228, iters: 3664, time: 0.100, data: 0.012) loss: 0.000 
saving the model at the end of epoch 228, iters 849984
End of epoch 228 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001871
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 228, TEST ACC: [95.144 %]

(epoch: 229, iters: 16, time: 0.117, data: 0.012) loss: 0.000 
saving the latest model (epoch 229, total_steps 850000)
(epoch: 229, iters: 96, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 229, iters: 176, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 229, iters: 256, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 229, iters: 336, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 229, iters: 416, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 229, iters: 496, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 229, iters: 576, time: 0.107, data: 0.047) loss: 0.000 
(epoch: 229, iters: 656, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 229, iters: 736, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 229, iters: 816, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 229, iters: 896, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 229, iters: 976, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 229, iters: 1056, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 229, iters: 1136, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 229, iters: 1216, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 229, iters: 1296, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 229, iters: 1376, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 229, iters: 1456, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 229, iters: 1536, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 229, iters: 1616, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 229, iters: 1696, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 229, iters: 1776, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 229, iters: 1856, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 229, iters: 1936, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 229, iters: 2016, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 229, iters: 2096, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 229, iters: 2176, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 229, iters: 2256, time: 0.105, data: 0.048) loss: 0.000 
(epoch: 229, iters: 2336, time: 0.106, data: 0.000) loss: 0.002 
(epoch: 229, iters: 2416, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 229, iters: 2496, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 229, iters: 2576, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 229, iters: 2656, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 229, iters: 2736, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 229, iters: 2816, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 229, iters: 2896, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 229, iters: 2976, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 229, iters: 3056, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 229, iters: 3136, time: 0.104, data: 0.011) loss: 0.060 
(epoch: 229, iters: 3216, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 229, iters: 3296, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 229, iters: 3376, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 229, iters: 3456, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 229, iters: 3536, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 229, iters: 3616, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 229, iters: 3696, time: 0.098, data: 0.011) loss: 0.116 
saving the model at the end of epoch 229, iters 853712
End of epoch 229 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001870
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 229, TEST ACC: [94.992 %]

saving the latest model (epoch 230, total_steps 853728)
(epoch: 230, iters: 48, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 230, iters: 128, time: 0.104, data: 0.025) loss: 0.000 
(epoch: 230, iters: 208, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 230, iters: 288, time: 0.105, data: 0.000) loss: 0.258 
(epoch: 230, iters: 368, time: 0.106, data: 0.039) loss: 0.000 
(epoch: 230, iters: 448, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 230, iters: 528, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 230, iters: 608, time: 0.105, data: 0.000) loss: 0.038 
(epoch: 230, iters: 688, time: 0.104, data: 0.011) loss: 0.001 
(epoch: 230, iters: 768, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 230, iters: 848, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 230, iters: 928, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 230, iters: 1008, time: 0.105, data: 0.000) loss: 0.013 
(epoch: 230, iters: 1088, time: 0.103, data: 0.011) loss: 0.000 
(epoch: 230, iters: 1168, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 230, iters: 1248, time: 0.105, data: 0.011) loss: 0.001 
(epoch: 230, iters: 1328, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 230, iters: 1408, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 230, iters: 1488, time: 0.105, data: 0.039) loss: 0.000 
(epoch: 230, iters: 1568, time: 0.105, data: 0.000) loss: 0.006 
(epoch: 230, iters: 1648, time: 0.102, data: 0.011) loss: 0.000 
(epoch: 230, iters: 1728, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 230, iters: 1808, time: 0.104, data: 0.011) loss: 0.000 
(epoch: 230, iters: 1888, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 230, iters: 1968, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 230, iters: 2048, time: 0.105, data: 0.047) loss: 0.000 
(epoch: 230, iters: 2128, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 230, iters: 2208, time: 0.103, data: 0.021) loss: 0.000 
(epoch: 230, iters: 2288, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 230, iters: 2368, time: 0.106, data: 0.011) loss: 0.000 
(epoch: 230, iters: 2448, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 230, iters: 2528, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 230, iters: 2608, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 230, iters: 2688, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 230, iters: 2768, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 230, iters: 2848, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 230, iters: 2928, time: 0.104, data: 0.012) loss: 0.000 
(epoch: 230, iters: 3008, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 230, iters: 3088, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 230, iters: 3168, time: 0.107, data: 0.038) loss: 0.000 
(epoch: 230, iters: 3248, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 230, iters: 3328, time: 0.103, data: 0.012) loss: 0.000 
(epoch: 230, iters: 3408, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 230, iters: 3488, time: 0.105, data: 0.012) loss: 0.050 
(epoch: 230, iters: 3568, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 230, iters: 3648, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 230, iters: 3728, time: 0.065, data: 0.014) loss: 0.000 
saving the model at the end of epoch 230, iters 857440
End of epoch 230 / 2100 	 Time Taken: 394 sec
learning rate = 0.0001869
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes_original/latest_net.pth
epoch: 230, TEST ACC: [95.751 %]

saving the latest model (epoch 231, total_steps 857456)
(epoch: 231, iters: 80, time: 0.103, data: 0.478) loss: 0.059 
(epoch: 231, iters: 160, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 231, iters: 240, time: 0.104, data: 0.011) loss: 0.009 
(epoch: 231, iters: 320, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 231, iters: 400, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 231, iters: 480, time: 0.105, data: 0.038) loss: 0.004 
(epoch: 231, iters: 560, time: 0.106, data: 0.000) loss: 0.023 
(epoch: 231, iters: 640, time: 0.103, data: 0.011) loss: 0.002 
(epoch: 231, iters: 720, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 231, iters: 800, time: 0.105, data: 0.011) loss: 0.000 
(epoch: 231, iters: 880, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 231, iters: 960, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 231, iters: 1040, time: 0.105, data: 0.038) loss: 0.000 
(epoch: 231, iters: 1120, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 231, iters: 1200, time: 0.104, data: 0.011) loss: 0.000 
Traceback (most recent call last):
  File "train.py", line 35, in <module>
    writer.print_current_losses(epoch, epoch_iter, loss, t, t_data)
  File "/home/dpere013/MeshCNN/util/writer.py", line 42, in print_current_losses
    with open(self.log_name, "a") as log_file:
FileNotFoundError: [Errno 2] No such file or directory: './checkpoints/cubes_original/loss_log.txt'

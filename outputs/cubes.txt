
Due to MODULEPATH changes, the following have been reloaded:
  1) python/3.6

/usr/bin/env: bash: No such file or directory

Due to MODULEPATH changes, the following have been reloaded:
  1) python/3.6

/usr/bin/env: bash: No such file or directory

Due to MODULEPATH changes, the following have been reloaded:
  1) python/3.6

scripts/cubes/train.sh: line 2: : command not found
tensorboard X not installed, visualizing wont be available
------------ Options -------------
arch: mconvnet
batch_size: 16
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
dataroot: datasets/shrec_16
dataset_mode: classification
epoch_count: 1
export_folder: 
fc_n: 100
flip_edges: 0
gpu_ids: [0]
init_gain: 0.02
init_type: normal
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
name: debug2
ncf: [16, 32, 32]
ninput_edges: 750
niter: 100
niter_decay: 2000
no_vis: False
norm: batch
num_aug: 10
num_groups: 16
num_threads: 3
phase: train
pool_res: [1140, 780, 580]
print_freq: 10
resblocks: 0
run_test_freq: 1
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: False
seed: None
serial_batches: False
slide_verts: 0
verbose_plot: False
which_epoch: latest
-------------- End ----------------
loaded mean / std from cache
#training meshes = 480
---------- Network initialized -------------
[Network] Total number of parameters : 0.015 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 16)
(epoch: 1, iters: 80, time: 0.038, data: 1.151) loss: 3.405 
(epoch: 1, iters: 160, time: 0.038, data: 0.000) loss: 3.400 
(epoch: 1, iters: 240, time: 0.037, data: 0.031) loss: 3.409 
(epoch: 1, iters: 320, time: 0.039, data: 0.032) loss: 3.391 
(epoch: 1, iters: 400, time: 0.035, data: 0.011) loss: 3.380 
(epoch: 1, iters: 480, time: 0.032, data: 0.000) loss: 3.407 
saving the model at the end of epoch 1, iters 480
End of epoch 1 / 2100 	 Time Taken: 21 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/debug2/latest_net.pth
epoch: 1, TEST ACC: [5.8333 %]

saving the latest model (epoch 2, total_steps 496)
(epoch: 2, iters: 80, time: 0.039, data: 0.577) loss: 3.390 
(epoch: 2, iters: 160, time: 0.038, data: 0.000) loss: 3.386 
(epoch: 2, iters: 240, time: 0.037, data: 0.000) loss: 3.396 
(epoch: 2, iters: 320, time: 0.037, data: 0.031) loss: 3.398 
(epoch: 2, iters: 400, time: 0.033, data: 0.037) loss: 3.380 
(epoch: 2, iters: 480, time: 0.031, data: 0.011) loss: 3.385 
saving the model at the end of epoch 2, iters 960
End of epoch 2 / 2100 	 Time Taken: 18 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/debug2/latest_net.pth
epoch: 2, TEST ACC: [5.0 %]

saving the latest model (epoch 3, total_steps 976)
(epoch: 3, iters: 80, time: 0.037, data: 0.529) loss: 3.367 
(epoch: 3, iters: 160, time: 0.037, data: 0.000) loss: 3.376 
(epoch: 3, iters: 240, time: 0.037, data: 0.000) loss: 3.397 
(epoch: 3, iters: 320, time: 0.036, data: 0.037) loss: 3.418 
(epoch: 3, iters: 400, time: 0.034, data: 0.031) loss: 3.399 
(epoch: 3, iters: 480, time: 0.031, data: 0.011) loss: 3.370 
saving the model at the end of epoch 3, iters 1440
End of epoch 3 / 2100 	 Time Taken: 18 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/debug2/latest_net.pth
epoch: 3, TEST ACC: [10.0 %]

slurmstepd: error: *** JOB 8926043 ON coreV4-24-v100-004 CANCELLED AT 2019-09-05T15:09:11 ***

Due to MODULEPATH changes, the following have been reloaded:
  1) python/3.6

tensorboard X not installed, visualizing wont be available
------------ Options -------------
arch: mconvnet
batch_size: 16
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
dataroot: datasets/cubes
dataset_mode: classification
epoch_count: 1
export_folder: 
fc_n: 100
flip_edges: 0.2
gpu_ids: [0]
init_gain: 0.02
init_type: normal
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
name: cubes
ncf: [64, 128, 256, 256]
ninput_edges: 750
niter: 100
niter_decay: 2000
no_vis: False
norm: group
num_aug: 20
num_groups: 16
num_threads: 3
phase: train
pool_res: [600, 450, 300, 210]
print_freq: 10
resblocks: 1
run_test_freq: 1
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: False
seed: None
serial_batches: False
slide_verts: 0.2
verbose_plot: False
which_epoch: latest
-------------- End ----------------
computing mean std from train data...
0 of 3722
500 of 3722
1000 of 3722
1500 of 3722
2000 of 3722
2500 of 3722
3000 of 3722
3500 of 3722
saved:  datasets/cubes/mean_std_cache.p
loaded mean / std from cache
#training meshes = 3722
---------- Network initialized -------------
[Network] Total number of parameters : 1.323 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 16)
(epoch: 1, iters: 80, time: 0.199, data: 5.151) loss: 3.122 
(epoch: 1, iters: 160, time: 0.191, data: 0.012) loss: 3.054 
(epoch: 1, iters: 240, time: 0.191, data: 0.000) loss: 3.061 
(epoch: 1, iters: 320, time: 0.186, data: 0.000) loss: 3.071 
(epoch: 1, iters: 400, time: 0.200, data: 0.000) loss: 3.050 
(epoch: 1, iters: 480, time: 0.203, data: 0.000) loss: 3.057 
(epoch: 1, iters: 560, time: 0.201, data: 0.026) loss: 3.011 
(epoch: 1, iters: 640, time: 0.196, data: 0.026) loss: 3.058 
(epoch: 1, iters: 720, time: 0.196, data: 0.012) loss: 3.075 
(epoch: 1, iters: 800, time: 0.179, data: 0.000) loss: 2.944 
(epoch: 1, iters: 880, time: 0.175, data: 0.000) loss: 3.076 
(epoch: 1, iters: 960, time: 0.191, data: 0.000) loss: 2.993 
(epoch: 1, iters: 1040, time: 0.197, data: 0.000) loss: 2.944 
(epoch: 1, iters: 1120, time: 0.188, data: 0.026) loss: 2.876 
(epoch: 1, iters: 1200, time: 0.200, data: 0.026) loss: 2.928 
(epoch: 1, iters: 1280, time: 0.198, data: 0.012) loss: 2.718 
(epoch: 1, iters: 1360, time: 0.187, data: 0.000) loss: 2.777 
(epoch: 1, iters: 1440, time: 0.180, data: 0.000) loss: 2.821 
(epoch: 1, iters: 1520, time: 0.192, data: 0.000) loss: 2.748 
(epoch: 1, iters: 1600, time: 0.197, data: 0.000) loss: 2.869 
(epoch: 1, iters: 1680, time: 0.193, data: 0.027) loss: 2.795 
(epoch: 1, iters: 1760, time: 0.190, data: 0.026) loss: 2.802 
(epoch: 1, iters: 1840, time: 0.188, data: 0.012) loss: 2.761 
(epoch: 1, iters: 1920, time: 0.193, data: 0.000) loss: 2.751 
(epoch: 1, iters: 2000, time: 0.197, data: 0.000) loss: 2.594 
(epoch: 1, iters: 2080, time: 0.189, data: 0.000) loss: 2.633 
(epoch: 1, iters: 2160, time: 0.200, data: 0.000) loss: 2.718 
(epoch: 1, iters: 2240, time: 0.194, data: 0.027) loss: 2.752 
(epoch: 1, iters: 2320, time: 0.192, data: 0.036) loss: 2.856 
(epoch: 1, iters: 2400, time: 0.183, data: 0.022) loss: 2.618 
(epoch: 1, iters: 2480, time: 0.194, data: 0.000) loss: 2.712 
(epoch: 1, iters: 2560, time: 0.187, data: 0.000) loss: 2.690 
(epoch: 1, iters: 2640, time: 0.192, data: 0.000) loss: 2.528 
(epoch: 1, iters: 2720, time: 0.186, data: 0.000) loss: 2.590 
(epoch: 1, iters: 2800, time: 0.194, data: 0.027) loss: 2.793 
(epoch: 1, iters: 2880, time: 0.182, data: 0.026) loss: 2.569 
(epoch: 1, iters: 2960, time: 0.184, data: 0.012) loss: 2.785 
(epoch: 1, iters: 3040, time: 0.186, data: 0.000) loss: 2.719 
(epoch: 1, iters: 3120, time: 0.195, data: 0.000) loss: 2.496 
(epoch: 1, iters: 3200, time: 0.191, data: 0.000) loss: 2.622 
(epoch: 1, iters: 3280, time: 0.198, data: 0.000) loss: 2.458 
(epoch: 1, iters: 3360, time: 0.197, data: 0.037) loss: 2.830 
(epoch: 1, iters: 3440, time: 0.188, data: 0.036) loss: 2.472 
(epoch: 1, iters: 3520, time: 0.185, data: 0.021) loss: 2.260 
(epoch: 1, iters: 3600, time: 0.194, data: 0.000) loss: 2.539 
(epoch: 1, iters: 3680, time: 0.088, data: 0.000) loss: 2.613 
saving the model at the end of epoch 1, iters 3728
End of epoch 1 / 2100 	 Time Taken: 717 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1, TEST ACC: [15.933 %]

saving the latest model (epoch 2, total_steps 3744)
(epoch: 2, iters: 32, time: 0.260, data: 0.000) loss: 2.525 
(epoch: 2, iters: 112, time: 0.183, data: 0.000) loss: 2.667 
(epoch: 2, iters: 192, time: 0.193, data: 0.000) loss: 2.640 
(epoch: 2, iters: 272, time: 0.188, data: 0.000) loss: 2.387 
(epoch: 2, iters: 352, time: 0.189, data: 0.000) loss: 2.363 
(epoch: 2, iters: 432, time: 0.185, data: 0.026) loss: 2.438 
(epoch: 2, iters: 512, time: 0.189, data: 0.036) loss: 2.353 
(epoch: 2, iters: 592, time: 0.185, data: 0.012) loss: 2.548 
(epoch: 2, iters: 672, time: 0.166, data: 0.000) loss: 2.397 
(epoch: 2, iters: 752, time: 0.183, data: 0.000) loss: 2.327 
(epoch: 2, iters: 832, time: 0.190, data: 0.000) loss: 2.457 
(epoch: 2, iters: 912, time: 0.196, data: 0.000) loss: 2.510 
(epoch: 2, iters: 992, time: 0.193, data: 0.036) loss: 2.543 
(epoch: 2, iters: 1072, time: 0.190, data: 0.036) loss: 2.240 
(epoch: 2, iters: 1152, time: 0.191, data: 0.012) loss: 2.179 
(epoch: 2, iters: 1232, time: 0.192, data: 0.000) loss: 2.159 
(epoch: 2, iters: 1312, time: 0.197, data: 0.000) loss: 2.115 
(epoch: 2, iters: 1392, time: 0.183, data: 0.000) loss: 2.301 
(epoch: 2, iters: 1472, time: 0.193, data: 0.000) loss: 2.300 
(epoch: 2, iters: 1552, time: 0.188, data: 0.027) loss: 2.389 
(epoch: 2, iters: 1632, time: 0.203, data: 0.026) loss: 2.080 
(epoch: 2, iters: 1712, time: 0.184, data: 0.011) loss: 2.232 
(epoch: 2, iters: 1792, time: 0.182, data: 0.000) loss: 2.266 
(epoch: 2, iters: 1872, time: 0.186, data: 0.000) loss: 2.241 
(epoch: 2, iters: 1952, time: 0.195, data: 0.000) loss: 2.065 
(epoch: 2, iters: 2032, time: 0.188, data: 0.000) loss: 1.946 
(epoch: 2, iters: 2112, time: 0.200, data: 0.027) loss: 2.417 
(epoch: 2, iters: 2192, time: 0.186, data: 0.026) loss: 2.094 
(epoch: 2, iters: 2272, time: 0.159, data: 0.011) loss: 2.069 
(epoch: 2, iters: 2352, time: 0.178, data: 0.000) loss: 1.991 
(epoch: 2, iters: 2432, time: 0.172, data: 0.000) loss: 1.977 
(epoch: 2, iters: 2512, time: 0.186, data: 0.000) loss: 2.039 
(epoch: 2, iters: 2592, time: 0.186, data: 0.000) loss: 2.000 
(epoch: 2, iters: 2672, time: 0.188, data: 0.026) loss: 2.076 
(epoch: 2, iters: 2752, time: 0.180, data: 0.026) loss: 1.952 
(epoch: 2, iters: 2832, time: 0.184, data: 0.012) loss: 1.967 
(epoch: 2, iters: 2912, time: 0.175, data: 0.000) loss: 1.921 
(epoch: 2, iters: 2992, time: 0.190, data: 0.000) loss: 2.464 
(epoch: 2, iters: 3072, time: 0.194, data: 0.000) loss: 2.114 
(epoch: 2, iters: 3152, time: 0.192, data: 0.000) loss: 2.061 
(epoch: 2, iters: 3232, time: 0.189, data: 0.036) loss: 2.232 
(epoch: 2, iters: 3312, time: 0.186, data: 0.047) loss: 2.044 
(epoch: 2, iters: 3392, time: 0.192, data: 0.012) loss: 1.944 
(epoch: 2, iters: 3472, time: 0.185, data: 0.000) loss: 1.898 
(epoch: 2, iters: 3552, time: 0.194, data: 0.000) loss: 2.085 
(epoch: 2, iters: 3632, time: 0.165, data: 0.000) loss: 2.118 
(epoch: 2, iters: 3712, time: 0.090, data: 0.000) loss: 1.867 
saving the model at the end of epoch 2, iters 7456
End of epoch 2 / 2100 	 Time Taken: 694 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 2, TEST ACC: [27.314 %]

saving the latest model (epoch 3, total_steps 7472)
(epoch: 3, iters: 64, time: 0.190, data: 0.000) loss: 1.875 
(epoch: 3, iters: 144, time: 0.178, data: 0.048) loss: 2.243 
(epoch: 3, iters: 224, time: 0.180, data: 0.000) loss: 1.872 
(epoch: 3, iters: 304, time: 0.170, data: 0.000) loss: 2.254 
(epoch: 3, iters: 384, time: 0.190, data: 0.000) loss: 2.318 
(epoch: 3, iters: 464, time: 0.194, data: 0.000) loss: 1.962 
(epoch: 3, iters: 544, time: 0.186, data: 0.027) loss: 1.824 
(epoch: 3, iters: 624, time: 0.178, data: 0.027) loss: 1.970 
(epoch: 3, iters: 704, time: 0.184, data: 0.011) loss: 1.704 
(epoch: 3, iters: 784, time: 0.175, data: 0.000) loss: 2.212 
(epoch: 3, iters: 864, time: 0.185, data: 0.000) loss: 1.934 
(epoch: 3, iters: 944, time: 0.173, data: 0.000) loss: 1.880 
(epoch: 3, iters: 1024, time: 0.165, data: 0.000) loss: 1.676 
(epoch: 3, iters: 1104, time: 0.178, data: 0.026) loss: 1.691 
(epoch: 3, iters: 1184, time: 0.184, data: 0.027) loss: 1.697 
(epoch: 3, iters: 1264, time: 0.187, data: 0.013) loss: 2.024 
(epoch: 3, iters: 1344, time: 0.179, data: 0.000) loss: 1.613 
(epoch: 3, iters: 1424, time: 0.186, data: 0.000) loss: 1.637 
(epoch: 3, iters: 1504, time: 0.173, data: 0.000) loss: 2.240 
(epoch: 3, iters: 1584, time: 0.186, data: 0.000) loss: 2.027 
(epoch: 3, iters: 1664, time: 0.194, data: 0.026) loss: 1.945 
(epoch: 3, iters: 1744, time: 0.187, data: 0.026) loss: 1.511 
(epoch: 3, iters: 1824, time: 0.175, data: 0.012) loss: 1.766 
(epoch: 3, iters: 1904, time: 0.189, data: 0.000) loss: 1.836 
(epoch: 3, iters: 1984, time: 0.188, data: 0.000) loss: 2.418 
(epoch: 3, iters: 2064, time: 0.177, data: 0.000) loss: 2.059 
(epoch: 3, iters: 2144, time: 0.175, data: 0.000) loss: 1.875 
(epoch: 3, iters: 2224, time: 0.186, data: 0.026) loss: 1.888 
(epoch: 3, iters: 2304, time: 0.190, data: 0.027) loss: 1.808 
(epoch: 3, iters: 2384, time: 0.182, data: 0.011) loss: 2.121 
(epoch: 3, iters: 2464, time: 0.188, data: 0.000) loss: 1.938 
(epoch: 3, iters: 2544, time: 0.181, data: 0.000) loss: 1.797 
(epoch: 3, iters: 2624, time: 0.194, data: 0.000) loss: 2.174 
(epoch: 3, iters: 2704, time: 0.177, data: 0.000) loss: 1.947 
(epoch: 3, iters: 2784, time: 0.192, data: 0.027) loss: 1.957 
(epoch: 3, iters: 2864, time: 0.194, data: 0.027) loss: 1.597 
(epoch: 3, iters: 2944, time: 0.176, data: 0.012) loss: 2.313 
(epoch: 3, iters: 3024, time: 0.187, data: 0.000) loss: 2.118 
(epoch: 3, iters: 3104, time: 0.186, data: 0.000) loss: 2.043 
(epoch: 3, iters: 3184, time: 0.180, data: 0.000) loss: 2.120 
(epoch: 3, iters: 3264, time: 0.171, data: 0.000) loss: 1.797 
(epoch: 3, iters: 3344, time: 0.185, data: 0.027) loss: 2.358 
(epoch: 3, iters: 3424, time: 0.194, data: 0.027) loss: 1.868 
(epoch: 3, iters: 3504, time: 0.183, data: 0.012) loss: 1.635 
(epoch: 3, iters: 3584, time: 0.190, data: 0.000) loss: 1.735 
(epoch: 3, iters: 3664, time: 0.088, data: 0.000) loss: 2.050 
saving the model at the end of epoch 3, iters 11184
End of epoch 3 / 2100 	 Time Taken: 678 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 3, TEST ACC: [38.695 %]

(epoch: 4, iters: 16, time: 0.282, data: 0.000) loss: 1.612 
saving the latest model (epoch 4, total_steps 11200)
(epoch: 4, iters: 96, time: 0.169, data: 0.000) loss: 1.682 
(epoch: 4, iters: 176, time: 0.177, data: 0.000) loss: 1.876 
(epoch: 4, iters: 256, time: 0.159, data: 0.000) loss: 1.412 
(epoch: 4, iters: 336, time: 0.175, data: 0.000) loss: 1.742 
(epoch: 4, iters: 416, time: 0.174, data: 0.000) loss: 1.620 
(epoch: 4, iters: 496, time: 0.173, data: 0.026) loss: 1.595 
(epoch: 4, iters: 576, time: 0.180, data: 0.027) loss: 1.767 
(epoch: 4, iters: 656, time: 0.184, data: 0.013) loss: 1.554 
(epoch: 4, iters: 736, time: 0.159, data: 0.000) loss: 1.815 
(epoch: 4, iters: 816, time: 0.172, data: 0.000) loss: 1.581 
(epoch: 4, iters: 896, time: 0.179, data: 0.000) loss: 1.435 
(epoch: 4, iters: 976, time: 0.179, data: 0.000) loss: 1.669 
(epoch: 4, iters: 1056, time: 0.191, data: 0.027) loss: 1.660 
(epoch: 4, iters: 1136, time: 0.190, data: 0.028) loss: 1.953 
(epoch: 4, iters: 1216, time: 0.162, data: 0.012) loss: 1.457 
(epoch: 4, iters: 1296, time: 0.178, data: 0.000) loss: 1.720 
(epoch: 4, iters: 1376, time: 0.178, data: 0.000) loss: 1.507 
(epoch: 4, iters: 1456, time: 0.186, data: 0.000) loss: 1.645 
(epoch: 4, iters: 1536, time: 0.193, data: 0.000) loss: 1.598 
(epoch: 4, iters: 1616, time: 0.184, data: 0.026) loss: 1.729 
(epoch: 4, iters: 1696, time: 0.179, data: 0.035) loss: 1.857 
(epoch: 4, iters: 1776, time: 0.156, data: 0.013) loss: 1.617 
(epoch: 4, iters: 1856, time: 0.168, data: 0.000) loss: 1.395 
(epoch: 4, iters: 1936, time: 0.187, data: 0.000) loss: 1.682 
(epoch: 4, iters: 2016, time: 0.187, data: 0.000) loss: 1.557 
(epoch: 4, iters: 2096, time: 0.192, data: 0.000) loss: 2.019 
(epoch: 4, iters: 2176, time: 0.180, data: 0.036) loss: 1.636 
(epoch: 4, iters: 2256, time: 0.184, data: 0.036) loss: 1.589 
(epoch: 4, iters: 2336, time: 0.174, data: 0.022) loss: 1.623 
(epoch: 4, iters: 2416, time: 0.184, data: 0.000) loss: 1.701 
(epoch: 4, iters: 2496, time: 0.170, data: 0.000) loss: 1.595 
(epoch: 4, iters: 2576, time: 0.178, data: 0.000) loss: 1.310 
(epoch: 4, iters: 2656, time: 0.182, data: 0.000) loss: 1.633 
(epoch: 4, iters: 2736, time: 0.189, data: 0.038) loss: 1.714 
(epoch: 4, iters: 2816, time: 0.194, data: 0.026) loss: 1.381 
(epoch: 4, iters: 2896, time: 0.168, data: 0.012) loss: 1.988 
(epoch: 4, iters: 2976, time: 0.184, data: 0.000) loss: 1.489 
(epoch: 4, iters: 3056, time: 0.167, data: 0.000) loss: 1.635 
(epoch: 4, iters: 3136, time: 0.178, data: 0.000) loss: 1.929 
(epoch: 4, iters: 3216, time: 0.181, data: 0.000) loss: 1.663 
(epoch: 4, iters: 3296, time: 0.164, data: 0.026) loss: 1.665 
(epoch: 4, iters: 3376, time: 0.157, data: 0.026) loss: 1.760 
(epoch: 4, iters: 3456, time: 0.177, data: 0.012) loss: 1.808 
(epoch: 4, iters: 3536, time: 0.168, data: 0.000) loss: 1.583 
(epoch: 4, iters: 3616, time: 0.172, data: 0.000) loss: 1.618 
(epoch: 4, iters: 3696, time: 0.091, data: 0.000) loss: 1.407 
saving the model at the end of epoch 4, iters 14912
End of epoch 4 / 2100 	 Time Taken: 660 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 4, TEST ACC: [39.757 %]

saving the latest model (epoch 5, total_steps 14928)
(epoch: 5, iters: 48, time: 0.153, data: 0.000) loss: 1.737 
(epoch: 5, iters: 128, time: 0.183, data: 0.012) loss: 1.705 
(epoch: 5, iters: 208, time: 0.189, data: 0.000) loss: 1.530 
(epoch: 5, iters: 288, time: 0.185, data: 0.000) loss: 1.528 
(epoch: 5, iters: 368, time: 0.156, data: 0.037) loss: 1.420 
(epoch: 5, iters: 448, time: 0.164, data: 0.026) loss: 1.916 
(epoch: 5, iters: 528, time: 0.162, data: 0.012) loss: 1.654 
(epoch: 5, iters: 608, time: 0.173, data: 0.000) loss: 2.083 
(epoch: 5, iters: 688, time: 0.171, data: 0.000) loss: 1.186 
(epoch: 5, iters: 768, time: 0.183, data: 0.000) loss: 1.441 
(epoch: 5, iters: 848, time: 0.173, data: 0.000) loss: 1.736 
(epoch: 5, iters: 928, time: 0.175, data: 0.027) loss: 2.049 
(epoch: 5, iters: 1008, time: 0.163, data: 0.027) loss: 1.816 
(epoch: 5, iters: 1088, time: 0.171, data: 0.012) loss: 1.787 
(epoch: 5, iters: 1168, time: 0.174, data: 0.000) loss: 1.463 
(epoch: 5, iters: 1248, time: 0.170, data: 0.000) loss: 1.468 
(epoch: 5, iters: 1328, time: 0.177, data: 0.000) loss: 1.431 
(epoch: 5, iters: 1408, time: 0.191, data: 0.000) loss: 1.473 
(epoch: 5, iters: 1488, time: 0.189, data: 0.027) loss: 1.480 
(epoch: 5, iters: 1568, time: 0.156, data: 0.026) loss: 1.417 
(epoch: 5, iters: 1648, time: 0.166, data: 0.012) loss: 1.593 
(epoch: 5, iters: 1728, time: 0.175, data: 0.000) loss: 1.547 
(epoch: 5, iters: 1808, time: 0.156, data: 0.000) loss: 1.802 
(epoch: 5, iters: 1888, time: 0.159, data: 0.000) loss: 1.925 
(epoch: 5, iters: 1968, time: 0.180, data: 0.000) loss: 1.418 
(epoch: 5, iters: 2048, time: 0.190, data: 0.026) loss: 1.602 
(epoch: 5, iters: 2128, time: 0.152, data: 0.037) loss: 1.679 
(epoch: 5, iters: 2208, time: 0.192, data: 0.013) loss: 1.426 
(epoch: 5, iters: 2288, time: 0.168, data: 0.000) loss: 0.939 
(epoch: 5, iters: 2368, time: 0.181, data: 0.000) loss: 1.830 
(epoch: 5, iters: 2448, time: 0.187, data: 0.000) loss: 1.246 
(epoch: 5, iters: 2528, time: 0.178, data: 0.000) loss: 1.723 
(epoch: 5, iters: 2608, time: 0.177, data: 0.027) loss: 1.478 
(epoch: 5, iters: 2688, time: 0.175, data: 0.037) loss: 1.397 
(epoch: 5, iters: 2768, time: 0.161, data: 0.012) loss: 1.692 
(epoch: 5, iters: 2848, time: 0.173, data: 0.000) loss: 1.661 
(epoch: 5, iters: 2928, time: 0.159, data: 0.000) loss: 1.639 
(epoch: 5, iters: 3008, time: 0.200, data: 0.000) loss: 1.434 
(epoch: 5, iters: 3088, time: 0.174, data: 0.000) loss: 1.789 
(epoch: 5, iters: 3168, time: 0.173, data: 0.027) loss: 1.687 
(epoch: 5, iters: 3248, time: 0.185, data: 0.028) loss: 1.307 
(epoch: 5, iters: 3328, time: 0.140, data: 0.012) loss: 1.175 
(epoch: 5, iters: 3408, time: 0.165, data: 0.000) loss: 1.469 
(epoch: 5, iters: 3488, time: 0.179, data: 0.012) loss: 1.404 
(epoch: 5, iters: 3568, time: 0.184, data: 0.000) loss: 1.175 
(epoch: 5, iters: 3648, time: 0.091, data: 0.000) loss: 1.308 
(epoch: 5, iters: 3728, time: 0.058, data: 0.023) loss: 1.663 
saving the model at the end of epoch 5, iters 18640
End of epoch 5 / 2100 	 Time Taken: 644 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 5, TEST ACC: [46.282 %]

saving the latest model (epoch 6, total_steps 18656)
(epoch: 6, iters: 80, time: 0.180, data: 4.386) loss: 1.493 
(epoch: 6, iters: 160, time: 0.170, data: 0.037) loss: 1.651 
(epoch: 6, iters: 240, time: 0.181, data: 0.026) loss: 1.872 
(epoch: 6, iters: 320, time: 0.174, data: 0.013) loss: 1.483 
(epoch: 6, iters: 400, time: 0.176, data: 0.000) loss: 1.187 
(epoch: 6, iters: 480, time: 0.157, data: 0.000) loss: 1.996 
(epoch: 6, iters: 560, time: 0.170, data: 0.000) loss: 1.378 
(epoch: 6, iters: 640, time: 0.187, data: 0.000) loss: 1.209 
(epoch: 6, iters: 720, time: 0.176, data: 0.050) loss: 1.343 
(epoch: 6, iters: 800, time: 0.176, data: 0.037) loss: 1.547 
(epoch: 6, iters: 880, time: 0.183, data: 0.012) loss: 1.084 
(epoch: 6, iters: 960, time: 0.162, data: 0.000) loss: 1.840 
(epoch: 6, iters: 1040, time: 0.165, data: 0.000) loss: 1.350 
(epoch: 6, iters: 1120, time: 0.174, data: 0.000) loss: 1.106 
(epoch: 6, iters: 1200, time: 0.180, data: 0.000) loss: 1.362 
(epoch: 6, iters: 1280, time: 0.166, data: 0.026) loss: 1.118 
(epoch: 6, iters: 1360, time: 0.158, data: 0.027) loss: 1.257 
(epoch: 6, iters: 1440, time: 0.169, data: 0.012) loss: 1.519 
(epoch: 6, iters: 1520, time: 0.159, data: 0.000) loss: 1.146 
(epoch: 6, iters: 1600, time: 0.164, data: 0.000) loss: 1.296 
(epoch: 6, iters: 1680, time: 0.158, data: 0.000) loss: 1.252 
(epoch: 6, iters: 1760, time: 0.164, data: 0.000) loss: 1.111 
(epoch: 6, iters: 1840, time: 0.172, data: 0.061) loss: 1.163 
(epoch: 6, iters: 1920, time: 0.177, data: 0.026) loss: 1.285 
(epoch: 6, iters: 2000, time: 0.159, data: 0.011) loss: 1.026 
(epoch: 6, iters: 2080, time: 0.165, data: 0.000) loss: 1.088 
(epoch: 6, iters: 2160, time: 0.188, data: 0.000) loss: 1.430 
(epoch: 6, iters: 2240, time: 0.177, data: 0.000) loss: 1.008 
(epoch: 6, iters: 2320, time: 0.164, data: 0.000) loss: 1.232 
(epoch: 6, iters: 2400, time: 0.159, data: 0.029) loss: 1.344 
(epoch: 6, iters: 2480, time: 0.157, data: 0.027) loss: 1.026 
(epoch: 6, iters: 2560, time: 0.181, data: 0.012) loss: 1.112 
(epoch: 6, iters: 2640, time: 0.166, data: 0.000) loss: 1.237 
(epoch: 6, iters: 2720, time: 0.170, data: 0.000) loss: 1.143 
(epoch: 6, iters: 2800, time: 0.182, data: 0.000) loss: 1.289 
(epoch: 6, iters: 2880, time: 0.170, data: 0.000) loss: 0.916 
(epoch: 6, iters: 2960, time: 0.176, data: 0.031) loss: 0.945 
(epoch: 6, iters: 3040, time: 0.168, data: 0.000) loss: 1.266 
(epoch: 6, iters: 3120, time: 0.175, data: 0.012) loss: 1.029 
(epoch: 6, iters: 3200, time: 0.167, data: 0.000) loss: 1.187 
(epoch: 6, iters: 3280, time: 0.173, data: 0.000) loss: 1.089 
(epoch: 6, iters: 3360, time: 0.185, data: 0.000) loss: 1.180 
(epoch: 6, iters: 3440, time: 0.206, data: 0.000) loss: 1.479 
(epoch: 6, iters: 3520, time: 0.165, data: 0.027) loss: 1.056 
(epoch: 6, iters: 3600, time: 0.171, data: 0.027) loss: 1.258 
(epoch: 6, iters: 3680, time: 0.090, data: 0.012) loss: 1.207 
saving the model at the end of epoch 6, iters 22368
End of epoch 6 / 2100 	 Time Taken: 636 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 6, TEST ACC: [57.967 %]

saving the latest model (epoch 7, total_steps 22384)
(epoch: 7, iters: 32, time: 0.221, data: 0.000) loss: 1.625 
(epoch: 7, iters: 112, time: 0.186, data: 0.000) loss: 0.661 
(epoch: 7, iters: 192, time: 0.173, data: 0.000) loss: 1.186 
(epoch: 7, iters: 272, time: 0.159, data: 0.000) loss: 0.947 
(epoch: 7, iters: 352, time: 0.157, data: 0.027) loss: 1.051 
(epoch: 7, iters: 432, time: 0.155, data: 0.027) loss: 1.180 
(epoch: 7, iters: 512, time: 0.161, data: 0.012) loss: 0.981 
(epoch: 7, iters: 592, time: 0.150, data: 0.000) loss: 0.989 
(epoch: 7, iters: 672, time: 0.163, data: 0.000) loss: 1.583 
(epoch: 7, iters: 752, time: 0.157, data: 0.000) loss: 1.434 
(epoch: 7, iters: 832, time: 0.181, data: 0.000) loss: 0.856 
(epoch: 7, iters: 912, time: 0.173, data: 0.030) loss: 1.385 
(epoch: 7, iters: 992, time: 0.151, data: 0.000) loss: 1.085 
(epoch: 7, iters: 1072, time: 0.167, data: 0.012) loss: 1.396 
(epoch: 7, iters: 1152, time: 0.144, data: 0.000) loss: 0.690 
(epoch: 7, iters: 1232, time: 0.157, data: 0.000) loss: 1.511 
(epoch: 7, iters: 1312, time: 0.180, data: 0.000) loss: 1.399 
(epoch: 7, iters: 1392, time: 0.161, data: 0.000) loss: 1.665 
(epoch: 7, iters: 1472, time: 0.188, data: 0.026) loss: 1.481 
(epoch: 7, iters: 1552, time: 0.181, data: 0.037) loss: 1.041 
(epoch: 7, iters: 1632, time: 0.161, data: 0.012) loss: 1.486 
(epoch: 7, iters: 1712, time: 0.150, data: 0.000) loss: 0.780 
(epoch: 7, iters: 1792, time: 0.180, data: 0.000) loss: 0.942 
(epoch: 7, iters: 1872, time: 0.157, data: 0.000) loss: 1.065 
(epoch: 7, iters: 1952, time: 0.175, data: 0.000) loss: 0.798 
(epoch: 7, iters: 2032, time: 0.183, data: 0.036) loss: 1.079 
(epoch: 7, iters: 2112, time: 0.155, data: 0.037) loss: 1.049 
(epoch: 7, iters: 2192, time: 0.151, data: 0.012) loss: 1.089 
(epoch: 7, iters: 2272, time: 0.145, data: 0.000) loss: 0.859 
(epoch: 7, iters: 2352, time: 0.168, data: 0.012) loss: 1.204 
(epoch: 7, iters: 2432, time: 0.157, data: 0.000) loss: 1.024 
(epoch: 7, iters: 2512, time: 0.164, data: 0.000) loss: 1.138 
(epoch: 7, iters: 2592, time: 0.154, data: 0.026) loss: 0.731 
(epoch: 7, iters: 2672, time: 0.177, data: 0.026) loss: 0.999 
(epoch: 7, iters: 2752, time: 0.158, data: 0.012) loss: 1.760 
(epoch: 7, iters: 2832, time: 0.171, data: 0.000) loss: 0.857 
(epoch: 7, iters: 2912, time: 0.153, data: 0.000) loss: 0.954 
(epoch: 7, iters: 2992, time: 0.168, data: 0.000) loss: 0.886 
(epoch: 7, iters: 3072, time: 0.171, data: 0.000) loss: 0.965 
(epoch: 7, iters: 3152, time: 0.171, data: 0.026) loss: 1.332 
(epoch: 7, iters: 3232, time: 0.167, data: 0.027) loss: 0.687 
(epoch: 7, iters: 3312, time: 0.182, data: 0.012) loss: 1.433 
(epoch: 7, iters: 3392, time: 0.161, data: 0.000) loss: 0.994 
(epoch: 7, iters: 3472, time: 0.157, data: 0.000) loss: 0.918 
(epoch: 7, iters: 3552, time: 0.181, data: 0.000) loss: 0.854 
(epoch: 7, iters: 3632, time: 0.159, data: 0.000) loss: 0.952 
(epoch: 7, iters: 3712, time: 0.088, data: 0.023) loss: 1.268 
saving the model at the end of epoch 7, iters 26096
End of epoch 7 / 2100 	 Time Taken: 624 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 7, TEST ACC: [69.499 %]

saving the latest model (epoch 8, total_steps 26112)
(epoch: 8, iters: 64, time: 0.160, data: 0.000) loss: 1.169 
(epoch: 8, iters: 144, time: 0.153, data: 0.000) loss: 1.213 
(epoch: 8, iters: 224, time: 0.158, data: 0.000) loss: 1.104 
(epoch: 8, iters: 304, time: 0.175, data: 0.000) loss: 1.133 
(epoch: 8, iters: 384, time: 0.168, data: 0.031) loss: 0.678 
(epoch: 8, iters: 464, time: 0.157, data: 0.000) loss: 0.932 
(epoch: 8, iters: 544, time: 0.148, data: 0.012) loss: 0.863 
(epoch: 8, iters: 624, time: 0.174, data: 0.000) loss: 0.914 
(epoch: 8, iters: 704, time: 0.167, data: 0.000) loss: 0.869 
(epoch: 8, iters: 784, time: 0.158, data: 0.000) loss: 1.003 
(epoch: 8, iters: 864, time: 0.175, data: 0.000) loss: 0.754 
(epoch: 8, iters: 944, time: 0.153, data: 0.044) loss: 1.230 
(epoch: 8, iters: 1024, time: 0.153, data: 0.037) loss: 1.030 
(epoch: 8, iters: 1104, time: 0.150, data: 0.012) loss: 1.480 
(epoch: 8, iters: 1184, time: 0.170, data: 0.000) loss: 1.176 
(epoch: 8, iters: 1264, time: 0.165, data: 0.012) loss: 1.216 
(epoch: 8, iters: 1344, time: 0.155, data: 0.000) loss: 0.943 
(epoch: 8, iters: 1424, time: 0.166, data: 0.000) loss: 0.544 
(epoch: 8, iters: 1504, time: 0.164, data: 0.026) loss: 0.820 
(epoch: 8, iters: 1584, time: 0.155, data: 0.037) loss: 0.939 
(epoch: 8, iters: 1664, time: 0.163, data: 0.012) loss: 0.650 
(epoch: 8, iters: 1744, time: 0.177, data: 0.000) loss: 0.879 
(epoch: 8, iters: 1824, time: 0.175, data: 0.000) loss: 1.126 
(epoch: 8, iters: 1904, time: 0.156, data: 0.000) loss: 0.921 
(epoch: 8, iters: 1984, time: 0.175, data: 0.000) loss: 1.738 
(epoch: 8, iters: 2064, time: 0.151, data: 0.027) loss: 1.308 
(epoch: 8, iters: 2144, time: 0.168, data: 0.027) loss: 0.695 
(epoch: 8, iters: 2224, time: 0.171, data: 0.013) loss: 1.580 
(epoch: 8, iters: 2304, time: 0.150, data: 0.000) loss: 1.288 
(epoch: 8, iters: 2384, time: 0.187, data: 0.000) loss: 0.906 
(epoch: 8, iters: 2464, time: 0.150, data: 0.000) loss: 1.107 
(epoch: 8, iters: 2544, time: 0.163, data: 0.000) loss: 1.734 
(epoch: 8, iters: 2624, time: 0.158, data: 0.038) loss: 0.484 
(epoch: 8, iters: 2704, time: 0.189, data: 0.027) loss: 1.157 
(epoch: 8, iters: 2784, time: 0.152, data: 0.012) loss: 0.818 
(epoch: 8, iters: 2864, time: 0.151, data: 0.000) loss: 0.634 
(epoch: 8, iters: 2944, time: 0.164, data: 0.000) loss: 1.287 
(epoch: 8, iters: 3024, time: 0.167, data: 0.000) loss: 1.032 
(epoch: 8, iters: 3104, time: 0.161, data: 0.000) loss: 1.567 
(epoch: 8, iters: 3184, time: 0.158, data: 0.027) loss: 0.910 
(epoch: 8, iters: 3264, time: 0.164, data: 0.026) loss: 0.695 
(epoch: 8, iters: 3344, time: 0.165, data: 0.012) loss: 0.827 
(epoch: 8, iters: 3424, time: 0.165, data: 0.000) loss: 0.777 
(epoch: 8, iters: 3504, time: 0.170, data: 0.000) loss: 0.947 
(epoch: 8, iters: 3584, time: 0.124, data: 0.000) loss: 1.083 
(epoch: 8, iters: 3664, time: 0.089, data: 0.000) loss: 0.733 
saving the model at the end of epoch 8, iters 29824
End of epoch 8 / 2100 	 Time Taken: 605 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 8, TEST ACC: [65.402 %]

(epoch: 9, iters: 16, time: 0.328, data: 0.026) loss: 0.759 
saving the latest model (epoch 9, total_steps 29840)
(epoch: 9, iters: 96, time: 0.143, data: 0.024) loss: 0.682 
(epoch: 9, iters: 176, time: 0.165, data: 0.000) loss: 0.633 
(epoch: 9, iters: 256, time: 0.163, data: 0.000) loss: 0.902 
(epoch: 9, iters: 336, time: 0.157, data: 0.000) loss: 1.012 
(epoch: 9, iters: 416, time: 0.157, data: 0.000) loss: 1.020 
(epoch: 9, iters: 496, time: 0.160, data: 0.038) loss: 1.726 
(epoch: 9, iters: 576, time: 0.156, data: 0.027) loss: 0.822 
(epoch: 9, iters: 656, time: 0.153, data: 0.012) loss: 0.864 
(epoch: 9, iters: 736, time: 0.159, data: 0.000) loss: 0.658 
(epoch: 9, iters: 816, time: 0.151, data: 0.011) loss: 1.450 
(epoch: 9, iters: 896, time: 0.166, data: 0.012) loss: 0.609 
(epoch: 9, iters: 976, time: 0.160, data: 0.000) loss: 0.853 
(epoch: 9, iters: 1056, time: 0.164, data: 0.000) loss: 1.040 
(epoch: 9, iters: 1136, time: 0.178, data: 0.027) loss: 0.662 
(epoch: 9, iters: 1216, time: 0.164, data: 0.027) loss: 0.866 
(epoch: 9, iters: 1296, time: 0.152, data: 0.000) loss: 0.581 
(epoch: 9, iters: 1376, time: 0.154, data: 0.000) loss: 0.838 
(epoch: 9, iters: 1456, time: 0.159, data: 0.042) loss: 0.840 
(epoch: 9, iters: 1536, time: 0.151, data: 0.026) loss: 1.379 
(epoch: 9, iters: 1616, time: 0.153, data: 0.012) loss: 0.915 
(epoch: 9, iters: 1696, time: 0.157, data: 0.000) loss: 0.823 
(epoch: 9, iters: 1776, time: 0.145, data: 0.018) loss: 0.737 
(epoch: 9, iters: 1856, time: 0.165, data: 0.000) loss: 0.897 
(epoch: 9, iters: 1936, time: 0.172, data: 0.000) loss: 0.890 
(epoch: 9, iters: 2016, time: 0.164, data: 0.061) loss: 1.066 
(epoch: 9, iters: 2096, time: 0.179, data: 0.026) loss: 1.014 
(epoch: 9, iters: 2176, time: 0.150, data: 0.012) loss: 1.026 
(epoch: 9, iters: 2256, time: 0.146, data: 0.025) loss: 0.931 
(epoch: 9, iters: 2336, time: 0.154, data: 0.000) loss: 1.395 
(epoch: 9, iters: 2416, time: 0.165, data: 0.012) loss: 0.515 
(epoch: 9, iters: 2496, time: 0.158, data: 0.000) loss: 1.047 
(epoch: 9, iters: 2576, time: 0.132, data: 0.000) loss: 1.380 
(epoch: 9, iters: 2656, time: 0.152, data: 0.000) loss: 0.964 
(epoch: 9, iters: 2736, time: 0.146, data: 0.000) loss: 1.005 
(epoch: 9, iters: 2816, time: 0.155, data: 0.012) loss: 0.879 
(epoch: 9, iters: 2896, time: 0.159, data: 0.012) loss: 0.841 
(epoch: 9, iters: 2976, time: 0.155, data: 0.067) loss: 1.037 
(epoch: 9, iters: 3056, time: 0.152, data: 0.000) loss: 0.831 
(epoch: 9, iters: 3136, time: 0.157, data: 0.000) loss: 0.891 
(epoch: 9, iters: 3216, time: 0.134, data: 0.000) loss: 0.804 
(epoch: 9, iters: 3296, time: 0.152, data: 0.000) loss: 0.934 
(epoch: 9, iters: 3376, time: 0.173, data: 0.038) loss: 1.079 
(epoch: 9, iters: 3456, time: 0.159, data: 0.000) loss: 1.115 
(epoch: 9, iters: 3536, time: 0.169, data: 0.000) loss: 1.352 
(epoch: 9, iters: 3616, time: 0.145, data: 0.012) loss: 0.947 
(epoch: 9, iters: 3696, time: 0.091, data: 0.000) loss: 0.828 
saving the model at the end of epoch 9, iters 33552
End of epoch 9 / 2100 	 Time Taken: 590 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 9, TEST ACC: [72.231 %]

saving the latest model (epoch 10, total_steps 33568)
(epoch: 10, iters: 48, time: 0.154, data: 0.005) loss: 0.555 
(epoch: 10, iters: 128, time: 0.154, data: 0.080) loss: 0.768 
(epoch: 10, iters: 208, time: 0.153, data: 0.027) loss: 1.232 
(epoch: 10, iters: 288, time: 0.123, data: 0.012) loss: 0.926 
(epoch: 10, iters: 368, time: 0.143, data: 0.031) loss: 0.595 
(epoch: 10, iters: 448, time: 0.143, data: 0.000) loss: 0.804 
(epoch: 10, iters: 528, time: 0.158, data: 0.012) loss: 0.848 
(epoch: 10, iters: 608, time: 0.159, data: 0.000) loss: 0.819 
(epoch: 10, iters: 688, time: 0.156, data: 0.000) loss: 1.448 
(epoch: 10, iters: 768, time: 0.152, data: 0.000) loss: 0.862 
(epoch: 10, iters: 848, time: 0.184, data: 0.000) loss: 1.154 
(epoch: 10, iters: 928, time: 0.146, data: 0.028) loss: 0.713 
(epoch: 10, iters: 1008, time: 0.150, data: 0.028) loss: 0.945 
(epoch: 10, iters: 1088, time: 0.150, data: 0.012) loss: 1.014 
(epoch: 10, iters: 1168, time: 0.164, data: 0.000) loss: 1.135 
(epoch: 10, iters: 1248, time: 0.175, data: 0.012) loss: 0.849 
(epoch: 10, iters: 1328, time: 0.147, data: 0.012) loss: 0.662 
(epoch: 10, iters: 1408, time: 0.163, data: 0.000) loss: 0.763 
(epoch: 10, iters: 1488, time: 0.161, data: 0.000) loss: 0.641 
(epoch: 10, iters: 1568, time: 0.169, data: 0.031) loss: 1.311 
(epoch: 10, iters: 1648, time: 0.162, data: 0.037) loss: 0.601 
(epoch: 10, iters: 1728, time: 0.147, data: 0.012) loss: 0.704 
(epoch: 10, iters: 1808, time: 0.155, data: 0.000) loss: 1.577 
(epoch: 10, iters: 1888, time: 0.154, data: 0.000) loss: 0.787 
(epoch: 10, iters: 1968, time: 0.151, data: 0.000) loss: 0.914 
(epoch: 10, iters: 2048, time: 0.154, data: 0.000) loss: 0.678 
(epoch: 10, iters: 2128, time: 0.155, data: 0.027) loss: 0.472 
(epoch: 10, iters: 2208, time: 0.164, data: 0.027) loss: 0.720 
(epoch: 10, iters: 2288, time: 0.151, data: 0.012) loss: 1.362 
(epoch: 10, iters: 2368, time: 0.148, data: 0.027) loss: 0.805 
(epoch: 10, iters: 2448, time: 0.161, data: 0.026) loss: 0.856 
(epoch: 10, iters: 2528, time: 0.166, data: 0.013) loss: 0.620 
(epoch: 10, iters: 2608, time: 0.163, data: 0.029) loss: 0.858 
(epoch: 10, iters: 2688, time: 0.161, data: 0.000) loss: 0.724 
(epoch: 10, iters: 2768, time: 0.147, data: 0.012) loss: 0.497 
(epoch: 10, iters: 2848, time: 0.176, data: 0.000) loss: 0.839 
(epoch: 10, iters: 2928, time: 0.153, data: 0.012) loss: 0.596 
(epoch: 10, iters: 3008, time: 0.158, data: 0.012) loss: 0.428 
(epoch: 10, iters: 3088, time: 0.153, data: 0.000) loss: 0.672 
(epoch: 10, iters: 3168, time: 0.151, data: 0.000) loss: 0.580 
(epoch: 10, iters: 3248, time: 0.162, data: 0.000) loss: 0.830 
(epoch: 10, iters: 3328, time: 0.144, data: 0.000) loss: 0.511 
(epoch: 10, iters: 3408, time: 0.159, data: 0.026) loss: 0.966 
(epoch: 10, iters: 3488, time: 0.153, data: 0.000) loss: 0.854 
(epoch: 10, iters: 3568, time: 0.133, data: 0.000) loss: 0.834 
(epoch: 10, iters: 3648, time: 0.090, data: 0.035) loss: 0.926 
(epoch: 10, iters: 3728, time: 0.058, data: 0.000) loss: 1.087 
saving the model at the end of epoch 10, iters 37280
End of epoch 10 / 2100 	 Time Taken: 585 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 10, TEST ACC: [63.733 %]

saving the latest model (epoch 11, total_steps 37296)
(epoch: 11, iters: 80, time: 0.145, data: 3.679) loss: 0.632 
(epoch: 11, iters: 160, time: 0.153, data: 0.012) loss: 0.666 
(epoch: 11, iters: 240, time: 0.156, data: 0.000) loss: 0.674 
(epoch: 11, iters: 320, time: 0.175, data: 0.012) loss: 0.749 
(epoch: 11, iters: 400, time: 0.147, data: 0.000) loss: 0.733 
(epoch: 11, iters: 480, time: 0.161, data: 0.000) loss: 0.551 
(epoch: 11, iters: 560, time: 0.139, data: 0.048) loss: 0.569 
(epoch: 11, iters: 640, time: 0.151, data: 0.027) loss: 0.518 
(epoch: 11, iters: 720, time: 0.153, data: 0.012) loss: 0.810 
(epoch: 11, iters: 800, time: 0.141, data: 0.021) loss: 1.002 
(epoch: 11, iters: 880, time: 0.163, data: 0.026) loss: 0.812 
(epoch: 11, iters: 960, time: 0.166, data: 0.013) loss: 0.720 
(epoch: 11, iters: 1040, time: 0.151, data: 0.000) loss: 0.660 
(epoch: 11, iters: 1120, time: 0.168, data: 0.000) loss: 0.646 
(epoch: 11, iters: 1200, time: 0.134, data: 0.000) loss: 0.583 
(epoch: 11, iters: 1280, time: 0.156, data: 0.000) loss: 0.827 
(epoch: 11, iters: 1360, time: 0.153, data: 0.047) loss: 0.757 
(epoch: 11, iters: 1440, time: 0.145, data: 0.027) loss: 0.740 
(epoch: 11, iters: 1520, time: 0.127, data: 0.000) loss: 0.593 
(epoch: 11, iters: 1600, time: 0.156, data: 0.000) loss: 0.568 
(epoch: 11, iters: 1680, time: 0.157, data: 0.000) loss: 0.779 
(epoch: 11, iters: 1760, time: 0.162, data: 0.000) loss: 0.767 
(epoch: 11, iters: 1840, time: 0.158, data: 0.000) loss: 0.426 
(epoch: 11, iters: 1920, time: 0.157, data: 0.036) loss: 1.921 
(epoch: 11, iters: 2000, time: 0.157, data: 0.000) loss: 1.181 
(epoch: 11, iters: 2080, time: 0.158, data: 0.000) loss: 0.710 
(epoch: 11, iters: 2160, time: 0.162, data: 0.047) loss: 0.671 
(epoch: 11, iters: 2240, time: 0.141, data: 0.036) loss: 0.655 
(epoch: 11, iters: 2320, time: 0.151, data: 0.012) loss: 1.059 
(epoch: 11, iters: 2400, time: 0.140, data: 0.000) loss: 0.593 
(epoch: 11, iters: 2480, time: 0.141, data: 0.012) loss: 0.401 
(epoch: 11, iters: 2560, time: 0.168, data: 0.000) loss: 0.409 
(epoch: 11, iters: 2640, time: 0.176, data: 0.000) loss: 0.496 
(epoch: 11, iters: 2720, time: 0.149, data: 0.040) loss: 0.436 
(epoch: 11, iters: 2800, time: 0.155, data: 0.000) loss: 0.674 
(epoch: 11, iters: 2880, time: 0.145, data: 0.012) loss: 0.830 
(epoch: 11, iters: 2960, time: 0.127, data: 0.040) loss: 0.708 
(epoch: 11, iters: 3040, time: 0.157, data: 0.000) loss: 0.421 
(epoch: 11, iters: 3120, time: 0.172, data: 0.000) loss: 0.760 
(epoch: 11, iters: 3200, time: 0.156, data: 0.012) loss: 0.542 
(epoch: 11, iters: 3280, time: 0.156, data: 0.015) loss: 0.460 
(epoch: 11, iters: 3360, time: 0.165, data: 0.028) loss: 0.461 
(epoch: 11, iters: 3440, time: 0.157, data: 0.013) loss: 0.604 
(epoch: 11, iters: 3520, time: 0.121, data: 0.036) loss: 0.690 
(epoch: 11, iters: 3600, time: 0.148, data: 0.027) loss: 0.526 
(epoch: 11, iters: 3680, time: 0.088, data: 0.012) loss: 0.378 
saving the model at the end of epoch 11, iters 41008
End of epoch 11 / 2100 	 Time Taken: 573 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 11, TEST ACC: [77.086 %]

saving the latest model (epoch 12, total_steps 41024)
(epoch: 12, iters: 32, time: 0.179, data: 0.007) loss: 0.563 
(epoch: 12, iters: 112, time: 0.146, data: 0.012) loss: 0.782 
(epoch: 12, iters: 192, time: 0.144, data: 0.012) loss: 0.641 
(epoch: 12, iters: 272, time: 0.146, data: 0.000) loss: 0.283 
(epoch: 12, iters: 352, time: 0.157, data: 0.013) loss: 0.793 
(epoch: 12, iters: 432, time: 0.148, data: 0.000) loss: 0.815 
(epoch: 12, iters: 512, time: 0.172, data: 0.000) loss: 0.573 
(epoch: 12, iters: 592, time: 0.160, data: 0.000) loss: 0.426 
(epoch: 12, iters: 672, time: 0.171, data: 0.000) loss: 0.863 
(epoch: 12, iters: 752, time: 0.128, data: 0.000) loss: 0.491 
(epoch: 12, iters: 832, time: 0.156, data: 0.000) loss: 0.291 
(epoch: 12, iters: 912, time: 0.178, data: 0.027) loss: 0.464 
(epoch: 12, iters: 992, time: 0.157, data: 0.028) loss: 0.722 
(epoch: 12, iters: 1072, time: 0.150, data: 0.013) loss: 0.989 
(epoch: 12, iters: 1152, time: 0.171, data: 0.026) loss: 0.658 
(epoch: 12, iters: 1232, time: 0.142, data: 0.000) loss: 0.747 
(epoch: 12, iters: 1312, time: 0.158, data: 0.000) loss: 0.833 
(epoch: 12, iters: 1392, time: 0.154, data: 0.000) loss: 0.562 
(epoch: 12, iters: 1472, time: 0.127, data: 0.026) loss: 0.799 
(epoch: 12, iters: 1552, time: 0.147, data: 0.027) loss: 0.436 
(epoch: 12, iters: 1632, time: 0.144, data: 0.012) loss: 0.687 
(epoch: 12, iters: 1712, time: 0.139, data: 0.000) loss: 0.628 
(epoch: 12, iters: 1792, time: 0.171, data: 0.012) loss: 0.716 
(epoch: 12, iters: 1872, time: 0.150, data: 0.000) loss: 0.876 
(epoch: 12, iters: 1952, time: 0.164, data: 0.000) loss: 0.840 
(epoch: 12, iters: 2032, time: 0.156, data: 0.012) loss: 0.415 
(epoch: 12, iters: 2112, time: 0.155, data: 0.012) loss: 0.952 
(epoch: 12, iters: 2192, time: 0.168, data: 0.016) loss: 0.440 
(epoch: 12, iters: 2272, time: 0.153, data: 0.027) loss: 0.600 
(epoch: 12, iters: 2352, time: 0.154, data: 0.012) loss: 0.544 
(epoch: 12, iters: 2432, time: 0.161, data: 0.037) loss: 0.855 
(epoch: 12, iters: 2512, time: 0.143, data: 0.027) loss: 0.844 
(epoch: 12, iters: 2592, time: 0.167, data: 0.012) loss: 0.440 
(epoch: 12, iters: 2672, time: 0.155, data: 0.030) loss: 0.888 
(epoch: 12, iters: 2752, time: 0.147, data: 0.000) loss: 0.534 
(epoch: 12, iters: 2832, time: 0.159, data: 0.000) loss: 0.986 
(epoch: 12, iters: 2912, time: 0.159, data: 0.040) loss: 0.687 
(epoch: 12, iters: 2992, time: 0.147, data: 0.000) loss: 0.798 
(epoch: 12, iters: 3072, time: 0.133, data: 0.000) loss: 0.587 
(epoch: 12, iters: 3152, time: 0.169, data: 0.026) loss: 0.447 
(epoch: 12, iters: 3232, time: 0.127, data: 0.000) loss: 0.316 
(epoch: 12, iters: 3312, time: 0.165, data: 0.000) loss: 1.076 
(epoch: 12, iters: 3392, time: 0.146, data: 0.031) loss: 0.706 
(epoch: 12, iters: 3472, time: 0.162, data: 0.028) loss: 0.761 
(epoch: 12, iters: 3552, time: 0.161, data: 0.013) loss: 0.438 
(epoch: 12, iters: 3632, time: 0.120, data: 0.000) loss: 0.429 
(epoch: 12, iters: 3712, time: 0.090, data: 0.000) loss: 0.300 
saving the model at the end of epoch 12, iters 44736
End of epoch 12 / 2100 	 Time Taken: 564 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 12, TEST ACC: [69.196 %]

saving the latest model (epoch 13, total_steps 44752)
(epoch: 13, iters: 64, time: 0.153, data: 0.000) loss: 0.374 
(epoch: 13, iters: 144, time: 0.133, data: 0.000) loss: 0.433 
(epoch: 13, iters: 224, time: 0.163, data: 0.012) loss: 0.421 
(epoch: 13, iters: 304, time: 0.147, data: 0.013) loss: 0.766 
(epoch: 13, iters: 384, time: 0.162, data: 0.026) loss: 0.400 
(epoch: 13, iters: 464, time: 0.140, data: 0.000) loss: 0.546 
(epoch: 13, iters: 544, time: 0.138, data: 0.011) loss: 0.706 
(epoch: 13, iters: 624, time: 0.151, data: 0.000) loss: 0.547 
(epoch: 13, iters: 704, time: 0.134, data: 0.011) loss: 0.423 
(epoch: 13, iters: 784, time: 0.151, data: 0.012) loss: 0.719 
(epoch: 13, iters: 864, time: 0.133, data: 0.000) loss: 0.480 
(epoch: 13, iters: 944, time: 0.151, data: 0.012) loss: 0.266 
(epoch: 13, iters: 1024, time: 0.150, data: 0.000) loss: 0.363 
(epoch: 13, iters: 1104, time: 0.135, data: 0.000) loss: 0.338 
(epoch: 13, iters: 1184, time: 0.162, data: 0.012) loss: 0.448 
(epoch: 13, iters: 1264, time: 0.147, data: 0.000) loss: 0.428 
(epoch: 13, iters: 1344, time: 0.144, data: 0.000) loss: 0.622 
(epoch: 13, iters: 1424, time: 0.152, data: 0.031) loss: 0.359 
(epoch: 13, iters: 1504, time: 0.121, data: 0.000) loss: 0.466 
(epoch: 13, iters: 1584, time: 0.140, data: 0.012) loss: 0.214 
(epoch: 13, iters: 1664, time: 0.136, data: 0.000) loss: 0.338 
(epoch: 13, iters: 1744, time: 0.145, data: 0.012) loss: 1.659 
(epoch: 13, iters: 1824, time: 0.153, data: 0.000) loss: 0.451 
(epoch: 13, iters: 1904, time: 0.146, data: 0.000) loss: 0.358 
(epoch: 13, iters: 1984, time: 0.152, data: 0.041) loss: 0.563 
(epoch: 13, iters: 2064, time: 0.146, data: 0.000) loss: 0.384 
(epoch: 13, iters: 2144, time: 0.142, data: 0.012) loss: 0.960 
(epoch: 13, iters: 2224, time: 0.140, data: 0.000) loss: 0.231 
(epoch: 13, iters: 2304, time: 0.139, data: 0.011) loss: 0.537 
(epoch: 13, iters: 2384, time: 0.131, data: 0.000) loss: 0.410 
(epoch: 13, iters: 2464, time: 0.153, data: 0.000) loss: 0.310 
(epoch: 13, iters: 2544, time: 0.146, data: 0.012) loss: 0.345 
(epoch: 13, iters: 2624, time: 0.157, data: 0.011) loss: 0.403 
(epoch: 13, iters: 2704, time: 0.130, data: 0.027) loss: 0.491 
(epoch: 13, iters: 2784, time: 0.154, data: 0.000) loss: 0.595 
(epoch: 13, iters: 2864, time: 0.157, data: 0.000) loss: 0.624 
(epoch: 13, iters: 2944, time: 0.146, data: 0.000) loss: 0.461 
(epoch: 13, iters: 3024, time: 0.158, data: 0.000) loss: 1.125 
(epoch: 13, iters: 3104, time: 0.143, data: 0.030) loss: 0.293 
(epoch: 13, iters: 3184, time: 0.137, data: 0.026) loss: 0.283 
(epoch: 13, iters: 3264, time: 0.146, data: 0.012) loss: 0.224 
(epoch: 13, iters: 3344, time: 0.153, data: 0.030) loss: 0.418 
(epoch: 13, iters: 3424, time: 0.156, data: 0.000) loss: 0.572 
(epoch: 13, iters: 3504, time: 0.149, data: 0.000) loss: 0.417 
(epoch: 13, iters: 3584, time: 0.138, data: 0.026) loss: 0.569 
(epoch: 13, iters: 3664, time: 0.090, data: 0.000) loss: 0.467 
saving the model at the end of epoch 13, iters 48464
End of epoch 13 / 2100 	 Time Taken: 553 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 13, TEST ACC: [79.514 %]

(epoch: 14, iters: 16, time: 0.311, data: 0.000) loss: 0.466 
saving the latest model (epoch 14, total_steps 48480)
(epoch: 14, iters: 96, time: 0.167, data: 0.099) loss: 0.797 
(epoch: 14, iters: 176, time: 0.134, data: 0.027) loss: 0.722 
(epoch: 14, iters: 256, time: 0.152, data: 0.012) loss: 0.850 
(epoch: 14, iters: 336, time: 0.153, data: 0.000) loss: 0.369 
(epoch: 14, iters: 416, time: 0.149, data: 0.013) loss: 0.853 
(epoch: 14, iters: 496, time: 0.152, data: 0.012) loss: 0.439 
(epoch: 14, iters: 576, time: 0.141, data: 0.000) loss: 0.374 
(epoch: 14, iters: 656, time: 0.151, data: 0.000) loss: 0.735 
(epoch: 14, iters: 736, time: 0.153, data: 0.000) loss: 0.435 
(epoch: 14, iters: 816, time: 0.153, data: 0.000) loss: 0.705 
(epoch: 14, iters: 896, time: 0.154, data: 0.036) loss: 0.817 
(epoch: 14, iters: 976, time: 0.162, data: 0.048) loss: 0.660 
(epoch: 14, iters: 1056, time: 0.157, data: 0.027) loss: 0.380 
(epoch: 14, iters: 1136, time: 0.138, data: 0.013) loss: 0.570 
(epoch: 14, iters: 1216, time: 0.146, data: 0.026) loss: 0.418 
(epoch: 14, iters: 1296, time: 0.146, data: 0.000) loss: 0.350 
(epoch: 14, iters: 1376, time: 0.133, data: 0.012) loss: 0.653 
(epoch: 14, iters: 1456, time: 0.146, data: 0.000) loss: 0.760 
(epoch: 14, iters: 1536, time: 0.134, data: 0.012) loss: 0.335 
(epoch: 14, iters: 1616, time: 0.125, data: 0.012) loss: 0.113 
(epoch: 14, iters: 1696, time: 0.156, data: 0.000) loss: 1.095 
(epoch: 14, iters: 1776, time: 0.158, data: 0.012) loss: 0.578 
(epoch: 14, iters: 1856, time: 0.147, data: 0.000) loss: 0.392 
(epoch: 14, iters: 1936, time: 0.159, data: 0.000) loss: 0.435 
(epoch: 14, iters: 2016, time: 0.157, data: 0.026) loss: 0.392 
(epoch: 14, iters: 2096, time: 0.154, data: 0.000) loss: 0.416 
(epoch: 14, iters: 2176, time: 0.147, data: 0.000) loss: 0.666 
(epoch: 14, iters: 2256, time: 0.171, data: 0.041) loss: 0.235 
(epoch: 14, iters: 2336, time: 0.152, data: 0.000) loss: 0.756 
(epoch: 14, iters: 2416, time: 0.153, data: 0.000) loss: 0.356 
(epoch: 14, iters: 2496, time: 0.140, data: 0.031) loss: 0.699 
(epoch: 14, iters: 2576, time: 0.140, data: 0.000) loss: 0.321 
(epoch: 14, iters: 2656, time: 0.148, data: 0.012) loss: 0.752 
(epoch: 14, iters: 2736, time: 0.155, data: 0.000) loss: 0.594 
(epoch: 14, iters: 2816, time: 0.133, data: 0.020) loss: 0.396 
(epoch: 14, iters: 2896, time: 0.155, data: 0.000) loss: 0.302 
(epoch: 14, iters: 2976, time: 0.128, data: 0.000) loss: 0.417 
(epoch: 14, iters: 3056, time: 0.129, data: 0.049) loss: 0.370 
(epoch: 14, iters: 3136, time: 0.154, data: 0.000) loss: 0.311 
(epoch: 14, iters: 3216, time: 0.159, data: 0.012) loss: 0.986 
(epoch: 14, iters: 3296, time: 0.139, data: 0.039) loss: 0.193 
(epoch: 14, iters: 3376, time: 0.153, data: 0.038) loss: 0.481 
(epoch: 14, iters: 3456, time: 0.149, data: 0.000) loss: 0.711 
(epoch: 14, iters: 3536, time: 0.116, data: 0.012) loss: 0.497 
(epoch: 14, iters: 3616, time: 0.119, data: 0.000) loss: 0.239 
(epoch: 14, iters: 3696, time: 0.090, data: 0.000) loss: 0.249 
saving the model at the end of epoch 14, iters 52192
End of epoch 14 / 2100 	 Time Taken: 543 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 14, TEST ACC: [73.596 %]

saving the latest model (epoch 15, total_steps 52208)
(epoch: 15, iters: 48, time: 0.132, data: 0.000) loss: 0.297 
(epoch: 15, iters: 128, time: 0.155, data: 0.042) loss: 0.271 
(epoch: 15, iters: 208, time: 0.134, data: 0.000) loss: 0.510 
(epoch: 15, iters: 288, time: 0.154, data: 0.011) loss: 0.208 
(epoch: 15, iters: 368, time: 0.159, data: 0.024) loss: 0.199 
(epoch: 15, iters: 448, time: 0.146, data: 0.047) loss: 0.493 
(epoch: 15, iters: 528, time: 0.149, data: 0.037) loss: 0.384 
(epoch: 15, iters: 608, time: 0.149, data: 0.012) loss: 0.256 
(epoch: 15, iters: 688, time: 0.152, data: 0.000) loss: 0.699 
(epoch: 15, iters: 768, time: 0.138, data: 0.012) loss: 0.486 
(epoch: 15, iters: 848, time: 0.128, data: 0.000) loss: 0.621 
(epoch: 15, iters: 928, time: 0.113, data: 0.000) loss: 0.346 
(epoch: 15, iters: 1008, time: 0.132, data: 0.039) loss: 0.622 
(epoch: 15, iters: 1088, time: 0.145, data: 0.000) loss: 0.366 
(epoch: 15, iters: 1168, time: 0.148, data: 0.011) loss: 0.758 
(epoch: 15, iters: 1248, time: 0.142, data: 0.000) loss: 0.631 
(epoch: 15, iters: 1328, time: 0.156, data: 0.012) loss: 0.519 
(epoch: 15, iters: 1408, time: 0.141, data: 0.012) loss: 0.883 
(epoch: 15, iters: 1488, time: 0.146, data: 0.000) loss: 0.180 
(epoch: 15, iters: 1568, time: 0.127, data: 0.011) loss: 0.403 
(epoch: 15, iters: 1648, time: 0.154, data: 0.012) loss: 0.401 
(epoch: 15, iters: 1728, time: 0.127, data: 0.029) loss: 0.368 
(epoch: 15, iters: 1808, time: 0.134, data: 0.000) loss: 0.319 
(epoch: 15, iters: 1888, time: 0.153, data: 0.000) loss: 0.321 
(epoch: 15, iters: 1968, time: 0.126, data: 0.023) loss: 0.232 
(epoch: 15, iters: 2048, time: 0.159, data: 0.000) loss: 0.298 
(epoch: 15, iters: 2128, time: 0.126, data: 0.000) loss: 0.445 
(epoch: 15, iters: 2208, time: 0.142, data: 0.040) loss: 0.235 
(epoch: 15, iters: 2288, time: 0.136, data: 0.000) loss: 0.282 
(epoch: 15, iters: 2368, time: 0.146, data: 0.012) loss: 0.318 
(epoch: 15, iters: 2448, time: 0.140, data: 0.000) loss: 0.231 
(epoch: 15, iters: 2528, time: 0.127, data: 0.012) loss: 0.455 
(epoch: 15, iters: 2608, time: 0.159, data: 0.000) loss: 0.362 
(epoch: 15, iters: 2688, time: 0.161, data: 0.000) loss: 0.189 
(epoch: 15, iters: 2768, time: 0.147, data: 0.040) loss: 0.455 
(epoch: 15, iters: 2848, time: 0.152, data: 0.000) loss: 0.361 
(epoch: 15, iters: 2928, time: 0.145, data: 0.013) loss: 0.758 
(epoch: 15, iters: 3008, time: 0.139, data: 0.000) loss: 0.846 
(epoch: 15, iters: 3088, time: 0.151, data: 0.012) loss: 0.489 
(epoch: 15, iters: 3168, time: 0.128, data: 0.000) loss: 0.706 
(epoch: 15, iters: 3248, time: 0.135, data: 0.000) loss: 0.819 
(epoch: 15, iters: 3328, time: 0.145, data: 0.026) loss: 0.288 
(epoch: 15, iters: 3408, time: 0.146, data: 0.000) loss: 0.384 
(epoch: 15, iters: 3488, time: 0.150, data: 0.000) loss: 0.727 
(epoch: 15, iters: 3568, time: 0.156, data: 0.016) loss: 0.227 
(epoch: 15, iters: 3648, time: 0.089, data: 0.000) loss: 0.368 
(epoch: 15, iters: 3728, time: 0.057, data: 0.000) loss: 0.892 
saving the model at the end of epoch 15, iters 55920
End of epoch 15 / 2100 	 Time Taken: 532 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 15, TEST ACC: [76.935 %]

saving the latest model (epoch 16, total_steps 55936)
(epoch: 16, iters: 80, time: 0.135, data: 1.804) loss: 0.416 
(epoch: 16, iters: 160, time: 0.159, data: 0.000) loss: 0.638 
(epoch: 16, iters: 240, time: 0.146, data: 0.030) loss: 0.275 
(epoch: 16, iters: 320, time: 0.147, data: 0.000) loss: 0.840 
(epoch: 16, iters: 400, time: 0.150, data: 0.000) loss: 0.244 
(epoch: 16, iters: 480, time: 0.134, data: 0.037) loss: 0.763 
(epoch: 16, iters: 560, time: 0.132, data: 0.000) loss: 0.448 
(epoch: 16, iters: 640, time: 0.123, data: 0.000) loss: 0.541 
(epoch: 16, iters: 720, time: 0.152, data: 0.012) loss: 0.436 
(epoch: 16, iters: 800, time: 0.160, data: 0.000) loss: 0.206 
(epoch: 16, iters: 880, time: 0.149, data: 0.000) loss: 0.468 
(epoch: 16, iters: 960, time: 0.145, data: 0.015) loss: 0.329 
(epoch: 16, iters: 1040, time: 0.141, data: 0.000) loss: 0.233 
(epoch: 16, iters: 1120, time: 0.129, data: 0.000) loss: 0.408 
(epoch: 16, iters: 1200, time: 0.135, data: 0.025) loss: 0.302 
(epoch: 16, iters: 1280, time: 0.130, data: 0.000) loss: 0.787 
(epoch: 16, iters: 1360, time: 0.139, data: 0.000) loss: 0.201 
(epoch: 16, iters: 1440, time: 0.139, data: 0.050) loss: 0.529 
(epoch: 16, iters: 1520, time: 0.140, data: 0.000) loss: 0.530 
(epoch: 16, iters: 1600, time: 0.154, data: 0.012) loss: 0.277 
(epoch: 16, iters: 1680, time: 0.134, data: 0.000) loss: 0.397 
(epoch: 16, iters: 1760, time: 0.145, data: 0.012) loss: 0.209 
(epoch: 16, iters: 1840, time: 0.153, data: 0.000) loss: 0.225 
(epoch: 16, iters: 1920, time: 0.144, data: 0.000) loss: 0.247 
(epoch: 16, iters: 2000, time: 0.153, data: 0.050) loss: 0.486 
(epoch: 16, iters: 2080, time: 0.136, data: 0.000) loss: 0.221 
(epoch: 16, iters: 2160, time: 0.120, data: 0.022) loss: 0.279 
(epoch: 16, iters: 2240, time: 0.127, data: 0.000) loss: 0.374 
(epoch: 16, iters: 2320, time: 0.141, data: 0.012) loss: 0.223 
(epoch: 16, iters: 2400, time: 0.132, data: 0.021) loss: 0.197 
(epoch: 16, iters: 2480, time: 0.153, data: 0.000) loss: 0.574 
(epoch: 16, iters: 2560, time: 0.120, data: 0.012) loss: 0.550 
(epoch: 16, iters: 2640, time: 0.139, data: 0.000) loss: 0.385 
(epoch: 16, iters: 2720, time: 0.141, data: 0.000) loss: 0.353 
(epoch: 16, iters: 2800, time: 0.158, data: 0.012) loss: 0.375 
(epoch: 16, iters: 2880, time: 0.134, data: 0.013) loss: 0.279 
(epoch: 16, iters: 2960, time: 0.145, data: 0.000) loss: 0.655 
(epoch: 16, iters: 3040, time: 0.150, data: 0.012) loss: 0.568 
(epoch: 16, iters: 3120, time: 0.142, data: 0.021) loss: 0.284 
(epoch: 16, iters: 3200, time: 0.153, data: 0.000) loss: 0.227 
(epoch: 16, iters: 3280, time: 0.134, data: 0.012) loss: 0.517 
(epoch: 16, iters: 3360, time: 0.135, data: 0.000) loss: 0.603 
(epoch: 16, iters: 3440, time: 0.130, data: 0.000) loss: 0.378 
(epoch: 16, iters: 3520, time: 0.143, data: 0.049) loss: 0.836 
(epoch: 16, iters: 3600, time: 0.153, data: 0.000) loss: 0.647 
(epoch: 16, iters: 3680, time: 0.089, data: 0.022) loss: 0.258 
saving the model at the end of epoch 16, iters 59648
End of epoch 16 / 2100 	 Time Taken: 526 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 16, TEST ACC: [82.246 %]

saving the latest model (epoch 17, total_steps 59664)
(epoch: 17, iters: 32, time: 0.158, data: 0.008) loss: 0.268 
(epoch: 17, iters: 112, time: 0.116, data: 0.027) loss: 0.885 
(epoch: 17, iters: 192, time: 0.152, data: 0.000) loss: 0.504 
(epoch: 17, iters: 272, time: 0.135, data: 0.000) loss: 0.173 
(epoch: 17, iters: 352, time: 0.135, data: 0.024) loss: 0.557 
(epoch: 17, iters: 432, time: 0.128, data: 0.000) loss: 0.139 
(epoch: 17, iters: 512, time: 0.132, data: 0.000) loss: 0.634 
(epoch: 17, iters: 592, time: 0.140, data: 0.039) loss: 0.341 
(epoch: 17, iters: 672, time: 0.140, data: 0.000) loss: 0.375 
(epoch: 17, iters: 752, time: 0.153, data: 0.012) loss: 0.297 
(epoch: 17, iters: 832, time: 0.155, data: 0.000) loss: 0.343 
(epoch: 17, iters: 912, time: 0.145, data: 0.013) loss: 0.106 
(epoch: 17, iters: 992, time: 0.141, data: 0.000) loss: 0.199 
(epoch: 17, iters: 1072, time: 0.134, data: 0.000) loss: 0.189 
(epoch: 17, iters: 1152, time: 0.146, data: 0.040) loss: 0.167 
(epoch: 17, iters: 1232, time: 0.162, data: 0.000) loss: 0.387 
(epoch: 17, iters: 1312, time: 0.149, data: 0.000) loss: 0.203 
(epoch: 17, iters: 1392, time: 0.157, data: 0.031) loss: 0.307 
(epoch: 17, iters: 1472, time: 0.111, data: 0.000) loss: 0.247 
(epoch: 17, iters: 1552, time: 0.140, data: 0.012) loss: 0.640 
(epoch: 17, iters: 1632, time: 0.141, data: 0.000) loss: 0.390 
(epoch: 17, iters: 1712, time: 0.154, data: 0.012) loss: 0.290 
(epoch: 17, iters: 1792, time: 0.129, data: 0.000) loss: 0.186 
(epoch: 17, iters: 1872, time: 0.127, data: 0.000) loss: 0.687 
(epoch: 17, iters: 1952, time: 0.133, data: 0.040) loss: 0.224 
(epoch: 17, iters: 2032, time: 0.159, data: 0.000) loss: 0.182 
(epoch: 17, iters: 2112, time: 0.133, data: 0.000) loss: 0.124 
(epoch: 17, iters: 2192, time: 0.140, data: 0.040) loss: 0.274 
(epoch: 17, iters: 2272, time: 0.156, data: 0.000) loss: 0.298 
(epoch: 17, iters: 2352, time: 0.140, data: 0.012) loss: 0.245 
(epoch: 17, iters: 2432, time: 0.146, data: 0.000) loss: 0.990 
(epoch: 17, iters: 2512, time: 0.128, data: 0.011) loss: 0.444 
(epoch: 17, iters: 2592, time: 0.138, data: 0.011) loss: 0.555 
(epoch: 17, iters: 2672, time: 0.133, data: 0.000) loss: 0.610 
(epoch: 17, iters: 2752, time: 0.158, data: 0.011) loss: 0.911 
(epoch: 17, iters: 2832, time: 0.140, data: 0.011) loss: 0.626 
(epoch: 17, iters: 2912, time: 0.129, data: 0.026) loss: 0.343 
(epoch: 17, iters: 2992, time: 0.145, data: 0.000) loss: 0.225 
(epoch: 17, iters: 3072, time: 0.119, data: 0.012) loss: 0.297 
(epoch: 17, iters: 3152, time: 0.140, data: 0.000) loss: 0.567 
(epoch: 17, iters: 3232, time: 0.153, data: 0.012) loss: 0.315 
(epoch: 17, iters: 3312, time: 0.146, data: 0.000) loss: 0.453 
(epoch: 17, iters: 3392, time: 0.138, data: 0.000) loss: 0.671 
(epoch: 17, iters: 3472, time: 0.148, data: 0.040) loss: 0.547 
(epoch: 17, iters: 3552, time: 0.151, data: 0.000) loss: 0.465 
(epoch: 17, iters: 3632, time: 0.126, data: 0.011) loss: 1.049 
(epoch: 17, iters: 3712, time: 0.092, data: 0.022) loss: 0.095 
saving the model at the end of epoch 17, iters 63376
End of epoch 17 / 2100 	 Time Taken: 517 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 17, TEST ACC: [81.791 %]

saving the latest model (epoch 18, total_steps 63392)
(epoch: 18, iters: 64, time: 0.142, data: 0.000) loss: 0.260 
(epoch: 18, iters: 144, time: 0.127, data: 0.012) loss: 0.491 
(epoch: 18, iters: 224, time: 0.158, data: 0.000) loss: 0.450 
(epoch: 18, iters: 304, time: 0.148, data: 0.012) loss: 0.742 
(epoch: 18, iters: 384, time: 0.109, data: 0.012) loss: 0.774 
(epoch: 18, iters: 464, time: 0.140, data: 0.029) loss: 0.399 
(epoch: 18, iters: 544, time: 0.136, data: 0.000) loss: 0.212 
(epoch: 18, iters: 624, time: 0.119, data: 0.000) loss: 0.103 
(epoch: 18, iters: 704, time: 0.136, data: 0.040) loss: 0.523 
(epoch: 18, iters: 784, time: 0.153, data: 0.000) loss: 0.329 
(epoch: 18, iters: 864, time: 0.147, data: 0.012) loss: 0.982 
(epoch: 18, iters: 944, time: 0.114, data: 0.000) loss: 0.083 
(epoch: 18, iters: 1024, time: 0.154, data: 0.012) loss: 0.543 
(epoch: 18, iters: 1104, time: 0.127, data: 0.000) loss: 0.142 
(epoch: 18, iters: 1184, time: 0.114, data: 0.000) loss: 0.097 
(epoch: 18, iters: 1264, time: 0.155, data: 0.041) loss: 0.132 
(epoch: 18, iters: 1344, time: 0.133, data: 0.000) loss: 0.320 
(epoch: 18, iters: 1424, time: 0.153, data: 0.012) loss: 0.346 
(epoch: 18, iters: 1504, time: 0.146, data: 0.029) loss: 0.329 
(epoch: 18, iters: 1584, time: 0.133, data: 0.000) loss: 0.103 
(epoch: 18, iters: 1664, time: 0.149, data: 0.012) loss: 0.237 
(epoch: 18, iters: 1744, time: 0.140, data: 0.000) loss: 0.080 
(epoch: 18, iters: 1824, time: 0.139, data: 0.012) loss: 0.398 
(epoch: 18, iters: 1904, time: 0.147, data: 0.000) loss: 0.058 
(epoch: 18, iters: 1984, time: 0.151, data: 0.000) loss: 0.248 
(epoch: 18, iters: 2064, time: 0.133, data: 0.041) loss: 0.440 
(epoch: 18, iters: 2144, time: 0.131, data: 0.000) loss: 0.330 
(epoch: 18, iters: 2224, time: 0.121, data: 0.012) loss: 0.368 
(epoch: 18, iters: 2304, time: 0.152, data: 0.000) loss: 0.588 
(epoch: 18, iters: 2384, time: 0.139, data: 0.012) loss: 0.200 
(epoch: 18, iters: 2464, time: 0.160, data: 0.000) loss: 0.437 
(epoch: 18, iters: 2544, time: 0.152, data: 0.000) loss: 0.915 
(epoch: 18, iters: 2624, time: 0.134, data: 0.040) loss: 0.328 
(epoch: 18, iters: 2704, time: 0.152, data: 0.000) loss: 0.306 
(epoch: 18, iters: 2784, time: 0.124, data: 0.013) loss: 0.196 
(epoch: 18, iters: 2864, time: 0.146, data: 0.000) loss: 0.242 
(epoch: 18, iters: 2944, time: 0.146, data: 0.012) loss: 0.446 
(epoch: 18, iters: 3024, time: 0.143, data: 0.012) loss: 0.288 
(epoch: 18, iters: 3104, time: 0.133, data: 0.000) loss: 0.195 
(epoch: 18, iters: 3184, time: 0.134, data: 0.012) loss: 0.255 
(epoch: 18, iters: 3264, time: 0.132, data: 0.012) loss: 0.579 
(epoch: 18, iters: 3344, time: 0.156, data: 0.000) loss: 0.151 
(epoch: 18, iters: 3424, time: 0.133, data: 0.013) loss: 0.738 
(epoch: 18, iters: 3504, time: 0.135, data: 0.000) loss: 0.772 
(epoch: 18, iters: 3584, time: 0.152, data: 0.000) loss: 0.190 
(epoch: 18, iters: 3664, time: 0.089, data: 0.033) loss: 0.555 
saving the model at the end of epoch 18, iters 67104
End of epoch 18 / 2100 	 Time Taken: 509 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 18, TEST ACC: [83.005 %]

(epoch: 19, iters: 16, time: 0.200, data: 0.000) loss: 0.132 
saving the latest model (epoch 19, total_steps 67120)
(epoch: 19, iters: 96, time: 0.119, data: 0.000) loss: 0.510 
(epoch: 19, iters: 176, time: 0.146, data: 0.000) loss: 0.420 
(epoch: 19, iters: 256, time: 0.113, data: 0.012) loss: 0.444 
(epoch: 19, iters: 336, time: 0.108, data: 0.000) loss: 0.353 
(epoch: 19, iters: 416, time: 0.127, data: 0.000) loss: 0.454 
(epoch: 19, iters: 496, time: 0.136, data: 0.052) loss: 0.258 
(epoch: 19, iters: 576, time: 0.136, data: 0.000) loss: 0.319 
(epoch: 19, iters: 656, time: 0.119, data: 0.022) loss: 0.212 
(epoch: 19, iters: 736, time: 0.115, data: 0.000) loss: 0.156 
(epoch: 19, iters: 816, time: 0.120, data: 0.012) loss: 0.356 
(epoch: 19, iters: 896, time: 0.142, data: 0.000) loss: 0.187 
(epoch: 19, iters: 976, time: 0.126, data: 0.000) loss: 0.171 
(epoch: 19, iters: 1056, time: 0.128, data: 0.036) loss: 1.058 
(epoch: 19, iters: 1136, time: 0.140, data: 0.000) loss: 0.312 
(epoch: 19, iters: 1216, time: 0.109, data: 0.000) loss: 0.439 
(epoch: 19, iters: 1296, time: 0.129, data: 0.040) loss: 0.266 
(epoch: 19, iters: 1376, time: 0.140, data: 0.000) loss: 0.346 
(epoch: 19, iters: 1456, time: 0.131, data: 0.012) loss: 0.244 
(epoch: 19, iters: 1536, time: 0.127, data: 0.000) loss: 0.630 
(epoch: 19, iters: 1616, time: 0.118, data: 0.012) loss: 0.319 
(epoch: 19, iters: 1696, time: 0.137, data: 0.000) loss: 0.189 
(epoch: 19, iters: 1776, time: 0.134, data: 0.000) loss: 0.098 
(epoch: 19, iters: 1856, time: 0.134, data: 0.040) loss: 0.308 
(epoch: 19, iters: 1936, time: 0.123, data: 0.000) loss: 0.209 
(epoch: 19, iters: 2016, time: 0.139, data: 0.012) loss: 0.280 
(epoch: 19, iters: 2096, time: 0.149, data: 0.000) loss: 0.161 
(epoch: 19, iters: 2176, time: 0.127, data: 0.012) loss: 0.515 
(epoch: 19, iters: 2256, time: 0.125, data: 0.000) loss: 0.335 
(epoch: 19, iters: 2336, time: 0.120, data: 0.000) loss: 0.235 
(epoch: 19, iters: 2416, time: 0.152, data: 0.011) loss: 0.402 
(epoch: 19, iters: 2496, time: 0.138, data: 0.012) loss: 0.348 
(epoch: 19, iters: 2576, time: 0.133, data: 0.000) loss: 0.103 
(epoch: 19, iters: 2656, time: 0.132, data: 0.012) loss: 0.175 
(epoch: 19, iters: 2736, time: 0.147, data: 0.000) loss: 0.585 
(epoch: 19, iters: 2816, time: 0.139, data: 0.000) loss: 0.233 
(epoch: 19, iters: 2896, time: 0.151, data: 0.041) loss: 0.954 
(epoch: 19, iters: 2976, time: 0.134, data: 0.000) loss: 0.513 
(epoch: 19, iters: 3056, time: 0.131, data: 0.012) loss: 0.135 
(epoch: 19, iters: 3136, time: 0.133, data: 0.000) loss: 0.230 
(epoch: 19, iters: 3216, time: 0.126, data: 0.013) loss: 0.373 
(epoch: 19, iters: 3296, time: 0.147, data: 0.000) loss: 0.257 
(epoch: 19, iters: 3376, time: 0.132, data: 0.000) loss: 0.489 
(epoch: 19, iters: 3456, time: 0.139, data: 0.042) loss: 0.219 
(epoch: 19, iters: 3536, time: 0.141, data: 0.000) loss: 0.471 
(epoch: 19, iters: 3616, time: 0.122, data: 0.013) loss: 0.154 
(epoch: 19, iters: 3696, time: 0.089, data: 0.030) loss: 0.107 
saving the model at the end of epoch 19, iters 70832
End of epoch 19 / 2100 	 Time Taken: 498 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 19, TEST ACC: [66.464 %]

saving the latest model (epoch 20, total_steps 70848)
(epoch: 20, iters: 48, time: 0.134, data: 0.000) loss: 0.256 
(epoch: 20, iters: 128, time: 0.134, data: 0.012) loss: 0.681 
(epoch: 20, iters: 208, time: 0.144, data: 0.012) loss: 0.118 
(epoch: 20, iters: 288, time: 0.137, data: 0.000) loss: 0.170 
(epoch: 20, iters: 368, time: 0.133, data: 0.012) loss: 0.287 
(epoch: 20, iters: 448, time: 0.127, data: 0.000) loss: 0.257 
(epoch: 20, iters: 528, time: 0.140, data: 0.000) loss: 0.281 
(epoch: 20, iters: 608, time: 0.126, data: 0.026) loss: 0.470 
(epoch: 20, iters: 688, time: 0.118, data: 0.000) loss: 0.385 
(epoch: 20, iters: 768, time: 0.121, data: 0.000) loss: 0.546 
(epoch: 20, iters: 848, time: 0.138, data: 0.012) loss: 0.321 
(epoch: 20, iters: 928, time: 0.120, data: 0.000) loss: 0.119 
(epoch: 20, iters: 1008, time: 0.139, data: 0.000) loss: 0.499 
(epoch: 20, iters: 1088, time: 0.153, data: 0.040) loss: 0.149 
(epoch: 20, iters: 1168, time: 0.120, data: 0.000) loss: 0.430 
(epoch: 20, iters: 1248, time: 0.143, data: 0.011) loss: 0.149 
(epoch: 20, iters: 1328, time: 0.133, data: 0.000) loss: 0.268 
(epoch: 20, iters: 1408, time: 0.122, data: 0.012) loss: 0.385 
(epoch: 20, iters: 1488, time: 0.128, data: 0.000) loss: 0.380 
(epoch: 20, iters: 1568, time: 0.138, data: 0.000) loss: 0.127 
(epoch: 20, iters: 1648, time: 0.141, data: 0.040) loss: 0.200 
(epoch: 20, iters: 1728, time: 0.147, data: 0.000) loss: 0.121 
(epoch: 20, iters: 1808, time: 0.107, data: 0.012) loss: 0.120 
(epoch: 20, iters: 1888, time: 0.128, data: 0.000) loss: 0.366 
(epoch: 20, iters: 1968, time: 0.102, data: 0.012) loss: 0.257 
(epoch: 20, iters: 2048, time: 0.134, data: 0.000) loss: 0.221 
(epoch: 20, iters: 2128, time: 0.134, data: 0.000) loss: 0.102 
(epoch: 20, iters: 2208, time: 0.140, data: 0.041) loss: 0.102 
(epoch: 20, iters: 2288, time: 0.127, data: 0.000) loss: 0.294 
(epoch: 20, iters: 2368, time: 0.138, data: 0.011) loss: 0.158 
(epoch: 20, iters: 2448, time: 0.120, data: 0.000) loss: 0.196 
(epoch: 20, iters: 2528, time: 0.126, data: 0.012) loss: 0.267 
(epoch: 20, iters: 2608, time: 0.120, data: 0.000) loss: 0.173 
(epoch: 20, iters: 2688, time: 0.107, data: 0.000) loss: 0.318 
(epoch: 20, iters: 2768, time: 0.129, data: 0.040) loss: 0.215 
(epoch: 20, iters: 2848, time: 0.153, data: 0.000) loss: 0.345 
(epoch: 20, iters: 2928, time: 0.131, data: 0.012) loss: 0.067 
(epoch: 20, iters: 3008, time: 0.133, data: 0.025) loss: 0.198 
(epoch: 20, iters: 3088, time: 0.114, data: 0.000) loss: 0.391 
(epoch: 20, iters: 3168, time: 0.145, data: 0.012) loss: 0.107 
(epoch: 20, iters: 3248, time: 0.115, data: 0.000) loss: 0.206 
(epoch: 20, iters: 3328, time: 0.127, data: 0.012) loss: 0.089 
(epoch: 20, iters: 3408, time: 0.118, data: 0.012) loss: 0.158 
(epoch: 20, iters: 3488, time: 0.135, data: 0.000) loss: 0.175 
(epoch: 20, iters: 3568, time: 0.155, data: 0.012) loss: 0.273 
(epoch: 20, iters: 3648, time: 0.090, data: 0.000) loss: 0.309 
(epoch: 20, iters: 3728, time: 0.058, data: 0.000) loss: 0.236 
saving the model at the end of epoch 20, iters 74560
End of epoch 20 / 2100 	 Time Taken: 492 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 20, TEST ACC: [77.542 %]

saving the latest model (epoch 21, total_steps 74576)
(epoch: 21, iters: 80, time: 0.127, data: 1.306) loss: 0.442 
(epoch: 21, iters: 160, time: 0.145, data: 0.012) loss: 0.470 
(epoch: 21, iters: 240, time: 0.140, data: 0.000) loss: 0.204 
(epoch: 21, iters: 320, time: 0.119, data: 0.011) loss: 0.158 
(epoch: 21, iters: 400, time: 0.121, data: 0.000) loss: 0.238 
(epoch: 21, iters: 480, time: 0.114, data: 0.000) loss: 0.305 
(epoch: 21, iters: 560, time: 0.134, data: 0.040) loss: 0.483 
(epoch: 21, iters: 640, time: 0.133, data: 0.000) loss: 0.130 
(epoch: 21, iters: 720, time: 0.139, data: 0.013) loss: 0.231 
(epoch: 21, iters: 800, time: 0.114, data: 0.000) loss: 0.270 
(epoch: 21, iters: 880, time: 0.133, data: 0.012) loss: 0.469 
(epoch: 21, iters: 960, time: 0.145, data: 0.000) loss: 0.070 
(epoch: 21, iters: 1040, time: 0.131, data: 0.000) loss: 0.807 
(epoch: 21, iters: 1120, time: 0.120, data: 0.039) loss: 0.280 
(epoch: 21, iters: 1200, time: 0.140, data: 0.000) loss: 0.286 
(epoch: 21, iters: 1280, time: 0.135, data: 0.012) loss: 0.045 
(epoch: 21, iters: 1360, time: 0.114, data: 0.000) loss: 0.224 
(epoch: 21, iters: 1440, time: 0.126, data: 0.012) loss: 0.118 
(epoch: 21, iters: 1520, time: 0.108, data: 0.000) loss: 0.312 
(epoch: 21, iters: 1600, time: 0.148, data: 0.000) loss: 0.368 
(epoch: 21, iters: 1680, time: 0.133, data: 0.041) loss: 0.317 
(epoch: 21, iters: 1760, time: 0.158, data: 0.000) loss: 0.147 
(epoch: 21, iters: 1840, time: 0.122, data: 0.000) loss: 0.416 
(epoch: 21, iters: 1920, time: 0.127, data: 0.039) loss: 0.400 
(epoch: 21, iters: 2000, time: 0.153, data: 0.000) loss: 0.155 
(epoch: 21, iters: 2080, time: 0.133, data: 0.000) loss: 0.207 
(epoch: 21, iters: 2160, time: 0.132, data: 0.026) loss: 0.298 
(epoch: 21, iters: 2240, time: 0.133, data: 0.000) loss: 0.834 
(epoch: 21, iters: 2320, time: 0.131, data: 0.000) loss: 0.396 
(epoch: 21, iters: 2400, time: 0.140, data: 0.041) loss: 0.354 
(epoch: 21, iters: 2480, time: 0.116, data: 0.000) loss: 0.243 
(epoch: 21, iters: 2560, time: 0.133, data: 0.012) loss: 0.266 
(epoch: 21, iters: 2640, time: 0.147, data: 0.000) loss: 0.163 
(epoch: 21, iters: 2720, time: 0.122, data: 0.013) loss: 0.285 
(epoch: 21, iters: 2800, time: 0.119, data: 0.000) loss: 0.544 
(epoch: 21, iters: 2880, time: 0.120, data: 0.000) loss: 0.183 
(epoch: 21, iters: 2960, time: 0.136, data: 0.039) loss: 0.518 
(epoch: 21, iters: 3040, time: 0.148, data: 0.000) loss: 0.183 
(epoch: 21, iters: 3120, time: 0.119, data: 0.000) loss: 0.164 
(epoch: 21, iters: 3200, time: 0.115, data: 0.040) loss: 0.309 
(epoch: 21, iters: 3280, time: 0.121, data: 0.000) loss: 0.393 
(epoch: 21, iters: 3360, time: 0.119, data: 0.011) loss: 0.770 
(epoch: 21, iters: 3440, time: 0.127, data: 0.000) loss: 0.123 
(epoch: 21, iters: 3520, time: 0.126, data: 0.011) loss: 0.371 
(epoch: 21, iters: 3600, time: 0.119, data: 0.000) loss: 0.183 
(epoch: 21, iters: 3680, time: 0.089, data: 0.000) loss: 0.094 
saving the model at the end of epoch 21, iters 78288
End of epoch 21 / 2100 	 Time Taken: 485 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 21, TEST ACC: [82.701 %]

saving the latest model (epoch 22, total_steps 78304)
(epoch: 22, iters: 32, time: 0.132, data: 0.004) loss: 0.225 
(epoch: 22, iters: 112, time: 0.140, data: 0.027) loss: 0.148 
(epoch: 22, iters: 192, time: 0.120, data: 0.000) loss: 0.189 
(epoch: 22, iters: 272, time: 0.106, data: 0.000) loss: 0.095 
(epoch: 22, iters: 352, time: 0.120, data: 0.000) loss: 0.264 
(epoch: 22, iters: 432, time: 0.135, data: 0.000) loss: 0.146 
(epoch: 22, iters: 512, time: 0.140, data: 0.000) loss: 0.158 
(epoch: 22, iters: 592, time: 0.117, data: 0.040) loss: 0.287 
(epoch: 22, iters: 672, time: 0.135, data: 0.000) loss: 0.130 
(epoch: 22, iters: 752, time: 0.125, data: 0.012) loss: 0.168 
(epoch: 22, iters: 832, time: 0.133, data: 0.000) loss: 0.319 
(epoch: 22, iters: 912, time: 0.120, data: 0.012) loss: 0.481 
(epoch: 22, iters: 992, time: 0.124, data: 0.000) loss: 0.533 
(epoch: 22, iters: 1072, time: 0.119, data: 0.000) loss: 0.072 
(epoch: 22, iters: 1152, time: 0.120, data: 0.040) loss: 0.199 
(epoch: 22, iters: 1232, time: 0.122, data: 0.000) loss: 0.773 
(epoch: 22, iters: 1312, time: 0.126, data: 0.000) loss: 0.377 
(epoch: 22, iters: 1392, time: 0.137, data: 0.025) loss: 0.531 
(epoch: 22, iters: 1472, time: 0.144, data: 0.000) loss: 0.218 
(epoch: 22, iters: 1552, time: 0.129, data: 0.000) loss: 0.246 
(epoch: 22, iters: 1632, time: 0.137, data: 0.050) loss: 0.197 
(epoch: 22, iters: 1712, time: 0.129, data: 0.000) loss: 0.602 
(epoch: 22, iters: 1792, time: 0.141, data: 0.012) loss: 0.165 
(epoch: 22, iters: 1872, time: 0.133, data: 0.000) loss: 0.110 
(epoch: 22, iters: 1952, time: 0.135, data: 0.012) loss: 0.549 
(epoch: 22, iters: 2032, time: 0.143, data: 0.000) loss: 0.337 
(epoch: 22, iters: 2112, time: 0.128, data: 0.000) loss: 0.249 
(epoch: 22, iters: 2192, time: 0.142, data: 0.040) loss: 0.063 
(epoch: 22, iters: 2272, time: 0.142, data: 0.000) loss: 0.263 
(epoch: 22, iters: 2352, time: 0.140, data: 0.012) loss: 0.202 
(epoch: 22, iters: 2432, time: 0.123, data: 0.000) loss: 0.270 
(epoch: 22, iters: 2512, time: 0.149, data: 0.013) loss: 0.417 
(epoch: 22, iters: 2592, time: 0.123, data: 0.000) loss: 0.071 
(epoch: 22, iters: 2672, time: 0.151, data: 0.000) loss: 0.171 
(epoch: 22, iters: 2752, time: 0.133, data: 0.041) loss: 0.103 
(epoch: 22, iters: 2832, time: 0.134, data: 0.000) loss: 0.241 
(epoch: 22, iters: 2912, time: 0.125, data: 0.012) loss: 0.598 
(epoch: 22, iters: 2992, time: 0.133, data: 0.000) loss: 0.241 
(epoch: 22, iters: 3072, time: 0.137, data: 0.012) loss: 0.095 
(epoch: 22, iters: 3152, time: 0.133, data: 0.000) loss: 0.080 
(epoch: 22, iters: 3232, time: 0.112, data: 0.000) loss: 0.601 
(epoch: 22, iters: 3312, time: 0.143, data: 0.040) loss: 0.276 
(epoch: 22, iters: 3392, time: 0.129, data: 0.000) loss: 0.210 
(epoch: 22, iters: 3472, time: 0.133, data: 0.012) loss: 0.440 
(epoch: 22, iters: 3552, time: 0.121, data: 0.000) loss: 0.258 
(epoch: 22, iters: 3632, time: 0.112, data: 0.012) loss: 0.263 
(epoch: 22, iters: 3712, time: 0.089, data: 0.000) loss: 0.251 
saving the model at the end of epoch 22, iters 82016
End of epoch 22 / 2100 	 Time Taken: 484 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 22, TEST ACC: [88.467 %]

saving the latest model (epoch 23, total_steps 82032)
(epoch: 23, iters: 64, time: 0.132, data: 0.000) loss: 0.181 
(epoch: 23, iters: 144, time: 0.146, data: 0.027) loss: 0.334 
(epoch: 23, iters: 224, time: 0.139, data: 0.000) loss: 0.227 
(epoch: 23, iters: 304, time: 0.119, data: 0.012) loss: 0.101 
(epoch: 23, iters: 384, time: 0.120, data: 0.000) loss: 0.320 
(epoch: 23, iters: 464, time: 0.120, data: 0.021) loss: 0.230 
(epoch: 23, iters: 544, time: 0.134, data: 0.000) loss: 0.391 
(epoch: 23, iters: 624, time: 0.114, data: 0.000) loss: 0.263 
(epoch: 23, iters: 704, time: 0.121, data: 0.049) loss: 0.440 
(epoch: 23, iters: 784, time: 0.122, data: 0.000) loss: 0.464 
(epoch: 23, iters: 864, time: 0.107, data: 0.012) loss: 0.268 
(epoch: 23, iters: 944, time: 0.128, data: 0.000) loss: 0.076 
(epoch: 23, iters: 1024, time: 0.126, data: 0.012) loss: 0.276 
(epoch: 23, iters: 1104, time: 0.127, data: 0.000) loss: 0.136 
(epoch: 23, iters: 1184, time: 0.127, data: 0.000) loss: 0.109 
(epoch: 23, iters: 1264, time: 0.134, data: 0.040) loss: 0.271 
(epoch: 23, iters: 1344, time: 0.134, data: 0.000) loss: 0.212 
(epoch: 23, iters: 1424, time: 0.112, data: 0.012) loss: 0.806 
(epoch: 23, iters: 1504, time: 0.121, data: 0.000) loss: 0.206 
(epoch: 23, iters: 1584, time: 0.140, data: 0.012) loss: 0.175 
(epoch: 23, iters: 1664, time: 0.124, data: 0.012) loss: 0.387 
(epoch: 23, iters: 1744, time: 0.134, data: 0.000) loss: 0.597 
(epoch: 23, iters: 1824, time: 0.126, data: 0.012) loss: 0.265 
(epoch: 23, iters: 1904, time: 0.116, data: 0.000) loss: 0.204 
(epoch: 23, iters: 1984, time: 0.119, data: 0.000) loss: 0.821 
(epoch: 23, iters: 2064, time: 0.115, data: 0.040) loss: 0.153 
(epoch: 23, iters: 2144, time: 0.128, data: 0.000) loss: 0.102 
(epoch: 23, iters: 2224, time: 0.151, data: 0.012) loss: 0.095 
(epoch: 23, iters: 2304, time: 0.108, data: 0.000) loss: 0.421 
(epoch: 23, iters: 2384, time: 0.131, data: 0.011) loss: 0.174 
(epoch: 23, iters: 2464, time: 0.140, data: 0.000) loss: 0.125 
(epoch: 23, iters: 2544, time: 0.119, data: 0.000) loss: 0.052 
(epoch: 23, iters: 2624, time: 0.127, data: 0.040) loss: 0.108 
(epoch: 23, iters: 2704, time: 0.121, data: 0.000) loss: 0.051 
(epoch: 23, iters: 2784, time: 0.131, data: 0.012) loss: 0.093 
(epoch: 23, iters: 2864, time: 0.139, data: 0.000) loss: 0.150 
(epoch: 23, iters: 2944, time: 0.114, data: 0.012) loss: 0.333 
(epoch: 23, iters: 3024, time: 0.133, data: 0.000) loss: 0.427 
(epoch: 23, iters: 3104, time: 0.145, data: 0.000) loss: 0.367 
(epoch: 23, iters: 3184, time: 0.108, data: 0.026) loss: 0.199 
(epoch: 23, iters: 3264, time: 0.140, data: 0.000) loss: 0.157 
(epoch: 23, iters: 3344, time: 0.106, data: 0.000) loss: 0.163 
(epoch: 23, iters: 3424, time: 0.150, data: 0.040) loss: 0.185 
(epoch: 23, iters: 3504, time: 0.108, data: 0.000) loss: 0.111 
(epoch: 23, iters: 3584, time: 0.124, data: 0.012) loss: 0.125 
(epoch: 23, iters: 3664, time: 0.089, data: 0.000) loss: 0.184 
saving the model at the end of epoch 23, iters 85744
End of epoch 23 / 2100 	 Time Taken: 468 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 23, TEST ACC: [77.845 %]

(epoch: 24, iters: 16, time: 0.235, data: 0.009) loss: 0.706 
saving the latest model (epoch 24, total_steps 85760)
(epoch: 24, iters: 96, time: 0.114, data: 0.011) loss: 0.478 
(epoch: 24, iters: 176, time: 0.131, data: 0.011) loss: 0.194 
(epoch: 24, iters: 256, time: 0.102, data: 0.000) loss: 0.236 
(epoch: 24, iters: 336, time: 0.142, data: 0.011) loss: 0.114 
(epoch: 24, iters: 416, time: 0.130, data: 0.000) loss: 0.210 
(epoch: 24, iters: 496, time: 0.121, data: 0.000) loss: 0.298 
(epoch: 24, iters: 576, time: 0.115, data: 0.039) loss: 0.072 
(epoch: 24, iters: 656, time: 0.143, data: 0.000) loss: 0.303 
(epoch: 24, iters: 736, time: 0.112, data: 0.012) loss: 0.289 
(epoch: 24, iters: 816, time: 0.110, data: 0.000) loss: 0.251 
(epoch: 24, iters: 896, time: 0.122, data: 0.012) loss: 0.159 
(epoch: 24, iters: 976, time: 0.121, data: 0.000) loss: 0.097 
(epoch: 24, iters: 1056, time: 0.128, data: 0.000) loss: 0.154 
(epoch: 24, iters: 1136, time: 0.122, data: 0.041) loss: 0.221 
(epoch: 24, iters: 1216, time: 0.140, data: 0.000) loss: 0.066 
(epoch: 24, iters: 1296, time: 0.119, data: 0.012) loss: 0.287 
(epoch: 24, iters: 1376, time: 0.123, data: 0.000) loss: 0.128 
(epoch: 24, iters: 1456, time: 0.133, data: 0.012) loss: 0.099 
(epoch: 24, iters: 1536, time: 0.127, data: 0.000) loss: 0.510 
(epoch: 24, iters: 1616, time: 0.140, data: 0.000) loss: 0.158 
(epoch: 24, iters: 1696, time: 0.135, data: 0.051) loss: 0.184 
(epoch: 24, iters: 1776, time: 0.115, data: 0.000) loss: 0.149 
(epoch: 24, iters: 1856, time: 0.131, data: 0.022) loss: 0.105 
(epoch: 24, iters: 1936, time: 0.121, data: 0.000) loss: 0.033 
(epoch: 24, iters: 2016, time: 0.121, data: 0.011) loss: 0.130 
(epoch: 24, iters: 2096, time: 0.134, data: 0.000) loss: 0.796 
(epoch: 24, iters: 2176, time: 0.129, data: 0.000) loss: 0.275 
(epoch: 24, iters: 2256, time: 0.123, data: 0.040) loss: 0.293 
(epoch: 24, iters: 2336, time: 0.134, data: 0.000) loss: 0.469 
(epoch: 24, iters: 2416, time: 0.143, data: 0.012) loss: 0.033 
(epoch: 24, iters: 2496, time: 0.127, data: 0.000) loss: 0.498 
(epoch: 24, iters: 2576, time: 0.122, data: 0.012) loss: 0.120 
(epoch: 24, iters: 2656, time: 0.140, data: 0.000) loss: 0.032 
(epoch: 24, iters: 2736, time: 0.129, data: 0.000) loss: 0.246 
(epoch: 24, iters: 2816, time: 0.143, data: 0.040) loss: 0.178 
(epoch: 24, iters: 2896, time: 0.142, data: 0.000) loss: 0.325 
(epoch: 24, iters: 2976, time: 0.107, data: 0.012) loss: 0.364 
(epoch: 24, iters: 3056, time: 0.114, data: 0.000) loss: 0.083 
(epoch: 24, iters: 3136, time: 0.133, data: 0.012) loss: 0.320 
(epoch: 24, iters: 3216, time: 0.122, data: 0.000) loss: 0.059 
(epoch: 24, iters: 3296, time: 0.138, data: 0.000) loss: 0.577 
(epoch: 24, iters: 3376, time: 0.108, data: 0.040) loss: 0.126 
(epoch: 24, iters: 3456, time: 0.134, data: 0.000) loss: 0.191 
(epoch: 24, iters: 3536, time: 0.125, data: 0.012) loss: 0.331 
(epoch: 24, iters: 3616, time: 0.140, data: 0.000) loss: 0.961 
(epoch: 24, iters: 3696, time: 0.089, data: 0.012) loss: 0.115 
saving the model at the end of epoch 24, iters 89472
End of epoch 24 / 2100 	 Time Taken: 465 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 24, TEST ACC: [86.039 %]

saving the latest model (epoch 25, total_steps 89488)
(epoch: 25, iters: 48, time: 0.103, data: 0.000) loss: 0.191 
(epoch: 25, iters: 128, time: 0.121, data: 0.000) loss: 0.302 
(epoch: 25, iters: 208, time: 0.116, data: 0.030) loss: 0.099 
(epoch: 25, iters: 288, time: 0.142, data: 0.000) loss: 0.076 
(epoch: 25, iters: 368, time: 0.115, data: 0.012) loss: 0.183 
(epoch: 25, iters: 448, time: 0.121, data: 0.000) loss: 0.124 
(epoch: 25, iters: 528, time: 0.128, data: 0.011) loss: 0.162 
(epoch: 25, iters: 608, time: 0.112, data: 0.012) loss: 0.113 
(epoch: 25, iters: 688, time: 0.114, data: 0.000) loss: 0.159 
(epoch: 25, iters: 768, time: 0.126, data: 0.012) loss: 0.273 
(epoch: 25, iters: 848, time: 0.147, data: 0.000) loss: 0.124 
(epoch: 25, iters: 928, time: 0.101, data: 0.000) loss: 0.568 
(epoch: 25, iters: 1008, time: 0.101, data: 0.025) loss: 0.039 
(epoch: 25, iters: 1088, time: 0.121, data: 0.000) loss: 0.193 
(epoch: 25, iters: 1168, time: 0.132, data: 0.000) loss: 0.135 
(epoch: 25, iters: 1248, time: 0.132, data: 0.039) loss: 0.071 
(epoch: 25, iters: 1328, time: 0.120, data: 0.000) loss: 0.044 
(epoch: 25, iters: 1408, time: 0.125, data: 0.013) loss: 0.097 
(epoch: 25, iters: 1488, time: 0.142, data: 0.000) loss: 0.305 
(epoch: 25, iters: 1568, time: 0.121, data: 0.012) loss: 0.051 
(epoch: 25, iters: 1648, time: 0.109, data: 0.000) loss: 0.039 
(epoch: 25, iters: 1728, time: 0.120, data: 0.000) loss: 0.258 
(epoch: 25, iters: 1808, time: 0.134, data: 0.049) loss: 0.350 
(epoch: 25, iters: 1888, time: 0.121, data: 0.000) loss: 0.042 
(epoch: 25, iters: 1968, time: 0.124, data: 0.011) loss: 0.151 
(epoch: 25, iters: 2048, time: 0.109, data: 0.000) loss: 0.060 
(epoch: 25, iters: 2128, time: 0.126, data: 0.012) loss: 0.179 
(epoch: 25, iters: 2208, time: 0.121, data: 0.000) loss: 0.162 
(epoch: 25, iters: 2288, time: 0.126, data: 0.000) loss: 0.039 
(epoch: 25, iters: 2368, time: 0.140, data: 0.040) loss: 0.076 
(epoch: 25, iters: 2448, time: 0.135, data: 0.000) loss: 0.077 
(epoch: 25, iters: 2528, time: 0.120, data: 0.012) loss: 0.199 
(epoch: 25, iters: 2608, time: 0.142, data: 0.000) loss: 0.099 
(epoch: 25, iters: 2688, time: 0.109, data: 0.012) loss: 0.042 
(epoch: 25, iters: 2768, time: 0.130, data: 0.000) loss: 0.059 
(epoch: 25, iters: 2848, time: 0.103, data: 0.000) loss: 0.050 
(epoch: 25, iters: 2928, time: 0.110, data: 0.041) loss: 0.115 
(epoch: 25, iters: 3008, time: 0.135, data: 0.000) loss: 0.133 
(epoch: 25, iters: 3088, time: 0.113, data: 0.012) loss: 0.123 
(epoch: 25, iters: 3168, time: 0.142, data: 0.000) loss: 0.365 
(epoch: 25, iters: 3248, time: 0.120, data: 0.012) loss: 0.274 
(epoch: 25, iters: 3328, time: 0.114, data: 0.000) loss: 0.400 
(epoch: 25, iters: 3408, time: 0.129, data: 0.000) loss: 0.314 
(epoch: 25, iters: 3488, time: 0.117, data: 0.040) loss: 0.164 
(epoch: 25, iters: 3568, time: 0.121, data: 0.000) loss: 0.209 
(epoch: 25, iters: 3648, time: 0.088, data: 0.012) loss: 0.137 
(epoch: 25, iters: 3728, time: 0.057, data: 0.000) loss: 0.489 
saving the model at the end of epoch 25, iters 93200
End of epoch 25 / 2100 	 Time Taken: 461 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 25, TEST ACC: [89.074 %]

saving the latest model (epoch 26, total_steps 93216)
(epoch: 26, iters: 80, time: 0.123, data: 2.163) loss: 0.422 
(epoch: 26, iters: 160, time: 0.128, data: 0.042) loss: 0.195 
(epoch: 26, iters: 240, time: 0.116, data: 0.000) loss: 0.396 
(epoch: 26, iters: 320, time: 0.116, data: 0.012) loss: 0.137 
(epoch: 26, iters: 400, time: 0.108, data: 0.000) loss: 0.271 
(epoch: 26, iters: 480, time: 0.133, data: 0.020) loss: 0.254 
(epoch: 26, iters: 560, time: 0.115, data: 0.000) loss: 0.390 
(epoch: 26, iters: 640, time: 0.127, data: 0.000) loss: 0.142 
(epoch: 26, iters: 720, time: 0.121, data: 0.039) loss: 0.251 
(epoch: 26, iters: 800, time: 0.120, data: 0.000) loss: 0.043 
(epoch: 26, iters: 880, time: 0.113, data: 0.012) loss: 0.161 
(epoch: 26, iters: 960, time: 0.120, data: 0.000) loss: 0.051 
(epoch: 26, iters: 1040, time: 0.147, data: 0.011) loss: 0.150 
(epoch: 26, iters: 1120, time: 0.103, data: 0.000) loss: 0.059 
(epoch: 26, iters: 1200, time: 0.126, data: 0.000) loss: 0.309 
(epoch: 26, iters: 1280, time: 0.128, data: 0.043) loss: 0.121 
(epoch: 26, iters: 1360, time: 0.124, data: 0.000) loss: 0.315 
(epoch: 26, iters: 1440, time: 0.130, data: 0.012) loss: 0.237 
(epoch: 26, iters: 1520, time: 0.115, data: 0.000) loss: 0.104 
(epoch: 26, iters: 1600, time: 0.130, data: 0.012) loss: 0.033 
(epoch: 26, iters: 1680, time: 0.127, data: 0.000) loss: 0.103 
(epoch: 26, iters: 1760, time: 0.116, data: 0.000) loss: 0.182 
(epoch: 26, iters: 1840, time: 0.110, data: 0.039) loss: 0.277 
(epoch: 26, iters: 1920, time: 0.111, data: 0.000) loss: 0.242 
(epoch: 26, iters: 2000, time: 0.125, data: 0.012) loss: 0.109 
(epoch: 26, iters: 2080, time: 0.133, data: 0.000) loss: 0.176 
(epoch: 26, iters: 2160, time: 0.108, data: 0.012) loss: 0.153 
(epoch: 26, iters: 2240, time: 0.128, data: 0.000) loss: 0.362 
(epoch: 26, iters: 2320, time: 0.125, data: 0.000) loss: 0.071 
(epoch: 26, iters: 2400, time: 0.127, data: 0.039) loss: 0.279 
(epoch: 26, iters: 2480, time: 0.120, data: 0.000) loss: 0.173 
(epoch: 26, iters: 2560, time: 0.112, data: 0.012) loss: 0.085 
(epoch: 26, iters: 2640, time: 0.129, data: 0.000) loss: 0.083 
(epoch: 26, iters: 2720, time: 0.107, data: 0.012) loss: 0.411 
(epoch: 26, iters: 2800, time: 0.121, data: 0.000) loss: 0.176 
(epoch: 26, iters: 2880, time: 0.113, data: 0.000) loss: 0.102 
(epoch: 26, iters: 2960, time: 0.133, data: 0.051) loss: 0.204 
(epoch: 26, iters: 3040, time: 0.109, data: 0.000) loss: 0.118 
(epoch: 26, iters: 3120, time: 0.113, data: 0.021) loss: 0.107 
(epoch: 26, iters: 3200, time: 0.121, data: 0.000) loss: 0.565 
(epoch: 26, iters: 3280, time: 0.120, data: 0.012) loss: 0.446 
(epoch: 26, iters: 3360, time: 0.133, data: 0.000) loss: 0.461 
(epoch: 26, iters: 3440, time: 0.125, data: 0.000) loss: 0.167 
(epoch: 26, iters: 3520, time: 0.128, data: 0.050) loss: 0.116 
(epoch: 26, iters: 3600, time: 0.116, data: 0.000) loss: 0.669 
(epoch: 26, iters: 3680, time: 0.089, data: 0.012) loss: 0.121 
saving the model at the end of epoch 26, iters 96928
End of epoch 26 / 2100 	 Time Taken: 455 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 26, TEST ACC: [89.226 %]

saving the latest model (epoch 27, total_steps 96944)
(epoch: 27, iters: 32, time: 0.113, data: 0.007) loss: 0.500 
(epoch: 27, iters: 112, time: 0.128, data: 0.000) loss: 0.052 
(epoch: 27, iters: 192, time: 0.107, data: 0.000) loss: 0.108 
(epoch: 27, iters: 272, time: 0.121, data: 0.051) loss: 0.252 
(epoch: 27, iters: 352, time: 0.108, data: 0.000) loss: 0.275 
(epoch: 27, iters: 432, time: 0.112, data: 0.011) loss: 0.170 
(epoch: 27, iters: 512, time: 0.114, data: 0.000) loss: 0.276 
(epoch: 27, iters: 592, time: 0.108, data: 0.012) loss: 0.185 
(epoch: 27, iters: 672, time: 0.121, data: 0.000) loss: 0.124 
(epoch: 27, iters: 752, time: 0.106, data: 0.000) loss: 0.100 
(epoch: 27, iters: 832, time: 0.107, data: 0.051) loss: 0.316 
(epoch: 27, iters: 912, time: 0.128, data: 0.000) loss: 0.608 
(epoch: 27, iters: 992, time: 0.124, data: 0.012) loss: 0.220 
(epoch: 27, iters: 1072, time: 0.115, data: 0.000) loss: 0.308 
(epoch: 27, iters: 1152, time: 0.133, data: 0.021) loss: 0.146 
(epoch: 27, iters: 1232, time: 0.120, data: 0.000) loss: 0.076 
(epoch: 27, iters: 1312, time: 0.109, data: 0.000) loss: 0.309 
(epoch: 27, iters: 1392, time: 0.149, data: 0.041) loss: 0.245 
(epoch: 27, iters: 1472, time: 0.109, data: 0.000) loss: 0.078 
(epoch: 27, iters: 1552, time: 0.114, data: 0.012) loss: 0.048 
(epoch: 27, iters: 1632, time: 0.143, data: 0.000) loss: 0.458 
(epoch: 27, iters: 1712, time: 0.106, data: 0.013) loss: 0.033 
(epoch: 27, iters: 1792, time: 0.121, data: 0.000) loss: 0.047 
(epoch: 27, iters: 1872, time: 0.125, data: 0.000) loss: 0.063 
(epoch: 27, iters: 1952, time: 0.139, data: 0.039) loss: 0.203 
(epoch: 27, iters: 2032, time: 0.125, data: 0.000) loss: 0.034 
(epoch: 27, iters: 2112, time: 0.105, data: 0.012) loss: 0.053 
(epoch: 27, iters: 2192, time: 0.113, data: 0.000) loss: 0.224 
(epoch: 27, iters: 2272, time: 0.119, data: 0.013) loss: 0.085 
(epoch: 27, iters: 2352, time: 0.120, data: 0.000) loss: 0.488 
(epoch: 27, iters: 2432, time: 0.120, data: 0.000) loss: 0.153 
(epoch: 27, iters: 2512, time: 0.114, data: 0.040) loss: 0.152 
(epoch: 27, iters: 2592, time: 0.151, data: 0.000) loss: 0.216 
(epoch: 27, iters: 2672, time: 0.140, data: 0.012) loss: 0.260 
(epoch: 27, iters: 2752, time: 0.123, data: 0.000) loss: 0.696 
(epoch: 27, iters: 2832, time: 0.121, data: 0.012) loss: 0.122 
(epoch: 27, iters: 2912, time: 0.122, data: 0.000) loss: 0.280 
(epoch: 27, iters: 2992, time: 0.119, data: 0.000) loss: 0.256 
(epoch: 27, iters: 3072, time: 0.127, data: 0.040) loss: 0.285 
(epoch: 27, iters: 3152, time: 0.146, data: 0.000) loss: 0.068 
(epoch: 27, iters: 3232, time: 0.124, data: 0.012) loss: 0.189 
(epoch: 27, iters: 3312, time: 0.122, data: 0.000) loss: 0.149 
(epoch: 27, iters: 3392, time: 0.129, data: 0.012) loss: 0.213 
(epoch: 27, iters: 3472, time: 0.132, data: 0.000) loss: 0.091 
(epoch: 27, iters: 3552, time: 0.128, data: 0.000) loss: 0.132 
(epoch: 27, iters: 3632, time: 0.108, data: 0.041) loss: 0.292 
(epoch: 27, iters: 3712, time: 0.089, data: 0.000) loss: 0.026 
saving the model at the end of epoch 27, iters 100656
End of epoch 27 / 2100 	 Time Taken: 453 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 27, TEST ACC: [65.099 %]

saving the latest model (epoch 28, total_steps 100672)
(epoch: 28, iters: 64, time: 0.106, data: 0.000) loss: 0.167 
(epoch: 28, iters: 144, time: 0.108, data: 0.000) loss: 0.943 
(epoch: 28, iters: 224, time: 0.102, data: 0.000) loss: 0.047 
(epoch: 28, iters: 304, time: 0.120, data: 0.000) loss: 0.156 
(epoch: 28, iters: 384, time: 0.115, data: 0.041) loss: 0.099 
(epoch: 28, iters: 464, time: 0.109, data: 0.000) loss: 0.184 
(epoch: 28, iters: 544, time: 0.132, data: 0.012) loss: 0.123 
(epoch: 28, iters: 624, time: 0.133, data: 0.000) loss: 0.082 
(epoch: 28, iters: 704, time: 0.100, data: 0.013) loss: 0.070 
(epoch: 28, iters: 784, time: 0.108, data: 0.000) loss: 0.044 
(epoch: 28, iters: 864, time: 0.125, data: 0.000) loss: 0.484 
(epoch: 28, iters: 944, time: 0.120, data: 0.040) loss: 0.079 
(epoch: 28, iters: 1024, time: 0.102, data: 0.000) loss: 0.074 
(epoch: 28, iters: 1104, time: 0.113, data: 0.012) loss: 0.138 
(epoch: 28, iters: 1184, time: 0.115, data: 0.000) loss: 0.213 
(epoch: 28, iters: 1264, time: 0.108, data: 0.012) loss: 0.042 
(epoch: 28, iters: 1344, time: 0.108, data: 0.000) loss: 0.091 
(epoch: 28, iters: 1424, time: 0.132, data: 0.000) loss: 0.027 
(epoch: 28, iters: 1504, time: 0.108, data: 0.051) loss: 0.045 
(epoch: 28, iters: 1584, time: 0.116, data: 0.000) loss: 0.561 
(epoch: 28, iters: 1664, time: 0.126, data: 0.021) loss: 0.266 
(epoch: 28, iters: 1744, time: 0.121, data: 0.000) loss: 0.401 
(epoch: 28, iters: 1824, time: 0.117, data: 0.011) loss: 0.089 
(epoch: 28, iters: 1904, time: 0.136, data: 0.000) loss: 0.325 
(epoch: 28, iters: 1984, time: 0.114, data: 0.000) loss: 0.289 
(epoch: 28, iters: 2064, time: 0.127, data: 0.048) loss: 0.346 
(epoch: 28, iters: 2144, time: 0.109, data: 0.000) loss: 0.288 
(epoch: 28, iters: 2224, time: 0.133, data: 0.012) loss: 0.105 
(epoch: 28, iters: 2304, time: 0.109, data: 0.000) loss: 0.096 
(epoch: 28, iters: 2384, time: 0.120, data: 0.011) loss: 0.150 
(epoch: 28, iters: 2464, time: 0.128, data: 0.000) loss: 0.660 
(epoch: 28, iters: 2544, time: 0.109, data: 0.000) loss: 0.149 
(epoch: 28, iters: 2624, time: 0.125, data: 0.048) loss: 0.319 
(epoch: 28, iters: 2704, time: 0.106, data: 0.000) loss: 0.368 
(epoch: 28, iters: 2784, time: 0.117, data: 0.012) loss: 0.148 
(epoch: 28, iters: 2864, time: 0.144, data: 0.000) loss: 0.059 
(epoch: 28, iters: 2944, time: 0.110, data: 0.012) loss: 0.330 
(epoch: 28, iters: 3024, time: 0.124, data: 0.000) loss: 0.179 
(epoch: 28, iters: 3104, time: 0.124, data: 0.000) loss: 0.053 
(epoch: 28, iters: 3184, time: 0.110, data: 0.051) loss: 0.102 
(epoch: 28, iters: 3264, time: 0.117, data: 0.000) loss: 0.195 
(epoch: 28, iters: 3344, time: 0.115, data: 0.012) loss: 0.062 
(epoch: 28, iters: 3424, time: 0.129, data: 0.000) loss: 0.141 
(epoch: 28, iters: 3504, time: 0.136, data: 0.012) loss: 0.209 
(epoch: 28, iters: 3584, time: 0.133, data: 0.000) loss: 0.836 
(epoch: 28, iters: 3664, time: 0.091, data: 0.000) loss: 0.457 
saving the model at the end of epoch 28, iters 104384
End of epoch 28 / 2100 	 Time Taken: 448 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 28, TEST ACC: [90.288 %]

(epoch: 29, iters: 16, time: 0.192, data: 0.012) loss: 0.095 
saving the latest model (epoch 29, total_steps 104400)
(epoch: 29, iters: 96, time: 0.121, data: 0.000) loss: 0.087 
(epoch: 29, iters: 176, time: 0.133, data: 0.012) loss: 0.227 
(epoch: 29, iters: 256, time: 0.115, data: 0.000) loss: 0.119 
(epoch: 29, iters: 336, time: 0.125, data: 0.012) loss: 0.123 
(epoch: 29, iters: 416, time: 0.131, data: 0.000) loss: 0.222 
(epoch: 29, iters: 496, time: 0.133, data: 0.000) loss: 0.050 
(epoch: 29, iters: 576, time: 0.114, data: 0.040) loss: 0.081 
(epoch: 29, iters: 656, time: 0.124, data: 0.000) loss: 0.222 
(epoch: 29, iters: 736, time: 0.114, data: 0.012) loss: 0.110 
(epoch: 29, iters: 816, time: 0.133, data: 0.000) loss: 0.211 
(epoch: 29, iters: 896, time: 0.108, data: 0.021) loss: 0.134 
(epoch: 29, iters: 976, time: 0.110, data: 0.000) loss: 0.183 
(epoch: 29, iters: 1056, time: 0.114, data: 0.000) loss: 0.108 
(epoch: 29, iters: 1136, time: 0.140, data: 0.049) loss: 0.152 
(epoch: 29, iters: 1216, time: 0.116, data: 0.000) loss: 0.077 
(epoch: 29, iters: 1296, time: 0.100, data: 0.011) loss: 0.235 
(epoch: 29, iters: 1376, time: 0.114, data: 0.000) loss: 0.378 
(epoch: 29, iters: 1456, time: 0.115, data: 0.011) loss: 1.254 
(epoch: 29, iters: 1536, time: 0.103, data: 0.000) loss: 0.028 
(epoch: 29, iters: 1616, time: 0.121, data: 0.000) loss: 0.392 
(epoch: 29, iters: 1696, time: 0.121, data: 0.048) loss: 0.191 
(epoch: 29, iters: 1776, time: 0.111, data: 0.000) loss: 0.091 
(epoch: 29, iters: 1856, time: 0.103, data: 0.012) loss: 0.089 
(epoch: 29, iters: 1936, time: 0.115, data: 0.000) loss: 0.019 
(epoch: 29, iters: 2016, time: 0.102, data: 0.011) loss: 0.047 
(epoch: 29, iters: 2096, time: 0.123, data: 0.000) loss: 0.080 
(epoch: 29, iters: 2176, time: 0.115, data: 0.000) loss: 0.408 
(epoch: 29, iters: 2256, time: 0.128, data: 0.041) loss: 0.320 
(epoch: 29, iters: 2336, time: 0.115, data: 0.000) loss: 0.204 
(epoch: 29, iters: 2416, time: 0.106, data: 0.012) loss: 0.205 
(epoch: 29, iters: 2496, time: 0.123, data: 0.000) loss: 0.134 
(epoch: 29, iters: 2576, time: 0.138, data: 0.012) loss: 0.050 
(epoch: 29, iters: 2656, time: 0.114, data: 0.000) loss: 0.120 
(epoch: 29, iters: 2736, time: 0.125, data: 0.000) loss: 0.270 
(epoch: 29, iters: 2816, time: 0.121, data: 0.040) loss: 0.263 
(epoch: 29, iters: 2896, time: 0.108, data: 0.000) loss: 0.209 
(epoch: 29, iters: 2976, time: 0.127, data: 0.011) loss: 0.105 
(epoch: 29, iters: 3056, time: 0.126, data: 0.000) loss: 0.146 
(epoch: 29, iters: 3136, time: 0.100, data: 0.012) loss: 0.080 
(epoch: 29, iters: 3216, time: 0.133, data: 0.000) loss: 0.209 
(epoch: 29, iters: 3296, time: 0.094, data: 0.000) loss: 0.210 
(epoch: 29, iters: 3376, time: 0.114, data: 0.039) loss: 0.448 
(epoch: 29, iters: 3456, time: 0.115, data: 0.000) loss: 0.439 
(epoch: 29, iters: 3536, time: 0.113, data: 0.011) loss: 0.102 
(epoch: 29, iters: 3616, time: 0.123, data: 0.000) loss: 0.187 
(epoch: 29, iters: 3696, time: 0.090, data: 0.012) loss: 0.128 
saving the model at the end of epoch 29, iters 108112
End of epoch 29 / 2100 	 Time Taken: 440 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 29, TEST ACC: [83.46 %]

saving the latest model (epoch 30, total_steps 108128)
(epoch: 30, iters: 48, time: 0.100, data: 0.000) loss: 0.478 
(epoch: 30, iters: 128, time: 0.109, data: 0.026) loss: 0.104 
(epoch: 30, iters: 208, time: 0.117, data: 0.000) loss: 0.312 
(epoch: 30, iters: 288, time: 0.120, data: 0.000) loss: 0.140 
(epoch: 30, iters: 368, time: 0.116, data: 0.040) loss: 0.077 
(epoch: 30, iters: 448, time: 0.098, data: 0.000) loss: 0.763 
(epoch: 30, iters: 528, time: 0.118, data: 0.012) loss: 0.046 
(epoch: 30, iters: 608, time: 0.121, data: 0.000) loss: 0.405 
(epoch: 30, iters: 688, time: 0.126, data: 0.012) loss: 0.056 
(epoch: 30, iters: 768, time: 0.114, data: 0.000) loss: 0.186 
(epoch: 30, iters: 848, time: 0.132, data: 0.000) loss: 0.417 
(epoch: 30, iters: 928, time: 0.108, data: 0.026) loss: 0.050 
(epoch: 30, iters: 1008, time: 0.115, data: 0.000) loss: 0.238 
(epoch: 30, iters: 1088, time: 0.101, data: 0.000) loss: 0.185 
(epoch: 30, iters: 1168, time: 0.120, data: 0.039) loss: 0.338 
(epoch: 30, iters: 1248, time: 0.114, data: 0.000) loss: 0.108 
(epoch: 30, iters: 1328, time: 0.131, data: 0.013) loss: 0.217 
(epoch: 30, iters: 1408, time: 0.114, data: 0.000) loss: 0.122 
(epoch: 30, iters: 1488, time: 0.126, data: 0.012) loss: 0.028 
(epoch: 30, iters: 1568, time: 0.116, data: 0.000) loss: 0.084 
(epoch: 30, iters: 1648, time: 0.114, data: 0.000) loss: 0.296 
(epoch: 30, iters: 1728, time: 0.109, data: 0.040) loss: 0.045 
(epoch: 30, iters: 1808, time: 0.116, data: 0.000) loss: 0.102 
(epoch: 30, iters: 1888, time: 0.114, data: 0.012) loss: 0.017 
(epoch: 30, iters: 1968, time: 0.115, data: 0.000) loss: 0.021 
(epoch: 30, iters: 2048, time: 0.122, data: 0.012) loss: 0.049 
(epoch: 30, iters: 2128, time: 0.135, data: 0.000) loss: 0.048 
(epoch: 30, iters: 2208, time: 0.131, data: 0.000) loss: 0.085 
(epoch: 30, iters: 2288, time: 0.121, data: 0.039) loss: 0.106 
(epoch: 30, iters: 2368, time: 0.122, data: 0.000) loss: 0.095 
(epoch: 30, iters: 2448, time: 0.113, data: 0.013) loss: 0.055 
(epoch: 30, iters: 2528, time: 0.146, data: 0.000) loss: 0.025 
(epoch: 30, iters: 2608, time: 0.119, data: 0.012) loss: 0.032 
(epoch: 30, iters: 2688, time: 0.115, data: 0.000) loss: 0.265 
(epoch: 30, iters: 2768, time: 0.107, data: 0.000) loss: 0.159 
(epoch: 30, iters: 2848, time: 0.132, data: 0.039) loss: 0.033 
(epoch: 30, iters: 2928, time: 0.127, data: 0.000) loss: 0.306 
(epoch: 30, iters: 3008, time: 0.119, data: 0.012) loss: 0.176 
(epoch: 30, iters: 3088, time: 0.113, data: 0.000) loss: 0.135 
(epoch: 30, iters: 3168, time: 0.113, data: 0.012) loss: 0.315 
(epoch: 30, iters: 3248, time: 0.108, data: 0.000) loss: 0.096 
(epoch: 30, iters: 3328, time: 0.120, data: 0.000) loss: 0.084 
(epoch: 30, iters: 3408, time: 0.115, data: 0.039) loss: 0.140 
(epoch: 30, iters: 3488, time: 0.127, data: 0.000) loss: 0.037 
(epoch: 30, iters: 3568, time: 0.112, data: 0.012) loss: 0.300 
(epoch: 30, iters: 3648, time: 0.089, data: 0.000) loss: 0.044 
(epoch: 30, iters: 3728, time: 0.056, data: 0.012) loss: 0.095 
saving the model at the end of epoch 30, iters 111840
End of epoch 30 / 2100 	 Time Taken: 443 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 30, TEST ACC: [91.351 %]

saving the latest model (epoch 31, total_steps 111856)
(epoch: 31, iters: 80, time: 0.113, data: 1.610) loss: 0.306 
(epoch: 31, iters: 160, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 31, iters: 240, time: 0.095, data: 0.012) loss: 0.121 
(epoch: 31, iters: 320, time: 0.108, data: 0.000) loss: 0.263 
(epoch: 31, iters: 400, time: 0.107, data: 0.000) loss: 0.136 
(epoch: 31, iters: 480, time: 0.121, data: 0.039) loss: 0.173 
(epoch: 31, iters: 560, time: 0.121, data: 0.000) loss: 0.093 
(epoch: 31, iters: 640, time: 0.118, data: 0.012) loss: 0.083 
(epoch: 31, iters: 720, time: 0.128, data: 0.000) loss: 0.127 
(epoch: 31, iters: 800, time: 0.113, data: 0.013) loss: 0.177 
(epoch: 31, iters: 880, time: 0.115, data: 0.000) loss: 0.010 
(epoch: 31, iters: 960, time: 0.107, data: 0.000) loss: 0.029 
(epoch: 31, iters: 1040, time: 0.107, data: 0.039) loss: 0.172 
(epoch: 31, iters: 1120, time: 0.121, data: 0.000) loss: 0.154 
(epoch: 31, iters: 1200, time: 0.100, data: 0.012) loss: 0.239 
(epoch: 31, iters: 1280, time: 0.114, data: 0.000) loss: 0.315 
(epoch: 31, iters: 1360, time: 0.101, data: 0.011) loss: 0.156 
(epoch: 31, iters: 1440, time: 0.109, data: 0.000) loss: 0.144 
(epoch: 31, iters: 1520, time: 0.106, data: 0.000) loss: 0.032 
(epoch: 31, iters: 1600, time: 0.109, data: 0.040) loss: 0.345 
(epoch: 31, iters: 1680, time: 0.128, data: 0.000) loss: 0.209 
(epoch: 31, iters: 1760, time: 0.112, data: 0.012) loss: 0.024 
(epoch: 31, iters: 1840, time: 0.135, data: 0.000) loss: 0.058 
(epoch: 31, iters: 1920, time: 0.116, data: 0.012) loss: 0.193 
(epoch: 31, iters: 2000, time: 0.124, data: 0.000) loss: 0.285 
(epoch: 31, iters: 2080, time: 0.120, data: 0.000) loss: 0.083 
(epoch: 31, iters: 2160, time: 0.126, data: 0.051) loss: 0.021 
(epoch: 31, iters: 2240, time: 0.115, data: 0.000) loss: 0.026 
(epoch: 31, iters: 2320, time: 0.107, data: 0.022) loss: 0.035 
(epoch: 31, iters: 2400, time: 0.110, data: 0.000) loss: 0.218 
(epoch: 31, iters: 2480, time: 0.123, data: 0.021) loss: 0.146 
(epoch: 31, iters: 2560, time: 0.136, data: 0.000) loss: 0.127 
(epoch: 31, iters: 2640, time: 0.100, data: 0.000) loss: 0.076 
(epoch: 31, iters: 2720, time: 0.122, data: 0.048) loss: 0.087 
(epoch: 31, iters: 2800, time: 0.110, data: 0.000) loss: 0.080 
(epoch: 31, iters: 2880, time: 0.099, data: 0.012) loss: 0.058 
(epoch: 31, iters: 2960, time: 0.128, data: 0.000) loss: 0.024 
(epoch: 31, iters: 3040, time: 0.129, data: 0.012) loss: 0.045 
(epoch: 31, iters: 3120, time: 0.128, data: 0.000) loss: 0.053 
(epoch: 31, iters: 3200, time: 0.113, data: 0.000) loss: 0.125 
(epoch: 31, iters: 3280, time: 0.102, data: 0.049) loss: 0.164 
(epoch: 31, iters: 3360, time: 0.104, data: 0.000) loss: 0.303 
(epoch: 31, iters: 3440, time: 0.112, data: 0.012) loss: 0.009 
(epoch: 31, iters: 3520, time: 0.104, data: 0.000) loss: 0.128 
(epoch: 31, iters: 3600, time: 0.120, data: 0.012) loss: 0.097 
(epoch: 31, iters: 3680, time: 0.088, data: 0.000) loss: 0.046 
saving the model at the end of epoch 31, iters 115568
End of epoch 31 / 2100 	 Time Taken: 432 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 31, TEST ACC: [84.674 %]

saving the latest model (epoch 32, total_steps 115584)
(epoch: 32, iters: 32, time: 0.106, data: 0.000) loss: 0.043 
(epoch: 32, iters: 112, time: 0.121, data: 0.000) loss: 0.233 
(epoch: 32, iters: 192, time: 0.124, data: 0.000) loss: 0.219 
(epoch: 32, iters: 272, time: 0.114, data: 0.000) loss: 0.070 
(epoch: 32, iters: 352, time: 0.120, data: 0.040) loss: 0.191 
(epoch: 32, iters: 432, time: 0.124, data: 0.000) loss: 0.480 
(epoch: 32, iters: 512, time: 0.119, data: 0.012) loss: 0.081 
(epoch: 32, iters: 592, time: 0.120, data: 0.000) loss: 0.133 
(epoch: 32, iters: 672, time: 0.126, data: 0.012) loss: 0.262 
(epoch: 32, iters: 752, time: 0.120, data: 0.000) loss: 0.175 
(epoch: 32, iters: 832, time: 0.108, data: 0.000) loss: 0.666 
(epoch: 32, iters: 912, time: 0.095, data: 0.049) loss: 0.267 
(epoch: 32, iters: 992, time: 0.121, data: 0.000) loss: 0.254 
(epoch: 32, iters: 1072, time: 0.119, data: 0.012) loss: 0.169 
(epoch: 32, iters: 1152, time: 0.127, data: 0.000) loss: 0.059 
(epoch: 32, iters: 1232, time: 0.108, data: 0.012) loss: 0.212 
(epoch: 32, iters: 1312, time: 0.109, data: 0.000) loss: 0.134 
(epoch: 32, iters: 1392, time: 0.113, data: 0.000) loss: 0.096 
(epoch: 32, iters: 1472, time: 0.116, data: 0.040) loss: 0.217 
(epoch: 32, iters: 1552, time: 0.136, data: 0.000) loss: 0.351 
(epoch: 32, iters: 1632, time: 0.111, data: 0.000) loss: 0.051 
(epoch: 32, iters: 1712, time: 0.122, data: 0.012) loss: 0.273 
(epoch: 32, iters: 1792, time: 0.107, data: 0.027) loss: 0.154 
(epoch: 32, iters: 1872, time: 0.109, data: 0.000) loss: 0.045 
(epoch: 32, iters: 1952, time: 0.117, data: 0.000) loss: 0.381 
(epoch: 32, iters: 2032, time: 0.114, data: 0.012) loss: 0.098 
(epoch: 32, iters: 2112, time: 0.116, data: 0.026) loss: 0.153 
(epoch: 32, iters: 2192, time: 0.117, data: 0.000) loss: 0.353 
(epoch: 32, iters: 2272, time: 0.129, data: 0.000) loss: 0.474 
(epoch: 32, iters: 2352, time: 0.122, data: 0.012) loss: 0.660 
(epoch: 32, iters: 2432, time: 0.117, data: 0.000) loss: 0.041 
(epoch: 32, iters: 2512, time: 0.132, data: 0.000) loss: 0.058 
(epoch: 32, iters: 2592, time: 0.110, data: 0.040) loss: 0.241 
(epoch: 32, iters: 2672, time: 0.103, data: 0.000) loss: 0.109 
(epoch: 32, iters: 2752, time: 0.102, data: 0.012) loss: 0.058 
(epoch: 32, iters: 2832, time: 0.120, data: 0.000) loss: 0.053 
(epoch: 32, iters: 2912, time: 0.102, data: 0.012) loss: 0.057 
(epoch: 32, iters: 2992, time: 0.109, data: 0.000) loss: 0.011 
(epoch: 32, iters: 3072, time: 0.119, data: 0.000) loss: 0.129 
(epoch: 32, iters: 3152, time: 0.114, data: 0.050) loss: 0.064 
(epoch: 32, iters: 3232, time: 0.104, data: 0.000) loss: 0.356 
(epoch: 32, iters: 3312, time: 0.117, data: 0.022) loss: 0.086 
(epoch: 32, iters: 3392, time: 0.118, data: 0.000) loss: 0.125 
(epoch: 32, iters: 3472, time: 0.110, data: 0.012) loss: 0.824 
(epoch: 32, iters: 3552, time: 0.127, data: 0.000) loss: 0.584 
(epoch: 32, iters: 3632, time: 0.113, data: 0.000) loss: 0.052 
(epoch: 32, iters: 3712, time: 0.091, data: 0.037) loss: 0.042 
saving the model at the end of epoch 32, iters 119296
End of epoch 32 / 2100 	 Time Taken: 430 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 32, TEST ACC: [84.977 %]

saving the latest model (epoch 33, total_steps 119312)
(epoch: 33, iters: 64, time: 0.099, data: 0.000) loss: 0.190 
(epoch: 33, iters: 144, time: 0.120, data: 0.000) loss: 0.322 
(epoch: 33, iters: 224, time: 0.113, data: 0.012) loss: 0.147 
(epoch: 33, iters: 304, time: 0.114, data: 0.000) loss: 0.043 
(epoch: 33, iters: 384, time: 0.108, data: 0.000) loss: 0.081 
(epoch: 33, iters: 464, time: 0.101, data: 0.050) loss: 0.066 
(epoch: 33, iters: 544, time: 0.114, data: 0.000) loss: 0.124 
(epoch: 33, iters: 624, time: 0.120, data: 0.022) loss: 0.018 
(epoch: 33, iters: 704, time: 0.102, data: 0.000) loss: 0.019 
(epoch: 33, iters: 784, time: 0.102, data: 0.012) loss: 0.099 
(epoch: 33, iters: 864, time: 0.108, data: 0.000) loss: 0.237 
(epoch: 33, iters: 944, time: 0.126, data: 0.000) loss: 0.144 
(epoch: 33, iters: 1024, time: 0.108, data: 0.050) loss: 0.041 
(epoch: 33, iters: 1104, time: 0.103, data: 0.000) loss: 0.137 
(epoch: 33, iters: 1184, time: 0.131, data: 0.011) loss: 0.163 
(epoch: 33, iters: 1264, time: 0.109, data: 0.000) loss: 0.036 
(epoch: 33, iters: 1344, time: 0.108, data: 0.012) loss: 0.031 
(epoch: 33, iters: 1424, time: 0.127, data: 0.000) loss: 0.022 
(epoch: 33, iters: 1504, time: 0.113, data: 0.000) loss: 0.146 
(epoch: 33, iters: 1584, time: 0.120, data: 0.040) loss: 0.066 
(epoch: 33, iters: 1664, time: 0.114, data: 0.000) loss: 0.040 
(epoch: 33, iters: 1744, time: 0.125, data: 0.012) loss: 0.054 
(epoch: 33, iters: 1824, time: 0.120, data: 0.000) loss: 0.462 
(epoch: 33, iters: 1904, time: 0.113, data: 0.011) loss: 0.067 
(epoch: 33, iters: 1984, time: 0.143, data: 0.000) loss: 0.083 
(epoch: 33, iters: 2064, time: 0.101, data: 0.000) loss: 0.056 
(epoch: 33, iters: 2144, time: 0.119, data: 0.039) loss: 0.126 
(epoch: 33, iters: 2224, time: 0.114, data: 0.000) loss: 0.154 
(epoch: 33, iters: 2304, time: 0.125, data: 0.012) loss: 0.528 
(epoch: 33, iters: 2384, time: 0.101, data: 0.000) loss: 0.169 
(epoch: 33, iters: 2464, time: 0.107, data: 0.012) loss: 0.028 
(epoch: 33, iters: 2544, time: 0.154, data: 0.000) loss: 0.420 
(epoch: 33, iters: 2624, time: 0.139, data: 0.000) loss: 0.188 
(epoch: 33, iters: 2704, time: 0.113, data: 0.040) loss: 0.295 
(epoch: 33, iters: 2784, time: 0.115, data: 0.000) loss: 0.388 
(epoch: 33, iters: 2864, time: 0.119, data: 0.011) loss: 0.117 
(epoch: 33, iters: 2944, time: 0.114, data: 0.000) loss: 0.112 
(epoch: 33, iters: 3024, time: 0.119, data: 0.011) loss: 0.029 
(epoch: 33, iters: 3104, time: 0.114, data: 0.000) loss: 0.274 
(epoch: 33, iters: 3184, time: 0.121, data: 0.000) loss: 0.043 
(epoch: 33, iters: 3264, time: 0.126, data: 0.041) loss: 0.015 
(epoch: 33, iters: 3344, time: 0.095, data: 0.000) loss: 0.071 
(epoch: 33, iters: 3424, time: 0.107, data: 0.012) loss: 0.228 
(epoch: 33, iters: 3504, time: 0.114, data: 0.000) loss: 0.066 
(epoch: 33, iters: 3584, time: 0.113, data: 0.011) loss: 0.082 
(epoch: 33, iters: 3664, time: 0.089, data: 0.000) loss: 0.419 
saving the model at the end of epoch 33, iters 123024
End of epoch 33 / 2100 	 Time Taken: 424 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 33, TEST ACC: [91.502 %]

(epoch: 34, iters: 16, time: 0.193, data: 0.000) loss: 0.102 
saving the latest model (epoch 34, total_steps 123040)
(epoch: 34, iters: 96, time: 0.116, data: 0.012) loss: 0.175 
(epoch: 34, iters: 176, time: 0.113, data: 0.012) loss: 0.147 
(epoch: 34, iters: 256, time: 0.121, data: 0.000) loss: 0.031 
(epoch: 34, iters: 336, time: 0.114, data: 0.011) loss: 0.030 
(epoch: 34, iters: 416, time: 0.127, data: 0.000) loss: 0.036 
(epoch: 34, iters: 496, time: 0.107, data: 0.000) loss: 0.104 
(epoch: 34, iters: 576, time: 0.120, data: 0.040) loss: 0.101 
(epoch: 34, iters: 656, time: 0.114, data: 0.000) loss: 0.317 
(epoch: 34, iters: 736, time: 0.127, data: 0.012) loss: 0.142 
(epoch: 34, iters: 816, time: 0.150, data: 0.000) loss: 0.138 
(epoch: 34, iters: 896, time: 0.126, data: 0.012) loss: 0.139 
(epoch: 34, iters: 976, time: 0.127, data: 0.000) loss: 0.253 
(epoch: 34, iters: 1056, time: 0.114, data: 0.000) loss: 0.177 
(epoch: 34, iters: 1136, time: 0.126, data: 0.051) loss: 0.707 
(epoch: 34, iters: 1216, time: 0.108, data: 0.000) loss: 0.250 
(epoch: 34, iters: 1296, time: 0.112, data: 0.021) loss: 0.025 
(epoch: 34, iters: 1376, time: 0.113, data: 0.000) loss: 0.049 
(epoch: 34, iters: 1456, time: 0.108, data: 0.020) loss: 0.129 
(epoch: 34, iters: 1536, time: 0.114, data: 0.000) loss: 0.010 
(epoch: 34, iters: 1616, time: 0.120, data: 0.000) loss: 0.047 
(epoch: 34, iters: 1696, time: 0.114, data: 0.040) loss: 0.059 
(epoch: 34, iters: 1776, time: 0.114, data: 0.000) loss: 0.213 
(epoch: 34, iters: 1856, time: 0.113, data: 0.012) loss: 0.040 
(epoch: 34, iters: 1936, time: 0.109, data: 0.000) loss: 0.039 
(epoch: 34, iters: 2016, time: 0.100, data: 0.011) loss: 0.236 
(epoch: 34, iters: 2096, time: 0.108, data: 0.000) loss: 0.096 
(epoch: 34, iters: 2176, time: 0.102, data: 0.000) loss: 0.220 
(epoch: 34, iters: 2256, time: 0.136, data: 0.041) loss: 0.035 
(epoch: 34, iters: 2336, time: 0.110, data: 0.000) loss: 0.043 
(epoch: 34, iters: 2416, time: 0.113, data: 0.012) loss: 0.106 
(epoch: 34, iters: 2496, time: 0.101, data: 0.000) loss: 0.209 
(epoch: 34, iters: 2576, time: 0.107, data: 0.012) loss: 0.028 
(epoch: 34, iters: 2656, time: 0.114, data: 0.000) loss: 0.151 
(epoch: 34, iters: 2736, time: 0.104, data: 0.000) loss: 0.118 
(epoch: 34, iters: 2816, time: 0.116, data: 0.042) loss: 0.075 
(epoch: 34, iters: 2896, time: 0.101, data: 0.000) loss: 0.112 
(epoch: 34, iters: 2976, time: 0.112, data: 0.012) loss: 0.215 
(epoch: 34, iters: 3056, time: 0.122, data: 0.000) loss: 0.148 
(epoch: 34, iters: 3136, time: 0.100, data: 0.012) loss: 0.390 
(epoch: 34, iters: 3216, time: 0.108, data: 0.000) loss: 0.034 
(epoch: 34, iters: 3296, time: 0.101, data: 0.000) loss: 0.061 
(epoch: 34, iters: 3376, time: 0.114, data: 0.047) loss: 0.118 
(epoch: 34, iters: 3456, time: 0.120, data: 0.000) loss: 0.113 
(epoch: 34, iters: 3536, time: 0.105, data: 0.013) loss: 0.010 
(epoch: 34, iters: 3616, time: 0.101, data: 0.000) loss: 0.162 
(epoch: 34, iters: 3696, time: 0.088, data: 0.011) loss: 0.011 
saving the model at the end of epoch 34, iters 126752
End of epoch 34 / 2100 	 Time Taken: 423 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 34, TEST ACC: [87.709 %]

saving the latest model (epoch 35, total_steps 126768)
(epoch: 35, iters: 48, time: 0.119, data: 0.000) loss: 0.024 
(epoch: 35, iters: 128, time: 0.102, data: 0.042) loss: 0.123 
(epoch: 35, iters: 208, time: 0.102, data: 0.000) loss: 0.039 
(epoch: 35, iters: 288, time: 0.100, data: 0.012) loss: 0.121 
(epoch: 35, iters: 368, time: 0.114, data: 0.000) loss: 0.059 
(epoch: 35, iters: 448, time: 0.108, data: 0.012) loss: 0.194 
(epoch: 35, iters: 528, time: 0.109, data: 0.000) loss: 0.104 
(epoch: 35, iters: 608, time: 0.101, data: 0.000) loss: 0.098 
(epoch: 35, iters: 688, time: 0.114, data: 0.042) loss: 0.039 
(epoch: 35, iters: 768, time: 0.140, data: 0.000) loss: 0.103 
(epoch: 35, iters: 848, time: 0.100, data: 0.012) loss: 0.024 
(epoch: 35, iters: 928, time: 0.133, data: 0.000) loss: 0.027 
(epoch: 35, iters: 1008, time: 0.101, data: 0.012) loss: 0.088 
(epoch: 35, iters: 1088, time: 0.109, data: 0.000) loss: 0.052 
(epoch: 35, iters: 1168, time: 0.101, data: 0.000) loss: 0.011 
(epoch: 35, iters: 1248, time: 0.125, data: 0.037) loss: 0.005 
(epoch: 35, iters: 1328, time: 0.115, data: 0.000) loss: 0.041 
(epoch: 35, iters: 1408, time: 0.115, data: 0.000) loss: 0.023 
(epoch: 35, iters: 1488, time: 0.094, data: 0.012) loss: 0.151 
(epoch: 35, iters: 1568, time: 0.108, data: 0.000) loss: 0.019 
(epoch: 35, iters: 1648, time: 0.122, data: 0.012) loss: 0.086 
(epoch: 35, iters: 1728, time: 0.127, data: 0.000) loss: 0.034 
(epoch: 35, iters: 1808, time: 0.120, data: 0.000) loss: 0.032 
(epoch: 35, iters: 1888, time: 0.121, data: 0.040) loss: 0.143 
(epoch: 35, iters: 1968, time: 0.127, data: 0.000) loss: 0.018 
(epoch: 35, iters: 2048, time: 0.105, data: 0.012) loss: 0.075 
(epoch: 35, iters: 2128, time: 0.108, data: 0.000) loss: 0.115 
(epoch: 35, iters: 2208, time: 0.115, data: 0.012) loss: 0.220 
(epoch: 35, iters: 2288, time: 0.102, data: 0.000) loss: 0.101 
(epoch: 35, iters: 2368, time: 0.113, data: 0.000) loss: 0.025 
(epoch: 35, iters: 2448, time: 0.121, data: 0.041) loss: 0.085 
(epoch: 35, iters: 2528, time: 0.142, data: 0.000) loss: 0.087 
(epoch: 35, iters: 2608, time: 0.122, data: 0.012) loss: 0.069 
(epoch: 35, iters: 2688, time: 0.107, data: 0.000) loss: 0.145 
(epoch: 35, iters: 2768, time: 0.120, data: 0.011) loss: 0.047 
(epoch: 35, iters: 2848, time: 0.102, data: 0.000) loss: 0.062 
(epoch: 35, iters: 2928, time: 0.120, data: 0.000) loss: 0.012 
(epoch: 35, iters: 3008, time: 0.115, data: 0.041) loss: 0.263 
(epoch: 35, iters: 3088, time: 0.114, data: 0.000) loss: 0.134 
(epoch: 35, iters: 3168, time: 0.111, data: 0.011) loss: 0.052 
(epoch: 35, iters: 3248, time: 0.128, data: 0.000) loss: 0.039 
(epoch: 35, iters: 3328, time: 0.133, data: 0.012) loss: 0.303 
(epoch: 35, iters: 3408, time: 0.098, data: 0.000) loss: 0.105 
(epoch: 35, iters: 3488, time: 0.113, data: 0.000) loss: 0.131 
(epoch: 35, iters: 3568, time: 0.114, data: 0.039) loss: 0.110 
(epoch: 35, iters: 3648, time: 0.089, data: 0.000) loss: 0.245 
(epoch: 35, iters: 3728, time: 0.057, data: 0.011) loss: 0.029 
saving the model at the end of epoch 35, iters 130480
End of epoch 35 / 2100 	 Time Taken: 423 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 35, TEST ACC: [89.53 %]

saving the latest model (epoch 36, total_steps 130496)
(epoch: 36, iters: 80, time: 0.100, data: 1.685) loss: 0.099 
(epoch: 36, iters: 160, time: 0.121, data: 0.000) loss: 0.066 
(epoch: 36, iters: 240, time: 0.094, data: 0.011) loss: 0.235 
(epoch: 36, iters: 320, time: 0.095, data: 0.000) loss: 0.450 
(epoch: 36, iters: 400, time: 0.101, data: 0.000) loss: 0.039 
(epoch: 36, iters: 480, time: 0.114, data: 0.040) loss: 0.012 
(epoch: 36, iters: 560, time: 0.108, data: 0.000) loss: 0.194 
(epoch: 36, iters: 640, time: 0.119, data: 0.012) loss: 0.306 
(epoch: 36, iters: 720, time: 0.113, data: 0.000) loss: 0.429 
(epoch: 36, iters: 800, time: 0.127, data: 0.011) loss: 0.247 
(epoch: 36, iters: 880, time: 0.113, data: 0.012) loss: 0.058 
(epoch: 36, iters: 960, time: 0.112, data: 0.025) loss: 0.213 
(epoch: 36, iters: 1040, time: 0.120, data: 0.000) loss: 0.126 
(epoch: 36, iters: 1120, time: 0.096, data: 0.000) loss: 0.014 
(epoch: 36, iters: 1200, time: 0.126, data: 0.012) loss: 0.039 
(epoch: 36, iters: 1280, time: 0.125, data: 0.026) loss: 0.251 
(epoch: 36, iters: 1360, time: 0.122, data: 0.000) loss: 0.037 
(epoch: 36, iters: 1440, time: 0.102, data: 0.000) loss: 0.350 
(epoch: 36, iters: 1520, time: 0.101, data: 0.012) loss: 0.675 
(epoch: 36, iters: 1600, time: 0.101, data: 0.036) loss: 0.248 
(epoch: 36, iters: 1680, time: 0.108, data: 0.000) loss: 0.027 
(epoch: 36, iters: 1760, time: 0.102, data: 0.000) loss: 0.315 
(epoch: 36, iters: 1840, time: 0.110, data: 0.021) loss: 0.110 
(epoch: 36, iters: 1920, time: 0.108, data: 0.026) loss: 0.089 
(epoch: 36, iters: 2000, time: 0.114, data: 0.000) loss: 0.029 
(epoch: 36, iters: 2080, time: 0.122, data: 0.000) loss: 0.392 
(epoch: 36, iters: 2160, time: 0.102, data: 0.012) loss: 0.183 
(epoch: 36, iters: 2240, time: 0.132, data: 0.026) loss: 0.068 
(epoch: 36, iters: 2320, time: 0.114, data: 0.000) loss: 0.373 
(epoch: 36, iters: 2400, time: 0.128, data: 0.000) loss: 0.076 
(epoch: 36, iters: 2480, time: 0.108, data: 0.012) loss: 0.350 
(epoch: 36, iters: 2560, time: 0.113, data: 0.026) loss: 0.066 
(epoch: 36, iters: 2640, time: 0.108, data: 0.000) loss: 0.081 
(epoch: 36, iters: 2720, time: 0.127, data: 0.000) loss: 0.145 
(epoch: 36, iters: 2800, time: 0.095, data: 0.012) loss: 0.475 
(epoch: 36, iters: 2880, time: 0.112, data: 0.027) loss: 0.460 
(epoch: 36, iters: 2960, time: 0.107, data: 0.000) loss: 0.104 
(epoch: 36, iters: 3040, time: 0.108, data: 0.000) loss: 0.041 
(epoch: 36, iters: 3120, time: 0.107, data: 0.011) loss: 0.096 
(epoch: 36, iters: 3200, time: 0.101, data: 0.026) loss: 0.199 
(epoch: 36, iters: 3280, time: 0.115, data: 0.026) loss: 0.235 
(epoch: 36, iters: 3360, time: 0.117, data: 0.012) loss: 0.075 
(epoch: 36, iters: 3440, time: 0.107, data: 0.000) loss: 0.092 
(epoch: 36, iters: 3520, time: 0.113, data: 0.012) loss: 0.118 
(epoch: 36, iters: 3600, time: 0.113, data: 0.000) loss: 0.018 
(epoch: 36, iters: 3680, time: 0.090, data: 0.000) loss: 0.236 
saving the model at the end of epoch 36, iters 134208
End of epoch 36 / 2100 	 Time Taken: 415 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 36, TEST ACC: [91.654 %]

saving the latest model (epoch 37, total_steps 134224)
(epoch: 37, iters: 32, time: 0.106, data: 0.007) loss: 0.012 
(epoch: 37, iters: 112, time: 0.116, data: 0.042) loss: 0.022 
(epoch: 37, iters: 192, time: 0.109, data: 0.000) loss: 0.015 
(epoch: 37, iters: 272, time: 0.118, data: 0.000) loss: 0.151 
(epoch: 37, iters: 352, time: 0.124, data: 0.041) loss: 0.032 
(epoch: 37, iters: 432, time: 0.108, data: 0.000) loss: 0.160 
(epoch: 37, iters: 512, time: 0.106, data: 0.012) loss: 0.223 
(epoch: 37, iters: 592, time: 0.126, data: 0.000) loss: 0.021 
(epoch: 37, iters: 672, time: 0.107, data: 0.012) loss: 0.204 
(epoch: 37, iters: 752, time: 0.108, data: 0.000) loss: 0.147 
(epoch: 37, iters: 832, time: 0.113, data: 0.000) loss: 0.125 
(epoch: 37, iters: 912, time: 0.103, data: 0.039) loss: 0.196 
(epoch: 37, iters: 992, time: 0.108, data: 0.000) loss: 0.353 
(epoch: 37, iters: 1072, time: 0.106, data: 0.000) loss: 0.274 
(epoch: 37, iters: 1152, time: 0.095, data: 0.040) loss: 0.021 
(epoch: 37, iters: 1232, time: 0.114, data: 0.000) loss: 0.184 
(epoch: 37, iters: 1312, time: 0.100, data: 0.011) loss: 0.048 
(epoch: 37, iters: 1392, time: 0.096, data: 0.000) loss: 0.085 
(epoch: 37, iters: 1472, time: 0.119, data: 0.012) loss: 0.038 
(epoch: 37, iters: 1552, time: 0.108, data: 0.000) loss: 0.209 
(epoch: 37, iters: 1632, time: 0.107, data: 0.000) loss: 0.020 
(epoch: 37, iters: 1712, time: 0.107, data: 0.040) loss: 0.023 
(epoch: 37, iters: 1792, time: 0.108, data: 0.000) loss: 0.141 
(epoch: 37, iters: 1872, time: 0.113, data: 0.012) loss: 0.090 
(epoch: 37, iters: 1952, time: 0.120, data: 0.000) loss: 0.075 
(epoch: 37, iters: 2032, time: 0.121, data: 0.011) loss: 0.182 
(epoch: 37, iters: 2112, time: 0.098, data: 0.000) loss: 0.173 
(epoch: 37, iters: 2192, time: 0.109, data: 0.000) loss: 0.137 
(epoch: 37, iters: 2272, time: 0.118, data: 0.041) loss: 0.063 
(epoch: 37, iters: 2352, time: 0.110, data: 0.000) loss: 0.042 
(epoch: 37, iters: 2432, time: 0.102, data: 0.012) loss: 0.046 
(epoch: 37, iters: 2512, time: 0.096, data: 0.000) loss: 0.034 
(epoch: 37, iters: 2592, time: 0.129, data: 0.012) loss: 0.175 
(epoch: 37, iters: 2672, time: 0.124, data: 0.000) loss: 0.265 
(epoch: 37, iters: 2752, time: 0.108, data: 0.000) loss: 0.511 
(epoch: 37, iters: 2832, time: 0.117, data: 0.041) loss: 0.131 
(epoch: 37, iters: 2912, time: 0.111, data: 0.000) loss: 0.114 
(epoch: 37, iters: 2992, time: 0.102, data: 0.012) loss: 0.035 
(epoch: 37, iters: 3072, time: 0.110, data: 0.000) loss: 0.012 
(epoch: 37, iters: 3152, time: 0.101, data: 0.012) loss: 0.086 
(epoch: 37, iters: 3232, time: 0.127, data: 0.000) loss: 0.047 
(epoch: 37, iters: 3312, time: 0.095, data: 0.000) loss: 0.047 
(epoch: 37, iters: 3392, time: 0.114, data: 0.039) loss: 0.031 
(epoch: 37, iters: 3472, time: 0.121, data: 0.000) loss: 0.062 
(epoch: 37, iters: 3552, time: 0.100, data: 0.012) loss: 0.207 
(epoch: 37, iters: 3632, time: 0.099, data: 0.000) loss: 0.162 
(epoch: 37, iters: 3712, time: 0.089, data: 0.011) loss: 0.150 
saving the model at the end of epoch 37, iters 137936
End of epoch 37 / 2100 	 Time Taken: 412 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 37, TEST ACC: [89.226 %]

saving the latest model (epoch 38, total_steps 137952)
(epoch: 38, iters: 64, time: 0.107, data: 0.003) loss: 0.024 
(epoch: 38, iters: 144, time: 0.113, data: 0.000) loss: 0.045 
(epoch: 38, iters: 224, time: 0.108, data: 0.000) loss: 0.281 
(epoch: 38, iters: 304, time: 0.100, data: 0.000) loss: 0.057 
(epoch: 38, iters: 384, time: 0.109, data: 0.039) loss: 0.075 
(epoch: 38, iters: 464, time: 0.121, data: 0.000) loss: 0.127 
(epoch: 38, iters: 544, time: 0.114, data: 0.012) loss: 0.060 
(epoch: 38, iters: 624, time: 0.095, data: 0.000) loss: 0.030 
(epoch: 38, iters: 704, time: 0.119, data: 0.011) loss: 0.120 
(epoch: 38, iters: 784, time: 0.121, data: 0.000) loss: 0.256 
(epoch: 38, iters: 864, time: 0.120, data: 0.000) loss: 0.209 
(epoch: 38, iters: 944, time: 0.114, data: 0.039) loss: 0.141 
(epoch: 38, iters: 1024, time: 0.095, data: 0.000) loss: 0.029 
(epoch: 38, iters: 1104, time: 0.106, data: 0.011) loss: 0.082 
(epoch: 38, iters: 1184, time: 0.104, data: 0.000) loss: 0.026 
(epoch: 38, iters: 1264, time: 0.101, data: 0.000) loss: 0.027 
(epoch: 38, iters: 1344, time: 0.102, data: 0.000) loss: 0.210 
(epoch: 38, iters: 1424, time: 0.107, data: 0.000) loss: 0.073 
(epoch: 38, iters: 1504, time: 0.101, data: 0.040) loss: 0.084 
(epoch: 38, iters: 1584, time: 0.108, data: 0.000) loss: 0.087 
(epoch: 38, iters: 1664, time: 0.099, data: 0.011) loss: 0.071 
(epoch: 38, iters: 1744, time: 0.101, data: 0.000) loss: 0.335 
(epoch: 38, iters: 1824, time: 0.106, data: 0.012) loss: 0.038 
(epoch: 38, iters: 1904, time: 0.108, data: 0.000) loss: 0.040 
(epoch: 38, iters: 1984, time: 0.119, data: 0.000) loss: 0.024 
(epoch: 38, iters: 2064, time: 0.114, data: 0.040) loss: 0.183 
(epoch: 38, iters: 2144, time: 0.115, data: 0.000) loss: 0.057 
(epoch: 38, iters: 2224, time: 0.112, data: 0.012) loss: 0.101 
(epoch: 38, iters: 2304, time: 0.101, data: 0.000) loss: 0.055 
(epoch: 38, iters: 2384, time: 0.107, data: 0.011) loss: 0.130 
(epoch: 38, iters: 2464, time: 0.121, data: 0.000) loss: 0.076 
(epoch: 38, iters: 2544, time: 0.115, data: 0.000) loss: 0.020 
(epoch: 38, iters: 2624, time: 0.109, data: 0.040) loss: 0.090 
(epoch: 38, iters: 2704, time: 0.117, data: 0.000) loss: 0.040 
(epoch: 38, iters: 2784, time: 0.106, data: 0.011) loss: 0.074 
(epoch: 38, iters: 2864, time: 0.094, data: 0.000) loss: 0.028 
(epoch: 38, iters: 2944, time: 0.106, data: 0.011) loss: 0.109 
(epoch: 38, iters: 3024, time: 0.122, data: 0.000) loss: 0.175 
(epoch: 38, iters: 3104, time: 0.119, data: 0.000) loss: 0.095 
(epoch: 38, iters: 3184, time: 0.101, data: 0.049) loss: 0.080 
(epoch: 38, iters: 3264, time: 0.101, data: 0.000) loss: 0.063 
(epoch: 38, iters: 3344, time: 0.113, data: 0.021) loss: 0.228 
(epoch: 38, iters: 3424, time: 0.114, data: 0.000) loss: 0.058 
(epoch: 38, iters: 3504, time: 0.120, data: 0.012) loss: 0.027 
(epoch: 38, iters: 3584, time: 0.115, data: 0.000) loss: 0.407 
(epoch: 38, iters: 3664, time: 0.089, data: 0.000) loss: 0.067 
saving the model at the end of epoch 38, iters 141664
End of epoch 38 / 2100 	 Time Taken: 413 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 38, TEST ACC: [87.253 %]

(epoch: 39, iters: 16, time: 0.155, data: 0.013) loss: 0.084 
saving the latest model (epoch 39, total_steps 141680)
(epoch: 39, iters: 96, time: 0.106, data: 0.000) loss: 0.111 
(epoch: 39, iters: 176, time: 0.114, data: 0.000) loss: 0.201 
(epoch: 39, iters: 256, time: 0.122, data: 0.011) loss: 0.077 
(epoch: 39, iters: 336, time: 0.096, data: 0.000) loss: 0.025 
(epoch: 39, iters: 416, time: 0.113, data: 0.000) loss: 0.059 
(epoch: 39, iters: 496, time: 0.128, data: 0.048) loss: 0.005 
(epoch: 39, iters: 576, time: 0.128, data: 0.000) loss: 0.036 
(epoch: 39, iters: 656, time: 0.118, data: 0.012) loss: 0.389 
(epoch: 39, iters: 736, time: 0.095, data: 0.000) loss: 0.085 
(epoch: 39, iters: 816, time: 0.107, data: 0.011) loss: 0.018 
(epoch: 39, iters: 896, time: 0.116, data: 0.000) loss: 0.035 
(epoch: 39, iters: 976, time: 0.095, data: 0.000) loss: 0.020 
(epoch: 39, iters: 1056, time: 0.116, data: 0.039) loss: 0.139 
(epoch: 39, iters: 1136, time: 0.121, data: 0.000) loss: 0.221 
(epoch: 39, iters: 1216, time: 0.100, data: 0.012) loss: 0.025 
(epoch: 39, iters: 1296, time: 0.120, data: 0.000) loss: 0.017 
(epoch: 39, iters: 1376, time: 0.100, data: 0.012) loss: 0.031 
(epoch: 39, iters: 1456, time: 0.101, data: 0.000) loss: 0.052 
(epoch: 39, iters: 1536, time: 0.127, data: 0.000) loss: 0.094 
(epoch: 39, iters: 1616, time: 0.121, data: 0.041) loss: 0.013 
(epoch: 39, iters: 1696, time: 0.113, data: 0.000) loss: 0.044 
(epoch: 39, iters: 1776, time: 0.099, data: 0.012) loss: 0.241 
(epoch: 39, iters: 1856, time: 0.103, data: 0.000) loss: 0.024 
(epoch: 39, iters: 1936, time: 0.101, data: 0.012) loss: 0.076 
(epoch: 39, iters: 2016, time: 0.120, data: 0.000) loss: 0.153 
(epoch: 39, iters: 2096, time: 0.108, data: 0.000) loss: 0.040 
(epoch: 39, iters: 2176, time: 0.120, data: 0.041) loss: 0.216 
(epoch: 39, iters: 2256, time: 0.095, data: 0.000) loss: 0.113 
(epoch: 39, iters: 2336, time: 0.106, data: 0.011) loss: 0.054 
(epoch: 39, iters: 2416, time: 0.108, data: 0.000) loss: 0.010 
(epoch: 39, iters: 2496, time: 0.100, data: 0.012) loss: 0.162 
(epoch: 39, iters: 2576, time: 0.116, data: 0.000) loss: 0.025 
(epoch: 39, iters: 2656, time: 0.100, data: 0.000) loss: 0.471 
(epoch: 39, iters: 2736, time: 0.114, data: 0.049) loss: 0.263 
(epoch: 39, iters: 2816, time: 0.110, data: 0.000) loss: 0.024 
(epoch: 39, iters: 2896, time: 0.119, data: 0.011) loss: 0.124 
(epoch: 39, iters: 2976, time: 0.103, data: 0.000) loss: 0.042 
(epoch: 39, iters: 3056, time: 0.114, data: 0.021) loss: 0.731 
(epoch: 39, iters: 3136, time: 0.102, data: 0.000) loss: 0.032 
(epoch: 39, iters: 3216, time: 0.101, data: 0.000) loss: 0.348 
(epoch: 39, iters: 3296, time: 0.108, data: 0.040) loss: 0.091 
(epoch: 39, iters: 3376, time: 0.121, data: 0.000) loss: 0.073 
(epoch: 39, iters: 3456, time: 0.118, data: 0.012) loss: 0.114 
(epoch: 39, iters: 3536, time: 0.114, data: 0.000) loss: 0.216 
(epoch: 39, iters: 3616, time: 0.131, data: 0.011) loss: 0.010 
(epoch: 39, iters: 3696, time: 0.089, data: 0.000) loss: 0.027 
saving the model at the end of epoch 39, iters 145392
End of epoch 39 / 2100 	 Time Taken: 406 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 39, TEST ACC: [88.467 %]

saving the latest model (epoch 40, total_steps 145408)
(epoch: 40, iters: 48, time: 0.108, data: 0.000) loss: 0.185 
(epoch: 40, iters: 128, time: 0.108, data: 0.041) loss: 0.097 
(epoch: 40, iters: 208, time: 0.100, data: 0.011) loss: 0.083 
(epoch: 40, iters: 288, time: 0.116, data: 0.000) loss: 0.051 
(epoch: 40, iters: 368, time: 0.107, data: 0.011) loss: 0.046 
(epoch: 40, iters: 448, time: 0.102, data: 0.000) loss: 0.148 
(epoch: 40, iters: 528, time: 0.093, data: 0.000) loss: 0.264 
(epoch: 40, iters: 608, time: 0.108, data: 0.040) loss: 0.415 
(epoch: 40, iters: 688, time: 0.127, data: 0.000) loss: 0.025 
(epoch: 40, iters: 768, time: 0.096, data: 0.012) loss: 0.064 
(epoch: 40, iters: 848, time: 0.121, data: 0.000) loss: 0.555 
(epoch: 40, iters: 928, time: 0.106, data: 0.012) loss: 0.204 
(epoch: 40, iters: 1008, time: 0.096, data: 0.000) loss: 0.158 
(epoch: 40, iters: 1088, time: 0.107, data: 0.000) loss: 0.231 
(epoch: 40, iters: 1168, time: 0.103, data: 0.040) loss: 0.211 
(epoch: 40, iters: 1248, time: 0.122, data: 0.000) loss: 0.228 
(epoch: 40, iters: 1328, time: 0.101, data: 0.013) loss: 0.069 
(epoch: 40, iters: 1408, time: 0.134, data: 0.000) loss: 0.101 
(epoch: 40, iters: 1488, time: 0.101, data: 0.012) loss: 0.161 
(epoch: 40, iters: 1568, time: 0.122, data: 0.000) loss: 0.108 
(epoch: 40, iters: 1648, time: 0.096, data: 0.000) loss: 0.135 
(epoch: 40, iters: 1728, time: 0.108, data: 0.040) loss: 0.072 
(epoch: 40, iters: 1808, time: 0.103, data: 0.000) loss: 0.198 
(epoch: 40, iters: 1888, time: 0.105, data: 0.012) loss: 0.141 
(epoch: 40, iters: 1968, time: 0.123, data: 0.000) loss: 0.098 
(epoch: 40, iters: 2048, time: 0.132, data: 0.012) loss: 0.109 
(epoch: 40, iters: 2128, time: 0.107, data: 0.000) loss: 0.027 
(epoch: 40, iters: 2208, time: 0.103, data: 0.000) loss: 0.147 
(epoch: 40, iters: 2288, time: 0.115, data: 0.041) loss: 0.197 
(epoch: 40, iters: 2368, time: 0.103, data: 0.000) loss: 0.022 
(epoch: 40, iters: 2448, time: 0.101, data: 0.012) loss: 0.060 
(epoch: 40, iters: 2528, time: 0.109, data: 0.000) loss: 0.080 
(epoch: 40, iters: 2608, time: 0.101, data: 0.011) loss: 0.278 
(epoch: 40, iters: 2688, time: 0.096, data: 0.000) loss: 0.039 
(epoch: 40, iters: 2768, time: 0.100, data: 0.000) loss: 0.270 
(epoch: 40, iters: 2848, time: 0.128, data: 0.041) loss: 0.076 
(epoch: 40, iters: 2928, time: 0.108, data: 0.000) loss: 0.198 
(epoch: 40, iters: 3008, time: 0.112, data: 0.011) loss: 0.085 
(epoch: 40, iters: 3088, time: 0.114, data: 0.000) loss: 0.092 
(epoch: 40, iters: 3168, time: 0.094, data: 0.012) loss: 0.163 
(epoch: 40, iters: 3248, time: 0.108, data: 0.000) loss: 0.044 
(epoch: 40, iters: 3328, time: 0.101, data: 0.000) loss: 0.226 
(epoch: 40, iters: 3408, time: 0.108, data: 0.039) loss: 0.031 
(epoch: 40, iters: 3488, time: 0.108, data: 0.000) loss: 0.030 
(epoch: 40, iters: 3568, time: 0.112, data: 0.011) loss: 0.168 
(epoch: 40, iters: 3648, time: 0.089, data: 0.000) loss: 0.022 
(epoch: 40, iters: 3728, time: 0.057, data: 0.011) loss: 0.201 
saving the model at the end of epoch 40, iters 149120
End of epoch 40 / 2100 	 Time Taken: 404 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 40, TEST ACC: [89.681 %]

saving the latest model (epoch 41, total_steps 149136)
(epoch: 41, iters: 80, time: 0.104, data: 1.132) loss: 0.098 
(epoch: 41, iters: 160, time: 0.107, data: 0.000) loss: 0.038 
(epoch: 41, iters: 240, time: 0.114, data: 0.041) loss: 0.017 
(epoch: 41, iters: 320, time: 0.114, data: 0.000) loss: 0.060 
(epoch: 41, iters: 400, time: 0.105, data: 0.012) loss: 0.092 
(epoch: 41, iters: 480, time: 0.126, data: 0.000) loss: 0.172 
(epoch: 41, iters: 560, time: 0.119, data: 0.011) loss: 0.039 
(epoch: 41, iters: 640, time: 0.122, data: 0.000) loss: 0.014 
(epoch: 41, iters: 720, time: 0.109, data: 0.000) loss: 0.057 
(epoch: 41, iters: 800, time: 0.110, data: 0.040) loss: 0.067 
(epoch: 41, iters: 880, time: 0.108, data: 0.000) loss: 0.006 
(epoch: 41, iters: 960, time: 0.094, data: 0.011) loss: 0.091 
(epoch: 41, iters: 1040, time: 0.115, data: 0.000) loss: 0.326 
(epoch: 41, iters: 1120, time: 0.107, data: 0.011) loss: 0.099 
(epoch: 41, iters: 1200, time: 0.115, data: 0.000) loss: 0.051 
(epoch: 41, iters: 1280, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 41, iters: 1360, time: 0.113, data: 0.041) loss: 0.117 
(epoch: 41, iters: 1440, time: 0.096, data: 0.000) loss: 0.048 
(epoch: 41, iters: 1520, time: 0.114, data: 0.011) loss: 0.177 
(epoch: 41, iters: 1600, time: 0.108, data: 0.000) loss: 0.007 
(epoch: 41, iters: 1680, time: 0.108, data: 0.012) loss: 0.015 
(epoch: 41, iters: 1760, time: 0.109, data: 0.000) loss: 0.014 
(epoch: 41, iters: 1840, time: 0.107, data: 0.000) loss: 0.262 
(epoch: 41, iters: 1920, time: 0.114, data: 0.050) loss: 0.085 
(epoch: 41, iters: 2000, time: 0.122, data: 0.000) loss: 0.028 
(epoch: 41, iters: 2080, time: 0.105, data: 0.012) loss: 0.129 
(epoch: 41, iters: 2160, time: 0.105, data: 0.000) loss: 0.064 
(epoch: 41, iters: 2240, time: 0.114, data: 0.011) loss: 0.217 
(epoch: 41, iters: 2320, time: 0.117, data: 0.000) loss: 0.011 
(epoch: 41, iters: 2400, time: 0.119, data: 0.000) loss: 0.049 
(epoch: 41, iters: 2480, time: 0.095, data: 0.040) loss: 0.023 
(epoch: 41, iters: 2560, time: 0.111, data: 0.000) loss: 0.074 
(epoch: 41, iters: 2640, time: 0.100, data: 0.012) loss: 0.027 
(epoch: 41, iters: 2720, time: 0.110, data: 0.000) loss: 0.018 
(epoch: 41, iters: 2800, time: 0.108, data: 0.000) loss: 0.069 
(epoch: 41, iters: 2880, time: 0.107, data: 0.012) loss: 0.145 
(epoch: 41, iters: 2960, time: 0.101, data: 0.026) loss: 0.010 
(epoch: 41, iters: 3040, time: 0.102, data: 0.025) loss: 0.077 
(epoch: 41, iters: 3120, time: 0.113, data: 0.011) loss: 0.060 
(epoch: 41, iters: 3200, time: 0.114, data: 0.000) loss: 0.003 
(epoch: 41, iters: 3280, time: 0.107, data: 0.012) loss: 0.109 
(epoch: 41, iters: 3360, time: 0.103, data: 0.000) loss: 0.054 
(epoch: 41, iters: 3440, time: 0.095, data: 0.000) loss: 0.198 
(epoch: 41, iters: 3520, time: 0.115, data: 0.040) loss: 0.012 
(epoch: 41, iters: 3600, time: 0.121, data: 0.000) loss: 0.035 
(epoch: 41, iters: 3680, time: 0.088, data: 0.012) loss: 0.193 
saving the model at the end of epoch 41, iters 152848
End of epoch 41 / 2100 	 Time Taken: 403 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 41, TEST ACC: [90.137 %]

saving the latest model (epoch 42, total_steps 152864)
(epoch: 42, iters: 32, time: 0.106, data: 0.006) loss: 0.289 
(epoch: 42, iters: 112, time: 0.107, data: 0.000) loss: 0.025 
(epoch: 42, iters: 192, time: 0.097, data: 0.000) loss: 0.043 
(epoch: 42, iters: 272, time: 0.108, data: 0.000) loss: 0.236 
(epoch: 42, iters: 352, time: 0.102, data: 0.041) loss: 0.010 
(epoch: 42, iters: 432, time: 0.110, data: 0.000) loss: 0.011 
(epoch: 42, iters: 512, time: 0.105, data: 0.013) loss: 0.016 
(epoch: 42, iters: 592, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 42, iters: 672, time: 0.102, data: 0.012) loss: 0.040 
(epoch: 42, iters: 752, time: 0.104, data: 0.000) loss: 0.013 
(epoch: 42, iters: 832, time: 0.107, data: 0.000) loss: 0.120 
(epoch: 42, iters: 912, time: 0.108, data: 0.037) loss: 0.060 
(epoch: 42, iters: 992, time: 0.116, data: 0.000) loss: 0.160 
(epoch: 42, iters: 1072, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 42, iters: 1152, time: 0.108, data: 0.012) loss: 0.064 
(epoch: 42, iters: 1232, time: 0.112, data: 0.027) loss: 0.044 
(epoch: 42, iters: 1312, time: 0.102, data: 0.000) loss: 0.061 
(epoch: 42, iters: 1392, time: 0.095, data: 0.000) loss: 0.566 
(epoch: 42, iters: 1472, time: 0.106, data: 0.011) loss: 0.008 
(epoch: 42, iters: 1552, time: 0.114, data: 0.035) loss: 0.152 
(epoch: 42, iters: 1632, time: 0.097, data: 0.000) loss: 0.513 
(epoch: 42, iters: 1712, time: 0.121, data: 0.000) loss: 0.065 
(epoch: 42, iters: 1792, time: 0.108, data: 0.012) loss: 0.011 
(epoch: 42, iters: 1872, time: 0.112, data: 0.000) loss: 0.387 
(epoch: 42, iters: 1952, time: 0.101, data: 0.041) loss: 0.379 
(epoch: 42, iters: 2032, time: 0.101, data: 0.000) loss: 0.027 
(epoch: 42, iters: 2112, time: 0.099, data: 0.011) loss: 0.054 
(epoch: 42, iters: 2192, time: 0.101, data: 0.000) loss: 0.063 
(epoch: 42, iters: 2272, time: 0.101, data: 0.011) loss: 0.048 
(epoch: 42, iters: 2352, time: 0.108, data: 0.000) loss: 0.505 
(epoch: 42, iters: 2432, time: 0.115, data: 0.000) loss: 0.226 
(epoch: 42, iters: 2512, time: 0.101, data: 0.040) loss: 0.266 
(epoch: 42, iters: 2592, time: 0.102, data: 0.000) loss: 0.011 
(epoch: 42, iters: 2672, time: 0.125, data: 0.012) loss: 0.328 
(epoch: 42, iters: 2752, time: 0.103, data: 0.000) loss: 0.079 
(epoch: 42, iters: 2832, time: 0.101, data: 0.011) loss: 0.255 
(epoch: 42, iters: 2912, time: 0.102, data: 0.000) loss: 0.052 
(epoch: 42, iters: 2992, time: 0.114, data: 0.000) loss: 0.103 
(epoch: 42, iters: 3072, time: 0.108, data: 0.050) loss: 0.126 
(epoch: 42, iters: 3152, time: 0.102, data: 0.000) loss: 0.174 
(epoch: 42, iters: 3232, time: 0.099, data: 0.012) loss: 0.024 
(epoch: 42, iters: 3312, time: 0.104, data: 0.000) loss: 0.017 
(epoch: 42, iters: 3392, time: 0.105, data: 0.012) loss: 0.045 
(epoch: 42, iters: 3472, time: 0.104, data: 0.000) loss: 0.212 
(epoch: 42, iters: 3552, time: 0.117, data: 0.000) loss: 0.026 
(epoch: 42, iters: 3632, time: 0.101, data: 0.040) loss: 0.112 
(epoch: 42, iters: 3712, time: 0.091, data: 0.000) loss: 0.018 
saving the model at the end of epoch 42, iters 156576
End of epoch 42 / 2100 	 Time Taken: 402 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 42, TEST ACC: [93.171 %]

saving the latest model (epoch 43, total_steps 156592)
(epoch: 43, iters: 64, time: 0.116, data: 0.000) loss: 0.079 
(epoch: 43, iters: 144, time: 0.117, data: 0.028) loss: 0.022 
(epoch: 43, iters: 224, time: 0.111, data: 0.000) loss: 0.086 
(epoch: 43, iters: 304, time: 0.110, data: 0.012) loss: 0.118 
(epoch: 43, iters: 384, time: 0.106, data: 0.000) loss: 0.032 
(epoch: 43, iters: 464, time: 0.098, data: 0.012) loss: 0.052 
(epoch: 43, iters: 544, time: 0.110, data: 0.000) loss: 0.108 
(epoch: 43, iters: 624, time: 0.122, data: 0.000) loss: 0.027 
(epoch: 43, iters: 704, time: 0.104, data: 0.040) loss: 0.444 
(epoch: 43, iters: 784, time: 0.124, data: 0.000) loss: 0.057 
(epoch: 43, iters: 864, time: 0.101, data: 0.012) loss: 0.095 
(epoch: 43, iters: 944, time: 0.104, data: 0.000) loss: 0.123 
(epoch: 43, iters: 1024, time: 0.104, data: 0.012) loss: 0.108 
(epoch: 43, iters: 1104, time: 0.111, data: 0.000) loss: 0.345 
(epoch: 43, iters: 1184, time: 0.096, data: 0.000) loss: 0.033 
(epoch: 43, iters: 1264, time: 0.104, data: 0.041) loss: 0.022 
(epoch: 43, iters: 1344, time: 0.124, data: 0.000) loss: 0.011 
(epoch: 43, iters: 1424, time: 0.129, data: 0.012) loss: 0.084 
(epoch: 43, iters: 1504, time: 0.117, data: 0.000) loss: 0.191 
(epoch: 43, iters: 1584, time: 0.116, data: 0.012) loss: 0.102 
(epoch: 43, iters: 1664, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 43, iters: 1744, time: 0.102, data: 0.000) loss: 0.030 
(epoch: 43, iters: 1824, time: 0.117, data: 0.049) loss: 0.088 
(epoch: 43, iters: 1904, time: 0.112, data: 0.000) loss: 0.050 
(epoch: 43, iters: 1984, time: 0.102, data: 0.012) loss: 1.254 
(epoch: 43, iters: 2064, time: 0.107, data: 0.000) loss: 0.036 
(epoch: 43, iters: 2144, time: 0.113, data: 0.012) loss: 0.045 
(epoch: 43, iters: 2224, time: 0.102, data: 0.000) loss: 0.047 
(epoch: 43, iters: 2304, time: 0.107, data: 0.000) loss: 0.077 
(epoch: 43, iters: 2384, time: 0.109, data: 0.039) loss: 0.054 
(epoch: 43, iters: 2464, time: 0.115, data: 0.000) loss: 0.046 
(epoch: 43, iters: 2544, time: 0.100, data: 0.012) loss: 0.063 
(epoch: 43, iters: 2624, time: 0.117, data: 0.000) loss: 0.116 
(epoch: 43, iters: 2704, time: 0.094, data: 0.012) loss: 0.013 
(epoch: 43, iters: 2784, time: 0.097, data: 0.000) loss: 0.155 
(epoch: 43, iters: 2864, time: 0.102, data: 0.000) loss: 0.020 
(epoch: 43, iters: 2944, time: 0.107, data: 0.041) loss: 0.101 
(epoch: 43, iters: 3024, time: 0.108, data: 0.000) loss: 0.025 
(epoch: 43, iters: 3104, time: 0.119, data: 0.012) loss: 0.092 
(epoch: 43, iters: 3184, time: 0.102, data: 0.000) loss: 0.016 
(epoch: 43, iters: 3264, time: 0.116, data: 0.012) loss: 0.030 
(epoch: 43, iters: 3344, time: 0.117, data: 0.000) loss: 0.014 
(epoch: 43, iters: 3424, time: 0.106, data: 0.000) loss: 0.175 
(epoch: 43, iters: 3504, time: 0.101, data: 0.039) loss: 0.170 
(epoch: 43, iters: 3584, time: 0.122, data: 0.000) loss: 0.313 
(epoch: 43, iters: 3664, time: 0.087, data: 0.012) loss: 0.254 
saving the model at the end of epoch 43, iters 160304
End of epoch 43 / 2100 	 Time Taken: 402 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 43, TEST ACC: [88.619 %]

(epoch: 44, iters: 16, time: 0.143, data: 0.012) loss: 0.017 
saving the latest model (epoch 44, total_steps 160320)
(epoch: 44, iters: 96, time: 0.104, data: 0.000) loss: 0.292 
(epoch: 44, iters: 176, time: 0.102, data: 0.012) loss: 0.027 
(epoch: 44, iters: 256, time: 0.098, data: 0.000) loss: 0.029 
(epoch: 44, iters: 336, time: 0.100, data: 0.012) loss: 0.155 
(epoch: 44, iters: 416, time: 0.102, data: 0.000) loss: 0.031 
(epoch: 44, iters: 496, time: 0.094, data: 0.000) loss: 0.099 
(epoch: 44, iters: 576, time: 0.108, data: 0.048) loss: 0.020 
(epoch: 44, iters: 656, time: 0.104, data: 0.000) loss: 0.015 
(epoch: 44, iters: 736, time: 0.109, data: 0.012) loss: 0.006 
(epoch: 44, iters: 816, time: 0.109, data: 0.000) loss: 0.109 
(epoch: 44, iters: 896, time: 0.108, data: 0.020) loss: 0.108 
(epoch: 44, iters: 976, time: 0.123, data: 0.000) loss: 0.038 
(epoch: 44, iters: 1056, time: 0.120, data: 0.000) loss: 0.070 
(epoch: 44, iters: 1136, time: 0.101, data: 0.040) loss: 0.061 
(epoch: 44, iters: 1216, time: 0.102, data: 0.000) loss: 0.381 
(epoch: 44, iters: 1296, time: 0.106, data: 0.011) loss: 0.028 
(epoch: 44, iters: 1376, time: 0.121, data: 0.000) loss: 0.065 
(epoch: 44, iters: 1456, time: 0.113, data: 0.012) loss: 0.020 
(epoch: 44, iters: 1536, time: 0.108, data: 0.000) loss: 0.119 
(epoch: 44, iters: 1616, time: 0.100, data: 0.000) loss: 0.011 
(epoch: 44, iters: 1696, time: 0.107, data: 0.041) loss: 0.117 
(epoch: 44, iters: 1776, time: 0.108, data: 0.000) loss: 0.432 
(epoch: 44, iters: 1856, time: 0.099, data: 0.012) loss: 0.126 
(epoch: 44, iters: 1936, time: 0.101, data: 0.000) loss: 0.019 
(epoch: 44, iters: 2016, time: 0.101, data: 0.011) loss: 0.022 
(epoch: 44, iters: 2096, time: 0.120, data: 0.000) loss: 0.032 
(epoch: 44, iters: 2176, time: 0.101, data: 0.000) loss: 0.048 
(epoch: 44, iters: 2256, time: 0.108, data: 0.040) loss: 0.087 
(epoch: 44, iters: 2336, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 44, iters: 2416, time: 0.107, data: 0.012) loss: 0.082 
(epoch: 44, iters: 2496, time: 0.108, data: 0.000) loss: 0.154 
(epoch: 44, iters: 2576, time: 0.126, data: 0.012) loss: 0.349 
(epoch: 44, iters: 2656, time: 0.096, data: 0.000) loss: 0.014 
(epoch: 44, iters: 2736, time: 0.095, data: 0.000) loss: 0.020 
(epoch: 44, iters: 2816, time: 0.108, data: 0.050) loss: 0.011 
(epoch: 44, iters: 2896, time: 0.121, data: 0.000) loss: 0.014 
(epoch: 44, iters: 2976, time: 0.107, data: 0.022) loss: 0.179 
(epoch: 44, iters: 3056, time: 0.107, data: 0.000) loss: 0.068 
(epoch: 44, iters: 3136, time: 0.120, data: 0.011) loss: 0.008 
(epoch: 44, iters: 3216, time: 0.115, data: 0.000) loss: 0.106 
(epoch: 44, iters: 3296, time: 0.101, data: 0.000) loss: 0.125 
(epoch: 44, iters: 3376, time: 0.115, data: 0.039) loss: 0.072 
(epoch: 44, iters: 3456, time: 0.120, data: 0.000) loss: 0.042 
(epoch: 44, iters: 3536, time: 0.093, data: 0.011) loss: 0.057 
(epoch: 44, iters: 3616, time: 0.109, data: 0.000) loss: 0.086 
(epoch: 44, iters: 3696, time: 0.089, data: 0.012) loss: 0.065 
saving the model at the end of epoch 44, iters 164032
End of epoch 44 / 2100 	 Time Taken: 397 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 44, TEST ACC: [88.619 %]

saving the latest model (epoch 45, total_steps 164048)
(epoch: 45, iters: 48, time: 0.101, data: 0.000) loss: 0.043 
(epoch: 45, iters: 128, time: 0.107, data: 0.057) loss: 0.082 
(epoch: 45, iters: 208, time: 0.109, data: 0.000) loss: 0.207 
(epoch: 45, iters: 288, time: 0.100, data: 0.011) loss: 0.030 
(epoch: 45, iters: 368, time: 0.103, data: 0.000) loss: 0.088 
(epoch: 45, iters: 448, time: 0.107, data: 0.011) loss: 0.125 
(epoch: 45, iters: 528, time: 0.109, data: 0.000) loss: 0.009 
(epoch: 45, iters: 608, time: 0.103, data: 0.000) loss: 0.114 
(epoch: 45, iters: 688, time: 0.097, data: 0.040) loss: 0.011 
(epoch: 45, iters: 768, time: 0.108, data: 0.000) loss: 0.023 
(epoch: 45, iters: 848, time: 0.100, data: 0.011) loss: 0.075 
(epoch: 45, iters: 928, time: 0.101, data: 0.000) loss: 0.020 
(epoch: 45, iters: 1008, time: 0.113, data: 0.012) loss: 0.013 
(epoch: 45, iters: 1088, time: 0.101, data: 0.000) loss: 0.037 
(epoch: 45, iters: 1168, time: 0.094, data: 0.000) loss: 0.245 
(epoch: 45, iters: 1248, time: 0.101, data: 0.040) loss: 0.003 
(epoch: 45, iters: 1328, time: 0.108, data: 0.000) loss: 0.038 
(epoch: 45, iters: 1408, time: 0.094, data: 0.012) loss: 0.065 
(epoch: 45, iters: 1488, time: 0.101, data: 0.000) loss: 0.126 
(epoch: 45, iters: 1568, time: 0.107, data: 0.012) loss: 0.085 
(epoch: 45, iters: 1648, time: 0.102, data: 0.000) loss: 0.052 
(epoch: 45, iters: 1728, time: 0.101, data: 0.000) loss: 0.009 
(epoch: 45, iters: 1808, time: 0.110, data: 0.039) loss: 0.044 
(epoch: 45, iters: 1888, time: 0.109, data: 0.000) loss: 0.034 
(epoch: 45, iters: 1968, time: 0.119, data: 0.012) loss: 0.254 
(epoch: 45, iters: 2048, time: 0.107, data: 0.000) loss: 0.023 
(epoch: 45, iters: 2128, time: 0.113, data: 0.012) loss: 0.081 
(epoch: 45, iters: 2208, time: 0.114, data: 0.000) loss: 0.061 
(epoch: 45, iters: 2288, time: 0.101, data: 0.000) loss: 0.032 
(epoch: 45, iters: 2368, time: 0.095, data: 0.040) loss: 0.134 
(epoch: 45, iters: 2448, time: 0.110, data: 0.000) loss: 0.009 
(epoch: 45, iters: 2528, time: 0.113, data: 0.012) loss: 0.056 
(epoch: 45, iters: 2608, time: 0.113, data: 0.000) loss: 0.234 
(epoch: 45, iters: 2688, time: 0.100, data: 0.012) loss: 0.029 
(epoch: 45, iters: 2768, time: 0.103, data: 0.000) loss: 0.446 
(epoch: 45, iters: 2848, time: 0.102, data: 0.000) loss: 0.006 
(epoch: 45, iters: 2928, time: 0.096, data: 0.050) loss: 0.151 
(epoch: 45, iters: 3008, time: 0.121, data: 0.000) loss: 0.234 
(epoch: 45, iters: 3088, time: 0.111, data: 0.012) loss: 0.234 
(epoch: 45, iters: 3168, time: 0.108, data: 0.000) loss: 0.002 
(epoch: 45, iters: 3248, time: 0.094, data: 0.012) loss: 0.052 
(epoch: 45, iters: 3328, time: 0.110, data: 0.000) loss: 0.019 
(epoch: 45, iters: 3408, time: 0.126, data: 0.000) loss: 0.019 
(epoch: 45, iters: 3488, time: 0.107, data: 0.041) loss: 0.025 
(epoch: 45, iters: 3568, time: 0.101, data: 0.000) loss: 0.394 
(epoch: 45, iters: 3648, time: 0.089, data: 0.011) loss: 0.128 
(epoch: 45, iters: 3728, time: 0.057, data: 0.000) loss: 0.005 
saving the model at the end of epoch 45, iters 167760
End of epoch 45 / 2100 	 Time Taken: 398 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 45, TEST ACC: [90.137 %]

saving the latest model (epoch 46, total_steps 167776)
(epoch: 46, iters: 80, time: 0.108, data: 1.015) loss: 0.013 
(epoch: 46, iters: 160, time: 0.095, data: 0.031) loss: 0.015 
(epoch: 46, iters: 240, time: 0.101, data: 0.000) loss: 0.086 
(epoch: 46, iters: 320, time: 0.093, data: 0.011) loss: 0.038 
(epoch: 46, iters: 400, time: 0.108, data: 0.000) loss: 0.007 
(epoch: 46, iters: 480, time: 0.120, data: 0.011) loss: 0.135 
(epoch: 46, iters: 560, time: 0.108, data: 0.000) loss: 0.073 
(epoch: 46, iters: 640, time: 0.113, data: 0.000) loss: 0.032 
(epoch: 46, iters: 720, time: 0.107, data: 0.040) loss: 0.168 
(epoch: 46, iters: 800, time: 0.108, data: 0.000) loss: 0.072 
(epoch: 46, iters: 880, time: 0.099, data: 0.012) loss: 0.019 
(epoch: 46, iters: 960, time: 0.102, data: 0.000) loss: 0.008 
(epoch: 46, iters: 1040, time: 0.106, data: 0.012) loss: 0.263 
(epoch: 46, iters: 1120, time: 0.102, data: 0.000) loss: 0.026 
(epoch: 46, iters: 1200, time: 0.100, data: 0.000) loss: 0.015 
(epoch: 46, iters: 1280, time: 0.095, data: 0.050) loss: 0.092 
(epoch: 46, iters: 1360, time: 0.115, data: 0.000) loss: 0.017 
(epoch: 46, iters: 1440, time: 0.106, data: 0.011) loss: 0.021 
(epoch: 46, iters: 1520, time: 0.108, data: 0.000) loss: 0.046 
(epoch: 46, iters: 1600, time: 0.101, data: 0.012) loss: 0.042 
(epoch: 46, iters: 1680, time: 0.109, data: 0.000) loss: 0.625 
(epoch: 46, iters: 1760, time: 0.120, data: 0.000) loss: 0.032 
(epoch: 46, iters: 1840, time: 0.108, data: 0.041) loss: 0.014 
(epoch: 46, iters: 1920, time: 0.114, data: 0.000) loss: 0.044 
(epoch: 46, iters: 2000, time: 0.099, data: 0.012) loss: 0.067 
(epoch: 46, iters: 2080, time: 0.102, data: 0.000) loss: 0.008 
(epoch: 46, iters: 2160, time: 0.100, data: 0.012) loss: 0.065 
(epoch: 46, iters: 2240, time: 0.102, data: 0.000) loss: 0.022 
(epoch: 46, iters: 2320, time: 0.100, data: 0.000) loss: 0.054 
(epoch: 46, iters: 2400, time: 0.113, data: 0.040) loss: 0.007 
(epoch: 46, iters: 2480, time: 0.114, data: 0.000) loss: 0.011 
(epoch: 46, iters: 2560, time: 0.099, data: 0.013) loss: 0.027 
(epoch: 46, iters: 2640, time: 0.113, data: 0.000) loss: 0.022 
(epoch: 46, iters: 2720, time: 0.106, data: 0.011) loss: 0.019 
(epoch: 46, iters: 2800, time: 0.116, data: 0.000) loss: 0.004 
(epoch: 46, iters: 2880, time: 0.108, data: 0.000) loss: 0.478 
(epoch: 46, iters: 2960, time: 0.100, data: 0.039) loss: 0.112 
(epoch: 46, iters: 3040, time: 0.107, data: 0.000) loss: 0.238 
(epoch: 46, iters: 3120, time: 0.093, data: 0.011) loss: 0.009 
(epoch: 46, iters: 3200, time: 0.106, data: 0.035) loss: 0.036 
(epoch: 46, iters: 3280, time: 0.120, data: 0.000) loss: 0.059 
(epoch: 46, iters: 3360, time: 0.101, data: 0.000) loss: 0.086 
(epoch: 46, iters: 3440, time: 0.106, data: 0.012) loss: 0.102 
(epoch: 46, iters: 3520, time: 0.100, data: 0.034) loss: 0.212 
(epoch: 46, iters: 3600, time: 0.115, data: 0.000) loss: 0.071 
(epoch: 46, iters: 3680, time: 0.090, data: 0.000) loss: 0.020 
saving the model at the end of epoch 46, iters 171488
End of epoch 46 / 2100 	 Time Taken: 390 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 46, TEST ACC: [88.923 %]

saving the latest model (epoch 47, total_steps 171504)
(epoch: 47, iters: 32, time: 0.099, data: 0.005) loss: 0.003 
(epoch: 47, iters: 112, time: 0.103, data: 0.027) loss: 0.007 
(epoch: 47, iters: 192, time: 0.115, data: 0.000) loss: 0.151 
(epoch: 47, iters: 272, time: 0.103, data: 0.000) loss: 0.056 
(epoch: 47, iters: 352, time: 0.101, data: 0.051) loss: 0.114 
(epoch: 47, iters: 432, time: 0.101, data: 0.000) loss: 0.024 
(epoch: 47, iters: 512, time: 0.106, data: 0.021) loss: 0.085 
(epoch: 47, iters: 592, time: 0.101, data: 0.000) loss: 0.226 
(epoch: 47, iters: 672, time: 0.103, data: 0.020) loss: 0.156 
(epoch: 47, iters: 752, time: 0.109, data: 0.000) loss: 0.010 
(epoch: 47, iters: 832, time: 0.095, data: 0.000) loss: 0.031 
(epoch: 47, iters: 912, time: 0.117, data: 0.042) loss: 0.035 
(epoch: 47, iters: 992, time: 0.105, data: 0.000) loss: 0.082 
(epoch: 47, iters: 1072, time: 0.107, data: 0.011) loss: 0.010 
(epoch: 47, iters: 1152, time: 0.108, data: 0.000) loss: 0.046 
(epoch: 47, iters: 1232, time: 0.101, data: 0.012) loss: 0.019 
(epoch: 47, iters: 1312, time: 0.103, data: 0.000) loss: 0.012 
(epoch: 47, iters: 1392, time: 0.114, data: 0.000) loss: 0.087 
(epoch: 47, iters: 1472, time: 0.103, data: 0.039) loss: 0.212 
(epoch: 47, iters: 1552, time: 0.116, data: 0.000) loss: 0.167 
(epoch: 47, iters: 1632, time: 0.101, data: 0.012) loss: 0.020 
(epoch: 47, iters: 1712, time: 0.108, data: 0.000) loss: 0.051 
(epoch: 47, iters: 1792, time: 0.108, data: 0.011) loss: 0.129 
(epoch: 47, iters: 1872, time: 0.097, data: 0.000) loss: 0.027 
(epoch: 47, iters: 1952, time: 0.095, data: 0.000) loss: 0.046 
(epoch: 47, iters: 2032, time: 0.103, data: 0.040) loss: 0.075 
(epoch: 47, iters: 2112, time: 0.103, data: 0.000) loss: 0.023 
(epoch: 47, iters: 2192, time: 0.102, data: 0.013) loss: 0.204 
(epoch: 47, iters: 2272, time: 0.111, data: 0.000) loss: 0.010 
(epoch: 47, iters: 2352, time: 0.102, data: 0.012) loss: 0.124 
(epoch: 47, iters: 2432, time: 0.116, data: 0.000) loss: 0.012 
(epoch: 47, iters: 2512, time: 0.108, data: 0.000) loss: 0.152 
(epoch: 47, iters: 2592, time: 0.111, data: 0.040) loss: 0.010 
(epoch: 47, iters: 2672, time: 0.103, data: 0.000) loss: 0.004 
(epoch: 47, iters: 2752, time: 0.107, data: 0.013) loss: 0.019 
(epoch: 47, iters: 2832, time: 0.111, data: 0.000) loss: 0.027 
(epoch: 47, iters: 2912, time: 0.102, data: 0.012) loss: 0.049 
(epoch: 47, iters: 2992, time: 0.110, data: 0.000) loss: 0.069 
(epoch: 47, iters: 3072, time: 0.096, data: 0.000) loss: 0.014 
(epoch: 47, iters: 3152, time: 0.103, data: 0.040) loss: 0.016 
(epoch: 47, iters: 3232, time: 0.123, data: 0.000) loss: 0.128 
(epoch: 47, iters: 3312, time: 0.101, data: 0.012) loss: 0.170 
(epoch: 47, iters: 3392, time: 0.103, data: 0.000) loss: 0.042 
(epoch: 47, iters: 3472, time: 0.103, data: 0.012) loss: 0.158 
(epoch: 47, iters: 3552, time: 0.103, data: 0.000) loss: 0.177 
(epoch: 47, iters: 3632, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 47, iters: 3712, time: 0.091, data: 0.036) loss: 0.641 
saving the model at the end of epoch 47, iters 175216
End of epoch 47 / 2100 	 Time Taken: 395 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 47, TEST ACC: [67.678 %]

saving the latest model (epoch 48, total_steps 175232)
(epoch: 48, iters: 64, time: 0.106, data: 0.000) loss: 0.077 
(epoch: 48, iters: 144, time: 0.122, data: 0.000) loss: 0.041 
(epoch: 48, iters: 224, time: 0.109, data: 0.013) loss: 0.082 
(epoch: 48, iters: 304, time: 0.116, data: 0.000) loss: 0.072 
(epoch: 48, iters: 384, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 48, iters: 464, time: 0.096, data: 0.039) loss: 0.013 
(epoch: 48, iters: 544, time: 0.095, data: 0.000) loss: 0.094 
(epoch: 48, iters: 624, time: 0.107, data: 0.011) loss: 0.005 
(epoch: 48, iters: 704, time: 0.101, data: 0.000) loss: 0.030 
(epoch: 48, iters: 784, time: 0.095, data: 0.000) loss: 0.090 
(epoch: 48, iters: 864, time: 0.106, data: 0.012) loss: 0.041 
(epoch: 48, iters: 944, time: 0.093, data: 0.035) loss: 0.010 
(epoch: 48, iters: 1024, time: 0.101, data: 0.000) loss: 0.212 
(epoch: 48, iters: 1104, time: 0.095, data: 0.000) loss: 0.036 
(epoch: 48, iters: 1184, time: 0.100, data: 0.012) loss: 0.014 
(epoch: 48, iters: 1264, time: 0.106, data: 0.034) loss: 0.071 
(epoch: 48, iters: 1344, time: 0.103, data: 0.000) loss: 0.006 
(epoch: 48, iters: 1424, time: 0.109, data: 0.000) loss: 0.027 
(epoch: 48, iters: 1504, time: 0.107, data: 0.012) loss: 0.010 
(epoch: 48, iters: 1584, time: 0.099, data: 0.025) loss: 0.296 
(epoch: 48, iters: 1664, time: 0.101, data: 0.000) loss: 0.206 
(epoch: 48, iters: 1744, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 48, iters: 1824, time: 0.096, data: 0.012) loss: 0.079 
(epoch: 48, iters: 1904, time: 0.107, data: 0.025) loss: 0.010 
(epoch: 48, iters: 1984, time: 0.107, data: 0.000) loss: 0.026 
(epoch: 48, iters: 2064, time: 0.101, data: 0.000) loss: 0.004 
(epoch: 48, iters: 2144, time: 0.106, data: 0.011) loss: 0.060 
(epoch: 48, iters: 2224, time: 0.094, data: 0.000) loss: 0.043 
(epoch: 48, iters: 2304, time: 0.094, data: 0.012) loss: 0.036 
(epoch: 48, iters: 2384, time: 0.101, data: 0.000) loss: 0.047 
(epoch: 48, iters: 2464, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 48, iters: 2544, time: 0.101, data: 0.039) loss: 0.073 
(epoch: 48, iters: 2624, time: 0.096, data: 0.000) loss: 0.025 
(epoch: 48, iters: 2704, time: 0.098, data: 0.011) loss: 0.020 
(epoch: 48, iters: 2784, time: 0.101, data: 0.000) loss: 0.153 
(epoch: 48, iters: 2864, time: 0.102, data: 0.011) loss: 0.009 
(epoch: 48, iters: 2944, time: 0.105, data: 0.000) loss: 0.009 
(epoch: 48, iters: 3024, time: 0.112, data: 0.000) loss: 0.115 
(epoch: 48, iters: 3104, time: 0.107, data: 0.048) loss: 0.230 
(epoch: 48, iters: 3184, time: 0.109, data: 0.000) loss: 0.104 
(epoch: 48, iters: 3264, time: 0.105, data: 0.011) loss: 0.169 
(epoch: 48, iters: 3344, time: 0.095, data: 0.000) loss: 0.114 
(epoch: 48, iters: 3424, time: 0.106, data: 0.012) loss: 0.006 
(epoch: 48, iters: 3504, time: 0.095, data: 0.000) loss: 0.022 
(epoch: 48, iters: 3584, time: 0.102, data: 0.000) loss: 0.010 
(epoch: 48, iters: 3664, time: 0.089, data: 0.040) loss: 0.012 
saving the model at the end of epoch 48, iters 178944
End of epoch 48 / 2100 	 Time Taken: 386 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 48, TEST ACC: [83.005 %]

(epoch: 49, iters: 16, time: 0.144, data: 0.000) loss: 0.004 
saving the latest model (epoch 49, total_steps 178960)
(epoch: 49, iters: 96, time: 0.108, data: 0.000) loss: 0.005 
(epoch: 49, iters: 176, time: 0.102, data: 0.000) loss: 0.118 
(epoch: 49, iters: 256, time: 0.110, data: 0.011) loss: 0.079 
(epoch: 49, iters: 336, time: 0.102, data: 0.000) loss: 0.004 
(epoch: 49, iters: 416, time: 0.113, data: 0.000) loss: 0.014 
(epoch: 49, iters: 496, time: 0.108, data: 0.048) loss: 0.033 
(epoch: 49, iters: 576, time: 0.102, data: 0.000) loss: 0.173 
(epoch: 49, iters: 656, time: 0.101, data: 0.012) loss: 0.082 
(epoch: 49, iters: 736, time: 0.102, data: 0.000) loss: 0.045 
(epoch: 49, iters: 816, time: 0.094, data: 0.012) loss: 0.147 
(epoch: 49, iters: 896, time: 0.102, data: 0.000) loss: 0.203 
(epoch: 49, iters: 976, time: 0.115, data: 0.000) loss: 0.006 
(epoch: 49, iters: 1056, time: 0.120, data: 0.040) loss: 0.120 
(epoch: 49, iters: 1136, time: 0.101, data: 0.000) loss: 0.019 
(epoch: 49, iters: 1216, time: 0.093, data: 0.011) loss: 0.152 
(epoch: 49, iters: 1296, time: 0.100, data: 0.000) loss: 0.220 
(epoch: 49, iters: 1376, time: 0.096, data: 0.012) loss: 0.103 
(epoch: 49, iters: 1456, time: 0.096, data: 0.000) loss: 0.151 
(epoch: 49, iters: 1536, time: 0.106, data: 0.000) loss: 0.050 
(epoch: 49, iters: 1616, time: 0.103, data: 0.039) loss: 0.029 
(epoch: 49, iters: 1696, time: 0.103, data: 0.000) loss: 0.008 
(epoch: 49, iters: 1776, time: 0.101, data: 0.012) loss: 0.087 
(epoch: 49, iters: 1856, time: 0.107, data: 0.000) loss: 0.025 
(epoch: 49, iters: 1936, time: 0.113, data: 0.012) loss: 0.011 
(epoch: 49, iters: 2016, time: 0.114, data: 0.000) loss: 0.060 
(epoch: 49, iters: 2096, time: 0.101, data: 0.000) loss: 0.071 
(epoch: 49, iters: 2176, time: 0.096, data: 0.040) loss: 0.034 
(epoch: 49, iters: 2256, time: 0.101, data: 0.000) loss: 0.147 
(epoch: 49, iters: 2336, time: 0.094, data: 0.011) loss: 0.015 
(epoch: 49, iters: 2416, time: 0.113, data: 0.000) loss: 0.028 
(epoch: 49, iters: 2496, time: 0.100, data: 0.012) loss: 0.015 
(epoch: 49, iters: 2576, time: 0.107, data: 0.000) loss: 0.009 
(epoch: 49, iters: 2656, time: 0.101, data: 0.000) loss: 0.134 
(epoch: 49, iters: 2736, time: 0.107, data: 0.040) loss: 0.029 
(epoch: 49, iters: 2816, time: 0.108, data: 0.000) loss: 0.006 
(epoch: 49, iters: 2896, time: 0.093, data: 0.012) loss: 0.377 
(epoch: 49, iters: 2976, time: 0.095, data: 0.000) loss: 0.151 
(epoch: 49, iters: 3056, time: 0.106, data: 0.011) loss: 0.050 
(epoch: 49, iters: 3136, time: 0.114, data: 0.000) loss: 0.050 
(epoch: 49, iters: 3216, time: 0.108, data: 0.000) loss: 0.003 
(epoch: 49, iters: 3296, time: 0.120, data: 0.022) loss: 0.002 
(epoch: 49, iters: 3376, time: 0.113, data: 0.035) loss: 0.033 
(epoch: 49, iters: 3456, time: 0.108, data: 0.000) loss: 0.004 
(epoch: 49, iters: 3536, time: 0.110, data: 0.000) loss: 0.119 
(epoch: 49, iters: 3616, time: 0.107, data: 0.012) loss: 0.012 
(epoch: 49, iters: 3696, time: 0.088, data: 0.026) loss: 0.031 
saving the model at the end of epoch 49, iters 182672
End of epoch 49 / 2100 	 Time Taken: 385 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 49, TEST ACC: [54.325 %]

saving the latest model (epoch 50, total_steps 182688)
(epoch: 50, iters: 48, time: 0.095, data: 0.000) loss: 0.024 
(epoch: 50, iters: 128, time: 0.093, data: 0.027) loss: 0.053 
(epoch: 50, iters: 208, time: 0.107, data: 0.000) loss: 0.020 
(epoch: 50, iters: 288, time: 0.119, data: 0.000) loss: 0.015 
(epoch: 50, iters: 368, time: 0.095, data: 0.040) loss: 0.056 
(epoch: 50, iters: 448, time: 0.102, data: 0.000) loss: 0.063 
(epoch: 50, iters: 528, time: 0.093, data: 0.012) loss: 0.092 
(epoch: 50, iters: 608, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 50, iters: 688, time: 0.106, data: 0.012) loss: 0.035 
(epoch: 50, iters: 768, time: 0.108, data: 0.000) loss: 0.070 
(epoch: 50, iters: 848, time: 0.121, data: 0.000) loss: 0.008 
(epoch: 50, iters: 928, time: 0.103, data: 0.040) loss: 0.011 
(epoch: 50, iters: 1008, time: 0.097, data: 0.000) loss: 0.042 
(epoch: 50, iters: 1088, time: 0.118, data: 0.012) loss: 0.132 
(epoch: 50, iters: 1168, time: 0.101, data: 0.000) loss: 0.079 
(epoch: 50, iters: 1248, time: 0.094, data: 0.012) loss: 0.026 
(epoch: 50, iters: 1328, time: 0.095, data: 0.000) loss: 0.364 
(epoch: 50, iters: 1408, time: 0.099, data: 0.000) loss: 0.010 
(epoch: 50, iters: 1488, time: 0.108, data: 0.039) loss: 0.002 
(epoch: 50, iters: 1568, time: 0.101, data: 0.000) loss: 0.139 
(epoch: 50, iters: 1648, time: 0.099, data: 0.012) loss: 0.020 
(epoch: 50, iters: 1728, time: 0.096, data: 0.000) loss: 0.208 
(epoch: 50, iters: 1808, time: 0.094, data: 0.012) loss: 0.051 
(epoch: 50, iters: 1888, time: 0.102, data: 0.000) loss: 0.385 
(epoch: 50, iters: 1968, time: 0.100, data: 0.000) loss: 0.064 
(epoch: 50, iters: 2048, time: 0.113, data: 0.039) loss: 0.143 
(epoch: 50, iters: 2128, time: 0.102, data: 0.000) loss: 0.008 
(epoch: 50, iters: 2208, time: 0.100, data: 0.012) loss: 0.064 
(epoch: 50, iters: 2288, time: 0.096, data: 0.000) loss: 0.162 
(epoch: 50, iters: 2368, time: 0.108, data: 0.012) loss: 0.046 
(epoch: 50, iters: 2448, time: 0.102, data: 0.000) loss: 0.117 
(epoch: 50, iters: 2528, time: 0.108, data: 0.000) loss: 0.010 
(epoch: 50, iters: 2608, time: 0.104, data: 0.049) loss: 0.075 
(epoch: 50, iters: 2688, time: 0.102, data: 0.000) loss: 0.034 
(epoch: 50, iters: 2768, time: 0.113, data: 0.012) loss: 0.003 
(epoch: 50, iters: 2848, time: 0.101, data: 0.000) loss: 0.037 
(epoch: 50, iters: 2928, time: 0.107, data: 0.012) loss: 0.055 
(epoch: 50, iters: 3008, time: 0.122, data: 0.000) loss: 0.029 
(epoch: 50, iters: 3088, time: 0.107, data: 0.000) loss: 0.007 
(epoch: 50, iters: 3168, time: 0.109, data: 0.039) loss: 0.004 
(epoch: 50, iters: 3248, time: 0.104, data: 0.000) loss: 0.024 
(epoch: 50, iters: 3328, time: 0.102, data: 0.011) loss: 0.031 
(epoch: 50, iters: 3408, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 50, iters: 3488, time: 0.107, data: 0.011) loss: 0.020 
(epoch: 50, iters: 3568, time: 0.108, data: 0.000) loss: 0.007 
(epoch: 50, iters: 3648, time: 0.088, data: 0.000) loss: 0.033 
(epoch: 50, iters: 3728, time: 0.056, data: 0.016) loss: 0.163 
saving the model at the end of epoch 50, iters 186400
End of epoch 50 / 2100 	 Time Taken: 385 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 50, TEST ACC: [86.343 %]

saving the latest model (epoch 51, total_steps 186416)
(epoch: 51, iters: 80, time: 0.095, data: 0.581) loss: 0.016 
(epoch: 51, iters: 160, time: 0.102, data: 0.000) loss: 0.009 
(epoch: 51, iters: 240, time: 0.107, data: 0.000) loss: 0.081 
(epoch: 51, iters: 320, time: 0.110, data: 0.041) loss: 0.050 
(epoch: 51, iters: 400, time: 0.108, data: 0.000) loss: 0.090 
(epoch: 51, iters: 480, time: 0.098, data: 0.012) loss: 0.091 
(epoch: 51, iters: 560, time: 0.101, data: 0.000) loss: 0.069 
(epoch: 51, iters: 640, time: 0.094, data: 0.012) loss: 0.107 
(epoch: 51, iters: 720, time: 0.102, data: 0.000) loss: 0.381 
(epoch: 51, iters: 800, time: 0.108, data: 0.000) loss: 0.025 
(epoch: 51, iters: 880, time: 0.101, data: 0.040) loss: 0.029 
(epoch: 51, iters: 960, time: 0.096, data: 0.000) loss: 0.052 
(epoch: 51, iters: 1040, time: 0.099, data: 0.013) loss: 0.029 
(epoch: 51, iters: 1120, time: 0.095, data: 0.000) loss: 0.032 
(epoch: 51, iters: 1200, time: 0.094, data: 0.011) loss: 0.212 
(epoch: 51, iters: 1280, time: 0.103, data: 0.000) loss: 0.011 
(epoch: 51, iters: 1360, time: 0.100, data: 0.000) loss: 0.036 
(epoch: 51, iters: 1440, time: 0.101, data: 0.050) loss: 0.005 
(epoch: 51, iters: 1520, time: 0.115, data: 0.000) loss: 0.034 
(epoch: 51, iters: 1600, time: 0.100, data: 0.011) loss: 0.151 
(epoch: 51, iters: 1680, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 51, iters: 1760, time: 0.094, data: 0.012) loss: 0.011 
(epoch: 51, iters: 1840, time: 0.096, data: 0.000) loss: 0.063 
(epoch: 51, iters: 1920, time: 0.107, data: 0.000) loss: 0.042 
(epoch: 51, iters: 2000, time: 0.107, data: 0.039) loss: 0.091 
(epoch: 51, iters: 2080, time: 0.108, data: 0.000) loss: 0.036 
(epoch: 51, iters: 2160, time: 0.105, data: 0.011) loss: 0.032 
(epoch: 51, iters: 2240, time: 0.120, data: 0.000) loss: 0.016 
(epoch: 51, iters: 2320, time: 0.101, data: 0.012) loss: 0.049 
(epoch: 51, iters: 2400, time: 0.102, data: 0.000) loss: 0.004 
(epoch: 51, iters: 2480, time: 0.113, data: 0.000) loss: 0.057 
(epoch: 51, iters: 2560, time: 0.095, data: 0.050) loss: 0.056 
(epoch: 51, iters: 2640, time: 0.109, data: 0.000) loss: 0.092 
(epoch: 51, iters: 2720, time: 0.093, data: 0.011) loss: 0.446 
(epoch: 51, iters: 2800, time: 0.097, data: 0.000) loss: 0.014 
(epoch: 51, iters: 2880, time: 0.095, data: 0.011) loss: 0.005 
(epoch: 51, iters: 2960, time: 0.095, data: 0.000) loss: 0.052 
(epoch: 51, iters: 3040, time: 0.102, data: 0.000) loss: 0.129 
(epoch: 51, iters: 3120, time: 0.104, data: 0.040) loss: 0.104 
(epoch: 51, iters: 3200, time: 0.105, data: 0.000) loss: 0.159 
(epoch: 51, iters: 3280, time: 0.105, data: 0.012) loss: 0.104 
(epoch: 51, iters: 3360, time: 0.113, data: 0.000) loss: 0.044 
(epoch: 51, iters: 3440, time: 0.102, data: 0.012) loss: 0.017 
(epoch: 51, iters: 3520, time: 0.096, data: 0.000) loss: 0.073 
(epoch: 51, iters: 3600, time: 0.101, data: 0.000) loss: 0.130 
(epoch: 51, iters: 3680, time: 0.088, data: 0.049) loss: 0.180 
saving the model at the end of epoch 51, iters 190128
End of epoch 51 / 2100 	 Time Taken: 383 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 51, TEST ACC: [88.012 %]

saving the latest model (epoch 52, total_steps 190144)
(epoch: 52, iters: 32, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 52, iters: 112, time: 0.106, data: 0.000) loss: 0.027 
(epoch: 52, iters: 192, time: 0.115, data: 0.000) loss: 0.097 
(epoch: 52, iters: 272, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 52, iters: 352, time: 0.101, data: 0.040) loss: 0.034 
(epoch: 52, iters: 432, time: 0.101, data: 0.000) loss: 0.104 
(epoch: 52, iters: 512, time: 0.099, data: 0.011) loss: 0.157 
(epoch: 52, iters: 592, time: 0.096, data: 0.000) loss: 0.041 
(epoch: 52, iters: 672, time: 0.096, data: 0.012) loss: 0.050 
(epoch: 52, iters: 752, time: 0.102, data: 0.000) loss: 0.031 
(epoch: 52, iters: 832, time: 0.101, data: 0.000) loss: 0.026 
(epoch: 52, iters: 912, time: 0.100, data: 0.040) loss: 0.007 
(epoch: 52, iters: 992, time: 0.102, data: 0.000) loss: 0.005 
(epoch: 52, iters: 1072, time: 0.106, data: 0.012) loss: 0.008 
(epoch: 52, iters: 1152, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 52, iters: 1232, time: 0.094, data: 0.012) loss: 0.099 
(epoch: 52, iters: 1312, time: 0.108, data: 0.000) loss: 0.027 
(epoch: 52, iters: 1392, time: 0.106, data: 0.000) loss: 0.014 
(epoch: 52, iters: 1472, time: 0.101, data: 0.049) loss: 0.004 
(epoch: 52, iters: 1552, time: 0.103, data: 0.000) loss: 0.009 
(epoch: 52, iters: 1632, time: 0.105, data: 0.011) loss: 0.265 
(epoch: 52, iters: 1712, time: 0.107, data: 0.000) loss: 0.032 
(epoch: 52, iters: 1792, time: 0.120, data: 0.012) loss: 0.007 
(epoch: 52, iters: 1872, time: 0.102, data: 0.000) loss: 0.047 
(epoch: 52, iters: 1952, time: 0.100, data: 0.000) loss: 0.012 
(epoch: 52, iters: 2032, time: 0.101, data: 0.040) loss: 0.025 
(epoch: 52, iters: 2112, time: 0.095, data: 0.000) loss: 0.068 
(epoch: 52, iters: 2192, time: 0.100, data: 0.011) loss: 0.100 
(epoch: 52, iters: 2272, time: 0.102, data: 0.000) loss: 0.010 
(epoch: 52, iters: 2352, time: 0.101, data: 0.011) loss: 0.029 
(epoch: 52, iters: 2432, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 52, iters: 2512, time: 0.107, data: 0.000) loss: 0.026 
(epoch: 52, iters: 2592, time: 0.101, data: 0.039) loss: 0.039 
(epoch: 52, iters: 2672, time: 0.102, data: 0.000) loss: 0.039 
(epoch: 52, iters: 2752, time: 0.099, data: 0.012) loss: 0.048 
(epoch: 52, iters: 2832, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 52, iters: 2912, time: 0.094, data: 0.012) loss: 0.019 
(epoch: 52, iters: 2992, time: 0.101, data: 0.000) loss: 0.054 
(epoch: 52, iters: 3072, time: 0.106, data: 0.000) loss: 0.171 
(epoch: 52, iters: 3152, time: 0.102, data: 0.052) loss: 0.011 
(epoch: 52, iters: 3232, time: 0.104, data: 0.000) loss: 0.041 
(epoch: 52, iters: 3312, time: 0.099, data: 0.012) loss: 0.023 
(epoch: 52, iters: 3392, time: 0.116, data: 0.000) loss: 0.014 
(epoch: 52, iters: 3472, time: 0.114, data: 0.012) loss: 0.015 
(epoch: 52, iters: 3552, time: 0.108, data: 0.000) loss: 0.119 
(epoch: 52, iters: 3632, time: 0.099, data: 0.000) loss: 0.252 
(epoch: 52, iters: 3712, time: 0.088, data: 0.035) loss: 0.098 
saving the model at the end of epoch 52, iters 193856
End of epoch 52 / 2100 	 Time Taken: 383 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 52, TEST ACC: [78.756 %]

saving the latest model (epoch 53, total_steps 193872)
(epoch: 53, iters: 64, time: 0.100, data: 0.000) loss: 0.007 
(epoch: 53, iters: 144, time: 0.107, data: 0.000) loss: 0.036 
(epoch: 53, iters: 224, time: 0.109, data: 0.000) loss: 0.085 
(epoch: 53, iters: 304, time: 0.101, data: 0.000) loss: 0.237 
(epoch: 53, iters: 384, time: 0.095, data: 0.039) loss: 0.117 
(epoch: 53, iters: 464, time: 0.115, data: 0.000) loss: 0.032 
(epoch: 53, iters: 544, time: 0.106, data: 0.011) loss: 0.053 
(epoch: 53, iters: 624, time: 0.101, data: 0.000) loss: 0.044 
(epoch: 53, iters: 704, time: 0.101, data: 0.011) loss: 0.015 
(epoch: 53, iters: 784, time: 0.095, data: 0.000) loss: 0.020 
(epoch: 53, iters: 864, time: 0.095, data: 0.000) loss: 0.097 
(epoch: 53, iters: 944, time: 0.100, data: 0.050) loss: 0.008 
(epoch: 53, iters: 1024, time: 0.112, data: 0.000) loss: 0.083 
(epoch: 53, iters: 1104, time: 0.100, data: 0.012) loss: 0.010 
(epoch: 53, iters: 1184, time: 0.103, data: 0.000) loss: 0.102 
(epoch: 53, iters: 1264, time: 0.095, data: 0.012) loss: 0.067 
(epoch: 53, iters: 1344, time: 0.095, data: 0.000) loss: 0.063 
(epoch: 53, iters: 1424, time: 0.107, data: 0.000) loss: 0.096 
(epoch: 53, iters: 1504, time: 0.102, data: 0.039) loss: 0.015 
(epoch: 53, iters: 1584, time: 0.101, data: 0.000) loss: 0.018 
(epoch: 53, iters: 1664, time: 0.093, data: 0.011) loss: 0.019 
(epoch: 53, iters: 1744, time: 0.114, data: 0.000) loss: 0.042 
(epoch: 53, iters: 1824, time: 0.102, data: 0.012) loss: 0.016 
(epoch: 53, iters: 1904, time: 0.103, data: 0.000) loss: 0.006 
(epoch: 53, iters: 1984, time: 0.109, data: 0.000) loss: 0.012 
(epoch: 53, iters: 2064, time: 0.095, data: 0.040) loss: 0.224 
(epoch: 53, iters: 2144, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 53, iters: 2224, time: 0.113, data: 0.012) loss: 0.010 
(epoch: 53, iters: 2304, time: 0.101, data: 0.000) loss: 0.078 
(epoch: 53, iters: 2384, time: 0.095, data: 0.012) loss: 0.090 
(epoch: 53, iters: 2464, time: 0.101, data: 0.000) loss: 0.005 
(epoch: 53, iters: 2544, time: 0.102, data: 0.000) loss: 0.107 
(epoch: 53, iters: 2624, time: 0.110, data: 0.040) loss: 0.006 
(epoch: 53, iters: 2704, time: 0.102, data: 0.000) loss: 0.029 
(epoch: 53, iters: 2784, time: 0.093, data: 0.011) loss: 0.144 
(epoch: 53, iters: 2864, time: 0.102, data: 0.000) loss: 0.030 
(epoch: 53, iters: 2944, time: 0.107, data: 0.011) loss: 0.213 
(epoch: 53, iters: 3024, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 53, iters: 3104, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 53, iters: 3184, time: 0.101, data: 0.039) loss: 0.018 
(epoch: 53, iters: 3264, time: 0.105, data: 0.000) loss: 0.172 
(epoch: 53, iters: 3344, time: 0.102, data: 0.012) loss: 0.005 
(epoch: 53, iters: 3424, time: 0.101, data: 0.000) loss: 0.058 
(epoch: 53, iters: 3504, time: 0.102, data: 0.011) loss: 0.009 
(epoch: 53, iters: 3584, time: 0.102, data: 0.000) loss: 0.007 
(epoch: 53, iters: 3664, time: 0.090, data: 0.000) loss: 0.156 
saving the model at the end of epoch 53, iters 197584
End of epoch 53 / 2100 	 Time Taken: 379 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 53, TEST ACC: [91.047 %]

(epoch: 54, iters: 16, time: 0.144, data: 0.013) loss: 0.014 
saving the latest model (epoch 54, total_steps 197600)
(epoch: 54, iters: 96, time: 0.095, data: 0.012) loss: 0.095 
(epoch: 54, iters: 176, time: 0.112, data: 0.012) loss: 0.056 
(epoch: 54, iters: 256, time: 0.097, data: 0.000) loss: 0.065 
(epoch: 54, iters: 336, time: 0.100, data: 0.013) loss: 0.172 
(epoch: 54, iters: 416, time: 0.113, data: 0.000) loss: 0.006 
(epoch: 54, iters: 496, time: 0.107, data: 0.000) loss: 0.252 
(epoch: 54, iters: 576, time: 0.095, data: 0.040) loss: 0.042 
(epoch: 54, iters: 656, time: 0.102, data: 0.000) loss: 0.020 
(epoch: 54, iters: 736, time: 0.106, data: 0.012) loss: 0.019 
(epoch: 54, iters: 816, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 54, iters: 896, time: 0.095, data: 0.012) loss: 0.033 
(epoch: 54, iters: 976, time: 0.102, data: 0.000) loss: 0.110 
(epoch: 54, iters: 1056, time: 0.103, data: 0.000) loss: 0.047 
(epoch: 54, iters: 1136, time: 0.096, data: 0.048) loss: 0.024 
(epoch: 54, iters: 1216, time: 0.103, data: 0.000) loss: 0.006 
(epoch: 54, iters: 1296, time: 0.093, data: 0.013) loss: 0.023 
(epoch: 54, iters: 1376, time: 0.098, data: 0.000) loss: 0.060 
(epoch: 54, iters: 1456, time: 0.109, data: 0.012) loss: 0.056 
(epoch: 54, iters: 1536, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 54, iters: 1616, time: 0.101, data: 0.000) loss: 0.189 
(epoch: 54, iters: 1696, time: 0.110, data: 0.041) loss: 0.040 
(epoch: 54, iters: 1776, time: 0.097, data: 0.000) loss: 0.213 
(epoch: 54, iters: 1856, time: 0.107, data: 0.012) loss: 0.076 
(epoch: 54, iters: 1936, time: 0.101, data: 0.000) loss: 0.133 
(epoch: 54, iters: 2016, time: 0.101, data: 0.012) loss: 0.042 
(epoch: 54, iters: 2096, time: 0.109, data: 0.000) loss: 0.050 
(epoch: 54, iters: 2176, time: 0.114, data: 0.000) loss: 0.002 
(epoch: 54, iters: 2256, time: 0.101, data: 0.049) loss: 0.410 
(epoch: 54, iters: 2336, time: 0.101, data: 0.000) loss: 0.823 
(epoch: 54, iters: 2416, time: 0.106, data: 0.012) loss: 0.005 
(epoch: 54, iters: 2496, time: 0.107, data: 0.000) loss: 0.066 
(epoch: 54, iters: 2576, time: 0.108, data: 0.012) loss: 0.181 
(epoch: 54, iters: 2656, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 54, iters: 2736, time: 0.101, data: 0.000) loss: 0.089 
(epoch: 54, iters: 2816, time: 0.109, data: 0.040) loss: 0.019 
(epoch: 54, iters: 2896, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 54, iters: 2976, time: 0.094, data: 0.012) loss: 0.007 
(epoch: 54, iters: 3056, time: 0.095, data: 0.000) loss: 0.346 
(epoch: 54, iters: 3136, time: 0.097, data: 0.011) loss: 0.058 
(epoch: 54, iters: 3216, time: 0.098, data: 0.000) loss: 0.006 
(epoch: 54, iters: 3296, time: 0.116, data: 0.000) loss: 0.016 
(epoch: 54, iters: 3376, time: 0.114, data: 0.041) loss: 0.009 
(epoch: 54, iters: 3456, time: 0.109, data: 0.000) loss: 0.023 
(epoch: 54, iters: 3536, time: 0.108, data: 0.022) loss: 0.003 
(epoch: 54, iters: 3616, time: 0.102, data: 0.000) loss: 0.376 
(epoch: 54, iters: 3696, time: 0.090, data: 0.012) loss: 0.209 
saving the model at the end of epoch 54, iters 201312
End of epoch 54 / 2100 	 Time Taken: 382 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 54, TEST ACC: [89.833 %]

saving the latest model (epoch 55, total_steps 201328)
(epoch: 55, iters: 48, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 55, iters: 128, time: 0.095, data: 0.042) loss: 0.033 
(epoch: 55, iters: 208, time: 0.098, data: 0.000) loss: 0.017 
(epoch: 55, iters: 288, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 55, iters: 368, time: 0.096, data: 0.040) loss: 0.003 
(epoch: 55, iters: 448, time: 0.104, data: 0.000) loss: 0.417 
(epoch: 55, iters: 528, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 55, iters: 608, time: 0.101, data: 0.000) loss: 0.215 
(epoch: 55, iters: 688, time: 0.119, data: 0.012) loss: 0.006 
(epoch: 55, iters: 768, time: 0.102, data: 0.000) loss: 0.287 
(epoch: 55, iters: 848, time: 0.101, data: 0.000) loss: 0.437 
(epoch: 55, iters: 928, time: 0.102, data: 0.040) loss: 0.009 
(epoch: 55, iters: 1008, time: 0.102, data: 0.000) loss: 0.024 
(epoch: 55, iters: 1088, time: 0.113, data: 0.012) loss: 0.095 
(epoch: 55, iters: 1168, time: 0.102, data: 0.000) loss: 0.014 
(epoch: 55, iters: 1248, time: 0.122, data: 0.011) loss: 0.061 
(epoch: 55, iters: 1328, time: 0.118, data: 0.000) loss: 0.129 
(epoch: 55, iters: 1408, time: 0.107, data: 0.000) loss: 0.276 
(epoch: 55, iters: 1488, time: 0.095, data: 0.047) loss: 0.026 
(epoch: 55, iters: 1568, time: 0.101, data: 0.000) loss: 0.220 
(epoch: 55, iters: 1648, time: 0.118, data: 0.011) loss: 0.050 
(epoch: 55, iters: 1728, time: 0.107, data: 0.000) loss: 0.051 
(epoch: 55, iters: 1808, time: 0.101, data: 0.012) loss: 0.050 
(epoch: 55, iters: 1888, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 55, iters: 1968, time: 0.100, data: 0.000) loss: 0.020 
(epoch: 55, iters: 2048, time: 0.101, data: 0.039) loss: 0.010 
(epoch: 55, iters: 2128, time: 0.102, data: 0.000) loss: 0.026 
(epoch: 55, iters: 2208, time: 0.099, data: 0.012) loss: 0.004 
(epoch: 55, iters: 2288, time: 0.115, data: 0.000) loss: 0.036 
(epoch: 55, iters: 2368, time: 0.095, data: 0.012) loss: 0.006 
(epoch: 55, iters: 2448, time: 0.109, data: 0.000) loss: 0.019 
(epoch: 55, iters: 2528, time: 0.103, data: 0.000) loss: 0.006 
(epoch: 55, iters: 2608, time: 0.109, data: 0.052) loss: 0.013 
(epoch: 55, iters: 2688, time: 0.115, data: 0.000) loss: 0.009 
(epoch: 55, iters: 2768, time: 0.105, data: 0.012) loss: 0.021 
(epoch: 55, iters: 2848, time: 0.108, data: 0.000) loss: 0.014 
(epoch: 55, iters: 2928, time: 0.101, data: 0.011) loss: 0.098 
(epoch: 55, iters: 3008, time: 0.106, data: 0.000) loss: 0.030 
(epoch: 55, iters: 3088, time: 0.095, data: 0.000) loss: 0.053 
(epoch: 55, iters: 3168, time: 0.103, data: 0.040) loss: 0.179 
(epoch: 55, iters: 3248, time: 0.111, data: 0.000) loss: 0.018 
(epoch: 55, iters: 3328, time: 0.108, data: 0.011) loss: 0.018 
(epoch: 55, iters: 3408, time: 0.095, data: 0.000) loss: 0.084 
(epoch: 55, iters: 3488, time: 0.095, data: 0.012) loss: 0.019 
(epoch: 55, iters: 3568, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 55, iters: 3648, time: 0.089, data: 0.000) loss: 0.252 
(epoch: 55, iters: 3728, time: 0.057, data: 0.015) loss: 0.013 
saving the model at the end of epoch 55, iters 205040
End of epoch 55 / 2100 	 Time Taken: 384 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 55, TEST ACC: [86.95 %]

saving the latest model (epoch 56, total_steps 205056)
(epoch: 56, iters: 80, time: 0.100, data: 0.961) loss: 0.383 
(epoch: 56, iters: 160, time: 0.097, data: 0.000) loss: 0.043 
(epoch: 56, iters: 240, time: 0.094, data: 0.012) loss: 0.018 
(epoch: 56, iters: 320, time: 0.103, data: 0.000) loss: 0.248 
(epoch: 56, iters: 400, time: 0.094, data: 0.000) loss: 0.221 
(epoch: 56, iters: 480, time: 0.095, data: 0.038) loss: 0.041 
(epoch: 56, iters: 560, time: 0.101, data: 0.000) loss: 0.147 
(epoch: 56, iters: 640, time: 0.092, data: 0.011) loss: 0.109 
(epoch: 56, iters: 720, time: 0.101, data: 0.000) loss: 0.164 
(epoch: 56, iters: 800, time: 0.107, data: 0.011) loss: 0.172 
(epoch: 56, iters: 880, time: 0.108, data: 0.000) loss: 0.031 
(epoch: 56, iters: 960, time: 0.100, data: 0.000) loss: 0.023 
(epoch: 56, iters: 1040, time: 0.096, data: 0.048) loss: 0.023 
(epoch: 56, iters: 1120, time: 0.103, data: 0.000) loss: 0.019 
(epoch: 56, iters: 1200, time: 0.099, data: 0.012) loss: 0.185 
(epoch: 56, iters: 1280, time: 0.094, data: 0.000) loss: 0.054 
(epoch: 56, iters: 1360, time: 0.102, data: 0.011) loss: 0.137 
(epoch: 56, iters: 1440, time: 0.096, data: 0.000) loss: 0.205 
(epoch: 56, iters: 1520, time: 0.095, data: 0.000) loss: 0.055 
(epoch: 56, iters: 1600, time: 0.101, data: 0.041) loss: 0.036 
(epoch: 56, iters: 1680, time: 0.101, data: 0.000) loss: 0.029 
(epoch: 56, iters: 1760, time: 0.092, data: 0.013) loss: 0.003 
(epoch: 56, iters: 1840, time: 0.095, data: 0.000) loss: 0.032 
(epoch: 56, iters: 1920, time: 0.094, data: 0.012) loss: 0.028 
(epoch: 56, iters: 2000, time: 0.102, data: 0.000) loss: 0.030 
(epoch: 56, iters: 2080, time: 0.094, data: 0.000) loss: 0.031 
(epoch: 56, iters: 2160, time: 0.101, data: 0.049) loss: 0.084 
(epoch: 56, iters: 2240, time: 0.096, data: 0.000) loss: 0.080 
(epoch: 56, iters: 2320, time: 0.099, data: 0.011) loss: 0.011 
(epoch: 56, iters: 2400, time: 0.115, data: 0.000) loss: 0.040 
(epoch: 56, iters: 2480, time: 0.094, data: 0.013) loss: 0.044 
(epoch: 56, iters: 2560, time: 0.102, data: 0.000) loss: 0.009 
(epoch: 56, iters: 2640, time: 0.100, data: 0.000) loss: 0.041 
(epoch: 56, iters: 2720, time: 0.095, data: 0.039) loss: 0.060 
(epoch: 56, iters: 2800, time: 0.095, data: 0.000) loss: 0.215 
(epoch: 56, iters: 2880, time: 0.092, data: 0.011) loss: 0.027 
(epoch: 56, iters: 2960, time: 0.101, data: 0.000) loss: 0.008 
(epoch: 56, iters: 3040, time: 0.101, data: 0.011) loss: 0.008 
(epoch: 56, iters: 3120, time: 0.094, data: 0.026) loss: 0.008 
(epoch: 56, iters: 3200, time: 0.108, data: 0.000) loss: 0.219 
(epoch: 56, iters: 3280, time: 0.109, data: 0.000) loss: 0.008 
(epoch: 56, iters: 3360, time: 0.097, data: 0.012) loss: 0.142 
(epoch: 56, iters: 3440, time: 0.095, data: 0.027) loss: 0.012 
(epoch: 56, iters: 3520, time: 0.115, data: 0.000) loss: 0.007 
(epoch: 56, iters: 3600, time: 0.103, data: 0.000) loss: 0.009 
(epoch: 56, iters: 3680, time: 0.089, data: 0.011) loss: 0.053 
saving the model at the end of epoch 56, iters 208768
End of epoch 56 / 2100 	 Time Taken: 374 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 56, TEST ACC: [94.689 %]

saving the latest model (epoch 57, total_steps 208784)
(epoch: 57, iters: 32, time: 0.094, data: 0.006) loss: 0.018 
(epoch: 57, iters: 112, time: 0.096, data: 0.028) loss: 0.026 
(epoch: 57, iters: 192, time: 0.108, data: 0.000) loss: 0.099 
(epoch: 57, iters: 272, time: 0.107, data: 0.000) loss: 0.209 
(epoch: 57, iters: 352, time: 0.104, data: 0.049) loss: 0.041 
(epoch: 57, iters: 432, time: 0.102, data: 0.000) loss: 0.074 
(epoch: 57, iters: 512, time: 0.099, data: 0.012) loss: 0.347 
(epoch: 57, iters: 592, time: 0.102, data: 0.000) loss: 0.023 
(epoch: 57, iters: 672, time: 0.101, data: 0.012) loss: 0.009 
(epoch: 57, iters: 752, time: 0.094, data: 0.000) loss: 0.220 
(epoch: 57, iters: 832, time: 0.102, data: 0.000) loss: 0.037 
(epoch: 57, iters: 912, time: 0.100, data: 0.012) loss: 0.022 
(epoch: 57, iters: 992, time: 0.095, data: 0.000) loss: 0.021 
(epoch: 57, iters: 1072, time: 0.102, data: 0.000) loss: 0.020 
(epoch: 57, iters: 1152, time: 0.095, data: 0.040) loss: 0.012 
(epoch: 57, iters: 1232, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 57, iters: 1312, time: 0.105, data: 0.012) loss: 0.097 
(epoch: 57, iters: 1392, time: 0.113, data: 0.000) loss: 0.028 
(epoch: 57, iters: 1472, time: 0.112, data: 0.012) loss: 0.008 
(epoch: 57, iters: 1552, time: 0.109, data: 0.000) loss: 0.039 
(epoch: 57, iters: 1632, time: 0.094, data: 0.000) loss: 1.395 
(epoch: 57, iters: 1712, time: 0.103, data: 0.041) loss: 0.014 
(epoch: 57, iters: 1792, time: 0.116, data: 0.000) loss: 0.007 
(epoch: 57, iters: 1872, time: 0.093, data: 0.012) loss: 0.015 
(epoch: 57, iters: 1952, time: 0.102, data: 0.000) loss: 0.112 
(epoch: 57, iters: 2032, time: 0.100, data: 0.012) loss: 0.144 
(epoch: 57, iters: 2112, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 57, iters: 2192, time: 0.095, data: 0.000) loss: 0.057 
(epoch: 57, iters: 2272, time: 0.097, data: 0.041) loss: 0.022 
(epoch: 57, iters: 2352, time: 0.102, data: 0.000) loss: 0.007 
(epoch: 57, iters: 2432, time: 0.093, data: 0.012) loss: 0.007 
(epoch: 57, iters: 2512, time: 0.103, data: 0.000) loss: 0.075 
(epoch: 57, iters: 2592, time: 0.107, data: 0.012) loss: 0.532 
(epoch: 57, iters: 2672, time: 0.111, data: 0.000) loss: 0.016 
(epoch: 57, iters: 2752, time: 0.100, data: 0.000) loss: 0.197 
(epoch: 57, iters: 2832, time: 0.095, data: 0.039) loss: 0.286 
(epoch: 57, iters: 2912, time: 0.095, data: 0.000) loss: 0.026 
(epoch: 57, iters: 2992, time: 0.092, data: 0.011) loss: 0.012 
(epoch: 57, iters: 3072, time: 0.101, data: 0.000) loss: 0.164 
(epoch: 57, iters: 3152, time: 0.102, data: 0.011) loss: 0.030 
(epoch: 57, iters: 3232, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 57, iters: 3312, time: 0.100, data: 0.000) loss: 0.013 
(epoch: 57, iters: 3392, time: 0.095, data: 0.048) loss: 0.009 
(epoch: 57, iters: 3472, time: 0.101, data: 0.000) loss: 0.103 
(epoch: 57, iters: 3552, time: 0.093, data: 0.011) loss: 0.338 
(epoch: 57, iters: 3632, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 57, iters: 3712, time: 0.090, data: 0.012) loss: 0.063 
saving the model at the end of epoch 57, iters 212496
End of epoch 57 / 2100 	 Time Taken: 376 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 57, TEST ACC: [92.716 %]

saving the latest model (epoch 58, total_steps 212512)
(epoch: 58, iters: 64, time: 0.094, data: 0.004) loss: 0.006 
(epoch: 58, iters: 144, time: 0.094, data: 0.025) loss: 0.047 
(epoch: 58, iters: 224, time: 0.100, data: 0.000) loss: 0.003 
(epoch: 58, iters: 304, time: 0.100, data: 0.000) loss: 0.273 
(epoch: 58, iters: 384, time: 0.101, data: 0.040) loss: 0.086 
(epoch: 58, iters: 464, time: 0.096, data: 0.000) loss: 0.138 
(epoch: 58, iters: 544, time: 0.093, data: 0.012) loss: 0.088 
(epoch: 58, iters: 624, time: 0.096, data: 0.000) loss: 0.109 
(epoch: 58, iters: 704, time: 0.100, data: 0.011) loss: 0.010 
(epoch: 58, iters: 784, time: 0.095, data: 0.000) loss: 0.159 
(epoch: 58, iters: 864, time: 0.100, data: 0.000) loss: 0.007 
(epoch: 58, iters: 944, time: 0.100, data: 0.041) loss: 0.101 
(epoch: 58, iters: 1024, time: 0.102, data: 0.000) loss: 0.005 
(epoch: 58, iters: 1104, time: 0.094, data: 0.012) loss: 0.106 
(epoch: 58, iters: 1184, time: 0.103, data: 0.000) loss: 0.038 
(epoch: 58, iters: 1264, time: 0.113, data: 0.012) loss: 0.027 
(epoch: 58, iters: 1344, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 58, iters: 1424, time: 0.093, data: 0.000) loss: 0.052 
(epoch: 58, iters: 1504, time: 0.096, data: 0.048) loss: 0.045 
(epoch: 58, iters: 1584, time: 0.103, data: 0.000) loss: 0.011 
(epoch: 58, iters: 1664, time: 0.106, data: 0.012) loss: 0.041 
(epoch: 58, iters: 1744, time: 0.094, data: 0.000) loss: 0.174 
(epoch: 58, iters: 1824, time: 0.110, data: 0.012) loss: 0.018 
(epoch: 58, iters: 1904, time: 0.095, data: 0.000) loss: 0.084 
(epoch: 58, iters: 1984, time: 0.100, data: 0.000) loss: 0.363 
(epoch: 58, iters: 2064, time: 0.110, data: 0.039) loss: 0.009 
(epoch: 58, iters: 2144, time: 0.111, data: 0.000) loss: 0.060 
(epoch: 58, iters: 2224, time: 0.094, data: 0.011) loss: 0.044 
(epoch: 58, iters: 2304, time: 0.104, data: 0.000) loss: 0.038 
(epoch: 58, iters: 2384, time: 0.101, data: 0.012) loss: 0.151 
(epoch: 58, iters: 2464, time: 0.103, data: 0.000) loss: 0.108 
(epoch: 58, iters: 2544, time: 0.100, data: 0.000) loss: 0.011 
(epoch: 58, iters: 2624, time: 0.102, data: 0.040) loss: 0.012 
(epoch: 58, iters: 2704, time: 0.102, data: 0.000) loss: 0.016 
(epoch: 58, iters: 2784, time: 0.101, data: 0.012) loss: 0.061 
(epoch: 58, iters: 2864, time: 0.102, data: 0.000) loss: 0.010 
(epoch: 58, iters: 2944, time: 0.102, data: 0.012) loss: 0.004 
(epoch: 58, iters: 3024, time: 0.104, data: 0.000) loss: 0.021 
(epoch: 58, iters: 3104, time: 0.094, data: 0.000) loss: 0.033 
(epoch: 58, iters: 3184, time: 0.095, data: 0.048) loss: 0.063 
(epoch: 58, iters: 3264, time: 0.108, data: 0.000) loss: 0.039 
(epoch: 58, iters: 3344, time: 0.100, data: 0.011) loss: 0.039 
(epoch: 58, iters: 3424, time: 0.108, data: 0.000) loss: 0.006 
(epoch: 58, iters: 3504, time: 0.103, data: 0.012) loss: 0.030 
(epoch: 58, iters: 3584, time: 0.102, data: 0.000) loss: 0.020 
(epoch: 58, iters: 3664, time: 0.088, data: 0.000) loss: 0.021 
saving the model at the end of epoch 58, iters 216224
End of epoch 58 / 2100 	 Time Taken: 376 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 58, TEST ACC: [89.378 %]

(epoch: 59, iters: 16, time: 0.121, data: 0.012) loss: 0.043 
saving the latest model (epoch 59, total_steps 216240)
(epoch: 59, iters: 96, time: 0.102, data: 0.000) loss: 0.039 
(epoch: 59, iters: 176, time: 0.099, data: 0.012) loss: 0.025 
(epoch: 59, iters: 256, time: 0.095, data: 0.000) loss: 0.038 
(epoch: 59, iters: 336, time: 0.094, data: 0.011) loss: 0.022 
(epoch: 59, iters: 416, time: 0.102, data: 0.000) loss: 0.026 
(epoch: 59, iters: 496, time: 0.100, data: 0.000) loss: 0.006 
(epoch: 59, iters: 576, time: 0.107, data: 0.040) loss: 0.020 
(epoch: 59, iters: 656, time: 0.097, data: 0.000) loss: 0.058 
(epoch: 59, iters: 736, time: 0.099, data: 0.012) loss: 0.150 
(epoch: 59, iters: 816, time: 0.100, data: 0.000) loss: 0.050 
(epoch: 59, iters: 896, time: 0.093, data: 0.012) loss: 0.084 
(epoch: 59, iters: 976, time: 0.101, data: 0.000) loss: 0.026 
(epoch: 59, iters: 1056, time: 0.094, data: 0.000) loss: 0.041 
(epoch: 59, iters: 1136, time: 0.101, data: 0.048) loss: 0.041 
(epoch: 59, iters: 1216, time: 0.103, data: 0.000) loss: 0.020 
(epoch: 59, iters: 1296, time: 0.100, data: 0.012) loss: 0.002 
(epoch: 59, iters: 1376, time: 0.096, data: 0.000) loss: 0.047 
(epoch: 59, iters: 1456, time: 0.095, data: 0.011) loss: 0.019 
(epoch: 59, iters: 1536, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 59, iters: 1616, time: 0.100, data: 0.000) loss: 0.039 
(epoch: 59, iters: 1696, time: 0.101, data: 0.039) loss: 0.035 
(epoch: 59, iters: 1776, time: 0.101, data: 0.000) loss: 0.039 
(epoch: 59, iters: 1856, time: 0.106, data: 0.012) loss: 0.006 
(epoch: 59, iters: 1936, time: 0.101, data: 0.000) loss: 0.011 
(epoch: 59, iters: 2016, time: 0.094, data: 0.011) loss: 0.025 
(epoch: 59, iters: 2096, time: 0.109, data: 0.000) loss: 0.009 
(epoch: 59, iters: 2176, time: 0.101, data: 0.000) loss: 0.005 
(epoch: 59, iters: 2256, time: 0.103, data: 0.039) loss: 0.042 
(epoch: 59, iters: 2336, time: 0.104, data: 0.000) loss: 0.070 
(epoch: 59, iters: 2416, time: 0.106, data: 0.011) loss: 0.011 
(epoch: 59, iters: 2496, time: 0.101, data: 0.000) loss: 0.048 
(epoch: 59, iters: 2576, time: 0.100, data: 0.011) loss: 0.079 
(epoch: 59, iters: 2656, time: 0.096, data: 0.000) loss: 0.198 
(epoch: 59, iters: 2736, time: 0.107, data: 0.000) loss: 0.025 
(epoch: 59, iters: 2816, time: 0.101, data: 0.050) loss: 0.012 
(epoch: 59, iters: 2896, time: 0.104, data: 0.000) loss: 0.006 
(epoch: 59, iters: 2976, time: 0.100, data: 0.012) loss: 0.010 
(epoch: 59, iters: 3056, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 59, iters: 3136, time: 0.096, data: 0.012) loss: 0.039 
(epoch: 59, iters: 3216, time: 0.101, data: 0.000) loss: 0.007 
(epoch: 59, iters: 3296, time: 0.106, data: 0.000) loss: 0.022 
(epoch: 59, iters: 3376, time: 0.101, data: 0.041) loss: 0.082 
(epoch: 59, iters: 3456, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 59, iters: 3536, time: 0.101, data: 0.011) loss: 0.058 
(epoch: 59, iters: 3616, time: 0.094, data: 0.000) loss: 0.068 
(epoch: 59, iters: 3696, time: 0.088, data: 0.012) loss: 0.026 
saving the model at the end of epoch 59, iters 219952
End of epoch 59 / 2100 	 Time Taken: 372 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 59, TEST ACC: [92.413 %]

saving the latest model (epoch 60, total_steps 219968)
(epoch: 60, iters: 48, time: 0.101, data: 0.000) loss: 0.063 
(epoch: 60, iters: 128, time: 0.096, data: 0.042) loss: 0.076 
(epoch: 60, iters: 208, time: 0.096, data: 0.000) loss: 0.034 
(epoch: 60, iters: 288, time: 0.093, data: 0.011) loss: 0.039 
(epoch: 60, iters: 368, time: 0.108, data: 0.000) loss: 0.001 
(epoch: 60, iters: 448, time: 0.106, data: 0.011) loss: 0.111 
(epoch: 60, iters: 528, time: 0.108, data: 0.000) loss: 0.027 
(epoch: 60, iters: 608, time: 0.096, data: 0.000) loss: 0.025 
(epoch: 60, iters: 688, time: 0.095, data: 0.038) loss: 0.016 
(epoch: 60, iters: 768, time: 0.101, data: 0.000) loss: 0.394 
(epoch: 60, iters: 848, time: 0.103, data: 0.000) loss: 0.002 
(epoch: 60, iters: 928, time: 0.102, data: 0.011) loss: 0.158 
(epoch: 60, iters: 1008, time: 0.101, data: 0.027) loss: 0.007 
(epoch: 60, iters: 1088, time: 0.101, data: 0.000) loss: 0.028 
(epoch: 60, iters: 1168, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 60, iters: 1248, time: 0.101, data: 0.011) loss: 0.201 
(epoch: 60, iters: 1328, time: 0.100, data: 0.026) loss: 0.049 
(epoch: 60, iters: 1408, time: 0.097, data: 0.000) loss: 0.038 
(epoch: 60, iters: 1488, time: 0.103, data: 0.000) loss: 0.115 
(epoch: 60, iters: 1568, time: 0.102, data: 0.012) loss: 0.004 
(epoch: 60, iters: 1648, time: 0.094, data: 0.025) loss: 0.021 
(epoch: 60, iters: 1728, time: 0.093, data: 0.000) loss: 0.040 
(epoch: 60, iters: 1808, time: 0.096, data: 0.000) loss: 0.095 
(epoch: 60, iters: 1888, time: 0.095, data: 0.012) loss: 0.069 
(epoch: 60, iters: 1968, time: 0.094, data: 0.036) loss: 0.029 
(epoch: 60, iters: 2048, time: 0.102, data: 0.000) loss: 0.164 
(epoch: 60, iters: 2128, time: 0.096, data: 0.000) loss: 0.163 
(epoch: 60, iters: 2208, time: 0.101, data: 0.012) loss: 0.056 
(epoch: 60, iters: 2288, time: 0.093, data: 0.026) loss: 0.012 
(epoch: 60, iters: 2368, time: 0.094, data: 0.000) loss: 0.069 
(epoch: 60, iters: 2448, time: 0.102, data: 0.000) loss: 0.058 
(epoch: 60, iters: 2528, time: 0.094, data: 0.011) loss: 0.013 
(epoch: 60, iters: 2608, time: 0.094, data: 0.025) loss: 0.016 
(epoch: 60, iters: 2688, time: 0.101, data: 0.000) loss: 0.004 
(epoch: 60, iters: 2768, time: 0.102, data: 0.000) loss: 0.005 
(epoch: 60, iters: 2848, time: 0.095, data: 0.011) loss: 0.069 
(epoch: 60, iters: 2928, time: 0.094, data: 0.026) loss: 0.126 
(epoch: 60, iters: 3008, time: 0.101, data: 0.000) loss: 0.024 
(epoch: 60, iters: 3088, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 60, iters: 3168, time: 0.108, data: 0.012) loss: 0.396 
(epoch: 60, iters: 3248, time: 0.098, data: 0.027) loss: 0.091 
(epoch: 60, iters: 3328, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 60, iters: 3408, time: 0.102, data: 0.000) loss: 0.007 
(epoch: 60, iters: 3488, time: 0.094, data: 0.012) loss: 0.044 
(epoch: 60, iters: 3568, time: 0.096, data: 0.000) loss: 0.021 
(epoch: 60, iters: 3648, time: 0.088, data: 0.011) loss: 0.021 
(epoch: 60, iters: 3728, time: 0.056, data: 0.000) loss: 0.002 
saving the model at the end of epoch 60, iters 223680
End of epoch 60 / 2100 	 Time Taken: 375 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 60, TEST ACC: [93.02 %]

saving the latest model (epoch 61, total_steps 223696)
(epoch: 61, iters: 80, time: 0.100, data: 0.995) loss: 0.004 
(epoch: 61, iters: 160, time: 0.102, data: 0.000) loss: 0.230 
(epoch: 61, iters: 240, time: 0.097, data: 0.012) loss: 0.010 
(epoch: 61, iters: 320, time: 0.096, data: 0.000) loss: 0.020 
(epoch: 61, iters: 400, time: 0.094, data: 0.000) loss: 0.546 
(epoch: 61, iters: 480, time: 0.095, data: 0.040) loss: 0.006 
(epoch: 61, iters: 560, time: 0.101, data: 0.000) loss: 0.005 
(epoch: 61, iters: 640, time: 0.093, data: 0.011) loss: 0.048 
(epoch: 61, iters: 720, time: 0.101, data: 0.000) loss: 0.003 
(epoch: 61, iters: 800, time: 0.094, data: 0.012) loss: 0.027 
(epoch: 61, iters: 880, time: 0.103, data: 0.000) loss: 0.012 
(epoch: 61, iters: 960, time: 0.106, data: 0.000) loss: 0.054 
(epoch: 61, iters: 1040, time: 0.096, data: 0.040) loss: 0.116 
(epoch: 61, iters: 1120, time: 0.104, data: 0.000) loss: 0.197 
(epoch: 61, iters: 1200, time: 0.099, data: 0.011) loss: 0.010 
(epoch: 61, iters: 1280, time: 0.101, data: 0.000) loss: 0.012 
(epoch: 61, iters: 1360, time: 0.101, data: 0.011) loss: 0.047 
(epoch: 61, iters: 1440, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 61, iters: 1520, time: 0.101, data: 0.000) loss: 0.118 
(epoch: 61, iters: 1600, time: 0.094, data: 0.040) loss: 0.062 
(epoch: 61, iters: 1680, time: 0.101, data: 0.000) loss: 0.008 
(epoch: 61, iters: 1760, time: 0.096, data: 0.011) loss: 0.358 
(epoch: 61, iters: 1840, time: 0.101, data: 0.000) loss: 0.213 
(epoch: 61, iters: 1920, time: 0.100, data: 0.013) loss: 0.019 
(epoch: 61, iters: 2000, time: 0.101, data: 0.000) loss: 0.004 
(epoch: 61, iters: 2080, time: 0.094, data: 0.000) loss: 0.017 
(epoch: 61, iters: 2160, time: 0.095, data: 0.038) loss: 0.001 
(epoch: 61, iters: 2240, time: 0.102, data: 0.000) loss: 0.068 
(epoch: 61, iters: 2320, time: 0.099, data: 0.011) loss: 0.013 
(epoch: 61, iters: 2400, time: 0.095, data: 0.000) loss: 0.157 
(epoch: 61, iters: 2480, time: 0.106, data: 0.012) loss: 0.020 
(epoch: 61, iters: 2560, time: 0.101, data: 0.000) loss: 0.002 
(epoch: 61, iters: 2640, time: 0.100, data: 0.000) loss: 0.002 
(epoch: 61, iters: 2720, time: 0.095, data: 0.039) loss: 0.033 
(epoch: 61, iters: 2800, time: 0.101, data: 0.000) loss: 0.156 
(epoch: 61, iters: 2880, time: 0.092, data: 0.011) loss: 0.013 
(epoch: 61, iters: 2960, time: 0.095, data: 0.000) loss: 0.051 
(epoch: 61, iters: 3040, time: 0.095, data: 0.011) loss: 0.078 
(epoch: 61, iters: 3120, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 61, iters: 3200, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 61, iters: 3280, time: 0.103, data: 0.049) loss: 0.174 
(epoch: 61, iters: 3360, time: 0.107, data: 0.000) loss: 0.730 
(epoch: 61, iters: 3440, time: 0.106, data: 0.011) loss: 0.088 
(epoch: 61, iters: 3520, time: 0.100, data: 0.000) loss: 0.171 
(epoch: 61, iters: 3600, time: 0.094, data: 0.012) loss: 0.062 
(epoch: 61, iters: 3680, time: 0.087, data: 0.000) loss: 0.027 
saving the model at the end of epoch 61, iters 227408
End of epoch 61 / 2100 	 Time Taken: 372 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 61, TEST ACC: [69.651 %]

saving the latest model (epoch 62, total_steps 227424)
(epoch: 62, iters: 32, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 62, iters: 112, time: 0.100, data: 0.000) loss: 0.019 
(epoch: 62, iters: 192, time: 0.095, data: 0.000) loss: 0.378 
(epoch: 62, iters: 272, time: 0.100, data: 0.000) loss: 0.085 
(epoch: 62, iters: 352, time: 0.094, data: 0.039) loss: 0.014 
(epoch: 62, iters: 432, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 62, iters: 512, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 62, iters: 592, time: 0.101, data: 0.000) loss: 0.052 
(epoch: 62, iters: 672, time: 0.093, data: 0.012) loss: 0.019 
(epoch: 62, iters: 752, time: 0.097, data: 0.000) loss: 0.050 
(epoch: 62, iters: 832, time: 0.096, data: 0.000) loss: 0.017 
(epoch: 62, iters: 912, time: 0.095, data: 0.050) loss: 0.278 
(epoch: 62, iters: 992, time: 0.095, data: 0.000) loss: 0.206 
(epoch: 62, iters: 1072, time: 0.101, data: 0.012) loss: 0.050 
(epoch: 62, iters: 1152, time: 0.099, data: 0.026) loss: 0.055 
(epoch: 62, iters: 1232, time: 0.095, data: 0.000) loss: 0.132 
(epoch: 62, iters: 1312, time: 0.099, data: 0.012) loss: 0.004 
(epoch: 62, iters: 1392, time: 0.101, data: 0.000) loss: 0.168 
(epoch: 62, iters: 1472, time: 0.108, data: 0.013) loss: 0.101 
(epoch: 62, iters: 1552, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 62, iters: 1632, time: 0.100, data: 0.000) loss: 0.052 
(epoch: 62, iters: 1712, time: 0.095, data: 0.039) loss: 0.022 
(epoch: 62, iters: 1792, time: 0.101, data: 0.000) loss: 0.014 
(epoch: 62, iters: 1872, time: 0.100, data: 0.012) loss: 0.025 
(epoch: 62, iters: 1952, time: 0.095, data: 0.000) loss: 0.074 
(epoch: 62, iters: 2032, time: 0.093, data: 0.011) loss: 0.145 
(epoch: 62, iters: 2112, time: 0.095, data: 0.000) loss: 0.071 
(epoch: 62, iters: 2192, time: 0.093, data: 0.000) loss: 0.024 
(epoch: 62, iters: 2272, time: 0.103, data: 0.048) loss: 0.021 
(epoch: 62, iters: 2352, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 62, iters: 2432, time: 0.103, data: 0.012) loss: 0.024 
(epoch: 62, iters: 2512, time: 0.095, data: 0.000) loss: 0.095 
(epoch: 62, iters: 2592, time: 0.101, data: 0.012) loss: 0.025 
(epoch: 62, iters: 2672, time: 0.101, data: 0.000) loss: 0.012 
(epoch: 62, iters: 2752, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 62, iters: 2832, time: 0.094, data: 0.040) loss: 0.010 
(epoch: 62, iters: 2912, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 62, iters: 2992, time: 0.093, data: 0.011) loss: 0.129 
(epoch: 62, iters: 3072, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 62, iters: 3152, time: 0.094, data: 0.011) loss: 0.006 
(epoch: 62, iters: 3232, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 62, iters: 3312, time: 0.100, data: 0.000) loss: 0.014 
(epoch: 62, iters: 3392, time: 0.095, data: 0.039) loss: 0.002 
(epoch: 62, iters: 3472, time: 0.102, data: 0.000) loss: 0.012 
(epoch: 62, iters: 3552, time: 0.099, data: 0.012) loss: 0.155 
(epoch: 62, iters: 3632, time: 0.092, data: 0.000) loss: 0.036 
(epoch: 62, iters: 3712, time: 0.090, data: 0.012) loss: 0.023 
saving the model at the end of epoch 62, iters 231136
End of epoch 62 / 2100 	 Time Taken: 369 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 62, TEST ACC: [86.95 %]

saving the latest model (epoch 63, total_steps 231152)
(epoch: 63, iters: 64, time: 0.095, data: 0.003) loss: 0.069 
(epoch: 63, iters: 144, time: 0.113, data: 0.000) loss: 0.052 
(epoch: 63, iters: 224, time: 0.095, data: 0.022) loss: 0.170 
(epoch: 63, iters: 304, time: 0.102, data: 0.037) loss: 0.039 
(epoch: 63, iters: 384, time: 0.098, data: 0.000) loss: 0.005 
(epoch: 63, iters: 464, time: 0.099, data: 0.000) loss: 0.167 
(epoch: 63, iters: 544, time: 0.101, data: 0.012) loss: 0.020 
(epoch: 63, iters: 624, time: 0.093, data: 0.026) loss: 0.003 
(epoch: 63, iters: 704, time: 0.094, data: 0.000) loss: 0.157 
(epoch: 63, iters: 784, time: 0.102, data: 0.000) loss: 0.008 
(epoch: 63, iters: 864, time: 0.113, data: 0.013) loss: 0.055 
(epoch: 63, iters: 944, time: 0.105, data: 0.026) loss: 0.125 
(epoch: 63, iters: 1024, time: 0.103, data: 0.000) loss: 0.101 
(epoch: 63, iters: 1104, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 63, iters: 1184, time: 0.109, data: 0.011) loss: 0.004 
(epoch: 63, iters: 1264, time: 0.092, data: 0.025) loss: 0.007 
(epoch: 63, iters: 1344, time: 0.101, data: 0.000) loss: 0.213 
(epoch: 63, iters: 1424, time: 0.096, data: 0.000) loss: 0.014 
(epoch: 63, iters: 1504, time: 0.094, data: 0.011) loss: 0.178 
(epoch: 63, iters: 1584, time: 0.093, data: 0.026) loss: 0.007 
(epoch: 63, iters: 1664, time: 0.101, data: 0.000) loss: 0.007 
(epoch: 63, iters: 1744, time: 0.102, data: 0.000) loss: 0.015 
(epoch: 63, iters: 1824, time: 0.094, data: 0.011) loss: 0.025 
(epoch: 63, iters: 1904, time: 0.093, data: 0.026) loss: 0.088 
(epoch: 63, iters: 1984, time: 0.095, data: 0.000) loss: 0.020 
(epoch: 63, iters: 2064, time: 0.104, data: 0.000) loss: 0.244 
(epoch: 63, iters: 2144, time: 0.095, data: 0.012) loss: 0.121 
(epoch: 63, iters: 2224, time: 0.100, data: 0.034) loss: 0.066 
(epoch: 63, iters: 2304, time: 0.103, data: 0.000) loss: 0.007 
(epoch: 63, iters: 2384, time: 0.095, data: 0.000) loss: 1.043 
(epoch: 63, iters: 2464, time: 0.098, data: 0.013) loss: 0.236 
(epoch: 63, iters: 2544, time: 0.093, data: 0.026) loss: 0.131 
(epoch: 63, iters: 2624, time: 0.101, data: 0.000) loss: 0.206 
(epoch: 63, iters: 2704, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 63, iters: 2784, time: 0.095, data: 0.012) loss: 0.042 
(epoch: 63, iters: 2864, time: 0.094, data: 0.026) loss: 0.022 
(epoch: 63, iters: 2944, time: 0.106, data: 0.000) loss: 0.024 
(epoch: 63, iters: 3024, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 63, iters: 3104, time: 0.096, data: 0.000) loss: 0.015 
(epoch: 63, iters: 3184, time: 0.094, data: 0.000) loss: 0.293 
(epoch: 63, iters: 3264, time: 0.095, data: 0.039) loss: 0.021 
(epoch: 63, iters: 3344, time: 0.095, data: 0.000) loss: 0.124 
(epoch: 63, iters: 3424, time: 0.093, data: 0.012) loss: 0.259 
(epoch: 63, iters: 3504, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 63, iters: 3584, time: 0.101, data: 0.011) loss: 0.021 
(epoch: 63, iters: 3664, time: 0.090, data: 0.000) loss: 0.041 
saving the model at the end of epoch 63, iters 234864
End of epoch 63 / 2100 	 Time Taken: 369 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 63, TEST ACC: [86.95 %]

(epoch: 64, iters: 16, time: 0.112, data: 0.000) loss: 0.113 
saving the latest model (epoch 64, total_steps 234880)
(epoch: 64, iters: 96, time: 0.096, data: 0.000) loss: 0.052 
(epoch: 64, iters: 176, time: 0.099, data: 0.012) loss: 0.006 
(epoch: 64, iters: 256, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 64, iters: 336, time: 0.093, data: 0.011) loss: 0.125 
(epoch: 64, iters: 416, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 64, iters: 496, time: 0.102, data: 0.000) loss: 0.017 
(epoch: 64, iters: 576, time: 0.101, data: 0.040) loss: 0.004 
(epoch: 64, iters: 656, time: 0.102, data: 0.000) loss: 0.061 
(epoch: 64, iters: 736, time: 0.092, data: 0.012) loss: 0.037 
(epoch: 64, iters: 816, time: 0.107, data: 0.000) loss: 0.033 
(epoch: 64, iters: 896, time: 0.095, data: 0.011) loss: 0.009 
(epoch: 64, iters: 976, time: 0.098, data: 0.000) loss: 0.025 
(epoch: 64, iters: 1056, time: 0.096, data: 0.000) loss: 0.019 
(epoch: 64, iters: 1136, time: 0.097, data: 0.041) loss: 0.013 
(epoch: 64, iters: 1216, time: 0.104, data: 0.000) loss: 0.017 
(epoch: 64, iters: 1296, time: 0.102, data: 0.012) loss: 0.020 
(epoch: 64, iters: 1376, time: 0.102, data: 0.000) loss: 0.002 
(epoch: 64, iters: 1456, time: 0.095, data: 0.012) loss: 0.019 
(epoch: 64, iters: 1536, time: 0.095, data: 0.000) loss: 0.103 
(epoch: 64, iters: 1616, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 64, iters: 1696, time: 0.104, data: 0.040) loss: 0.057 
(epoch: 64, iters: 1776, time: 0.098, data: 0.000) loss: 0.068 
(epoch: 64, iters: 1856, time: 0.095, data: 0.013) loss: 0.030 
(epoch: 64, iters: 1936, time: 0.098, data: 0.000) loss: 0.171 
(epoch: 64, iters: 2016, time: 0.103, data: 0.012) loss: 0.034 
(epoch: 64, iters: 2096, time: 0.113, data: 0.000) loss: 0.006 
(epoch: 64, iters: 2176, time: 0.096, data: 0.000) loss: 0.052 
(epoch: 64, iters: 2256, time: 0.116, data: 0.042) loss: 0.006 
(epoch: 64, iters: 2336, time: 0.104, data: 0.000) loss: 0.007 
(epoch: 64, iters: 2416, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 64, iters: 2496, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 64, iters: 2576, time: 0.103, data: 0.012) loss: 0.006 
(epoch: 64, iters: 2656, time: 0.097, data: 0.000) loss: 0.273 
(epoch: 64, iters: 2736, time: 0.104, data: 0.000) loss: 0.088 
(epoch: 64, iters: 2816, time: 0.110, data: 0.041) loss: 0.019 
(epoch: 64, iters: 2896, time: 0.104, data: 0.000) loss: 0.014 
(epoch: 64, iters: 2976, time: 0.096, data: 0.022) loss: 0.002 
(epoch: 64, iters: 3056, time: 0.098, data: 0.000) loss: 0.095 
(epoch: 64, iters: 3136, time: 0.097, data: 0.013) loss: 0.005 
(epoch: 64, iters: 3216, time: 0.100, data: 0.000) loss: 0.030 
(epoch: 64, iters: 3296, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 64, iters: 3376, time: 0.108, data: 0.040) loss: 0.142 
(epoch: 64, iters: 3456, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 64, iters: 3536, time: 0.099, data: 0.011) loss: 0.006 
(epoch: 64, iters: 3616, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 64, iters: 3696, time: 0.088, data: 0.012) loss: 0.017 
saving the model at the end of epoch 64, iters 238592
End of epoch 64 / 2100 	 Time Taken: 373 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 64, TEST ACC: [95.144 %]

saving the latest model (epoch 65, total_steps 238608)
(epoch: 65, iters: 48, time: 0.102, data: 0.000) loss: 0.054 
(epoch: 65, iters: 128, time: 0.101, data: 0.000) loss: 0.006 
(epoch: 65, iters: 208, time: 0.101, data: 0.039) loss: 0.006 
(epoch: 65, iters: 288, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 65, iters: 368, time: 0.101, data: 0.012) loss: 0.061 
(epoch: 65, iters: 448, time: 0.101, data: 0.000) loss: 0.002 
(epoch: 65, iters: 528, time: 0.094, data: 0.012) loss: 0.163 
(epoch: 65, iters: 608, time: 0.102, data: 0.000) loss: 0.011 
(epoch: 65, iters: 688, time: 0.103, data: 0.000) loss: 0.027 
(epoch: 65, iters: 768, time: 0.097, data: 0.040) loss: 0.002 
(epoch: 65, iters: 848, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 65, iters: 928, time: 0.094, data: 0.012) loss: 0.006 
(epoch: 65, iters: 1008, time: 0.095, data: 0.000) loss: 0.118 
(epoch: 65, iters: 1088, time: 0.094, data: 0.012) loss: 0.024 
(epoch: 65, iters: 1168, time: 0.115, data: 0.000) loss: 0.013 
(epoch: 65, iters: 1248, time: 0.101, data: 0.000) loss: 0.010 
(epoch: 65, iters: 1328, time: 0.107, data: 0.040) loss: 0.051 
(epoch: 65, iters: 1408, time: 0.102, data: 0.000) loss: 0.144 
(epoch: 65, iters: 1488, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 65, iters: 1568, time: 0.095, data: 0.000) loss: 0.332 
(epoch: 65, iters: 1648, time: 0.094, data: 0.012) loss: 0.011 
(epoch: 65, iters: 1728, time: 0.103, data: 0.000) loss: 0.021 
(epoch: 65, iters: 1808, time: 0.095, data: 0.000) loss: 0.051 
(epoch: 65, iters: 1888, time: 0.096, data: 0.040) loss: 0.003 
(epoch: 65, iters: 1968, time: 0.104, data: 0.000) loss: 0.059 
(epoch: 65, iters: 2048, time: 0.095, data: 0.012) loss: 0.015 
(epoch: 65, iters: 2128, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 65, iters: 2208, time: 0.103, data: 0.012) loss: 0.065 
(epoch: 65, iters: 2288, time: 0.110, data: 0.000) loss: 0.006 
(epoch: 65, iters: 2368, time: 0.093, data: 0.000) loss: 0.020 
(epoch: 65, iters: 2448, time: 0.102, data: 0.039) loss: 0.006 
(epoch: 65, iters: 2528, time: 0.104, data: 0.000) loss: 0.019 
(epoch: 65, iters: 2608, time: 0.096, data: 0.011) loss: 0.012 
(epoch: 65, iters: 2688, time: 0.103, data: 0.000) loss: 0.023 
(epoch: 65, iters: 2768, time: 0.096, data: 0.021) loss: 0.331 
(epoch: 65, iters: 2848, time: 0.104, data: 0.000) loss: 0.199 
(epoch: 65, iters: 2928, time: 0.097, data: 0.000) loss: 0.392 
(epoch: 65, iters: 3008, time: 0.098, data: 0.040) loss: 0.009 
(epoch: 65, iters: 3088, time: 0.103, data: 0.000) loss: 0.002 
(epoch: 65, iters: 3168, time: 0.101, data: 0.012) loss: 0.006 
(epoch: 65, iters: 3248, time: 0.096, data: 0.000) loss: 0.040 
(epoch: 65, iters: 3328, time: 0.096, data: 0.012) loss: 0.005 
(epoch: 65, iters: 3408, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 65, iters: 3488, time: 0.094, data: 0.000) loss: 0.059 
(epoch: 65, iters: 3568, time: 0.097, data: 0.039) loss: 0.061 
(epoch: 65, iters: 3648, time: 0.092, data: 0.000) loss: 0.009 
(epoch: 65, iters: 3728, time: 0.058, data: 0.012) loss: 0.091 
saving the model at the end of epoch 65, iters 242320
End of epoch 65 / 2100 	 Time Taken: 373 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 65, TEST ACC: [89.681 %]

saving the latest model (epoch 66, total_steps 242336)
(epoch: 66, iters: 80, time: 0.098, data: 0.530) loss: 0.016 
(epoch: 66, iters: 160, time: 0.103, data: 0.000) loss: 0.059 
(epoch: 66, iters: 240, time: 0.104, data: 0.040) loss: 0.051 
(epoch: 66, iters: 320, time: 0.097, data: 0.000) loss: 0.013 
(epoch: 66, iters: 400, time: 0.101, data: 0.012) loss: 0.005 
(epoch: 66, iters: 480, time: 0.097, data: 0.000) loss: 0.282 
(epoch: 66, iters: 560, time: 0.097, data: 0.012) loss: 0.204 
(epoch: 66, iters: 640, time: 0.098, data: 0.000) loss: 0.037 
(epoch: 66, iters: 720, time: 0.103, data: 0.000) loss: 0.009 
(epoch: 66, iters: 800, time: 0.106, data: 0.050) loss: 0.282 
(epoch: 66, iters: 880, time: 0.098, data: 0.000) loss: 0.075 
(epoch: 66, iters: 960, time: 0.095, data: 0.012) loss: 0.074 
(epoch: 66, iters: 1040, time: 0.103, data: 0.000) loss: 0.012 
(epoch: 66, iters: 1120, time: 0.097, data: 0.011) loss: 0.005 
(epoch: 66, iters: 1200, time: 0.103, data: 0.000) loss: 0.072 
(epoch: 66, iters: 1280, time: 0.104, data: 0.000) loss: 0.041 
(epoch: 66, iters: 1360, time: 0.098, data: 0.041) loss: 0.017 
(epoch: 66, iters: 1440, time: 0.098, data: 0.000) loss: 0.017 
(epoch: 66, iters: 1520, time: 0.108, data: 0.012) loss: 0.070 
(epoch: 66, iters: 1600, time: 0.097, data: 0.000) loss: 0.016 
(epoch: 66, iters: 1680, time: 0.097, data: 0.012) loss: 0.041 
(epoch: 66, iters: 1760, time: 0.098, data: 0.000) loss: 0.041 
(epoch: 66, iters: 1840, time: 0.097, data: 0.000) loss: 0.054 
(epoch: 66, iters: 1920, time: 0.096, data: 0.041) loss: 0.023 
(epoch: 66, iters: 2000, time: 0.111, data: 0.000) loss: 0.015 
(epoch: 66, iters: 2080, time: 0.096, data: 0.012) loss: 0.033 
(epoch: 66, iters: 2160, time: 0.097, data: 0.000) loss: 0.006 
(epoch: 66, iters: 2240, time: 0.095, data: 0.012) loss: 0.005 
(epoch: 66, iters: 2320, time: 0.102, data: 0.000) loss: 0.014 
(epoch: 66, iters: 2400, time: 0.110, data: 0.000) loss: 0.005 
(epoch: 66, iters: 2480, time: 0.103, data: 0.012) loss: 0.011 
(epoch: 66, iters: 2560, time: 0.099, data: 0.000) loss: 0.007 
(epoch: 66, iters: 2640, time: 0.096, data: 0.000) loss: 0.046 
(epoch: 66, iters: 2720, time: 0.098, data: 0.048) loss: 0.016 
(epoch: 66, iters: 2800, time: 0.099, data: 0.000) loss: 0.001 
(epoch: 66, iters: 2880, time: 0.095, data: 0.013) loss: 0.014 
(epoch: 66, iters: 2960, time: 0.098, data: 0.000) loss: 0.053 
(epoch: 66, iters: 3040, time: 0.096, data: 0.013) loss: 0.052 
(epoch: 66, iters: 3120, time: 0.097, data: 0.000) loss: 0.033 
(epoch: 66, iters: 3200, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 66, iters: 3280, time: 0.097, data: 0.040) loss: 0.017 
(epoch: 66, iters: 3360, time: 0.103, data: 0.000) loss: 0.031 
(epoch: 66, iters: 3440, time: 0.095, data: 0.011) loss: 0.023 
(epoch: 66, iters: 3520, time: 0.103, data: 0.000) loss: 0.003 
(epoch: 66, iters: 3600, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 66, iters: 3680, time: 0.091, data: 0.000) loss: 0.092 
saving the model at the end of epoch 66, iters 246048
End of epoch 66 / 2100 	 Time Taken: 374 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 66, TEST ACC: [92.261 %]

saving the latest model (epoch 67, total_steps 246064)
(epoch: 67, iters: 32, time: 0.094, data: 0.000) loss: 0.139 
(epoch: 67, iters: 112, time: 0.099, data: 0.000) loss: 0.026 
(epoch: 67, iters: 192, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 67, iters: 272, time: 0.104, data: 0.042) loss: 0.094 
(epoch: 67, iters: 352, time: 0.098, data: 0.000) loss: 0.093 
(epoch: 67, iters: 432, time: 0.102, data: 0.012) loss: 0.062 
(epoch: 67, iters: 512, time: 0.103, data: 0.000) loss: 0.026 
(epoch: 67, iters: 592, time: 0.102, data: 0.011) loss: 0.060 
(epoch: 67, iters: 672, time: 0.103, data: 0.000) loss: 0.036 
(epoch: 67, iters: 752, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 67, iters: 832, time: 0.110, data: 0.040) loss: 0.327 
(epoch: 67, iters: 912, time: 0.097, data: 0.000) loss: 0.006 
(epoch: 67, iters: 992, time: 0.101, data: 0.012) loss: 0.169 
(epoch: 67, iters: 1072, time: 0.098, data: 0.000) loss: 0.171 
(epoch: 67, iters: 1152, time: 0.096, data: 0.011) loss: 0.043 
(epoch: 67, iters: 1232, time: 0.097, data: 0.000) loss: 0.030 
(epoch: 67, iters: 1312, time: 0.096, data: 0.000) loss: 0.032 
(epoch: 67, iters: 1392, time: 0.104, data: 0.050) loss: 0.038 
(epoch: 67, iters: 1472, time: 0.096, data: 0.000) loss: 0.062 
(epoch: 67, iters: 1552, time: 0.096, data: 0.011) loss: 0.019 
(epoch: 67, iters: 1632, time: 0.097, data: 0.000) loss: 0.261 
(epoch: 67, iters: 1712, time: 0.097, data: 0.012) loss: 0.010 
(epoch: 67, iters: 1792, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 67, iters: 1872, time: 0.096, data: 0.000) loss: 0.030 
(epoch: 67, iters: 1952, time: 0.097, data: 0.039) loss: 0.183 
(epoch: 67, iters: 2032, time: 0.104, data: 0.000) loss: 0.121 
(epoch: 67, iters: 2112, time: 0.108, data: 0.011) loss: 0.004 
(epoch: 67, iters: 2192, time: 0.097, data: 0.000) loss: 0.080 
(epoch: 67, iters: 2272, time: 0.097, data: 0.011) loss: 0.434 
(epoch: 67, iters: 2352, time: 0.111, data: 0.000) loss: 0.016 
(epoch: 67, iters: 2432, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 67, iters: 2512, time: 0.104, data: 0.041) loss: 0.100 
(epoch: 67, iters: 2592, time: 0.105, data: 0.000) loss: 0.001 
(epoch: 67, iters: 2672, time: 0.101, data: 0.012) loss: 0.515 
(epoch: 67, iters: 2752, time: 0.096, data: 0.000) loss: 0.108 
(epoch: 67, iters: 2832, time: 0.097, data: 0.012) loss: 0.007 
(epoch: 67, iters: 2912, time: 0.099, data: 0.000) loss: 0.062 
(epoch: 67, iters: 2992, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 67, iters: 3072, time: 0.109, data: 0.040) loss: 0.001 
(epoch: 67, iters: 3152, time: 0.098, data: 0.000) loss: 0.006 
(epoch: 67, iters: 3232, time: 0.108, data: 0.012) loss: 0.010 
(epoch: 67, iters: 3312, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 67, iters: 3392, time: 0.096, data: 0.012) loss: 0.004 
(epoch: 67, iters: 3472, time: 0.103, data: 0.000) loss: 0.008 
(epoch: 67, iters: 3552, time: 0.096, data: 0.000) loss: 0.021 
(epoch: 67, iters: 3632, time: 0.094, data: 0.039) loss: 0.005 
(epoch: 67, iters: 3712, time: 0.090, data: 0.000) loss: 0.024 
saving the model at the end of epoch 67, iters 249776
End of epoch 67 / 2100 	 Time Taken: 373 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 67, TEST ACC: [92.868 %]

saving the latest model (epoch 68, total_steps 249792)
(epoch: 68, iters: 64, time: 0.099, data: 0.000) loss: 0.025 
(epoch: 68, iters: 144, time: 0.094, data: 0.000) loss: 0.026 
(epoch: 68, iters: 224, time: 0.094, data: 0.012) loss: 0.082 
(epoch: 68, iters: 304, time: 0.095, data: 0.000) loss: 0.018 
(epoch: 68, iters: 384, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 68, iters: 464, time: 0.097, data: 0.039) loss: 0.074 
(epoch: 68, iters: 544, time: 0.103, data: 0.000) loss: 0.004 
(epoch: 68, iters: 624, time: 0.094, data: 0.012) loss: 0.081 
(epoch: 68, iters: 704, time: 0.095, data: 0.000) loss: 0.022 
(epoch: 68, iters: 784, time: 0.100, data: 0.012) loss: 0.019 
(epoch: 68, iters: 864, time: 0.102, data: 0.000) loss: 0.284 
(epoch: 68, iters: 944, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 68, iters: 1024, time: 0.101, data: 0.039) loss: 0.049 
(epoch: 68, iters: 1104, time: 0.104, data: 0.000) loss: 0.011 
(epoch: 68, iters: 1184, time: 0.094, data: 0.012) loss: 0.008 
(epoch: 68, iters: 1264, time: 0.114, data: 0.000) loss: 0.217 
(epoch: 68, iters: 1344, time: 0.096, data: 0.012) loss: 0.020 
(epoch: 68, iters: 1424, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 68, iters: 1504, time: 0.102, data: 0.000) loss: 0.117 
(epoch: 68, iters: 1584, time: 0.094, data: 0.041) loss: 0.128 
(epoch: 68, iters: 1664, time: 0.101, data: 0.000) loss: 0.096 
(epoch: 68, iters: 1744, time: 0.099, data: 0.012) loss: 0.126 
(epoch: 68, iters: 1824, time: 0.104, data: 0.000) loss: 0.021 
(epoch: 68, iters: 1904, time: 0.095, data: 0.012) loss: 0.036 
(epoch: 68, iters: 1984, time: 0.097, data: 0.000) loss: 0.258 
(epoch: 68, iters: 2064, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 68, iters: 2144, time: 0.096, data: 0.039) loss: 0.002 
(epoch: 68, iters: 2224, time: 0.111, data: 0.000) loss: 0.006 
(epoch: 68, iters: 2304, time: 0.093, data: 0.011) loss: 0.013 
(epoch: 68, iters: 2384, time: 0.095, data: 0.000) loss: 0.018 
(epoch: 68, iters: 2464, time: 0.100, data: 0.012) loss: 0.255 
(epoch: 68, iters: 2544, time: 0.096, data: 0.000) loss: 0.180 
(epoch: 68, iters: 2624, time: 0.094, data: 0.000) loss: 0.109 
(epoch: 68, iters: 2704, time: 0.108, data: 0.038) loss: 0.220 
(epoch: 68, iters: 2784, time: 0.096, data: 0.000) loss: 0.120 
(epoch: 68, iters: 2864, time: 0.092, data: 0.012) loss: 0.023 
(epoch: 68, iters: 2944, time: 0.095, data: 0.000) loss: 0.208 
(epoch: 68, iters: 3024, time: 0.101, data: 0.012) loss: 0.179 
(epoch: 68, iters: 3104, time: 0.103, data: 0.000) loss: 0.014 
(epoch: 68, iters: 3184, time: 0.114, data: 0.000) loss: 0.099 
(epoch: 68, iters: 3264, time: 0.104, data: 0.051) loss: 0.022 
(epoch: 68, iters: 3344, time: 0.102, data: 0.000) loss: 0.035 
(epoch: 68, iters: 3424, time: 0.093, data: 0.012) loss: 0.098 
(epoch: 68, iters: 3504, time: 0.096, data: 0.000) loss: 0.166 
(epoch: 68, iters: 3584, time: 0.094, data: 0.012) loss: 0.103 
(epoch: 68, iters: 3664, time: 0.091, data: 0.000) loss: 0.434 
saving the model at the end of epoch 68, iters 253504
End of epoch 68 / 2100 	 Time Taken: 369 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 68, TEST ACC: [89.833 %]

(epoch: 69, iters: 16, time: 0.123, data: 0.000) loss: 0.044 
saving the latest model (epoch 69, total_steps 253520)
(epoch: 69, iters: 96, time: 0.095, data: 0.000) loss: 0.302 
(epoch: 69, iters: 176, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 69, iters: 256, time: 0.095, data: 0.040) loss: 0.006 
(epoch: 69, iters: 336, time: 0.095, data: 0.000) loss: 0.032 
(epoch: 69, iters: 416, time: 0.094, data: 0.012) loss: 0.008 
(epoch: 69, iters: 496, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 69, iters: 576, time: 0.095, data: 0.011) loss: 0.036 
(epoch: 69, iters: 656, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 69, iters: 736, time: 0.103, data: 0.000) loss: 0.303 
(epoch: 69, iters: 816, time: 0.104, data: 0.048) loss: 0.011 
(epoch: 69, iters: 896, time: 0.095, data: 0.000) loss: 0.089 
(epoch: 69, iters: 976, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 69, iters: 1056, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 69, iters: 1136, time: 0.100, data: 0.011) loss: 0.362 
(epoch: 69, iters: 1216, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 69, iters: 1296, time: 0.094, data: 0.000) loss: 0.041 
(epoch: 69, iters: 1376, time: 0.094, data: 0.039) loss: 0.130 
(epoch: 69, iters: 1456, time: 0.102, data: 0.000) loss: 0.002 
(epoch: 69, iters: 1536, time: 0.100, data: 0.011) loss: 0.111 
(epoch: 69, iters: 1616, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 69, iters: 1696, time: 0.094, data: 0.011) loss: 0.170 
(epoch: 69, iters: 1776, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 69, iters: 1856, time: 0.101, data: 0.000) loss: 0.033 
(epoch: 69, iters: 1936, time: 0.094, data: 0.040) loss: 0.020 
(epoch: 69, iters: 2016, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 69, iters: 2096, time: 0.093, data: 0.011) loss: 0.092 
(epoch: 69, iters: 2176, time: 0.102, data: 0.000) loss: 0.003 
(epoch: 69, iters: 2256, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 69, iters: 2336, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 69, iters: 2416, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 69, iters: 2496, time: 0.100, data: 0.039) loss: 0.008 
(epoch: 69, iters: 2576, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 69, iters: 2656, time: 0.094, data: 0.012) loss: 0.177 
(epoch: 69, iters: 2736, time: 0.115, data: 0.000) loss: 0.013 
(epoch: 69, iters: 2816, time: 0.096, data: 0.021) loss: 0.001 
(epoch: 69, iters: 2896, time: 0.102, data: 0.000) loss: 0.004 
(epoch: 69, iters: 2976, time: 0.106, data: 0.000) loss: 0.021 
(epoch: 69, iters: 3056, time: 0.101, data: 0.039) loss: 0.102 
(epoch: 69, iters: 3136, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 69, iters: 3216, time: 0.094, data: 0.012) loss: 0.025 
(epoch: 69, iters: 3296, time: 0.095, data: 0.025) loss: 0.010 
(epoch: 69, iters: 3376, time: 0.110, data: 0.000) loss: 0.004 
(epoch: 69, iters: 3456, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 69, iters: 3536, time: 0.103, data: 0.012) loss: 0.002 
(epoch: 69, iters: 3616, time: 0.093, data: 0.025) loss: 0.017 
(epoch: 69, iters: 3696, time: 0.089, data: 0.000) loss: 0.114 
saving the model at the end of epoch 69, iters 257232
End of epoch 69 / 2100 	 Time Taken: 366 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 69, TEST ACC: [61.305 %]

saving the latest model (epoch 70, total_steps 257248)
(epoch: 70, iters: 48, time: 0.096, data: 0.000) loss: 0.027 
(epoch: 70, iters: 128, time: 0.104, data: 0.026) loss: 0.027 
(epoch: 70, iters: 208, time: 0.094, data: 0.012) loss: 0.101 
(epoch: 70, iters: 288, time: 0.100, data: 0.026) loss: 0.009 
(epoch: 70, iters: 368, time: 0.096, data: 0.000) loss: 0.023 
(epoch: 70, iters: 448, time: 0.098, data: 0.000) loss: 0.036 
(epoch: 70, iters: 528, time: 0.096, data: 0.012) loss: 0.097 
(epoch: 70, iters: 608, time: 0.095, data: 0.035) loss: 0.006 
(epoch: 70, iters: 688, time: 0.098, data: 0.000) loss: 0.003 
(epoch: 70, iters: 768, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 70, iters: 848, time: 0.095, data: 0.012) loss: 0.009 
(epoch: 70, iters: 928, time: 0.100, data: 0.027) loss: 0.073 
(epoch: 70, iters: 1008, time: 0.095, data: 0.000) loss: 0.156 
(epoch: 70, iters: 1088, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 70, iters: 1168, time: 0.108, data: 0.012) loss: 0.036 
(epoch: 70, iters: 1248, time: 0.095, data: 0.025) loss: 0.009 
(epoch: 70, iters: 1328, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 70, iters: 1408, time: 0.097, data: 0.000) loss: 0.008 
(epoch: 70, iters: 1488, time: 0.108, data: 0.011) loss: 0.020 
(epoch: 70, iters: 1568, time: 0.101, data: 0.026) loss: 0.003 
(epoch: 70, iters: 1648, time: 0.117, data: 0.000) loss: 0.003 
(epoch: 70, iters: 1728, time: 0.101, data: 0.000) loss: 0.075 
(epoch: 70, iters: 1808, time: 0.100, data: 0.012) loss: 0.007 
(epoch: 70, iters: 1888, time: 0.096, data: 0.025) loss: 0.003 
(epoch: 70, iters: 1968, time: 0.110, data: 0.000) loss: 0.008 
(epoch: 70, iters: 2048, time: 0.098, data: 0.000) loss: 0.006 
(epoch: 70, iters: 2128, time: 0.108, data: 0.012) loss: 0.016 
(epoch: 70, iters: 2208, time: 0.094, data: 0.025) loss: 0.032 
(epoch: 70, iters: 2288, time: 0.096, data: 0.000) loss: 0.017 
(epoch: 70, iters: 2368, time: 0.095, data: 0.000) loss: 0.497 
(epoch: 70, iters: 2448, time: 0.094, data: 0.011) loss: 0.052 
(epoch: 70, iters: 2528, time: 0.093, data: 0.027) loss: 0.012 
(epoch: 70, iters: 2608, time: 0.097, data: 0.000) loss: 0.008 
(epoch: 70, iters: 2688, time: 0.095, data: 0.000) loss: 0.033 
(epoch: 70, iters: 2768, time: 0.094, data: 0.011) loss: 0.006 
(epoch: 70, iters: 2848, time: 0.100, data: 0.027) loss: 0.000 
(epoch: 70, iters: 2928, time: 0.101, data: 0.000) loss: 0.027 
(epoch: 70, iters: 3008, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 70, iters: 3088, time: 0.097, data: 0.012) loss: 0.021 
(epoch: 70, iters: 3168, time: 0.108, data: 0.026) loss: 0.062 
(epoch: 70, iters: 3248, time: 0.094, data: 0.000) loss: 0.026 
(epoch: 70, iters: 3328, time: 0.109, data: 0.000) loss: 0.005 
(epoch: 70, iters: 3408, time: 0.095, data: 0.012) loss: 0.025 
(epoch: 70, iters: 3488, time: 0.096, data: 0.035) loss: 0.007 
(epoch: 70, iters: 3568, time: 0.096, data: 0.000) loss: 0.033 
(epoch: 70, iters: 3648, time: 0.089, data: 0.000) loss: 0.015 
(epoch: 70, iters: 3728, time: 0.056, data: 0.011) loss: 0.016 
saving the model at the end of epoch 70, iters 260960
End of epoch 70 / 2100 	 Time Taken: 368 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 70, TEST ACC: [94.537 %]

saving the latest model (epoch 71, total_steps 260976)
(epoch: 71, iters: 80, time: 0.095, data: 0.848) loss: 0.003 
(epoch: 71, iters: 160, time: 0.095, data: 0.000) loss: 0.119 
(epoch: 71, iters: 240, time: 0.096, data: 0.040) loss: 0.017 
(epoch: 71, iters: 320, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 71, iters: 400, time: 0.094, data: 0.011) loss: 0.064 
(epoch: 71, iters: 480, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 71, iters: 560, time: 0.094, data: 0.012) loss: 0.059 
(epoch: 71, iters: 640, time: 0.098, data: 0.000) loss: 0.054 
(epoch: 71, iters: 720, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 71, iters: 800, time: 0.096, data: 0.036) loss: 0.001 
(epoch: 71, iters: 880, time: 0.097, data: 0.000) loss: 0.018 
(epoch: 71, iters: 960, time: 0.104, data: 0.000) loss: 0.027 
(epoch: 71, iters: 1040, time: 0.103, data: 0.012) loss: 0.025 
(epoch: 71, iters: 1120, time: 0.092, data: 0.026) loss: 0.053 
(epoch: 71, iters: 1200, time: 0.096, data: 0.000) loss: 0.040 
(epoch: 71, iters: 1280, time: 0.095, data: 0.000) loss: 0.065 
(epoch: 71, iters: 1360, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 71, iters: 1440, time: 0.099, data: 0.025) loss: 0.008 
(epoch: 71, iters: 1520, time: 0.109, data: 0.000) loss: 0.001 
(epoch: 71, iters: 1600, time: 0.094, data: 0.000) loss: 0.051 
(epoch: 71, iters: 1680, time: 0.101, data: 0.000) loss: 0.039 
(epoch: 71, iters: 1760, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 71, iters: 1840, time: 0.094, data: 0.051) loss: 0.020 
(epoch: 71, iters: 1920, time: 0.097, data: 0.000) loss: 0.011 
(epoch: 71, iters: 2000, time: 0.093, data: 0.011) loss: 0.008 
(epoch: 71, iters: 2080, time: 0.095, data: 0.000) loss: 0.025 
(epoch: 71, iters: 2160, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 71, iters: 2240, time: 0.102, data: 0.000) loss: 0.001 
(epoch: 71, iters: 2320, time: 0.101, data: 0.000) loss: 0.008 
(epoch: 71, iters: 2400, time: 0.107, data: 0.039) loss: 0.010 
(epoch: 71, iters: 2480, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 71, iters: 2560, time: 0.093, data: 0.011) loss: 0.008 
(epoch: 71, iters: 2640, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 71, iters: 2720, time: 0.095, data: 0.011) loss: 0.011 
(epoch: 71, iters: 2800, time: 0.103, data: 0.000) loss: 0.032 
(epoch: 71, iters: 2880, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 71, iters: 2960, time: 0.095, data: 0.049) loss: 0.034 
(epoch: 71, iters: 3040, time: 0.095, data: 0.000) loss: 0.061 
(epoch: 71, iters: 3120, time: 0.100, data: 0.012) loss: 0.005 
(epoch: 71, iters: 3200, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 71, iters: 3280, time: 0.094, data: 0.011) loss: 0.009 
(epoch: 71, iters: 3360, time: 0.096, data: 0.000) loss: 0.068 
(epoch: 71, iters: 3440, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 71, iters: 3520, time: 0.096, data: 0.039) loss: 0.012 
(epoch: 71, iters: 3600, time: 0.108, data: 0.000) loss: 0.026 
(epoch: 71, iters: 3680, time: 0.088, data: 0.011) loss: 0.002 
saving the model at the end of epoch 71, iters 264688
End of epoch 71 / 2100 	 Time Taken: 366 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 71, TEST ACC: [89.833 %]

saving the latest model (epoch 72, total_steps 264704)
(epoch: 72, iters: 32, time: 0.096, data: 0.006) loss: 0.041 
(epoch: 72, iters: 112, time: 0.098, data: 0.043) loss: 0.010 
(epoch: 72, iters: 192, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 72, iters: 272, time: 0.104, data: 0.000) loss: 0.008 
(epoch: 72, iters: 352, time: 0.097, data: 0.040) loss: 0.222 
(epoch: 72, iters: 432, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 72, iters: 512, time: 0.094, data: 0.013) loss: 0.036 
(epoch: 72, iters: 592, time: 0.103, data: 0.000) loss: 0.013 
(epoch: 72, iters: 672, time: 0.101, data: 0.011) loss: 0.108 
(epoch: 72, iters: 752, time: 0.097, data: 0.000) loss: 0.121 
(epoch: 72, iters: 832, time: 0.097, data: 0.000) loss: 0.036 
(epoch: 72, iters: 912, time: 0.097, data: 0.041) loss: 0.016 
(epoch: 72, iters: 992, time: 0.098, data: 0.000) loss: 0.003 
(epoch: 72, iters: 1072, time: 0.095, data: 0.012) loss: 0.022 
(epoch: 72, iters: 1152, time: 0.098, data: 0.000) loss: 0.021 
(epoch: 72, iters: 1232, time: 0.096, data: 0.011) loss: 0.303 
(epoch: 72, iters: 1312, time: 0.105, data: 0.000) loss: 0.002 
(epoch: 72, iters: 1392, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 72, iters: 1472, time: 0.097, data: 0.041) loss: 0.159 
(epoch: 72, iters: 1552, time: 0.111, data: 0.000) loss: 0.003 
(epoch: 72, iters: 1632, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 72, iters: 1712, time: 0.097, data: 0.000) loss: 0.088 
(epoch: 72, iters: 1792, time: 0.097, data: 0.011) loss: 0.001 
(epoch: 72, iters: 1872, time: 0.097, data: 0.000) loss: 0.014 
(epoch: 72, iters: 1952, time: 0.103, data: 0.000) loss: 0.023 
(epoch: 72, iters: 2032, time: 0.096, data: 0.040) loss: 0.002 
(epoch: 72, iters: 2112, time: 0.097, data: 0.000) loss: 0.207 
(epoch: 72, iters: 2192, time: 0.094, data: 0.011) loss: 0.009 
(epoch: 72, iters: 2272, time: 0.095, data: 0.000) loss: 0.197 
(epoch: 72, iters: 2352, time: 0.094, data: 0.013) loss: 0.002 
(epoch: 72, iters: 2432, time: 0.102, data: 0.000) loss: 0.001 
(epoch: 72, iters: 2512, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 72, iters: 2592, time: 0.101, data: 0.039) loss: 0.001 
(epoch: 72, iters: 2672, time: 0.108, data: 0.000) loss: 0.002 
(epoch: 72, iters: 2752, time: 0.093, data: 0.012) loss: 0.030 
(epoch: 72, iters: 2832, time: 0.095, data: 0.000) loss: 0.152 
(epoch: 72, iters: 2912, time: 0.094, data: 0.012) loss: 0.014 
(epoch: 72, iters: 2992, time: 0.096, data: 0.000) loss: 0.156 
(epoch: 72, iters: 3072, time: 0.096, data: 0.000) loss: 0.027 
(epoch: 72, iters: 3152, time: 0.101, data: 0.039) loss: 0.003 
(epoch: 72, iters: 3232, time: 0.116, data: 0.000) loss: 0.006 
(epoch: 72, iters: 3312, time: 0.100, data: 0.011) loss: 0.088 
(epoch: 72, iters: 3392, time: 0.103, data: 0.000) loss: 0.055 
(epoch: 72, iters: 3472, time: 0.101, data: 0.011) loss: 0.055 
(epoch: 72, iters: 3552, time: 0.095, data: 0.000) loss: 0.155 
(epoch: 72, iters: 3632, time: 0.092, data: 0.000) loss: 0.174 
(epoch: 72, iters: 3712, time: 0.089, data: 0.036) loss: 0.199 
saving the model at the end of epoch 72, iters 268416
End of epoch 72 / 2100 	 Time Taken: 372 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 72, TEST ACC: [91.199 %]

saving the latest model (epoch 73, total_steps 268432)
(epoch: 73, iters: 64, time: 0.094, data: 0.000) loss: 0.034 
(epoch: 73, iters: 144, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 73, iters: 224, time: 0.108, data: 0.011) loss: 0.004 
(epoch: 73, iters: 304, time: 0.108, data: 0.000) loss: 0.019 
(epoch: 73, iters: 384, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 73, iters: 464, time: 0.095, data: 0.041) loss: 0.174 
(epoch: 73, iters: 544, time: 0.102, data: 0.000) loss: 0.006 
(epoch: 73, iters: 624, time: 0.094, data: 0.012) loss: 0.016 
(epoch: 73, iters: 704, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 73, iters: 784, time: 0.095, data: 0.011) loss: 0.036 
(epoch: 73, iters: 864, time: 0.102, data: 0.000) loss: 0.009 
(epoch: 73, iters: 944, time: 0.101, data: 0.000) loss: 0.003 
(epoch: 73, iters: 1024, time: 0.096, data: 0.039) loss: 0.014 
(epoch: 73, iters: 1104, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 73, iters: 1184, time: 0.094, data: 0.012) loss: 0.214 
(epoch: 73, iters: 1264, time: 0.096, data: 0.000) loss: 0.044 
(epoch: 73, iters: 1344, time: 0.095, data: 0.011) loss: 0.014 
(epoch: 73, iters: 1424, time: 0.106, data: 0.000) loss: 0.075 
(epoch: 73, iters: 1504, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 73, iters: 1584, time: 0.096, data: 0.039) loss: 0.011 
(epoch: 73, iters: 1664, time: 0.096, data: 0.000) loss: 0.021 
(epoch: 73, iters: 1744, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 73, iters: 1824, time: 0.103, data: 0.000) loss: 0.023 
(epoch: 73, iters: 1904, time: 0.102, data: 0.011) loss: 0.019 
(epoch: 73, iters: 1984, time: 0.097, data: 0.000) loss: 0.033 
(epoch: 73, iters: 2064, time: 0.102, data: 0.000) loss: 0.003 
(epoch: 73, iters: 2144, time: 0.105, data: 0.040) loss: 0.015 
(epoch: 73, iters: 2224, time: 0.102, data: 0.000) loss: 0.252 
(epoch: 73, iters: 2304, time: 0.100, data: 0.011) loss: 0.015 
(epoch: 73, iters: 2384, time: 0.097, data: 0.000) loss: 0.020 
(epoch: 73, iters: 2464, time: 0.102, data: 0.011) loss: 0.002 
(epoch: 73, iters: 2544, time: 0.099, data: 0.000) loss: 0.001 
(epoch: 73, iters: 2624, time: 0.101, data: 0.000) loss: 0.030 
(epoch: 73, iters: 2704, time: 0.096, data: 0.050) loss: 0.067 
(epoch: 73, iters: 2784, time: 0.096, data: 0.000) loss: 0.207 
(epoch: 73, iters: 2864, time: 0.100, data: 0.012) loss: 0.245 
(epoch: 73, iters: 2944, time: 0.095, data: 0.000) loss: 0.556 
(epoch: 73, iters: 3024, time: 0.095, data: 0.011) loss: 0.008 
(epoch: 73, iters: 3104, time: 0.108, data: 0.000) loss: 0.330 
(epoch: 73, iters: 3184, time: 0.094, data: 0.000) loss: 0.146 
(epoch: 73, iters: 3264, time: 0.097, data: 0.038) loss: 0.007 
(epoch: 73, iters: 3344, time: 0.097, data: 0.000) loss: 0.008 
(epoch: 73, iters: 3424, time: 0.093, data: 0.011) loss: 0.089 
(epoch: 73, iters: 3504, time: 0.097, data: 0.000) loss: 0.010 
(epoch: 73, iters: 3584, time: 0.104, data: 0.012) loss: 0.007 
(epoch: 73, iters: 3664, time: 0.091, data: 0.000) loss: 0.017 
saving the model at the end of epoch 73, iters 272144
End of epoch 73 / 2100 	 Time Taken: 368 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 73, TEST ACC: [91.654 %]

(epoch: 74, iters: 16, time: 0.111, data: 0.000) loss: 0.012 
saving the latest model (epoch 74, total_steps 272160)
(epoch: 74, iters: 96, time: 0.103, data: 0.000) loss: 0.006 
(epoch: 74, iters: 176, time: 0.107, data: 0.000) loss: 0.110 
(epoch: 74, iters: 256, time: 0.096, data: 0.049) loss: 0.131 
(epoch: 74, iters: 336, time: 0.098, data: 0.000) loss: 0.029 
(epoch: 74, iters: 416, time: 0.102, data: 0.012) loss: 0.026 
(epoch: 74, iters: 496, time: 0.101, data: 0.000) loss: 0.326 
(epoch: 74, iters: 576, time: 0.095, data: 0.011) loss: 0.021 
(epoch: 74, iters: 656, time: 0.102, data: 0.000) loss: 0.002 
(epoch: 74, iters: 736, time: 0.101, data: 0.000) loss: 0.004 
(epoch: 74, iters: 816, time: 0.103, data: 0.039) loss: 0.060 
(epoch: 74, iters: 896, time: 0.102, data: 0.000) loss: 0.010 
(epoch: 74, iters: 976, time: 0.100, data: 0.011) loss: 0.041 
(epoch: 74, iters: 1056, time: 0.108, data: 0.000) loss: 0.015 
(epoch: 74, iters: 1136, time: 0.100, data: 0.011) loss: 0.007 
(epoch: 74, iters: 1216, time: 0.103, data: 0.000) loss: 0.013 
(epoch: 74, iters: 1296, time: 0.094, data: 0.000) loss: 0.023 
(epoch: 74, iters: 1376, time: 0.095, data: 0.041) loss: 0.016 
(epoch: 74, iters: 1456, time: 0.095, data: 0.000) loss: 0.156 
(epoch: 74, iters: 1536, time: 0.103, data: 0.012) loss: 0.091 
(epoch: 74, iters: 1616, time: 0.095, data: 0.000) loss: 0.096 
(epoch: 74, iters: 1696, time: 0.095, data: 0.020) loss: 0.013 
(epoch: 74, iters: 1776, time: 0.095, data: 0.000) loss: 0.063 
(epoch: 74, iters: 1856, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 74, iters: 1936, time: 0.101, data: 0.042) loss: 0.057 
(epoch: 74, iters: 2016, time: 0.095, data: 0.000) loss: 0.094 
(epoch: 74, iters: 2096, time: 0.100, data: 0.012) loss: 0.003 
(epoch: 74, iters: 2176, time: 0.096, data: 0.000) loss: 0.050 
(epoch: 74, iters: 2256, time: 0.095, data: 0.011) loss: 0.027 
(epoch: 74, iters: 2336, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 74, iters: 2416, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 74, iters: 2496, time: 0.096, data: 0.041) loss: 0.002 
(epoch: 74, iters: 2576, time: 0.097, data: 0.000) loss: 0.013 
(epoch: 74, iters: 2656, time: 0.094, data: 0.012) loss: 0.012 
(epoch: 74, iters: 2736, time: 0.095, data: 0.000) loss: 0.055 
(epoch: 74, iters: 2816, time: 0.095, data: 0.011) loss: 0.008 
(epoch: 74, iters: 2896, time: 0.096, data: 0.000) loss: 0.025 
(epoch: 74, iters: 2976, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 74, iters: 3056, time: 0.108, data: 0.041) loss: 0.047 
(epoch: 74, iters: 3136, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 74, iters: 3216, time: 0.094, data: 0.011) loss: 0.357 
(epoch: 74, iters: 3296, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 74, iters: 3376, time: 0.107, data: 0.012) loss: 0.021 
(epoch: 74, iters: 3456, time: 0.096, data: 0.000) loss: 0.055 
(epoch: 74, iters: 3536, time: 0.101, data: 0.000) loss: 0.015 
(epoch: 74, iters: 3616, time: 0.102, data: 0.040) loss: 0.015 
(epoch: 74, iters: 3696, time: 0.089, data: 0.000) loss: 0.003 
saving the model at the end of epoch 74, iters 275872
End of epoch 74 / 2100 	 Time Taken: 366 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 74, TEST ACC: [98.179 %]

saving the latest model (epoch 75, total_steps 275888)
(epoch: 75, iters: 48, time: 0.097, data: 0.000) loss: 0.055 
(epoch: 75, iters: 128, time: 0.099, data: 0.041) loss: 0.446 
(epoch: 75, iters: 208, time: 0.099, data: 0.012) loss: 0.019 
(epoch: 75, iters: 288, time: 0.095, data: 0.000) loss: 0.094 
(epoch: 75, iters: 368, time: 0.095, data: 0.011) loss: 0.017 
(epoch: 75, iters: 448, time: 0.103, data: 0.000) loss: 0.006 
(epoch: 75, iters: 528, time: 0.095, data: 0.000) loss: 0.058 
(epoch: 75, iters: 608, time: 0.096, data: 0.039) loss: 0.075 
(epoch: 75, iters: 688, time: 0.098, data: 0.000) loss: 0.005 
(epoch: 75, iters: 768, time: 0.092, data: 0.011) loss: 0.038 
(epoch: 75, iters: 848, time: 0.095, data: 0.000) loss: 0.067 
(epoch: 75, iters: 928, time: 0.094, data: 0.011) loss: 0.289 
(epoch: 75, iters: 1008, time: 0.098, data: 0.000) loss: 0.007 
(epoch: 75, iters: 1088, time: 0.096, data: 0.000) loss: 0.023 
(epoch: 75, iters: 1168, time: 0.096, data: 0.050) loss: 0.017 
(epoch: 75, iters: 1248, time: 0.112, data: 0.000) loss: 0.193 
(epoch: 75, iters: 1328, time: 0.095, data: 0.012) loss: 0.007 
(epoch: 75, iters: 1408, time: 0.104, data: 0.000) loss: 0.003 
(epoch: 75, iters: 1488, time: 0.095, data: 0.011) loss: 0.143 
(epoch: 75, iters: 1568, time: 0.104, data: 0.000) loss: 0.005 
(epoch: 75, iters: 1648, time: 0.102, data: 0.000) loss: 0.056 
(epoch: 75, iters: 1728, time: 0.098, data: 0.040) loss: 0.056 
(epoch: 75, iters: 1808, time: 0.105, data: 0.000) loss: 0.010 
(epoch: 75, iters: 1888, time: 0.095, data: 0.012) loss: 0.042 
(epoch: 75, iters: 1968, time: 0.099, data: 0.000) loss: 0.231 
(epoch: 75, iters: 2048, time: 0.096, data: 0.012) loss: 0.022 
(epoch: 75, iters: 2128, time: 0.111, data: 0.000) loss: 0.117 
(epoch: 75, iters: 2208, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 75, iters: 2288, time: 0.097, data: 0.041) loss: 0.263 
(epoch: 75, iters: 2368, time: 0.106, data: 0.000) loss: 0.028 
(epoch: 75, iters: 2448, time: 0.102, data: 0.012) loss: 0.143 
(epoch: 75, iters: 2528, time: 0.105, data: 0.000) loss: 0.172 
(epoch: 75, iters: 2608, time: 0.104, data: 0.012) loss: 0.005 
(epoch: 75, iters: 2688, time: 0.098, data: 0.000) loss: 0.005 
(epoch: 75, iters: 2768, time: 0.096, data: 0.000) loss: 0.280 
(epoch: 75, iters: 2848, time: 0.097, data: 0.040) loss: 0.072 
(epoch: 75, iters: 2928, time: 0.103, data: 0.000) loss: 0.400 
(epoch: 75, iters: 3008, time: 0.096, data: 0.012) loss: 0.010 
(epoch: 75, iters: 3088, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 75, iters: 3168, time: 0.094, data: 0.012) loss: 0.011 
(epoch: 75, iters: 3248, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 75, iters: 3328, time: 0.101, data: 0.000) loss: 0.013 
(epoch: 75, iters: 3408, time: 0.096, data: 0.049) loss: 0.029 
(epoch: 75, iters: 3488, time: 0.096, data: 0.000) loss: 0.018 
(epoch: 75, iters: 3568, time: 0.092, data: 0.012) loss: 0.014 
(epoch: 75, iters: 3648, time: 0.089, data: 0.001) loss: 0.002 
(epoch: 75, iters: 3728, time: 0.057, data: 0.012) loss: 0.051 
saving the model at the end of epoch 75, iters 279600
End of epoch 75 / 2100 	 Time Taken: 370 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 75, TEST ACC: [95.903 %]

saving the latest model (epoch 76, total_steps 279616)
(epoch: 76, iters: 80, time: 0.095, data: 0.860) loss: 0.001 
(epoch: 76, iters: 160, time: 0.095, data: 0.000) loss: 0.031 
(epoch: 76, iters: 240, time: 0.095, data: 0.040) loss: 0.002 
(epoch: 76, iters: 320, time: 0.098, data: 0.000) loss: 0.006 
(epoch: 76, iters: 400, time: 0.097, data: 0.012) loss: 0.064 
(epoch: 76, iters: 480, time: 0.111, data: 0.000) loss: 0.020 
(epoch: 76, iters: 560, time: 0.096, data: 0.012) loss: 0.003 
(epoch: 76, iters: 640, time: 0.103, data: 0.000) loss: 0.008 
(epoch: 76, iters: 720, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 76, iters: 800, time: 0.096, data: 0.048) loss: 0.001 
(epoch: 76, iters: 880, time: 0.102, data: 0.000) loss: 0.004 
(epoch: 76, iters: 960, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 76, iters: 1040, time: 0.097, data: 0.000) loss: 0.025 
(epoch: 76, iters: 1120, time: 0.096, data: 0.011) loss: 0.002 
(epoch: 76, iters: 1200, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 76, iters: 1280, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 76, iters: 1360, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 76, iters: 1440, time: 0.096, data: 0.000) loss: 0.111 
(epoch: 76, iters: 1520, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 76, iters: 1600, time: 0.096, data: 0.000) loss: 0.109 
(epoch: 76, iters: 1680, time: 0.109, data: 0.011) loss: 0.064 
(epoch: 76, iters: 1760, time: 0.097, data: 0.000) loss: 0.033 
(epoch: 76, iters: 1840, time: 0.095, data: 0.000) loss: 0.058 
(epoch: 76, iters: 1920, time: 0.094, data: 0.051) loss: 0.042 
(epoch: 76, iters: 2000, time: 0.101, data: 0.000) loss: 0.071 
(epoch: 76, iters: 2080, time: 0.100, data: 0.021) loss: 0.307 
(epoch: 76, iters: 2160, time: 0.094, data: 0.000) loss: 0.033 
(epoch: 76, iters: 2240, time: 0.101, data: 0.019) loss: 0.005 
(epoch: 76, iters: 2320, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 76, iters: 2400, time: 0.099, data: 0.000) loss: 0.007 
(epoch: 76, iters: 2480, time: 0.094, data: 0.041) loss: 0.006 
(epoch: 76, iters: 2560, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 76, iters: 2640, time: 0.094, data: 0.011) loss: 0.012 
(epoch: 76, iters: 2720, time: 0.095, data: 0.000) loss: 0.026 
(epoch: 76, iters: 2800, time: 0.103, data: 0.012) loss: 0.003 
(epoch: 76, iters: 2880, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 76, iters: 2960, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 76, iters: 3040, time: 0.095, data: 0.041) loss: 0.002 
(epoch: 76, iters: 3120, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 76, iters: 3200, time: 0.094, data: 0.011) loss: 0.009 
(epoch: 76, iters: 3280, time: 0.102, data: 0.000) loss: 0.008 
(epoch: 76, iters: 3360, time: 0.096, data: 0.012) loss: 0.023 
(epoch: 76, iters: 3440, time: 0.104, data: 0.000) loss: 0.177 
(epoch: 76, iters: 3520, time: 0.102, data: 0.000) loss: 0.008 
(epoch: 76, iters: 3600, time: 0.104, data: 0.050) loss: 0.027 
(epoch: 76, iters: 3680, time: 0.090, data: 0.000) loss: 0.016 
saving the model at the end of epoch 76, iters 283328
End of epoch 76 / 2100 	 Time Taken: 365 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 76, TEST ACC: [92.564 %]

saving the latest model (epoch 77, total_steps 283344)
(epoch: 77, iters: 32, time: 0.101, data: 0.004) loss: 0.004 
(epoch: 77, iters: 112, time: 0.095, data: 0.028) loss: 0.011 
(epoch: 77, iters: 192, time: 0.098, data: 0.000) loss: 0.016 
(epoch: 77, iters: 272, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 77, iters: 352, time: 0.101, data: 0.041) loss: 0.013 
(epoch: 77, iters: 432, time: 0.101, data: 0.000) loss: 0.001 
(epoch: 77, iters: 512, time: 0.093, data: 0.011) loss: 0.210 
(epoch: 77, iters: 592, time: 0.102, data: 0.000) loss: 0.062 
(epoch: 77, iters: 672, time: 0.094, data: 0.012) loss: 0.085 
(epoch: 77, iters: 752, time: 0.097, data: 0.000) loss: 0.010 
(epoch: 77, iters: 832, time: 0.102, data: 0.000) loss: 0.008 
(epoch: 77, iters: 912, time: 0.095, data: 0.040) loss: 0.020 
(epoch: 77, iters: 992, time: 0.115, data: 0.000) loss: 0.003 
(epoch: 77, iters: 1072, time: 0.093, data: 0.013) loss: 0.042 
(epoch: 77, iters: 1152, time: 0.095, data: 0.000) loss: 0.413 
(epoch: 77, iters: 1232, time: 0.101, data: 0.011) loss: 0.001 
(epoch: 77, iters: 1312, time: 0.095, data: 0.000) loss: 0.236 
(epoch: 77, iters: 1392, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 77, iters: 1472, time: 0.096, data: 0.040) loss: 0.094 
(epoch: 77, iters: 1552, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 77, iters: 1632, time: 0.092, data: 0.011) loss: 0.084 
(epoch: 77, iters: 1712, time: 0.094, data: 0.000) loss: 0.287 
(epoch: 77, iters: 1792, time: 0.100, data: 0.011) loss: 0.210 
(epoch: 77, iters: 1872, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 77, iters: 1952, time: 0.101, data: 0.000) loss: 0.002 
(epoch: 77, iters: 2032, time: 0.095, data: 0.040) loss: 0.111 
(epoch: 77, iters: 2112, time: 0.101, data: 0.000) loss: 0.005 
(epoch: 77, iters: 2192, time: 0.101, data: 0.011) loss: 0.012 
(epoch: 77, iters: 2272, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 77, iters: 2352, time: 0.095, data: 0.020) loss: 0.026 
(epoch: 77, iters: 2432, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 77, iters: 2512, time: 0.095, data: 0.000) loss: 0.131 
(epoch: 77, iters: 2592, time: 0.097, data: 0.039) loss: 0.001 
(epoch: 77, iters: 2672, time: 0.098, data: 0.000) loss: 0.052 
(epoch: 77, iters: 2752, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 77, iters: 2832, time: 0.102, data: 0.000) loss: 0.029 
(epoch: 77, iters: 2912, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 77, iters: 2992, time: 0.096, data: 0.000) loss: 0.021 
(epoch: 77, iters: 3072, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 77, iters: 3152, time: 0.095, data: 0.038) loss: 0.004 
(epoch: 77, iters: 3232, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 77, iters: 3312, time: 0.102, data: 0.012) loss: 0.001 
(epoch: 77, iters: 3392, time: 0.104, data: 0.000) loss: 0.067 
(epoch: 77, iters: 3472, time: 0.097, data: 0.012) loss: 0.267 
(epoch: 77, iters: 3552, time: 0.097, data: 0.000) loss: 0.350 
(epoch: 77, iters: 3632, time: 0.098, data: 0.000) loss: 0.006 
(epoch: 77, iters: 3712, time: 0.091, data: 0.044) loss: 0.003 
saving the model at the end of epoch 77, iters 287056
End of epoch 77 / 2100 	 Time Taken: 363 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 77, TEST ACC: [91.047 %]

saving the latest model (epoch 78, total_steps 287072)
(epoch: 78, iters: 64, time: 0.097, data: 0.000) loss: 0.095 
(epoch: 78, iters: 144, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 78, iters: 224, time: 0.095, data: 0.000) loss: 0.175 
(epoch: 78, iters: 304, time: 0.095, data: 0.012) loss: 0.180 
(epoch: 78, iters: 384, time: 0.097, data: 0.000) loss: 0.010 
(epoch: 78, iters: 464, time: 0.102, data: 0.000) loss: 0.075 
(epoch: 78, iters: 544, time: 0.094, data: 0.040) loss: 0.019 
(epoch: 78, iters: 624, time: 0.109, data: 0.000) loss: 0.033 
(epoch: 78, iters: 704, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 78, iters: 784, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 78, iters: 864, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 78, iters: 944, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 78, iters: 1024, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 78, iters: 1104, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 78, iters: 1184, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 78, iters: 1264, time: 0.094, data: 0.025) loss: 0.035 
(epoch: 78, iters: 1344, time: 0.096, data: 0.000) loss: 0.071 
(epoch: 78, iters: 1424, time: 0.107, data: 0.000) loss: 0.001 
(epoch: 78, iters: 1504, time: 0.095, data: 0.012) loss: 0.004 
(epoch: 78, iters: 1584, time: 0.093, data: 0.025) loss: 0.002 
(epoch: 78, iters: 1664, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 78, iters: 1744, time: 0.098, data: 0.000) loss: 0.314 
(epoch: 78, iters: 1824, time: 0.094, data: 0.012) loss: 0.019 
(epoch: 78, iters: 1904, time: 0.100, data: 0.025) loss: 0.028 
(epoch: 78, iters: 1984, time: 0.096, data: 0.000) loss: 0.267 
(epoch: 78, iters: 2064, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 78, iters: 2144, time: 0.097, data: 0.012) loss: 0.009 
(epoch: 78, iters: 2224, time: 0.102, data: 0.000) loss: 0.029 
(epoch: 78, iters: 2304, time: 0.102, data: 0.040) loss: 0.004 
(epoch: 78, iters: 2384, time: 0.097, data: 0.000) loss: 0.065 
(epoch: 78, iters: 2464, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 78, iters: 2544, time: 0.101, data: 0.000) loss: 0.399 
(epoch: 78, iters: 2624, time: 0.094, data: 0.011) loss: 0.037 
(epoch: 78, iters: 2704, time: 0.102, data: 0.000) loss: 0.005 
(epoch: 78, iters: 2784, time: 0.097, data: 0.000) loss: 0.061 
(epoch: 78, iters: 2864, time: 0.101, data: 0.040) loss: 0.110 
(epoch: 78, iters: 2944, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 78, iters: 3024, time: 0.093, data: 0.012) loss: 0.014 
(epoch: 78, iters: 3104, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 78, iters: 3184, time: 0.094, data: 0.011) loss: 0.112 
(epoch: 78, iters: 3264, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 78, iters: 3344, time: 0.095, data: 0.000) loss: 0.045 
(epoch: 78, iters: 3424, time: 0.096, data: 0.048) loss: 0.021 
(epoch: 78, iters: 3504, time: 0.095, data: 0.000) loss: 0.058 
(epoch: 78, iters: 3584, time: 0.099, data: 0.012) loss: 0.016 
(epoch: 78, iters: 3664, time: 0.089, data: 0.000) loss: 0.004 
saving the model at the end of epoch 78, iters 290784
End of epoch 78 / 2100 	 Time Taken: 363 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 78, TEST ACC: [94.082 %]

(epoch: 79, iters: 16, time: 0.122, data: 0.009) loss: 0.004 
saving the latest model (epoch 79, total_steps 290800)
(epoch: 79, iters: 96, time: 0.103, data: 0.000) loss: 0.004 
(epoch: 79, iters: 176, time: 0.092, data: 0.012) loss: 0.005 
(epoch: 79, iters: 256, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 79, iters: 336, time: 0.094, data: 0.011) loss: 0.007 
(epoch: 79, iters: 416, time: 0.101, data: 0.000) loss: 0.002 
(epoch: 79, iters: 496, time: 0.094, data: 0.000) loss: 0.047 
(epoch: 79, iters: 576, time: 0.101, data: 0.039) loss: 0.002 
(epoch: 79, iters: 656, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 79, iters: 736, time: 0.100, data: 0.011) loss: 0.002 
(epoch: 79, iters: 816, time: 0.104, data: 0.000) loss: 0.033 
(epoch: 79, iters: 896, time: 0.095, data: 0.012) loss: 0.010 
(epoch: 79, iters: 976, time: 0.096, data: 0.000) loss: 0.245 
(epoch: 79, iters: 1056, time: 0.096, data: 0.000) loss: 0.215 
(epoch: 79, iters: 1136, time: 0.095, data: 0.022) loss: 0.003 
(epoch: 79, iters: 1216, time: 0.093, data: 0.025) loss: 0.002 
(epoch: 79, iters: 1296, time: 0.101, data: 0.000) loss: 0.003 
(epoch: 79, iters: 1376, time: 0.101, data: 0.000) loss: 0.162 
(epoch: 79, iters: 1456, time: 0.095, data: 0.012) loss: 0.047 
(epoch: 79, iters: 1536, time: 0.092, data: 0.025) loss: 0.058 
(epoch: 79, iters: 1616, time: 0.095, data: 0.000) loss: 0.081 
(epoch: 79, iters: 1696, time: 0.095, data: 0.000) loss: 0.027 
(epoch: 79, iters: 1776, time: 0.095, data: 0.020) loss: 0.001 
(epoch: 79, iters: 1856, time: 0.093, data: 0.026) loss: 0.034 
(epoch: 79, iters: 1936, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 79, iters: 2016, time: 0.095, data: 0.000) loss: 0.026 
(epoch: 79, iters: 2096, time: 0.094, data: 0.011) loss: 0.008 
(epoch: 79, iters: 2176, time: 0.093, data: 0.024) loss: 0.002 
(epoch: 79, iters: 2256, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 79, iters: 2336, time: 0.102, data: 0.000) loss: 0.001 
(epoch: 79, iters: 2416, time: 0.094, data: 0.012) loss: 0.017 
(epoch: 79, iters: 2496, time: 0.096, data: 0.025) loss: 0.006 
(epoch: 79, iters: 2576, time: 0.101, data: 0.000) loss: 0.017 
(epoch: 79, iters: 2656, time: 0.095, data: 0.049) loss: 0.001 
(epoch: 79, iters: 2736, time: 0.102, data: 0.000) loss: 0.013 
(epoch: 79, iters: 2816, time: 0.099, data: 0.012) loss: 0.013 
(epoch: 79, iters: 2896, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 79, iters: 2976, time: 0.101, data: 0.012) loss: 0.010 
(epoch: 79, iters: 3056, time: 0.096, data: 0.000) loss: 0.075 
(epoch: 79, iters: 3136, time: 0.094, data: 0.000) loss: 0.372 
(epoch: 79, iters: 3216, time: 0.095, data: 0.039) loss: 0.137 
(epoch: 79, iters: 3296, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 79, iters: 3376, time: 0.093, data: 0.011) loss: 0.117 
(epoch: 79, iters: 3456, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 79, iters: 3536, time: 0.094, data: 0.011) loss: 0.004 
(epoch: 79, iters: 3616, time: 0.114, data: 0.000) loss: 0.009 
(epoch: 79, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 79, iters 294512
End of epoch 79 / 2100 	 Time Taken: 361 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 79, TEST ACC: [59.788 %]

saving the latest model (epoch 80, total_steps 294528)
(epoch: 80, iters: 48, time: 0.097, data: 0.008) loss: 0.013 
(epoch: 80, iters: 128, time: 0.095, data: 0.000) loss: 0.022 
(epoch: 80, iters: 208, time: 0.100, data: 0.041) loss: 0.078 
(epoch: 80, iters: 288, time: 0.101, data: 0.000) loss: 0.537 
(epoch: 80, iters: 368, time: 0.098, data: 0.012) loss: 0.078 
(epoch: 80, iters: 448, time: 0.096, data: 0.000) loss: 0.071 
(epoch: 80, iters: 528, time: 0.102, data: 0.012) loss: 0.534 
(epoch: 80, iters: 608, time: 0.096, data: 0.000) loss: 0.052 
(epoch: 80, iters: 688, time: 0.094, data: 0.000) loss: 0.029 
(epoch: 80, iters: 768, time: 0.095, data: 0.040) loss: 0.013 
(epoch: 80, iters: 848, time: 0.103, data: 0.000) loss: 0.018 
(epoch: 80, iters: 928, time: 0.093, data: 0.011) loss: 0.061 
(epoch: 80, iters: 1008, time: 0.095, data: 0.000) loss: 0.027 
(epoch: 80, iters: 1088, time: 0.100, data: 0.011) loss: 0.035 
(epoch: 80, iters: 1168, time: 0.101, data: 0.000) loss: 0.119 
(epoch: 80, iters: 1248, time: 0.106, data: 0.000) loss: 0.010 
(epoch: 80, iters: 1328, time: 0.095, data: 0.041) loss: 0.002 
(epoch: 80, iters: 1408, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 80, iters: 1488, time: 0.093, data: 0.012) loss: 0.021 
(epoch: 80, iters: 1568, time: 0.095, data: 0.000) loss: 0.089 
(epoch: 80, iters: 1648, time: 0.101, data: 0.011) loss: 0.012 
(epoch: 80, iters: 1728, time: 0.095, data: 0.000) loss: 0.040 
(epoch: 80, iters: 1808, time: 0.094, data: 0.000) loss: 0.066 
(epoch: 80, iters: 1888, time: 0.101, data: 0.041) loss: 0.003 
(epoch: 80, iters: 1968, time: 0.095, data: 0.000) loss: 0.069 
(epoch: 80, iters: 2048, time: 0.093, data: 0.012) loss: 0.252 
(epoch: 80, iters: 2128, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 80, iters: 2208, time: 0.094, data: 0.012) loss: 0.151 
(epoch: 80, iters: 2288, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 80, iters: 2368, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 80, iters: 2448, time: 0.096, data: 0.040) loss: 0.009 
(epoch: 80, iters: 2528, time: 0.096, data: 0.000) loss: 0.463 
(epoch: 80, iters: 2608, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 80, iters: 2688, time: 0.103, data: 0.000) loss: 0.012 
(epoch: 80, iters: 2768, time: 0.094, data: 0.011) loss: 0.024 
(epoch: 80, iters: 2848, time: 0.102, data: 0.000) loss: 0.003 
(epoch: 80, iters: 2928, time: 0.095, data: 0.000) loss: 0.216 
(epoch: 80, iters: 3008, time: 0.095, data: 0.040) loss: 0.007 
(epoch: 80, iters: 3088, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 80, iters: 3168, time: 0.093, data: 0.012) loss: 0.038 
(epoch: 80, iters: 3248, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 80, iters: 3328, time: 0.101, data: 0.011) loss: 0.004 
(epoch: 80, iters: 3408, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 80, iters: 3488, time: 0.101, data: 0.000) loss: 0.019 
(epoch: 80, iters: 3568, time: 0.101, data: 0.039) loss: 0.027 
(epoch: 80, iters: 3648, time: 0.088, data: 0.000) loss: 0.083 
(epoch: 80, iters: 3728, time: 0.057, data: 0.012) loss: 0.003 
saving the model at the end of epoch 80, iters 298240
End of epoch 80 / 2100 	 Time Taken: 361 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 80, TEST ACC: [94.082 %]

saving the latest model (epoch 81, total_steps 298256)
(epoch: 81, iters: 80, time: 0.095, data: 0.674) loss: 0.001 
(epoch: 81, iters: 160, time: 0.094, data: 0.000) loss: 0.032 
(epoch: 81, iters: 240, time: 0.105, data: 0.049) loss: 0.004 
(epoch: 81, iters: 320, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 81, iters: 400, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 81, iters: 480, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 81, iters: 560, time: 0.094, data: 0.012) loss: 0.034 
(epoch: 81, iters: 640, time: 0.096, data: 0.000) loss: 0.285 
(epoch: 81, iters: 720, time: 0.094, data: 0.000) loss: 0.182 
(epoch: 81, iters: 800, time: 0.095, data: 0.039) loss: 0.016 
(epoch: 81, iters: 880, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 81, iters: 960, time: 0.100, data: 0.012) loss: 0.011 
(epoch: 81, iters: 1040, time: 0.096, data: 0.000) loss: 0.047 
(epoch: 81, iters: 1120, time: 0.095, data: 0.013) loss: 0.002 
(epoch: 81, iters: 1200, time: 0.097, data: 0.000) loss: 0.167 
(epoch: 81, iters: 1280, time: 0.106, data: 0.000) loss: 0.017 
(epoch: 81, iters: 1360, time: 0.101, data: 0.039) loss: 0.002 
(epoch: 81, iters: 1440, time: 0.096, data: 0.000) loss: 0.062 
(epoch: 81, iters: 1520, time: 0.094, data: 0.011) loss: 0.057 
(epoch: 81, iters: 1600, time: 0.093, data: 0.025) loss: 0.005 
(epoch: 81, iters: 1680, time: 0.095, data: 0.000) loss: 0.039 
(epoch: 81, iters: 1760, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 81, iters: 1840, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 81, iters: 1920, time: 0.094, data: 0.011) loss: 0.086 
(epoch: 81, iters: 2000, time: 0.099, data: 0.026) loss: 0.031 
(epoch: 81, iters: 2080, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 81, iters: 2160, time: 0.095, data: 0.000) loss: 0.048 
(epoch: 81, iters: 2240, time: 0.094, data: 0.011) loss: 0.050 
(epoch: 81, iters: 2320, time: 0.093, data: 0.025) loss: 0.018 
(epoch: 81, iters: 2400, time: 0.095, data: 0.000) loss: 0.062 
(epoch: 81, iters: 2480, time: 0.095, data: 0.000) loss: 0.050 
(epoch: 81, iters: 2560, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 81, iters: 2640, time: 0.093, data: 0.026) loss: 0.002 
(epoch: 81, iters: 2720, time: 0.104, data: 0.000) loss: 0.001 
(epoch: 81, iters: 2800, time: 0.097, data: 0.000) loss: 0.010 
(epoch: 81, iters: 2880, time: 0.096, data: 0.011) loss: 0.035 
(epoch: 81, iters: 2960, time: 0.094, data: 0.027) loss: 0.004 
(epoch: 81, iters: 3040, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 81, iters: 3120, time: 0.096, data: 0.000) loss: 0.038 
(epoch: 81, iters: 3200, time: 0.096, data: 0.011) loss: 0.008 
(epoch: 81, iters: 3280, time: 0.095, data: 0.035) loss: 0.007 
(epoch: 81, iters: 3360, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 81, iters: 3440, time: 0.102, data: 0.000) loss: 0.011 
(epoch: 81, iters: 3520, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 81, iters: 3600, time: 0.092, data: 0.027) loss: 0.001 
(epoch: 81, iters: 3680, time: 0.089, data: 0.000) loss: 0.044 
saving the model at the end of epoch 81, iters 301968
End of epoch 81 / 2100 	 Time Taken: 361 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 81, TEST ACC: [94.385 %]

saving the latest model (epoch 82, total_steps 301984)
(epoch: 82, iters: 32, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 82, iters: 112, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 82, iters: 192, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 82, iters: 272, time: 0.095, data: 0.039) loss: 0.002 
(epoch: 82, iters: 352, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 82, iters: 432, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 82, iters: 512, time: 0.095, data: 0.000) loss: 0.027 
(epoch: 82, iters: 592, time: 0.095, data: 0.012) loss: 0.024 
(epoch: 82, iters: 672, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 82, iters: 752, time: 0.094, data: 0.000) loss: 0.080 
(epoch: 82, iters: 832, time: 0.102, data: 0.048) loss: 0.007 
(epoch: 82, iters: 912, time: 0.096, data: 0.000) loss: 0.065 
(epoch: 82, iters: 992, time: 0.093, data: 0.011) loss: 0.083 
(epoch: 82, iters: 1072, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 82, iters: 1152, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 82, iters: 1232, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 82, iters: 1312, time: 0.094, data: 0.000) loss: 0.130 
(epoch: 82, iters: 1392, time: 0.095, data: 0.041) loss: 0.004 
(epoch: 82, iters: 1472, time: 0.096, data: 0.000) loss: 0.054 
(epoch: 82, iters: 1552, time: 0.100, data: 0.011) loss: 0.204 
(epoch: 82, iters: 1632, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 82, iters: 1712, time: 0.095, data: 0.013) loss: 0.021 
(epoch: 82, iters: 1792, time: 0.100, data: 0.012) loss: 0.681 
(epoch: 82, iters: 1872, time: 0.093, data: 0.025) loss: 0.075 
(epoch: 82, iters: 1952, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 82, iters: 2032, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 82, iters: 2112, time: 0.093, data: 0.012) loss: 0.018 
(epoch: 82, iters: 2192, time: 0.093, data: 0.026) loss: 0.224 
(epoch: 82, iters: 2272, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 82, iters: 2352, time: 0.094, data: 0.000) loss: 0.284 
(epoch: 82, iters: 2432, time: 0.094, data: 0.011) loss: 0.004 
(epoch: 82, iters: 2512, time: 0.094, data: 0.035) loss: 0.003 
(epoch: 82, iters: 2592, time: 0.094, data: 0.000) loss: 0.034 
(epoch: 82, iters: 2672, time: 0.102, data: 0.000) loss: 0.006 
(epoch: 82, iters: 2752, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 82, iters: 2832, time: 0.093, data: 0.025) loss: 0.012 
(epoch: 82, iters: 2912, time: 0.095, data: 0.000) loss: 0.060 
(epoch: 82, iters: 2992, time: 0.102, data: 0.000) loss: 0.001 
(epoch: 82, iters: 3072, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 82, iters: 3152, time: 0.094, data: 0.025) loss: 0.005 
(epoch: 82, iters: 3232, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 82, iters: 3312, time: 0.096, data: 0.000) loss: 0.236 
(epoch: 82, iters: 3392, time: 0.095, data: 0.012) loss: 0.006 
(epoch: 82, iters: 3472, time: 0.099, data: 0.025) loss: 0.065 
(epoch: 82, iters: 3552, time: 0.096, data: 0.000) loss: 0.147 
(epoch: 82, iters: 3632, time: 0.092, data: 0.000) loss: 0.004 
(epoch: 82, iters: 3712, time: 0.089, data: 0.011) loss: 0.012 
saving the model at the end of epoch 82, iters 305696
End of epoch 82 / 2100 	 Time Taken: 358 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 82, TEST ACC: [88.164 %]

saving the latest model (epoch 83, total_steps 305712)
(epoch: 83, iters: 64, time: 0.093, data: 0.000) loss: 0.253 
(epoch: 83, iters: 144, time: 0.094, data: 0.000) loss: 0.042 
(epoch: 83, iters: 224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 83, iters: 304, time: 0.108, data: 0.000) loss: 0.008 
(epoch: 83, iters: 384, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 83, iters: 464, time: 0.099, data: 0.048) loss: 0.033 
(epoch: 83, iters: 544, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 83, iters: 624, time: 0.093, data: 0.011) loss: 0.007 
(epoch: 83, iters: 704, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 83, iters: 784, time: 0.096, data: 0.011) loss: 0.013 
(epoch: 83, iters: 864, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 83, iters: 944, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 83, iters: 1024, time: 0.094, data: 0.012) loss: 0.014 
(epoch: 83, iters: 1104, time: 0.092, data: 0.025) loss: 0.018 
(epoch: 83, iters: 1184, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 83, iters: 1264, time: 0.096, data: 0.000) loss: 0.018 
(epoch: 83, iters: 1344, time: 0.094, data: 0.012) loss: 0.018 
(epoch: 83, iters: 1424, time: 0.093, data: 0.025) loss: 0.009 
(epoch: 83, iters: 1504, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 83, iters: 1584, time: 0.102, data: 0.000) loss: 0.004 
(epoch: 83, iters: 1664, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 83, iters: 1744, time: 0.094, data: 0.025) loss: 0.002 
(epoch: 83, iters: 1824, time: 0.101, data: 0.000) loss: 0.008 
(epoch: 83, iters: 1904, time: 0.096, data: 0.000) loss: 0.016 
(epoch: 83, iters: 1984, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 83, iters: 2064, time: 0.097, data: 0.049) loss: 0.001 
(epoch: 83, iters: 2144, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 83, iters: 2224, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 83, iters: 2304, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 83, iters: 2384, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 83, iters: 2464, time: 0.094, data: 0.000) loss: 0.020 
(epoch: 83, iters: 2544, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 83, iters: 2624, time: 0.101, data: 0.000) loss: 0.004 
(epoch: 83, iters: 2704, time: 0.094, data: 0.012) loss: 0.006 
(epoch: 83, iters: 2784, time: 0.107, data: 0.034) loss: 0.008 
(epoch: 83, iters: 2864, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 83, iters: 2944, time: 0.096, data: 0.000) loss: 0.067 
(epoch: 83, iters: 3024, time: 0.094, data: 0.011) loss: 0.062 
(epoch: 83, iters: 3104, time: 0.100, data: 0.026) loss: 0.007 
(epoch: 83, iters: 3184, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 83, iters: 3264, time: 0.102, data: 0.000) loss: 0.005 
(epoch: 83, iters: 3344, time: 0.095, data: 0.012) loss: 0.037 
(epoch: 83, iters: 3424, time: 0.094, data: 0.025) loss: 0.008 
(epoch: 83, iters: 3504, time: 0.095, data: 0.000) loss: 0.086 
(epoch: 83, iters: 3584, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 83, iters: 3664, time: 0.088, data: 0.013) loss: 0.073 
saving the model at the end of epoch 83, iters 309424
End of epoch 83 / 2100 	 Time Taken: 362 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 83, TEST ACC: [90.137 %]

(epoch: 84, iters: 16, time: 0.132, data: 0.012) loss: 0.042 
saving the latest model (epoch 84, total_steps 309440)
(epoch: 84, iters: 96, time: 0.096, data: 0.058) loss: 0.002 
(epoch: 84, iters: 176, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 84, iters: 256, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 84, iters: 336, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 84, iters: 416, time: 0.093, data: 0.011) loss: 0.022 
(epoch: 84, iters: 496, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 84, iters: 576, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 84, iters: 656, time: 0.101, data: 0.039) loss: 0.021 
(epoch: 84, iters: 736, time: 0.095, data: 0.000) loss: 0.082 
(epoch: 84, iters: 816, time: 0.093, data: 0.012) loss: 0.164 
(epoch: 84, iters: 896, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 84, iters: 976, time: 0.094, data: 0.011) loss: 0.097 
(epoch: 84, iters: 1056, time: 0.095, data: 0.000) loss: 0.109 
(epoch: 84, iters: 1136, time: 0.094, data: 0.000) loss: 0.029 
(epoch: 84, iters: 1216, time: 0.097, data: 0.040) loss: 0.003 
(epoch: 84, iters: 1296, time: 0.096, data: 0.000) loss: 0.025 
(epoch: 84, iters: 1376, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 84, iters: 1456, time: 0.097, data: 0.000) loss: 0.013 
(epoch: 84, iters: 1536, time: 0.096, data: 0.013) loss: 0.076 
(epoch: 84, iters: 1616, time: 0.097, data: 0.000) loss: 0.204 
(epoch: 84, iters: 1696, time: 0.101, data: 0.000) loss: 0.075 
(epoch: 84, iters: 1776, time: 0.094, data: 0.040) loss: 0.018 
(epoch: 84, iters: 1856, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 84, iters: 1936, time: 0.093, data: 0.011) loss: 0.034 
(epoch: 84, iters: 2016, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 84, iters: 2096, time: 0.094, data: 0.012) loss: 0.315 
(epoch: 84, iters: 2176, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 84, iters: 2256, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 84, iters: 2336, time: 0.094, data: 0.041) loss: 0.004 
(epoch: 84, iters: 2416, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 84, iters: 2496, time: 0.092, data: 0.012) loss: 0.085 
(epoch: 84, iters: 2576, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 84, iters: 2656, time: 0.101, data: 0.012) loss: 0.057 
(epoch: 84, iters: 2736, time: 0.108, data: 0.000) loss: 0.001 
(epoch: 84, iters: 2816, time: 0.100, data: 0.000) loss: 0.006 
(epoch: 84, iters: 2896, time: 0.094, data: 0.040) loss: 0.014 
(epoch: 84, iters: 2976, time: 0.094, data: 0.000) loss: 0.028 
(epoch: 84, iters: 3056, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 84, iters: 3136, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 84, iters: 3216, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 84, iters: 3296, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 84, iters: 3376, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 84, iters: 3456, time: 0.095, data: 0.050) loss: 0.003 
(epoch: 84, iters: 3536, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 84, iters: 3616, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 84, iters: 3696, time: 0.091, data: 0.000) loss: 0.068 
saving the model at the end of epoch 84, iters 313152
End of epoch 84 / 2100 	 Time Taken: 359 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 84, TEST ACC: [90.895 %]

saving the latest model (epoch 85, total_steps 313168)
(epoch: 85, iters: 48, time: 0.094, data: 0.004) loss: 0.002 
(epoch: 85, iters: 128, time: 0.094, data: 0.012) loss: 0.005 
(epoch: 85, iters: 208, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 85, iters: 288, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 85, iters: 368, time: 0.095, data: 0.048) loss: 0.005 
(epoch: 85, iters: 448, time: 0.101, data: 0.000) loss: 0.003 
(epoch: 85, iters: 528, time: 0.099, data: 0.012) loss: 0.003 
(epoch: 85, iters: 608, time: 0.102, data: 0.000) loss: 0.052 
(epoch: 85, iters: 688, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 85, iters: 768, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 85, iters: 848, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 85, iters: 928, time: 0.095, data: 0.050) loss: 0.004 
(epoch: 85, iters: 1008, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 85, iters: 1088, time: 0.092, data: 0.012) loss: 0.040 
(epoch: 85, iters: 1168, time: 0.096, data: 0.000) loss: 0.058 
(epoch: 85, iters: 1248, time: 0.094, data: 0.011) loss: 0.047 
(epoch: 85, iters: 1328, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 85, iters: 1408, time: 0.100, data: 0.000) loss: 0.020 
(epoch: 85, iters: 1488, time: 0.102, data: 0.040) loss: 0.001 
(epoch: 85, iters: 1568, time: 0.101, data: 0.000) loss: 0.002 
(epoch: 85, iters: 1648, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 85, iters: 1728, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 85, iters: 1808, time: 0.093, data: 0.011) loss: 0.031 
(epoch: 85, iters: 1888, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 85, iters: 1968, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 85, iters: 2048, time: 0.100, data: 0.040) loss: 0.010 
(epoch: 85, iters: 2128, time: 0.094, data: 0.000) loss: 0.050 
(epoch: 85, iters: 2208, time: 0.099, data: 0.011) loss: 0.033 
(epoch: 85, iters: 2288, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 85, iters: 2368, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 85, iters: 2448, time: 0.096, data: 0.000) loss: 0.016 
(epoch: 85, iters: 2528, time: 0.097, data: 0.000) loss: 0.019 
(epoch: 85, iters: 2608, time: 0.095, data: 0.042) loss: 0.008 
(epoch: 85, iters: 2688, time: 0.102, data: 0.000) loss: 0.190 
(epoch: 85, iters: 2768, time: 0.093, data: 0.011) loss: 0.016 
(epoch: 85, iters: 2848, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 85, iters: 2928, time: 0.096, data: 0.011) loss: 0.008 
(epoch: 85, iters: 3008, time: 0.101, data: 0.000) loss: 0.027 
(epoch: 85, iters: 3088, time: 0.096, data: 0.000) loss: 0.109 
(epoch: 85, iters: 3168, time: 0.094, data: 0.051) loss: 0.023 
(epoch: 85, iters: 3248, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 85, iters: 3328, time: 0.094, data: 0.012) loss: 0.150 
(epoch: 85, iters: 3408, time: 0.094, data: 0.000) loss: 0.186 
(epoch: 85, iters: 3488, time: 0.094, data: 0.011) loss: 0.007 
(epoch: 85, iters: 3568, time: 0.096, data: 0.000) loss: 0.109 
(epoch: 85, iters: 3648, time: 0.090, data: 0.000) loss: 0.167 
(epoch: 85, iters: 3728, time: 0.056, data: 0.016) loss: 0.001 
saving the model at the end of epoch 85, iters 316880
End of epoch 85 / 2100 	 Time Taken: 360 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 85, TEST ACC: [92.261 %]

saving the latest model (epoch 86, total_steps 316896)
(epoch: 86, iters: 80, time: 0.095, data: 0.641) loss: 0.000 
(epoch: 86, iters: 160, time: 0.093, data: 0.000) loss: 0.013 
(epoch: 86, iters: 240, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 86, iters: 320, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 86, iters: 400, time: 0.094, data: 0.011) loss: 0.075 
(epoch: 86, iters: 480, time: 0.096, data: 0.000) loss: 0.080 
(epoch: 86, iters: 560, time: 0.095, data: 0.011) loss: 0.022 
(epoch: 86, iters: 640, time: 0.099, data: 0.000) loss: 0.009 
(epoch: 86, iters: 720, time: 0.122, data: 0.000) loss: 0.136 
(epoch: 86, iters: 800, time: 0.098, data: 0.040) loss: 0.006 
(epoch: 86, iters: 880, time: 0.098, data: 0.000) loss: 0.003 
(epoch: 86, iters: 960, time: 0.092, data: 0.012) loss: 0.144 
(epoch: 86, iters: 1040, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 86, iters: 1120, time: 0.100, data: 0.012) loss: 0.021 
(epoch: 86, iters: 1200, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 86, iters: 1280, time: 0.095, data: 0.000) loss: 0.128 
(epoch: 86, iters: 1360, time: 0.102, data: 0.039) loss: 0.011 
(epoch: 86, iters: 1440, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 86, iters: 1520, time: 0.099, data: 0.011) loss: 0.002 
(epoch: 86, iters: 1600, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 86, iters: 1680, time: 0.099, data: 0.012) loss: 0.012 
(epoch: 86, iters: 1760, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 86, iters: 1840, time: 0.100, data: 0.000) loss: 0.001 
(epoch: 86, iters: 1920, time: 0.095, data: 0.038) loss: 0.004 
(epoch: 86, iters: 2000, time: 0.102, data: 0.000) loss: 0.309 
(epoch: 86, iters: 2080, time: 0.094, data: 0.012) loss: 0.012 
(epoch: 86, iters: 2160, time: 0.093, data: 0.025) loss: 0.002 
(epoch: 86, iters: 2240, time: 0.103, data: 0.000) loss: 0.002 
(epoch: 86, iters: 2320, time: 0.101, data: 0.000) loss: 0.002 
(epoch: 86, iters: 2400, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 86, iters: 2480, time: 0.093, data: 0.025) loss: 0.002 
(epoch: 86, iters: 2560, time: 0.093, data: 0.000) loss: 0.113 
(epoch: 86, iters: 2640, time: 0.092, data: 0.000) loss: 0.003 
(epoch: 86, iters: 2720, time: 0.101, data: 0.000) loss: 0.001 
(epoch: 86, iters: 2800, time: 0.094, data: 0.012) loss: 0.018 
(epoch: 86, iters: 2880, time: 0.096, data: 0.000) loss: 0.021 
(epoch: 86, iters: 2960, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 86, iters: 3040, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 86, iters: 3120, time: 0.095, data: 0.000) loss: 0.092 
(epoch: 86, iters: 3200, time: 0.092, data: 0.012) loss: 0.010 
(epoch: 86, iters: 3280, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 86, iters: 3360, time: 0.093, data: 0.011) loss: 0.173 
(epoch: 86, iters: 3440, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 86, iters: 3520, time: 0.093, data: 0.000) loss: 0.012 
(epoch: 86, iters: 3600, time: 0.094, data: 0.039) loss: 0.050 
(epoch: 86, iters: 3680, time: 0.090, data: 0.000) loss: 0.134 
saving the model at the end of epoch 86, iters 320608
End of epoch 86 / 2100 	 Time Taken: 359 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 86, TEST ACC: [88.316 %]

saving the latest model (epoch 87, total_steps 320624)
(epoch: 87, iters: 32, time: 0.094, data: 0.014) loss: 0.025 
(epoch: 87, iters: 112, time: 0.094, data: 0.011) loss: 0.105 
(epoch: 87, iters: 192, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 87, iters: 272, time: 0.093, data: 0.000) loss: 0.100 
(epoch: 87, iters: 352, time: 0.094, data: 0.039) loss: 0.002 
(epoch: 87, iters: 432, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 87, iters: 512, time: 0.093, data: 0.020) loss: 0.001 
(epoch: 87, iters: 592, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 87, iters: 672, time: 0.094, data: 0.012) loss: 0.015 
(epoch: 87, iters: 752, time: 0.095, data: 0.000) loss: 0.098 
(epoch: 87, iters: 832, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 87, iters: 912, time: 0.094, data: 0.040) loss: 0.013 
(epoch: 87, iters: 992, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 87, iters: 1072, time: 0.094, data: 0.011) loss: 0.004 
(epoch: 87, iters: 1152, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 87, iters: 1232, time: 0.093, data: 0.011) loss: 0.012 
(epoch: 87, iters: 1312, time: 0.096, data: 0.000) loss: 0.043 
(epoch: 87, iters: 1392, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 87, iters: 1472, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 87, iters: 1552, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 87, iters: 1632, time: 0.093, data: 0.011) loss: 0.047 
(epoch: 87, iters: 1712, time: 0.094, data: 0.000) loss: 0.099 
(epoch: 87, iters: 1792, time: 0.093, data: 0.012) loss: 0.031 
(epoch: 87, iters: 1872, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 87, iters: 1952, time: 0.094, data: 0.000) loss: 0.017 
(epoch: 87, iters: 2032, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 87, iters: 2112, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 87, iters: 2192, time: 0.093, data: 0.011) loss: 0.019 
(epoch: 87, iters: 2272, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 87, iters: 2352, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 87, iters: 2432, time: 0.095, data: 0.000) loss: 0.028 
(epoch: 87, iters: 2512, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 87, iters: 2592, time: 0.100, data: 0.040) loss: 0.085 
(epoch: 87, iters: 2672, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 87, iters: 2752, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 87, iters: 2832, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 87, iters: 2912, time: 0.095, data: 0.012) loss: 0.286 
(epoch: 87, iters: 2992, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 87, iters: 3072, time: 0.093, data: 0.000) loss: 0.026 
(epoch: 87, iters: 3152, time: 0.094, data: 0.041) loss: 0.165 
(epoch: 87, iters: 3232, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 87, iters: 3312, time: 0.093, data: 0.012) loss: 0.021 
(epoch: 87, iters: 3392, time: 0.100, data: 0.000) loss: 0.001 
(epoch: 87, iters: 3472, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 87, iters: 3552, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 87, iters: 3632, time: 0.092, data: 0.000) loss: 0.039 
(epoch: 87, iters: 3712, time: 0.087, data: 0.036) loss: 0.006 
saving the model at the end of epoch 87, iters 324336
End of epoch 87 / 2100 	 Time Taken: 357 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 87, TEST ACC: [78.149 %]

saving the latest model (epoch 88, total_steps 324352)
(epoch: 88, iters: 64, time: 0.092, data: 0.000) loss: 0.176 
(epoch: 88, iters: 144, time: 0.108, data: 0.000) loss: 0.004 
(epoch: 88, iters: 224, time: 0.094, data: 0.011) loss: 0.046 
(epoch: 88, iters: 304, time: 0.102, data: 0.000) loss: 0.008 
(epoch: 88, iters: 384, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 88, iters: 464, time: 0.094, data: 0.040) loss: 0.010 
(epoch: 88, iters: 544, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 88, iters: 624, time: 0.092, data: 0.012) loss: 0.181 
(epoch: 88, iters: 704, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 88, iters: 784, time: 0.096, data: 0.011) loss: 0.304 
(epoch: 88, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 88, iters: 944, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 88, iters: 1024, time: 0.095, data: 0.048) loss: 0.002 
(epoch: 88, iters: 1104, time: 0.095, data: 0.000) loss: 0.023 
(epoch: 88, iters: 1184, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 88, iters: 1264, time: 0.095, data: 0.000) loss: 0.042 
(epoch: 88, iters: 1344, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 88, iters: 1424, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 88, iters: 1504, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 88, iters: 1584, time: 0.094, data: 0.050) loss: 0.001 
(epoch: 88, iters: 1664, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 88, iters: 1744, time: 0.092, data: 0.011) loss: 0.018 
(epoch: 88, iters: 1824, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 88, iters: 1904, time: 0.094, data: 0.012) loss: 0.376 
(epoch: 88, iters: 1984, time: 0.095, data: 0.000) loss: 0.028 
(epoch: 88, iters: 2064, time: 0.094, data: 0.000) loss: 0.054 
(epoch: 88, iters: 2144, time: 0.094, data: 0.039) loss: 0.009 
(epoch: 88, iters: 2224, time: 0.095, data: 0.000) loss: 0.095 
(epoch: 88, iters: 2304, time: 0.092, data: 0.012) loss: 0.005 
(epoch: 88, iters: 2384, time: 0.094, data: 0.000) loss: 0.033 
(epoch: 88, iters: 2464, time: 0.094, data: 0.011) loss: 0.007 
(epoch: 88, iters: 2544, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 88, iters: 2624, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 88, iters: 2704, time: 0.094, data: 0.040) loss: 0.004 
(epoch: 88, iters: 2784, time: 0.095, data: 0.000) loss: 0.165 
(epoch: 88, iters: 2864, time: 0.093, data: 0.021) loss: 0.001 
(epoch: 88, iters: 2944, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 88, iters: 3024, time: 0.093, data: 0.012) loss: 0.027 
(epoch: 88, iters: 3104, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 88, iters: 3184, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 88, iters: 3264, time: 0.108, data: 0.039) loss: 0.008 
(epoch: 88, iters: 3344, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 88, iters: 3424, time: 0.098, data: 0.012) loss: 0.002 
(epoch: 88, iters: 3504, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 88, iters: 3584, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 88, iters: 3664, time: 0.088, data: 0.000) loss: 0.002 
saving the model at the end of epoch 88, iters 328064
End of epoch 88 / 2100 	 Time Taken: 358 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 88, TEST ACC: [94.385 %]

(epoch: 89, iters: 16, time: 0.110, data: 0.000) loss: 0.008 
saving the latest model (epoch 89, total_steps 328080)
(epoch: 89, iters: 96, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 89, iters: 176, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 89, iters: 256, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 89, iters: 336, time: 0.101, data: 0.012) loss: 0.004 
(epoch: 89, iters: 416, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 89, iters: 496, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 89, iters: 576, time: 0.097, data: 0.039) loss: 0.005 
(epoch: 89, iters: 656, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 89, iters: 736, time: 0.094, data: 0.011) loss: 0.008 
(epoch: 89, iters: 816, time: 0.094, data: 0.000) loss: 0.083 
(epoch: 89, iters: 896, time: 0.102, data: 0.012) loss: 0.006 
(epoch: 89, iters: 976, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 89, iters: 1056, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 89, iters: 1136, time: 0.095, data: 0.039) loss: 0.011 
(epoch: 89, iters: 1216, time: 0.095, data: 0.000) loss: 0.092 
(epoch: 89, iters: 1296, time: 0.093, data: 0.012) loss: 0.035 
(epoch: 89, iters: 1376, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 89, iters: 1456, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 89, iters: 1536, time: 0.096, data: 0.000) loss: 0.018 
(epoch: 89, iters: 1616, time: 0.094, data: 0.000) loss: 0.029 
(epoch: 89, iters: 1696, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 89, iters: 1776, time: 0.098, data: 0.000) loss: 0.017 
(epoch: 89, iters: 1856, time: 0.095, data: 0.012) loss: 0.050 
(epoch: 89, iters: 1936, time: 0.095, data: 0.000) loss: 0.132 
(epoch: 89, iters: 2016, time: 0.100, data: 0.012) loss: 0.031 
(epoch: 89, iters: 2096, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 89, iters: 2176, time: 0.093, data: 0.000) loss: 0.056 
(epoch: 89, iters: 2256, time: 0.095, data: 0.048) loss: 0.007 
(epoch: 89, iters: 2336, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 89, iters: 2416, time: 0.092, data: 0.012) loss: 0.029 
(epoch: 89, iters: 2496, time: 0.095, data: 0.000) loss: 0.309 
(epoch: 89, iters: 2576, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 89, iters: 2656, time: 0.095, data: 0.000) loss: 0.044 
(epoch: 89, iters: 2736, time: 0.093, data: 0.000) loss: 0.096 
(epoch: 89, iters: 2816, time: 0.096, data: 0.053) loss: 0.001 
(epoch: 89, iters: 2896, time: 0.096, data: 0.000) loss: 0.015 
(epoch: 89, iters: 2976, time: 0.098, data: 0.012) loss: 0.001 
(epoch: 89, iters: 3056, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 89, iters: 3136, time: 0.100, data: 0.012) loss: 0.002 
(epoch: 89, iters: 3216, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 89, iters: 3296, time: 0.097, data: 0.000) loss: 0.172 
(epoch: 89, iters: 3376, time: 0.098, data: 0.052) loss: 0.001 
(epoch: 89, iters: 3456, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 89, iters: 3536, time: 0.093, data: 0.012) loss: 0.039 
(epoch: 89, iters: 3616, time: 0.103, data: 0.000) loss: 0.024 
(epoch: 89, iters: 3696, time: 0.091, data: 0.012) loss: 0.114 
saving the model at the end of epoch 89, iters 331792
End of epoch 89 / 2100 	 Time Taken: 359 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 89, TEST ACC: [93.627 %]

saving the latest model (epoch 90, total_steps 331808)
(epoch: 90, iters: 48, time: 0.101, data: 0.000) loss: 0.050 
(epoch: 90, iters: 128, time: 0.096, data: 0.012) loss: 0.004 
(epoch: 90, iters: 208, time: 0.092, data: 0.012) loss: 0.022 
(epoch: 90, iters: 288, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 90, iters: 368, time: 0.094, data: 0.011) loss: 0.017 
(epoch: 90, iters: 448, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 90, iters: 528, time: 0.101, data: 0.000) loss: 0.045 
(epoch: 90, iters: 608, time: 0.094, data: 0.040) loss: 0.050 
(epoch: 90, iters: 688, time: 0.095, data: 0.000) loss: 0.021 
(epoch: 90, iters: 768, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 90, iters: 848, time: 0.094, data: 0.000) loss: 0.052 
(epoch: 90, iters: 928, time: 0.094, data: 0.011) loss: 0.004 
(epoch: 90, iters: 1008, time: 0.097, data: 0.000) loss: 0.205 
(epoch: 90, iters: 1088, time: 0.093, data: 0.000) loss: 0.042 
(epoch: 90, iters: 1168, time: 0.099, data: 0.000) loss: 0.012 
(epoch: 90, iters: 1248, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 90, iters: 1328, time: 0.095, data: 0.000) loss: 0.025 
(epoch: 90, iters: 1408, time: 0.099, data: 0.049) loss: 0.107 
(epoch: 90, iters: 1488, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 90, iters: 1568, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 90, iters: 1648, time: 0.101, data: 0.000) loss: 0.008 
(epoch: 90, iters: 1728, time: 0.094, data: 0.012) loss: 0.015 
(epoch: 90, iters: 1808, time: 0.095, data: 0.000) loss: 0.833 
(epoch: 90, iters: 1888, time: 0.096, data: 0.000) loss: 0.072 
(epoch: 90, iters: 1968, time: 0.094, data: 0.039) loss: 0.286 
(epoch: 90, iters: 2048, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 90, iters: 2128, time: 0.094, data: 0.011) loss: 0.098 
(epoch: 90, iters: 2208, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 90, iters: 2288, time: 0.097, data: 0.012) loss: 0.163 
(epoch: 90, iters: 2368, time: 0.096, data: 0.000) loss: 0.028 
(epoch: 90, iters: 2448, time: 0.099, data: 0.000) loss: 0.015 
(epoch: 90, iters: 2528, time: 0.091, data: 0.035) loss: 0.005 
(epoch: 90, iters: 2608, time: 0.095, data: 0.000) loss: 0.044 
(epoch: 90, iters: 2688, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 90, iters: 2768, time: 0.101, data: 0.012) loss: 0.032 
(epoch: 90, iters: 2848, time: 0.093, data: 0.026) loss: 0.058 
(epoch: 90, iters: 2928, time: 0.093, data: 0.000) loss: 0.027 
(epoch: 90, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 90, iters: 3088, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 90, iters: 3168, time: 0.093, data: 0.027) loss: 0.017 
(epoch: 90, iters: 3248, time: 0.094, data: 0.000) loss: 0.121 
(epoch: 90, iters: 3328, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 90, iters: 3408, time: 0.100, data: 0.021) loss: 0.007 
(epoch: 90, iters: 3488, time: 0.095, data: 0.026) loss: 0.006 
(epoch: 90, iters: 3568, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 90, iters: 3648, time: 0.088, data: 0.000) loss: 0.010 
(epoch: 90, iters: 3728, time: 0.056, data: 0.012) loss: 0.006 
saving the model at the end of epoch 90, iters 335520
End of epoch 90 / 2100 	 Time Taken: 359 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 90, TEST ACC: [57.967 %]

saving the latest model (epoch 91, total_steps 335536)
(epoch: 91, iters: 80, time: 0.096, data: 0.514) loss: 0.008 
(epoch: 91, iters: 160, time: 0.094, data: 0.030) loss: 0.102 
(epoch: 91, iters: 240, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 91, iters: 320, time: 0.094, data: 0.011) loss: 0.122 
(epoch: 91, iters: 400, time: 0.093, data: 0.025) loss: 0.016 
(epoch: 91, iters: 480, time: 0.096, data: 0.000) loss: 0.115 
(epoch: 91, iters: 560, time: 0.094, data: 0.000) loss: 0.025 
(epoch: 91, iters: 640, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 91, iters: 720, time: 0.092, data: 0.025) loss: 0.002 
(epoch: 91, iters: 800, time: 0.095, data: 0.000) loss: 0.022 
(epoch: 91, iters: 880, time: 0.097, data: 0.000) loss: 0.015 
(epoch: 91, iters: 960, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 91, iters: 1040, time: 0.096, data: 0.027) loss: 0.001 
(epoch: 91, iters: 1120, time: 0.096, data: 0.000) loss: 0.077 
(epoch: 91, iters: 1200, time: 0.101, data: 0.000) loss: 0.002 
(epoch: 91, iters: 1280, time: 0.095, data: 0.011) loss: 0.013 
(epoch: 91, iters: 1360, time: 0.093, data: 0.034) loss: 0.000 
(epoch: 91, iters: 1440, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 91, iters: 1520, time: 0.101, data: 0.000) loss: 0.001 
(epoch: 91, iters: 1600, time: 0.094, data: 0.012) loss: 0.011 
(epoch: 91, iters: 1680, time: 0.093, data: 0.027) loss: 0.018 
(epoch: 91, iters: 1760, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 91, iters: 1840, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 91, iters: 1920, time: 0.094, data: 0.012) loss: 0.005 
(epoch: 91, iters: 2000, time: 0.092, data: 0.026) loss: 0.001 
(epoch: 91, iters: 2080, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 91, iters: 2160, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 91, iters: 2240, time: 0.102, data: 0.000) loss: 0.002 
(epoch: 91, iters: 2320, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 91, iters: 2400, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 91, iters: 2480, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 91, iters: 2560, time: 0.095, data: 0.048) loss: 0.068 
(epoch: 91, iters: 2640, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 91, iters: 2720, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 91, iters: 2800, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 91, iters: 2880, time: 0.096, data: 0.012) loss: 0.028 
(epoch: 91, iters: 2960, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 91, iters: 3040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 91, iters: 3120, time: 0.097, data: 0.049) loss: 0.001 
(epoch: 91, iters: 3200, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 91, iters: 3280, time: 0.101, data: 0.012) loss: 0.003 
(epoch: 91, iters: 3360, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 91, iters: 3440, time: 0.096, data: 0.012) loss: 0.002 
(epoch: 91, iters: 3520, time: 0.105, data: 0.000) loss: 0.023 
(epoch: 91, iters: 3600, time: 0.095, data: 0.000) loss: 0.076 
(epoch: 91, iters: 3680, time: 0.090, data: 0.050) loss: 0.001 
saving the model at the end of epoch 91, iters 339248
End of epoch 91 / 2100 	 Time Taken: 359 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 91, TEST ACC: [93.627 %]

saving the latest model (epoch 92, total_steps 339264)
(epoch: 92, iters: 32, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 92, iters: 112, time: 0.099, data: 0.000) loss: 0.046 
(epoch: 92, iters: 192, time: 0.096, data: 0.000) loss: 0.014 
(epoch: 92, iters: 272, time: 0.096, data: 0.040) loss: 0.013 
(epoch: 92, iters: 352, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 92, iters: 432, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 92, iters: 512, time: 0.097, data: 0.000) loss: 0.021 
(epoch: 92, iters: 592, time: 0.103, data: 0.012) loss: 0.004 
(epoch: 92, iters: 672, time: 0.110, data: 0.000) loss: 0.004 
(epoch: 92, iters: 752, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 92, iters: 832, time: 0.097, data: 0.048) loss: 0.003 
(epoch: 92, iters: 912, time: 0.097, data: 0.000) loss: 0.008 
(epoch: 92, iters: 992, time: 0.099, data: 0.011) loss: 0.005 
(epoch: 92, iters: 1072, time: 0.101, data: 0.000) loss: 0.073 
(epoch: 92, iters: 1152, time: 0.101, data: 0.012) loss: 0.021 
(epoch: 92, iters: 1232, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 92, iters: 1312, time: 0.094, data: 0.000) loss: 0.250 
(epoch: 92, iters: 1392, time: 0.101, data: 0.051) loss: 0.111 
(epoch: 92, iters: 1472, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 92, iters: 1552, time: 0.094, data: 0.011) loss: 0.043 
(epoch: 92, iters: 1632, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 92, iters: 1712, time: 0.101, data: 0.000) loss: 0.018 
(epoch: 92, iters: 1792, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 92, iters: 1872, time: 0.093, data: 0.012) loss: 0.015 
(epoch: 92, iters: 1952, time: 0.093, data: 0.025) loss: 0.048 
(epoch: 92, iters: 2032, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 92, iters: 2112, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 92, iters: 2192, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 92, iters: 2272, time: 0.093, data: 0.025) loss: 0.002 
(epoch: 92, iters: 2352, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 92, iters: 2432, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 92, iters: 2512, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 92, iters: 2592, time: 0.095, data: 0.025) loss: 0.004 
(epoch: 92, iters: 2672, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 92, iters: 2752, time: 0.094, data: 0.000) loss: 0.174 
(epoch: 92, iters: 2832, time: 0.094, data: 0.012) loss: 0.006 
(epoch: 92, iters: 2912, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 92, iters: 2992, time: 0.094, data: 0.000) loss: 0.127 
(epoch: 92, iters: 3072, time: 0.093, data: 0.039) loss: 0.077 
(epoch: 92, iters: 3152, time: 0.095, data: 0.000) loss: 0.020 
(epoch: 92, iters: 3232, time: 0.094, data: 0.012) loss: 0.020 
(epoch: 92, iters: 3312, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 92, iters: 3392, time: 0.094, data: 0.012) loss: 0.044 
(epoch: 92, iters: 3472, time: 0.096, data: 0.000) loss: 0.023 
(epoch: 92, iters: 3552, time: 0.093, data: 0.000) loss: 0.013 
(epoch: 92, iters: 3632, time: 0.092, data: 0.039) loss: 0.033 
(epoch: 92, iters: 3712, time: 0.091, data: 0.000) loss: 0.004 
saving the model at the end of epoch 92, iters 342976
End of epoch 92 / 2100 	 Time Taken: 359 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 92, TEST ACC: [89.985 %]

saving the latest model (epoch 93, total_steps 342992)
(epoch: 93, iters: 64, time: 0.099, data: 0.000) loss: 0.007 
(epoch: 93, iters: 144, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 93, iters: 224, time: 0.101, data: 0.011) loss: 0.002 
(epoch: 93, iters: 304, time: 0.094, data: 0.000) loss: 0.422 
(epoch: 93, iters: 384, time: 0.093, data: 0.000) loss: 0.035 
(epoch: 93, iters: 464, time: 0.096, data: 0.049) loss: 0.090 
(epoch: 93, iters: 544, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 93, iters: 624, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 93, iters: 704, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 93, iters: 784, time: 0.096, data: 0.011) loss: 0.009 
(epoch: 93, iters: 864, time: 0.097, data: 0.000) loss: 0.251 
(epoch: 93, iters: 944, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 93, iters: 1024, time: 0.095, data: 0.048) loss: 0.003 
(epoch: 93, iters: 1104, time: 0.094, data: 0.000) loss: 0.056 
(epoch: 93, iters: 1184, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 93, iters: 1264, time: 0.095, data: 0.000) loss: 0.334 
(epoch: 93, iters: 1344, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 93, iters: 1424, time: 0.101, data: 0.000) loss: 0.015 
(epoch: 93, iters: 1504, time: 0.093, data: 0.000) loss: 0.020 
(epoch: 93, iters: 1584, time: 0.096, data: 0.048) loss: 0.014 
(epoch: 93, iters: 1664, time: 0.095, data: 0.000) loss: 0.062 
(epoch: 93, iters: 1744, time: 0.092, data: 0.011) loss: 0.008 
(epoch: 93, iters: 1824, time: 0.095, data: 0.000) loss: 0.150 
(epoch: 93, iters: 1904, time: 0.093, data: 0.011) loss: 0.015 
(epoch: 93, iters: 1984, time: 0.095, data: 0.000) loss: 0.737 
(epoch: 93, iters: 2064, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 93, iters: 2144, time: 0.096, data: 0.048) loss: 0.080 
(epoch: 93, iters: 2224, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 93, iters: 2304, time: 0.092, data: 0.011) loss: 0.008 
(epoch: 93, iters: 2384, time: 0.094, data: 0.000) loss: 0.164 
(epoch: 93, iters: 2464, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 93, iters: 2544, time: 0.096, data: 0.000) loss: 0.089 
(epoch: 93, iters: 2624, time: 0.095, data: 0.000) loss: 0.107 
(epoch: 93, iters: 2704, time: 0.095, data: 0.040) loss: 0.189 
(epoch: 93, iters: 2784, time: 0.097, data: 0.000) loss: 0.071 
(epoch: 93, iters: 2864, time: 0.094, data: 0.012) loss: 0.005 
(epoch: 93, iters: 2944, time: 0.107, data: 0.000) loss: 0.009 
(epoch: 93, iters: 3024, time: 0.094, data: 0.012) loss: 0.050 
(epoch: 93, iters: 3104, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 93, iters: 3184, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 93, iters: 3264, time: 0.094, data: 0.040) loss: 0.207 
(epoch: 93, iters: 3344, time: 0.101, data: 0.000) loss: 0.063 
(epoch: 93, iters: 3424, time: 0.094, data: 0.011) loss: 0.009 
(epoch: 93, iters: 3504, time: 0.095, data: 0.000) loss: 0.044 
(epoch: 93, iters: 3584, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 93, iters: 3664, time: 0.090, data: 0.000) loss: 0.002 
saving the model at the end of epoch 93, iters 346704
End of epoch 93 / 2100 	 Time Taken: 357 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 93, TEST ACC: [89.985 %]

(epoch: 94, iters: 16, time: 0.115, data: 0.000) loss: 0.130 
saving the latest model (epoch 94, total_steps 346720)
(epoch: 94, iters: 96, time: 0.098, data: 0.000) loss: 0.005 
(epoch: 94, iters: 176, time: 0.094, data: 0.012) loss: 0.065 
(epoch: 94, iters: 256, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 94, iters: 336, time: 0.097, data: 0.012) loss: 0.094 
(epoch: 94, iters: 416, time: 0.094, data: 0.000) loss: 0.167 
(epoch: 94, iters: 496, time: 0.093, data: 0.000) loss: 0.036 
(epoch: 94, iters: 576, time: 0.095, data: 0.041) loss: 0.002 
(epoch: 94, iters: 656, time: 0.102, data: 0.000) loss: 0.018 
(epoch: 94, iters: 736, time: 0.092, data: 0.011) loss: 0.035 
(epoch: 94, iters: 816, time: 0.094, data: 0.000) loss: 0.035 
(epoch: 94, iters: 896, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 94, iters: 976, time: 0.101, data: 0.000) loss: 0.023 
(epoch: 94, iters: 1056, time: 0.094, data: 0.000) loss: 0.017 
(epoch: 94, iters: 1136, time: 0.095, data: 0.039) loss: 0.016 
(epoch: 94, iters: 1216, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 94, iters: 1296, time: 0.094, data: 0.011) loss: 0.005 
(epoch: 94, iters: 1376, time: 0.102, data: 0.000) loss: 0.073 
(epoch: 94, iters: 1456, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 94, iters: 1536, time: 0.102, data: 0.000) loss: 0.022 
(epoch: 94, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 94, iters: 1696, time: 0.094, data: 0.039) loss: 0.243 
(epoch: 94, iters: 1776, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 94, iters: 1856, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 94, iters: 1936, time: 0.101, data: 0.000) loss: 0.004 
(epoch: 94, iters: 2016, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 94, iters: 2096, time: 0.097, data: 0.000) loss: 0.079 
(epoch: 94, iters: 2176, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 94, iters: 2256, time: 0.095, data: 0.040) loss: 0.202 
(epoch: 94, iters: 2336, time: 0.095, data: 0.000) loss: 0.022 
(epoch: 94, iters: 2416, time: 0.093, data: 0.011) loss: 0.018 
(epoch: 94, iters: 2496, time: 0.102, data: 0.000) loss: 0.318 
(epoch: 94, iters: 2576, time: 0.093, data: 0.011) loss: 0.009 
(epoch: 94, iters: 2656, time: 0.095, data: 0.000) loss: 0.074 
(epoch: 94, iters: 2736, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 94, iters: 2816, time: 0.096, data: 0.048) loss: 0.081 
(epoch: 94, iters: 2896, time: 0.095, data: 0.000) loss: 0.065 
(epoch: 94, iters: 2976, time: 0.100, data: 0.012) loss: 0.014 
(epoch: 94, iters: 3056, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 94, iters: 3136, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 94, iters: 3216, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 94, iters: 3296, time: 0.101, data: 0.011) loss: 0.046 
(epoch: 94, iters: 3376, time: 0.096, data: 0.025) loss: 0.096 
(epoch: 94, iters: 3456, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 94, iters: 3536, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 94, iters: 3616, time: 0.094, data: 0.013) loss: 0.022 
(epoch: 94, iters: 3696, time: 0.089, data: 0.025) loss: 0.155 
saving the model at the end of epoch 94, iters 350432
End of epoch 94 / 2100 	 Time Taken: 359 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 94, TEST ACC: [94.082 %]

saving the latest model (epoch 95, total_steps 350448)
(epoch: 95, iters: 48, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 95, iters: 128, time: 0.102, data: 0.042) loss: 0.006 
(epoch: 95, iters: 208, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 95, iters: 288, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 95, iters: 368, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 95, iters: 448, time: 0.094, data: 0.011) loss: 0.007 
(epoch: 95, iters: 528, time: 0.096, data: 0.000) loss: 0.020 
(epoch: 95, iters: 608, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 95, iters: 688, time: 0.095, data: 0.040) loss: 0.033 
(epoch: 95, iters: 768, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 95, iters: 848, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 95, iters: 928, time: 0.097, data: 0.000) loss: 0.020 
(epoch: 95, iters: 1008, time: 0.102, data: 0.012) loss: 0.003 
(epoch: 95, iters: 1088, time: 0.095, data: 0.000) loss: 0.034 
(epoch: 95, iters: 1168, time: 0.101, data: 0.000) loss: 0.027 
(epoch: 95, iters: 1248, time: 0.104, data: 0.049) loss: 0.002 
(epoch: 95, iters: 1328, time: 0.095, data: 0.000) loss: 0.095 
(epoch: 95, iters: 1408, time: 0.093, data: 0.012) loss: 0.015 
(epoch: 95, iters: 1488, time: 0.095, data: 0.000) loss: 0.026 
(epoch: 95, iters: 1568, time: 0.093, data: 0.013) loss: 0.004 
(epoch: 95, iters: 1648, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 95, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 95, iters: 1808, time: 0.095, data: 0.050) loss: 0.014 
(epoch: 95, iters: 1888, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 95, iters: 1968, time: 0.093, data: 0.012) loss: 0.015 
(epoch: 95, iters: 2048, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 95, iters: 2128, time: 0.094, data: 0.011) loss: 0.014 
(epoch: 95, iters: 2208, time: 0.102, data: 0.000) loss: 0.007 
(epoch: 95, iters: 2288, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 95, iters: 2368, time: 0.096, data: 0.041) loss: 0.178 
(epoch: 95, iters: 2448, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 95, iters: 2528, time: 0.093, data: 0.011) loss: 0.091 
(epoch: 95, iters: 2608, time: 0.101, data: 0.000) loss: 0.079 
(epoch: 95, iters: 2688, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 95, iters: 2768, time: 0.103, data: 0.000) loss: 0.010 
(epoch: 95, iters: 2848, time: 0.095, data: 0.000) loss: 0.191 
(epoch: 95, iters: 2928, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 95, iters: 3008, time: 0.094, data: 0.000) loss: 0.032 
(epoch: 95, iters: 3088, time: 0.093, data: 0.011) loss: 0.017 
(epoch: 95, iters: 3168, time: 0.095, data: 0.000) loss: 0.023 
(epoch: 95, iters: 3248, time: 0.094, data: 0.011) loss: 0.139 
(epoch: 95, iters: 3328, time: 0.097, data: 0.000) loss: 0.019 
(epoch: 95, iters: 3408, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 95, iters: 3488, time: 0.095, data: 0.038) loss: 0.054 
(epoch: 95, iters: 3568, time: 0.095, data: 0.000) loss: 0.020 
(epoch: 95, iters: 3648, time: 0.087, data: 0.011) loss: 0.040 
(epoch: 95, iters: 3728, time: 0.057, data: 0.000) loss: 0.001 
saving the model at the end of epoch 95, iters 354160
End of epoch 95 / 2100 	 Time Taken: 359 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 95, TEST ACC: [92.564 %]

saving the latest model (epoch 96, total_steps 354176)
(epoch: 96, iters: 80, time: 0.095, data: 0.481) loss: 0.364 
(epoch: 96, iters: 160, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 96, iters: 240, time: 0.096, data: 0.039) loss: 0.005 
(epoch: 96, iters: 320, time: 0.102, data: 0.000) loss: 0.005 
(epoch: 96, iters: 400, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 96, iters: 480, time: 0.097, data: 0.000) loss: 0.162 
(epoch: 96, iters: 560, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 96, iters: 640, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 96, iters: 720, time: 0.094, data: 0.000) loss: 0.035 
(epoch: 96, iters: 800, time: 0.094, data: 0.039) loss: 0.016 
(epoch: 96, iters: 880, time: 0.096, data: 0.000) loss: 0.067 
(epoch: 96, iters: 960, time: 0.092, data: 0.011) loss: 0.006 
(epoch: 96, iters: 1040, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 96, iters: 1120, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 96, iters: 1200, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 96, iters: 1280, time: 0.100, data: 0.000) loss: 0.006 
(epoch: 96, iters: 1360, time: 0.094, data: 0.039) loss: 0.106 
(epoch: 96, iters: 1440, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 96, iters: 1520, time: 0.095, data: 0.011) loss: 0.274 
(epoch: 96, iters: 1600, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 96, iters: 1680, time: 0.094, data: 0.011) loss: 0.008 
(epoch: 96, iters: 1760, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 96, iters: 1840, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 96, iters: 1920, time: 0.095, data: 0.040) loss: 0.002 
(epoch: 96, iters: 2000, time: 0.101, data: 0.000) loss: 0.001 
(epoch: 96, iters: 2080, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 96, iters: 2160, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 96, iters: 2240, time: 0.096, data: 0.012) loss: 0.007 
(epoch: 96, iters: 2320, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 96, iters: 2400, time: 0.094, data: 0.000) loss: 0.046 
(epoch: 96, iters: 2480, time: 0.095, data: 0.050) loss: 0.005 
(epoch: 96, iters: 2560, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 96, iters: 2640, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 96, iters: 2720, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 96, iters: 2800, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 96, iters: 2880, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 96, iters: 2960, time: 0.094, data: 0.000) loss: 0.023 
(epoch: 96, iters: 3040, time: 0.094, data: 0.041) loss: 0.002 
(epoch: 96, iters: 3120, time: 0.096, data: 0.000) loss: 0.105 
(epoch: 96, iters: 3200, time: 0.095, data: 0.011) loss: 0.025 
(epoch: 96, iters: 3280, time: 0.093, data: 0.026) loss: 0.027 
(epoch: 96, iters: 3360, time: 0.101, data: 0.000) loss: 0.002 
(epoch: 96, iters: 3440, time: 0.102, data: 0.000) loss: 0.103 
(epoch: 96, iters: 3520, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 96, iters: 3600, time: 0.094, data: 0.024) loss: 0.046 
(epoch: 96, iters: 3680, time: 0.089, data: 0.000) loss: 0.006 
saving the model at the end of epoch 96, iters 357888
End of epoch 96 / 2100 	 Time Taken: 358 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 96, TEST ACC: [91.806 %]

saving the latest model (epoch 97, total_steps 357904)
(epoch: 97, iters: 32, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 97, iters: 112, time: 0.094, data: 0.000) loss: 0.026 
(epoch: 97, iters: 192, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 97, iters: 272, time: 0.094, data: 0.000) loss: 0.044 
(epoch: 97, iters: 352, time: 0.097, data: 0.040) loss: 0.010 
(epoch: 97, iters: 432, time: 0.095, data: 0.000) loss: 0.033 
(epoch: 97, iters: 512, time: 0.095, data: 0.011) loss: 0.124 
(epoch: 97, iters: 592, time: 0.102, data: 0.000) loss: 0.007 
(epoch: 97, iters: 672, time: 0.096, data: 0.011) loss: 0.004 
(epoch: 97, iters: 752, time: 0.096, data: 0.000) loss: 0.132 
(epoch: 97, iters: 832, time: 0.094, data: 0.000) loss: 0.162 
(epoch: 97, iters: 912, time: 0.096, data: 0.039) loss: 0.004 
(epoch: 97, iters: 992, time: 0.098, data: 0.000) loss: 0.145 
(epoch: 97, iters: 1072, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 97, iters: 1152, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 97, iters: 1232, time: 0.094, data: 0.012) loss: 0.065 
(epoch: 97, iters: 1312, time: 0.096, data: 0.000) loss: 0.044 
(epoch: 97, iters: 1392, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 97, iters: 1472, time: 0.095, data: 0.040) loss: 0.007 
(epoch: 97, iters: 1552, time: 0.095, data: 0.000) loss: 0.041 
(epoch: 97, iters: 1632, time: 0.094, data: 0.011) loss: 0.020 
(epoch: 97, iters: 1712, time: 0.096, data: 0.000) loss: 0.025 
(epoch: 97, iters: 1792, time: 0.100, data: 0.012) loss: 0.098 
(epoch: 97, iters: 1872, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 97, iters: 1952, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 97, iters: 2032, time: 0.095, data: 0.038) loss: 0.052 
(epoch: 97, iters: 2112, time: 0.096, data: 0.000) loss: 0.059 
(epoch: 97, iters: 2192, time: 0.095, data: 0.012) loss: 0.152 
(epoch: 97, iters: 2272, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 97, iters: 2352, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 97, iters: 2432, time: 0.095, data: 0.000) loss: 0.122 
(epoch: 97, iters: 2512, time: 0.094, data: 0.000) loss: 0.087 
(epoch: 97, iters: 2592, time: 0.096, data: 0.039) loss: 0.002 
(epoch: 97, iters: 2672, time: 0.097, data: 0.000) loss: 0.020 
(epoch: 97, iters: 2752, time: 0.096, data: 0.011) loss: 0.003 
(epoch: 97, iters: 2832, time: 0.096, data: 0.000) loss: 0.044 
(epoch: 97, iters: 2912, time: 0.095, data: 0.020) loss: 0.005 
(epoch: 97, iters: 2992, time: 0.096, data: 0.000) loss: 0.047 
(epoch: 97, iters: 3072, time: 0.102, data: 0.000) loss: 0.205 
(epoch: 97, iters: 3152, time: 0.095, data: 0.041) loss: 0.023 
(epoch: 97, iters: 3232, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 97, iters: 3312, time: 0.101, data: 0.012) loss: 0.004 
(epoch: 97, iters: 3392, time: 0.097, data: 0.000) loss: 0.034 
(epoch: 97, iters: 3472, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 97, iters: 3552, time: 0.096, data: 0.000) loss: 0.014 
(epoch: 97, iters: 3632, time: 0.093, data: 0.000) loss: 0.039 
(epoch: 97, iters: 3712, time: 0.090, data: 0.036) loss: 0.003 
saving the model at the end of epoch 97, iters 361616
End of epoch 97 / 2100 	 Time Taken: 359 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 97, TEST ACC: [90.44 %]

saving the latest model (epoch 98, total_steps 361632)
(epoch: 98, iters: 64, time: 0.095, data: 0.000) loss: 0.023 
(epoch: 98, iters: 144, time: 0.098, data: 0.000) loss: 0.003 
(epoch: 98, iters: 224, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 98, iters: 304, time: 0.096, data: 0.000) loss: 0.148 
(epoch: 98, iters: 384, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 98, iters: 464, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 98, iters: 544, time: 0.097, data: 0.000) loss: 0.025 
(epoch: 98, iters: 624, time: 0.099, data: 0.011) loss: 0.002 
(epoch: 98, iters: 704, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 98, iters: 784, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 98, iters: 864, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 98, iters: 944, time: 0.100, data: 0.000) loss: 0.003 
(epoch: 98, iters: 1024, time: 0.096, data: 0.039) loss: 0.109 
(epoch: 98, iters: 1104, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 98, iters: 1184, time: 0.094, data: 0.012) loss: 0.007 
(epoch: 98, iters: 1264, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 98, iters: 1344, time: 0.096, data: 0.020) loss: 0.075 
(epoch: 98, iters: 1424, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 98, iters: 1504, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 98, iters: 1584, time: 0.095, data: 0.039) loss: 0.011 
(epoch: 98, iters: 1664, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 98, iters: 1744, time: 0.101, data: 0.000) loss: 0.023 
(epoch: 98, iters: 1824, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 98, iters: 1904, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 98, iters: 1984, time: 0.093, data: 0.011) loss: 0.012 
(epoch: 98, iters: 2064, time: 0.095, data: 0.000) loss: 0.103 
(epoch: 98, iters: 2144, time: 0.095, data: 0.012) loss: 0.007 
(epoch: 98, iters: 2224, time: 0.102, data: 0.000) loss: 0.080 
(epoch: 98, iters: 2304, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 98, iters: 2384, time: 0.095, data: 0.039) loss: 0.028 
(epoch: 98, iters: 2464, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 98, iters: 2544, time: 0.101, data: 0.013) loss: 0.002 
(epoch: 98, iters: 2624, time: 0.103, data: 0.000) loss: 0.002 
(epoch: 98, iters: 2704, time: 0.095, data: 0.000) loss: 0.031 
(epoch: 98, iters: 2784, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 98, iters: 2864, time: 0.095, data: 0.025) loss: 0.009 
(epoch: 98, iters: 2944, time: 0.101, data: 0.000) loss: 0.004 
(epoch: 98, iters: 3024, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 98, iters: 3104, time: 0.102, data: 0.000) loss: 0.002 
(epoch: 98, iters: 3184, time: 0.095, data: 0.000) loss: 0.457 
(epoch: 98, iters: 3264, time: 0.095, data: 0.051) loss: 0.006 
(epoch: 98, iters: 3344, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 98, iters: 3424, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 98, iters: 3504, time: 0.094, data: 0.000) loss: 0.020 
(epoch: 98, iters: 3584, time: 0.094, data: 0.012) loss: 0.009 
(epoch: 98, iters: 3664, time: 0.089, data: 0.000) loss: 0.004 
saving the model at the end of epoch 98, iters 365344
End of epoch 98 / 2100 	 Time Taken: 359 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 98, TEST ACC: [71.168 %]

(epoch: 99, iters: 16, time: 0.113, data: 0.000) loss: 0.008 
saving the latest model (epoch 99, total_steps 365360)
(epoch: 99, iters: 96, time: 0.095, data: 0.011) loss: 0.007 
(epoch: 99, iters: 176, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 99, iters: 256, time: 0.096, data: 0.000) loss: 0.021 
(epoch: 99, iters: 336, time: 0.095, data: 0.012) loss: 0.011 
(epoch: 99, iters: 416, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 99, iters: 496, time: 0.094, data: 0.000) loss: 0.020 
(epoch: 99, iters: 576, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 99, iters: 656, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 99, iters: 736, time: 0.093, data: 0.012) loss: 0.008 
(epoch: 99, iters: 816, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 99, iters: 896, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 99, iters: 976, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 99, iters: 1056, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 99, iters: 1136, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 99, iters: 1216, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 99, iters: 1296, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 99, iters: 1376, time: 0.095, data: 0.000) loss: 0.043 
(epoch: 99, iters: 1456, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 99, iters: 1536, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 99, iters: 1616, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 99, iters: 1696, time: 0.094, data: 0.050) loss: 0.003 
(epoch: 99, iters: 1776, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 99, iters: 1856, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 99, iters: 1936, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 99, iters: 2016, time: 0.094, data: 0.011) loss: 0.036 
(epoch: 99, iters: 2096, time: 0.102, data: 0.000) loss: 0.095 
(epoch: 99, iters: 2176, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 99, iters: 2256, time: 0.096, data: 0.041) loss: 0.016 
(epoch: 99, iters: 2336, time: 0.099, data: 0.000) loss: 0.040 
(epoch: 99, iters: 2416, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 99, iters: 2496, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 99, iters: 2576, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 99, iters: 2656, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 99, iters: 2736, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 99, iters: 2816, time: 0.101, data: 0.040) loss: 0.006 
(epoch: 99, iters: 2896, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 99, iters: 2976, time: 0.098, data: 0.011) loss: 0.003 
(epoch: 99, iters: 3056, time: 0.095, data: 0.000) loss: 0.021 
(epoch: 99, iters: 3136, time: 0.094, data: 0.011) loss: 0.203 
(epoch: 99, iters: 3216, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 99, iters: 3296, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 99, iters: 3376, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 99, iters: 3456, time: 0.094, data: 0.011) loss: 0.105 
(epoch: 99, iters: 3536, time: 0.092, data: 0.025) loss: 0.001 
(epoch: 99, iters: 3616, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 99, iters: 3696, time: 0.088, data: 0.000) loss: 0.245 
saving the model at the end of epoch 99, iters 369072
End of epoch 99 / 2100 	 Time Taken: 357 sec
learning rate = 0.0002000
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 99, TEST ACC: [91.806 %]

saving the latest model (epoch 100, total_steps 369088)
(epoch: 100, iters: 48, time: 0.096, data: 0.004) loss: 0.003 
(epoch: 100, iters: 128, time: 0.110, data: 0.026) loss: 0.002 
(epoch: 100, iters: 208, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 100, iters: 288, time: 0.097, data: 0.000) loss: 0.016 
(epoch: 100, iters: 368, time: 0.097, data: 0.011) loss: 0.862 
(epoch: 100, iters: 448, time: 0.095, data: 0.000) loss: 0.032 
(epoch: 100, iters: 528, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 100, iters: 608, time: 0.094, data: 0.039) loss: 0.002 
(epoch: 100, iters: 688, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 100, iters: 768, time: 0.093, data: 0.012) loss: 0.030 
(epoch: 100, iters: 848, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 100, iters: 928, time: 0.101, data: 0.012) loss: 0.000 
(epoch: 100, iters: 1008, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 100, iters: 1088, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 100, iters: 1168, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 100, iters: 1248, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 100, iters: 1328, time: 0.093, data: 0.012) loss: 0.014 
(epoch: 100, iters: 1408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 100, iters: 1488, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 100, iters: 1568, time: 0.097, data: 0.000) loss: 0.010 
(epoch: 100, iters: 1648, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 100, iters: 1728, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 100, iters: 1808, time: 0.101, data: 0.000) loss: 0.010 
(epoch: 100, iters: 1888, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 100, iters: 1968, time: 0.094, data: 0.000) loss: 0.088 
(epoch: 100, iters: 2048, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 100, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 100, iters: 2208, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 100, iters: 2288, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 100, iters: 2368, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 100, iters: 2448, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 100, iters: 2528, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 100, iters: 2608, time: 0.096, data: 0.012) loss: 0.007 
(epoch: 100, iters: 2688, time: 0.095, data: 0.000) loss: 0.152 
(epoch: 100, iters: 2768, time: 0.095, data: 0.000) loss: 0.027 
(epoch: 100, iters: 2848, time: 0.094, data: 0.039) loss: 0.015 
(epoch: 100, iters: 2928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 100, iters: 3008, time: 0.093, data: 0.012) loss: 0.028 
(epoch: 100, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 100, iters: 3168, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 100, iters: 3248, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 100, iters: 3328, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 100, iters: 3408, time: 0.096, data: 0.039) loss: 0.005 
(epoch: 100, iters: 3488, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 100, iters: 3568, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 100, iters: 3648, time: 0.088, data: 0.000) loss: 0.024 
(epoch: 100, iters: 3728, time: 0.057, data: 0.013) loss: 0.003 
saving the model at the end of epoch 100, iters 372800
End of epoch 100 / 2100 	 Time Taken: 358 sec
learning rate = 0.0001999
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 100, TEST ACC: [91.958 %]

saving the latest model (epoch 101, total_steps 372816)
(epoch: 101, iters: 80, time: 0.095, data: 0.692) loss: 0.222 
(epoch: 101, iters: 160, time: 0.095, data: 0.031) loss: 0.224 
(epoch: 101, iters: 240, time: 0.102, data: 0.000) loss: 0.078 
(epoch: 101, iters: 320, time: 0.094, data: 0.012) loss: 0.232 
(epoch: 101, iters: 400, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 101, iters: 480, time: 0.097, data: 0.000) loss: 0.015 
(epoch: 101, iters: 560, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 101, iters: 640, time: 0.093, data: 0.025) loss: 0.001 
(epoch: 101, iters: 720, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 101, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 101, iters: 880, time: 0.095, data: 0.012) loss: 0.197 
(epoch: 101, iters: 960, time: 0.093, data: 0.035) loss: 0.001 
(epoch: 101, iters: 1040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 101, iters: 1120, time: 0.097, data: 0.000) loss: 0.029 
(epoch: 101, iters: 1200, time: 0.099, data: 0.012) loss: 0.466 
(epoch: 101, iters: 1280, time: 0.094, data: 0.024) loss: 0.058 
(epoch: 101, iters: 1360, time: 0.098, data: 0.000) loss: 0.056 
(epoch: 101, iters: 1440, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 101, iters: 1520, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 101, iters: 1600, time: 0.093, data: 0.026) loss: 0.017 
(epoch: 101, iters: 1680, time: 0.095, data: 0.000) loss: 0.094 
(epoch: 101, iters: 1760, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 101, iters: 1840, time: 0.095, data: 0.011) loss: 0.004 
(epoch: 101, iters: 1920, time: 0.093, data: 0.026) loss: 0.041 
(epoch: 101, iters: 2000, time: 0.094, data: 0.000) loss: 0.273 
(epoch: 101, iters: 2080, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 101, iters: 2160, time: 0.093, data: 0.012) loss: 0.100 
(epoch: 101, iters: 2240, time: 0.094, data: 0.024) loss: 0.019 
(epoch: 101, iters: 2320, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 101, iters: 2400, time: 0.095, data: 0.000) loss: 0.273 
(epoch: 101, iters: 2480, time: 0.096, data: 0.012) loss: 0.010 
(epoch: 101, iters: 2560, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 101, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 101, iters: 2720, time: 0.097, data: 0.000) loss: 0.020 
(epoch: 101, iters: 2800, time: 0.094, data: 0.011) loss: 0.009 
(epoch: 101, iters: 2880, time: 0.093, data: 0.026) loss: 0.022 
(epoch: 101, iters: 2960, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 101, iters: 3040, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 101, iters: 3120, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 101, iters: 3200, time: 0.095, data: 0.040) loss: 0.008 
(epoch: 101, iters: 3280, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 101, iters: 3360, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 101, iters: 3440, time: 0.095, data: 0.000) loss: 0.039 
(epoch: 101, iters: 3520, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 101, iters: 3600, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 101, iters: 3680, time: 0.088, data: 0.000) loss: 0.719 
saving the model at the end of epoch 101, iters 376528
End of epoch 101 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001998
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 101, TEST ACC: [71.775 %]

saving the latest model (epoch 102, total_steps 376544)
(epoch: 102, iters: 32, time: 0.092, data: 0.008) loss: 0.008 
(epoch: 102, iters: 112, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 102, iters: 192, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 102, iters: 272, time: 0.093, data: 0.000) loss: 0.051 
(epoch: 102, iters: 352, time: 0.093, data: 0.049) loss: 0.050 
(epoch: 102, iters: 432, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 102, iters: 512, time: 0.095, data: 0.012) loss: 0.004 
(epoch: 102, iters: 592, time: 0.095, data: 0.000) loss: 0.188 
(epoch: 102, iters: 672, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 102, iters: 752, time: 0.102, data: 0.000) loss: 0.008 
(epoch: 102, iters: 832, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 102, iters: 912, time: 0.095, data: 0.040) loss: 0.027 
(epoch: 102, iters: 992, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 102, iters: 1072, time: 0.094, data: 0.012) loss: 0.012 
(epoch: 102, iters: 1152, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 102, iters: 1232, time: 0.095, data: 0.012) loss: 0.004 
(epoch: 102, iters: 1312, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 102, iters: 1392, time: 0.093, data: 0.000) loss: 0.066 
(epoch: 102, iters: 1472, time: 0.094, data: 0.039) loss: 0.004 
(epoch: 102, iters: 1552, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 102, iters: 1632, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 102, iters: 1712, time: 0.096, data: 0.048) loss: 0.001 
(epoch: 102, iters: 1792, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 102, iters: 1872, time: 0.092, data: 0.012) loss: 0.256 
(epoch: 102, iters: 1952, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 102, iters: 2032, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 102, iters: 2112, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 102, iters: 2192, time: 0.094, data: 0.025) loss: 0.002 
(epoch: 102, iters: 2272, time: 0.095, data: 0.025) loss: 0.042 
(epoch: 102, iters: 2352, time: 0.093, data: 0.022) loss: 0.013 
(epoch: 102, iters: 2432, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 102, iters: 2512, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 102, iters: 2592, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 102, iters: 2672, time: 0.094, data: 0.000) loss: 0.226 
(epoch: 102, iters: 2752, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 102, iters: 2832, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 102, iters: 2912, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 102, iters: 2992, time: 0.095, data: 0.000) loss: 0.018 
(epoch: 102, iters: 3072, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 102, iters: 3152, time: 0.101, data: 0.000) loss: 0.013 
(epoch: 102, iters: 3232, time: 0.100, data: 0.000) loss: 0.087 
(epoch: 102, iters: 3312, time: 0.094, data: 0.039) loss: 0.021 
(epoch: 102, iters: 3392, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 102, iters: 3472, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 102, iters: 3552, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 102, iters: 3632, time: 0.092, data: 0.011) loss: 0.003 
(epoch: 102, iters: 3712, time: 0.089, data: 0.000) loss: 0.021 
saving the model at the end of epoch 102, iters 380256
End of epoch 102 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001997
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 102, TEST ACC: [94.537 %]

saving the latest model (epoch 103, total_steps 380272)
(epoch: 103, iters: 64, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 103, iters: 144, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 103, iters: 224, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 103, iters: 304, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 103, iters: 384, time: 0.095, data: 0.000) loss: 0.161 
(epoch: 103, iters: 464, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 103, iters: 544, time: 0.094, data: 0.041) loss: 0.011 
(epoch: 103, iters: 624, time: 0.094, data: 0.000) loss: 0.024 
(epoch: 103, iters: 704, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 103, iters: 784, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 103, iters: 864, time: 0.094, data: 0.025) loss: 0.213 
(epoch: 103, iters: 944, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 103, iters: 1024, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 103, iters: 1104, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 103, iters: 1184, time: 0.100, data: 0.000) loss: 0.001 
(epoch: 103, iters: 1264, time: 0.096, data: 0.039) loss: 0.001 
(epoch: 103, iters: 1344, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 103, iters: 1424, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 103, iters: 1504, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 103, iters: 1584, time: 0.096, data: 0.020) loss: 0.008 
(epoch: 103, iters: 1664, time: 0.096, data: 0.000) loss: 0.117 
(epoch: 103, iters: 1744, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 103, iters: 1824, time: 0.096, data: 0.040) loss: 0.015 
(epoch: 103, iters: 1904, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 103, iters: 1984, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 103, iters: 2064, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 103, iters: 2144, time: 0.094, data: 0.012) loss: 0.437 
(epoch: 103, iters: 2224, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 103, iters: 2304, time: 0.093, data: 0.000) loss: 0.074 
(epoch: 103, iters: 2384, time: 0.095, data: 0.039) loss: 0.006 
(epoch: 103, iters: 2464, time: 0.095, data: 0.000) loss: 0.261 
(epoch: 103, iters: 2544, time: 0.092, data: 0.012) loss: 0.008 
(epoch: 103, iters: 2624, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 103, iters: 2704, time: 0.094, data: 0.012) loss: 0.005 
(epoch: 103, iters: 2784, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 103, iters: 2864, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 103, iters: 2944, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 103, iters: 3024, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 103, iters: 3104, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 103, iters: 3184, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 103, iters: 3264, time: 0.094, data: 0.012) loss: 0.012 
(epoch: 103, iters: 3344, time: 0.102, data: 0.000) loss: 0.059 
(epoch: 103, iters: 3424, time: 0.101, data: 0.000) loss: 0.001 
(epoch: 103, iters: 3504, time: 0.096, data: 0.041) loss: 0.005 
(epoch: 103, iters: 3584, time: 0.094, data: 0.000) loss: 0.047 
(epoch: 103, iters: 3664, time: 0.088, data: 0.011) loss: 0.006 
saving the model at the end of epoch 103, iters 383984
End of epoch 103 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001996
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 103, TEST ACC: [86.191 %]

(epoch: 104, iters: 16, time: 0.108, data: 0.013) loss: 0.146 
saving the latest model (epoch 104, total_steps 384000)
(epoch: 104, iters: 96, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 104, iters: 176, time: 0.094, data: 0.000) loss: 0.108 
(epoch: 104, iters: 256, time: 0.096, data: 0.050) loss: 0.002 
(epoch: 104, iters: 336, time: 0.094, data: 0.000) loss: 0.041 
(epoch: 104, iters: 416, time: 0.094, data: 0.011) loss: 0.009 
(epoch: 104, iters: 496, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 104, iters: 576, time: 0.094, data: 0.012) loss: 0.059 
(epoch: 104, iters: 656, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 104, iters: 736, time: 0.094, data: 0.000) loss: 0.023 
(epoch: 104, iters: 816, time: 0.095, data: 0.039) loss: 0.017 
(epoch: 104, iters: 896, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 104, iters: 976, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 104, iters: 1056, time: 0.096, data: 0.000) loss: 0.048 
(epoch: 104, iters: 1136, time: 0.094, data: 0.011) loss: 0.213 
(epoch: 104, iters: 1216, time: 0.093, data: 0.025) loss: 0.001 
(epoch: 104, iters: 1296, time: 0.094, data: 0.000) loss: 0.036 
(epoch: 104, iters: 1376, time: 0.101, data: 0.000) loss: 0.002 
(epoch: 104, iters: 1456, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 104, iters: 1536, time: 0.093, data: 0.025) loss: 0.024 
(epoch: 104, iters: 1616, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 104, iters: 1696, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 104, iters: 1776, time: 0.101, data: 0.021) loss: 0.001 
(epoch: 104, iters: 1856, time: 0.092, data: 0.025) loss: 0.010 
(epoch: 104, iters: 1936, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 104, iters: 2016, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 104, iters: 2096, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 104, iters: 2176, time: 0.100, data: 0.000) loss: 0.082 
(epoch: 104, iters: 2256, time: 0.095, data: 0.048) loss: 0.027 
(epoch: 104, iters: 2336, time: 0.096, data: 0.000) loss: 0.045 
(epoch: 104, iters: 2416, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 104, iters: 2496, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 104, iters: 2576, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 104, iters: 2656, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 104, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 104, iters: 2816, time: 0.095, data: 0.048) loss: 0.009 
(epoch: 104, iters: 2896, time: 0.094, data: 0.000) loss: 0.139 
(epoch: 104, iters: 2976, time: 0.093, data: 0.012) loss: 0.032 
(epoch: 104, iters: 3056, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 104, iters: 3136, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 104, iters: 3216, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 104, iters: 3296, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 104, iters: 3376, time: 0.096, data: 0.049) loss: 0.013 
(epoch: 104, iters: 3456, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 104, iters: 3536, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 104, iters: 3616, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 104, iters: 3696, time: 0.087, data: 0.012) loss: 0.245 
saving the model at the end of epoch 104, iters 387712
End of epoch 104 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001995
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 104, TEST ACC: [67.982 %]

saving the latest model (epoch 105, total_steps 387728)
(epoch: 105, iters: 48, time: 0.093, data: 0.000) loss: 0.049 
(epoch: 105, iters: 128, time: 0.095, data: 0.026) loss: 0.018 
(epoch: 105, iters: 208, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 105, iters: 288, time: 0.093, data: 0.012) loss: 0.013 
(epoch: 105, iters: 368, time: 0.094, data: 0.000) loss: 0.035 
(epoch: 105, iters: 448, time: 0.094, data: 0.012) loss: 0.007 
(epoch: 105, iters: 528, time: 0.094, data: 0.000) loss: 0.351 
(epoch: 105, iters: 608, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 105, iters: 688, time: 0.095, data: 0.040) loss: 0.023 
(epoch: 105, iters: 768, time: 0.097, data: 0.000) loss: 0.042 
(epoch: 105, iters: 848, time: 0.094, data: 0.011) loss: 0.006 
(epoch: 105, iters: 928, time: 0.095, data: 0.000) loss: 0.032 
(epoch: 105, iters: 1008, time: 0.094, data: 0.011) loss: 0.053 
(epoch: 105, iters: 1088, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 105, iters: 1168, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 105, iters: 1248, time: 0.097, data: 0.041) loss: 0.082 
(epoch: 105, iters: 1328, time: 0.096, data: 0.000) loss: 0.049 
(epoch: 105, iters: 1408, time: 0.093, data: 0.011) loss: 0.091 
(epoch: 105, iters: 1488, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 105, iters: 1568, time: 0.094, data: 0.012) loss: 0.097 
(epoch: 105, iters: 1648, time: 0.094, data: 0.000) loss: 0.044 
(epoch: 105, iters: 1728, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 105, iters: 1808, time: 0.094, data: 0.040) loss: 0.010 
(epoch: 105, iters: 1888, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 105, iters: 1968, time: 0.093, data: 0.012) loss: 0.014 
(epoch: 105, iters: 2048, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 105, iters: 2128, time: 0.094, data: 0.011) loss: 0.024 
(epoch: 105, iters: 2208, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 105, iters: 2288, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 105, iters: 2368, time: 0.094, data: 0.052) loss: 0.011 
(epoch: 105, iters: 2448, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 105, iters: 2528, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 105, iters: 2608, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 105, iters: 2688, time: 0.094, data: 0.011) loss: 0.097 
(epoch: 105, iters: 2768, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 105, iters: 2848, time: 0.094, data: 0.000) loss: 0.017 
(epoch: 105, iters: 2928, time: 0.097, data: 0.050) loss: 0.002 
(epoch: 105, iters: 3008, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 105, iters: 3088, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 105, iters: 3168, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 105, iters: 3248, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 105, iters: 3328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 105, iters: 3408, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 105, iters: 3488, time: 0.095, data: 0.050) loss: 0.014 
(epoch: 105, iters: 3568, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 105, iters: 3648, time: 0.086, data: 0.012) loss: 0.005 
(epoch: 105, iters: 3728, time: 0.056, data: 0.000) loss: 0.102 
saving the model at the end of epoch 105, iters 391440
End of epoch 105 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001994
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 105, TEST ACC: [94.537 %]

saving the latest model (epoch 106, total_steps 391456)
(epoch: 106, iters: 80, time: 0.095, data: 0.517) loss: 0.002 
(epoch: 106, iters: 160, time: 0.095, data: 0.031) loss: 0.012 
(epoch: 106, iters: 240, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 106, iters: 320, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 106, iters: 400, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 106, iters: 480, time: 0.101, data: 0.011) loss: 0.007 
(epoch: 106, iters: 560, time: 0.096, data: 0.000) loss: 0.020 
(epoch: 106, iters: 640, time: 0.096, data: 0.000) loss: 0.020 
(epoch: 106, iters: 720, time: 0.097, data: 0.040) loss: 0.073 
(epoch: 106, iters: 800, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 106, iters: 880, time: 0.092, data: 0.011) loss: 0.007 
(epoch: 106, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 106, iters: 1040, time: 0.094, data: 0.012) loss: 0.157 
(epoch: 106, iters: 1120, time: 0.094, data: 0.000) loss: 0.045 
(epoch: 106, iters: 1200, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 106, iters: 1280, time: 0.102, data: 0.050) loss: 0.004 
(epoch: 106, iters: 1360, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 106, iters: 1440, time: 0.092, data: 0.012) loss: 0.009 
(epoch: 106, iters: 1520, time: 0.094, data: 0.000) loss: 0.088 
(epoch: 106, iters: 1600, time: 0.093, data: 0.011) loss: 0.214 
(epoch: 106, iters: 1680, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 106, iters: 1760, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 106, iters: 1840, time: 0.094, data: 0.040) loss: 0.015 
(epoch: 106, iters: 1920, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 106, iters: 2000, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 106, iters: 2080, time: 0.100, data: 0.000) loss: 0.026 
(epoch: 106, iters: 2160, time: 0.094, data: 0.011) loss: 0.348 
(epoch: 106, iters: 2240, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 106, iters: 2320, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 106, iters: 2400, time: 0.094, data: 0.038) loss: 0.003 
(epoch: 106, iters: 2480, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 106, iters: 2560, time: 0.094, data: 0.011) loss: 0.008 
(epoch: 106, iters: 2640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 106, iters: 2720, time: 0.093, data: 0.011) loss: 0.058 
(epoch: 106, iters: 2800, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 106, iters: 2880, time: 0.094, data: 0.000) loss: 0.036 
(epoch: 106, iters: 2960, time: 0.094, data: 0.038) loss: 0.016 
(epoch: 106, iters: 3040, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 106, iters: 3120, time: 0.099, data: 0.012) loss: 0.007 
(epoch: 106, iters: 3200, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 106, iters: 3280, time: 0.093, data: 0.011) loss: 0.030 
(epoch: 106, iters: 3360, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 106, iters: 3440, time: 0.094, data: 0.000) loss: 0.086 
(epoch: 106, iters: 3520, time: 0.094, data: 0.039) loss: 0.076 
(epoch: 106, iters: 3600, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 106, iters: 3680, time: 0.087, data: 0.011) loss: 0.021 
saving the model at the end of epoch 106, iters 395168
End of epoch 106 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001993
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 106, TEST ACC: [87.405 %]

saving the latest model (epoch 107, total_steps 395184)
(epoch: 107, iters: 32, time: 0.092, data: 0.006) loss: 0.000 
(epoch: 107, iters: 112, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 107, iters: 192, time: 0.093, data: 0.012) loss: 0.032 
(epoch: 107, iters: 272, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 107, iters: 352, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 107, iters: 432, time: 0.094, data: 0.040) loss: 0.014 
(epoch: 107, iters: 512, time: 0.097, data: 0.000) loss: 0.035 
(epoch: 107, iters: 592, time: 0.092, data: 0.012) loss: 0.044 
(epoch: 107, iters: 672, time: 0.094, data: 0.000) loss: 0.022 
(epoch: 107, iters: 752, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 107, iters: 832, time: 0.094, data: 0.000) loss: 0.061 
(epoch: 107, iters: 912, time: 0.100, data: 0.000) loss: 0.011 
(epoch: 107, iters: 992, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 107, iters: 1072, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 107, iters: 1152, time: 0.093, data: 0.011) loss: 0.097 
(epoch: 107, iters: 1232, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 107, iters: 1312, time: 0.094, data: 0.011) loss: 0.011 
(epoch: 107, iters: 1392, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 107, iters: 1472, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 107, iters: 1552, time: 0.094, data: 0.039) loss: 0.069 
(epoch: 107, iters: 1632, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 107, iters: 1712, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 107, iters: 1792, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 107, iters: 1872, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 107, iters: 1952, time: 0.101, data: 0.000) loss: 0.055 
(epoch: 107, iters: 2032, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 107, iters: 2112, time: 0.095, data: 0.047) loss: 0.001 
(epoch: 107, iters: 2192, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 107, iters: 2272, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 107, iters: 2352, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 107, iters: 2432, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 107, iters: 2512, time: 0.095, data: 0.000) loss: 0.099 
(epoch: 107, iters: 2592, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 107, iters: 2672, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 107, iters: 2752, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 107, iters: 2832, time: 0.093, data: 0.012) loss: 0.268 
(epoch: 107, iters: 2912, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 107, iters: 2992, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 107, iters: 3072, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 107, iters: 3152, time: 0.094, data: 0.000) loss: 0.051 
(epoch: 107, iters: 3232, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 107, iters: 3312, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 107, iters: 3392, time: 0.093, data: 0.011) loss: 0.109 
(epoch: 107, iters: 3472, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 107, iters: 3552, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 107, iters: 3632, time: 0.093, data: 0.000) loss: 0.063 
(epoch: 107, iters: 3712, time: 0.087, data: 0.000) loss: 0.001 
saving the model at the end of epoch 107, iters 398896
End of epoch 107 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001992
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 107, TEST ACC: [93.93 %]

saving the latest model (epoch 108, total_steps 398912)
(epoch: 108, iters: 64, time: 0.094, data: 0.003) loss: 0.010 
(epoch: 108, iters: 144, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 108, iters: 224, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 108, iters: 304, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 108, iters: 384, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 108, iters: 464, time: 0.095, data: 0.048) loss: 0.073 
(epoch: 108, iters: 544, time: 0.094, data: 0.000) loss: 0.055 
(epoch: 108, iters: 624, time: 0.092, data: 0.011) loss: 0.004 
(epoch: 108, iters: 704, time: 0.097, data: 0.000) loss: 0.021 
(epoch: 108, iters: 784, time: 0.095, data: 0.011) loss: 0.009 
(epoch: 108, iters: 864, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 108, iters: 944, time: 0.093, data: 0.026) loss: 0.041 
(epoch: 108, iters: 1024, time: 0.094, data: 0.000) loss: 0.185 
(epoch: 108, iters: 1104, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 108, iters: 1184, time: 0.094, data: 0.012) loss: 0.039 
(epoch: 108, iters: 1264, time: 0.093, data: 0.025) loss: 0.001 
(epoch: 108, iters: 1344, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 108, iters: 1424, time: 0.101, data: 0.000) loss: 0.020 
(epoch: 108, iters: 1504, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 108, iters: 1584, time: 0.092, data: 0.024) loss: 0.002 
(epoch: 108, iters: 1664, time: 0.101, data: 0.000) loss: 0.030 
(epoch: 108, iters: 1744, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 108, iters: 1824, time: 0.093, data: 0.011) loss: 0.117 
(epoch: 108, iters: 1904, time: 0.093, data: 0.027) loss: 0.002 
(epoch: 108, iters: 1984, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 108, iters: 2064, time: 0.100, data: 0.000) loss: 0.005 
(epoch: 108, iters: 2144, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 108, iters: 2224, time: 0.093, data: 0.025) loss: 0.002 
(epoch: 108, iters: 2304, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 108, iters: 2384, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 108, iters: 2464, time: 0.093, data: 0.011) loss: 0.030 
(epoch: 108, iters: 2544, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 108, iters: 2624, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 108, iters: 2704, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 108, iters: 2784, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 108, iters: 2864, time: 0.093, data: 0.025) loss: 0.002 
(epoch: 108, iters: 2944, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 108, iters: 3024, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 108, iters: 3104, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 108, iters: 3184, time: 0.093, data: 0.034) loss: 0.002 
(epoch: 108, iters: 3264, time: 0.095, data: 0.000) loss: 0.021 
(epoch: 108, iters: 3344, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 108, iters: 3424, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 108, iters: 3504, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 108, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 108, iters: 3664, time: 0.088, data: 0.000) loss: 0.002 
saving the model at the end of epoch 108, iters 402624
End of epoch 108 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001991
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 108, TEST ACC: [92.109 %]

(epoch: 109, iters: 16, time: 0.113, data: 0.009) loss: 0.000 
saving the latest model (epoch 109, total_steps 402640)
(epoch: 109, iters: 96, time: 0.097, data: 0.059) loss: 0.001 
(epoch: 109, iters: 176, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 109, iters: 256, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 109, iters: 336, time: 0.096, data: 0.000) loss: 0.246 
(epoch: 109, iters: 416, time: 0.094, data: 0.012) loss: 0.028 
(epoch: 109, iters: 496, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 109, iters: 576, time: 0.095, data: 0.000) loss: 0.026 
(epoch: 109, iters: 656, time: 0.096, data: 0.040) loss: 0.007 
(epoch: 109, iters: 736, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 109, iters: 816, time: 0.092, data: 0.012) loss: 0.014 
(epoch: 109, iters: 896, time: 0.094, data: 0.000) loss: 0.023 
(epoch: 109, iters: 976, time: 0.094, data: 0.011) loss: 0.005 
(epoch: 109, iters: 1056, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 109, iters: 1136, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 109, iters: 1216, time: 0.094, data: 0.039) loss: 0.007 
(epoch: 109, iters: 1296, time: 0.107, data: 0.000) loss: 0.011 
(epoch: 109, iters: 1376, time: 0.095, data: 0.012) loss: 0.026 
(epoch: 109, iters: 1456, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 109, iters: 1536, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 109, iters: 1616, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 109, iters: 1696, time: 0.094, data: 0.000) loss: 0.366 
(epoch: 109, iters: 1776, time: 0.094, data: 0.039) loss: 0.008 
(epoch: 109, iters: 1856, time: 0.096, data: 0.000) loss: 0.019 
(epoch: 109, iters: 1936, time: 0.094, data: 0.012) loss: 0.017 
(epoch: 109, iters: 2016, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 109, iters: 2096, time: 0.094, data: 0.011) loss: 0.087 
(epoch: 109, iters: 2176, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 109, iters: 2256, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 109, iters: 2336, time: 0.094, data: 0.039) loss: 0.071 
(epoch: 109, iters: 2416, time: 0.095, data: 0.000) loss: 0.127 
(epoch: 109, iters: 2496, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 109, iters: 2576, time: 0.094, data: 0.000) loss: 0.030 
(epoch: 109, iters: 2656, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 109, iters: 2736, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 109, iters: 2816, time: 0.093, data: 0.000) loss: 0.014 
(epoch: 109, iters: 2896, time: 0.095, data: 0.039) loss: 0.006 
(epoch: 109, iters: 2976, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 109, iters: 3056, time: 0.093, data: 0.013) loss: 0.005 
(epoch: 109, iters: 3136, time: 0.101, data: 0.000) loss: 0.015 
(epoch: 109, iters: 3216, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 109, iters: 3296, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 109, iters: 3376, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 109, iters: 3456, time: 0.094, data: 0.011) loss: 0.035 
(epoch: 109, iters: 3536, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 109, iters: 3616, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 109, iters: 3696, time: 0.088, data: 0.039) loss: 0.031 
saving the model at the end of epoch 109, iters 406352
End of epoch 109 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001990
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 109, TEST ACC: [95.144 %]

saving the latest model (epoch 110, total_steps 406368)
(epoch: 110, iters: 48, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 110, iters: 128, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 110, iters: 208, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 110, iters: 288, time: 0.093, data: 0.012) loss: 0.116 
(epoch: 110, iters: 368, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 110, iters: 448, time: 0.095, data: 0.012) loss: 0.008 
(epoch: 110, iters: 528, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 110, iters: 608, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 110, iters: 688, time: 0.095, data: 0.039) loss: 0.003 
(epoch: 110, iters: 768, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 110, iters: 848, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 110, iters: 928, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 110, iters: 1008, time: 0.095, data: 0.012) loss: 0.055 
(epoch: 110, iters: 1088, time: 0.098, data: 0.000) loss: 0.003 
(epoch: 110, iters: 1168, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 110, iters: 1248, time: 0.097, data: 0.040) loss: 0.004 
(epoch: 110, iters: 1328, time: 0.096, data: 0.000) loss: 0.085 
(epoch: 110, iters: 1408, time: 0.094, data: 0.011) loss: 0.008 
(epoch: 110, iters: 1488, time: 0.095, data: 0.000) loss: 0.189 
(epoch: 110, iters: 1568, time: 0.094, data: 0.012) loss: 0.147 
(epoch: 110, iters: 1648, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 110, iters: 1728, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 110, iters: 1808, time: 0.094, data: 0.040) loss: 0.005 
(epoch: 110, iters: 1888, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 110, iters: 1968, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 110, iters: 2048, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 110, iters: 2128, time: 0.102, data: 0.000) loss: 0.038 
(epoch: 110, iters: 2208, time: 0.093, data: 0.011) loss: 0.005 
(epoch: 110, iters: 2288, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 110, iters: 2368, time: 0.094, data: 0.019) loss: 0.001 
(epoch: 110, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 110, iters: 2528, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 110, iters: 2608, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 110, iters: 2688, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 110, iters: 2768, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 110, iters: 2848, time: 0.095, data: 0.000) loss: 0.029 
(epoch: 110, iters: 2928, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 110, iters: 3008, time: 0.096, data: 0.000) loss: 0.022 
(epoch: 110, iters: 3088, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 110, iters: 3168, time: 0.096, data: 0.041) loss: 0.002 
(epoch: 110, iters: 3248, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 110, iters: 3328, time: 0.094, data: 0.021) loss: 0.001 
(epoch: 110, iters: 3408, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 110, iters: 3488, time: 0.093, data: 0.011) loss: 0.005 
(epoch: 110, iters: 3568, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 110, iters: 3648, time: 0.089, data: 0.000) loss: 0.032 
(epoch: 110, iters: 3728, time: 0.057, data: 0.016) loss: 0.006 
saving the model at the end of epoch 110, iters 410080
End of epoch 110 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001989
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 110, TEST ACC: [67.83 %]

saving the latest model (epoch 111, total_steps 410096)
(epoch: 111, iters: 80, time: 0.095, data: 0.504) loss: 0.063 
(epoch: 111, iters: 160, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 111, iters: 240, time: 0.093, data: 0.035) loss: 0.464 
(epoch: 111, iters: 320, time: 0.095, data: 0.000) loss: 0.023 
(epoch: 111, iters: 400, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 111, iters: 480, time: 0.094, data: 0.011) loss: 0.008 
(epoch: 111, iters: 560, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 111, iters: 640, time: 0.095, data: 0.000) loss: 0.022 
(epoch: 111, iters: 720, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 111, iters: 800, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 111, iters: 880, time: 0.093, data: 0.025) loss: 0.225 
(epoch: 111, iters: 960, time: 0.094, data: 0.000) loss: 0.072 
(epoch: 111, iters: 1040, time: 0.101, data: 0.000) loss: 0.001 
(epoch: 111, iters: 1120, time: 0.095, data: 0.013) loss: 0.042 
(epoch: 111, iters: 1200, time: 0.093, data: 0.025) loss: 0.222 
(epoch: 111, iters: 1280, time: 0.095, data: 0.000) loss: 0.098 
(epoch: 111, iters: 1360, time: 0.095, data: 0.000) loss: 0.057 
(epoch: 111, iters: 1440, time: 0.094, data: 0.013) loss: 0.004 
(epoch: 111, iters: 1520, time: 0.093, data: 0.024) loss: 0.459 
(epoch: 111, iters: 1600, time: 0.101, data: 0.000) loss: 0.008 
(epoch: 111, iters: 1680, time: 0.102, data: 0.000) loss: 0.090 
(epoch: 111, iters: 1760, time: 0.095, data: 0.021) loss: 0.027 
(epoch: 111, iters: 1840, time: 0.093, data: 0.026) loss: 0.036 
(epoch: 111, iters: 1920, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 111, iters: 2000, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 111, iters: 2080, time: 0.094, data: 0.011) loss: 0.009 
(epoch: 111, iters: 2160, time: 0.093, data: 0.026) loss: 0.006 
(epoch: 111, iters: 2240, time: 0.096, data: 0.000) loss: 0.108 
(epoch: 111, iters: 2320, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 111, iters: 2400, time: 0.096, data: 0.011) loss: 0.002 
(epoch: 111, iters: 2480, time: 0.095, data: 0.035) loss: 0.037 
(epoch: 111, iters: 2560, time: 0.097, data: 0.000) loss: 0.092 
(epoch: 111, iters: 2640, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 111, iters: 2720, time: 0.100, data: 0.012) loss: 0.005 
(epoch: 111, iters: 2800, time: 0.094, data: 0.024) loss: 0.039 
(epoch: 111, iters: 2880, time: 0.096, data: 0.000) loss: 0.085 
(epoch: 111, iters: 2960, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 111, iters: 3040, time: 0.096, data: 0.012) loss: 0.012 
(epoch: 111, iters: 3120, time: 0.092, data: 0.025) loss: 0.001 
(epoch: 111, iters: 3200, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 111, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 111, iters: 3360, time: 0.100, data: 0.011) loss: 0.001 
(epoch: 111, iters: 3440, time: 0.093, data: 0.025) loss: 0.007 
(epoch: 111, iters: 3520, time: 0.094, data: 0.000) loss: 0.035 
(epoch: 111, iters: 3600, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 111, iters: 3680, time: 0.087, data: 0.000) loss: 0.004 
saving the model at the end of epoch 111, iters 413808
End of epoch 111 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001988
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 111, TEST ACC: [60.395 %]

saving the latest model (epoch 112, total_steps 413824)
(epoch: 112, iters: 32, time: 0.094, data: 0.000) loss: 0.038 
(epoch: 112, iters: 112, time: 0.093, data: 0.011) loss: 0.082 
(epoch: 112, iters: 192, time: 0.095, data: 0.000) loss: 0.093 
(epoch: 112, iters: 272, time: 0.095, data: 0.000) loss: 0.198 
(epoch: 112, iters: 352, time: 0.096, data: 0.039) loss: 0.026 
(epoch: 112, iters: 432, time: 0.103, data: 0.000) loss: 0.056 
(epoch: 112, iters: 512, time: 0.096, data: 0.011) loss: 0.028 
(epoch: 112, iters: 592, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 112, iters: 672, time: 0.094, data: 0.012) loss: 0.058 
(epoch: 112, iters: 752, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 112, iters: 832, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 112, iters: 912, time: 0.094, data: 0.038) loss: 0.017 
(epoch: 112, iters: 992, time: 0.095, data: 0.000) loss: 0.070 
(epoch: 112, iters: 1072, time: 0.092, data: 0.011) loss: 0.028 
(epoch: 112, iters: 1152, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 112, iters: 1232, time: 0.095, data: 0.012) loss: 0.125 
(epoch: 112, iters: 1312, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 112, iters: 1392, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 112, iters: 1472, time: 0.095, data: 0.038) loss: 0.008 
(epoch: 112, iters: 1552, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 112, iters: 1632, time: 0.093, data: 0.011) loss: 0.032 
(epoch: 112, iters: 1712, time: 0.095, data: 0.000) loss: 0.156 
(epoch: 112, iters: 1792, time: 0.101, data: 0.011) loss: 0.030 
(epoch: 112, iters: 1872, time: 0.096, data: 0.000) loss: 0.141 
(epoch: 112, iters: 1952, time: 0.093, data: 0.000) loss: 0.045 
(epoch: 112, iters: 2032, time: 0.094, data: 0.039) loss: 0.010 
(epoch: 112, iters: 2112, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 112, iters: 2192, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 112, iters: 2272, time: 0.095, data: 0.000) loss: 0.106 
(epoch: 112, iters: 2352, time: 0.095, data: 0.012) loss: 0.025 
(epoch: 112, iters: 2432, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 112, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 112, iters: 2592, time: 0.095, data: 0.039) loss: 0.007 
(epoch: 112, iters: 2672, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 112, iters: 2752, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 112, iters: 2832, time: 0.097, data: 0.000) loss: 0.012 
(epoch: 112, iters: 2912, time: 0.095, data: 0.012) loss: 0.009 
(epoch: 112, iters: 2992, time: 0.096, data: 0.000) loss: 0.049 
(epoch: 112, iters: 3072, time: 0.092, data: 0.000) loss: 0.021 
(epoch: 112, iters: 3152, time: 0.095, data: 0.047) loss: 0.002 
(epoch: 112, iters: 3232, time: 0.097, data: 0.000) loss: 0.008 
(epoch: 112, iters: 3312, time: 0.100, data: 0.012) loss: 0.003 
(epoch: 112, iters: 3392, time: 0.097, data: 0.000) loss: 0.008 
(epoch: 112, iters: 3472, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 112, iters: 3552, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 112, iters: 3632, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 112, iters: 3712, time: 0.090, data: 0.036) loss: 0.001 
saving the model at the end of epoch 112, iters 417536
End of epoch 112 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001987
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 112, TEST ACC: [91.047 %]

saving the latest model (epoch 113, total_steps 417552)
(epoch: 113, iters: 64, time: 0.093, data: 0.000) loss: 0.008 
(epoch: 113, iters: 144, time: 0.096, data: 0.027) loss: 0.004 
(epoch: 113, iters: 224, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 113, iters: 304, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 113, iters: 384, time: 0.095, data: 0.000) loss: 0.176 
(epoch: 113, iters: 464, time: 0.095, data: 0.011) loss: 0.046 
(epoch: 113, iters: 544, time: 0.095, data: 0.000) loss: 0.435 
(epoch: 113, iters: 624, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 113, iters: 704, time: 0.102, data: 0.049) loss: 0.022 
(epoch: 113, iters: 784, time: 0.095, data: 0.000) loss: 0.018 
(epoch: 113, iters: 864, time: 0.095, data: 0.012) loss: 0.011 
(epoch: 113, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 113, iters: 1024, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 113, iters: 1104, time: 0.096, data: 0.000) loss: 0.060 
(epoch: 113, iters: 1184, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 113, iters: 1264, time: 0.095, data: 0.050) loss: 0.001 
(epoch: 113, iters: 1344, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 113, iters: 1424, time: 0.094, data: 0.011) loss: 0.542 
(epoch: 113, iters: 1504, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 113, iters: 1584, time: 0.096, data: 0.013) loss: 0.096 
(epoch: 113, iters: 1664, time: 0.097, data: 0.000) loss: 0.116 
(epoch: 113, iters: 1744, time: 0.094, data: 0.000) loss: 0.230 
(epoch: 113, iters: 1824, time: 0.094, data: 0.040) loss: 0.530 
(epoch: 113, iters: 1904, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 113, iters: 1984, time: 0.099, data: 0.012) loss: 0.022 
(epoch: 113, iters: 2064, time: 0.097, data: 0.000) loss: 0.010 
(epoch: 113, iters: 2144, time: 0.096, data: 0.012) loss: 0.017 
(epoch: 113, iters: 2224, time: 0.103, data: 0.000) loss: 0.001 
(epoch: 113, iters: 2304, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 113, iters: 2384, time: 0.097, data: 0.040) loss: 0.002 
(epoch: 113, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 113, iters: 2544, time: 0.093, data: 0.011) loss: 0.008 
(epoch: 113, iters: 2624, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 113, iters: 2704, time: 0.093, data: 0.012) loss: 0.015 
(epoch: 113, iters: 2784, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 113, iters: 2864, time: 0.094, data: 0.000) loss: 0.030 
(epoch: 113, iters: 2944, time: 0.095, data: 0.049) loss: 0.094 
(epoch: 113, iters: 3024, time: 0.095, data: 0.000) loss: 0.417 
(epoch: 113, iters: 3104, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 113, iters: 3184, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 113, iters: 3264, time: 0.094, data: 0.011) loss: 0.070 
(epoch: 113, iters: 3344, time: 0.095, data: 0.000) loss: 0.266 
(epoch: 113, iters: 3424, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 113, iters: 3504, time: 0.095, data: 0.039) loss: 0.180 
(epoch: 113, iters: 3584, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 113, iters: 3664, time: 0.087, data: 0.012) loss: 0.004 
saving the model at the end of epoch 113, iters 421264
End of epoch 113 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001986
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 113, TEST ACC: [93.323 %]

(epoch: 114, iters: 16, time: 0.115, data: 0.014) loss: 0.019 
saving the latest model (epoch 114, total_steps 421280)
(epoch: 114, iters: 96, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 114, iters: 176, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 114, iters: 256, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 114, iters: 336, time: 0.093, data: 0.012) loss: 0.168 
(epoch: 114, iters: 416, time: 0.102, data: 0.000) loss: 0.013 
(epoch: 114, iters: 496, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 114, iters: 576, time: 0.095, data: 0.040) loss: 0.065 
(epoch: 114, iters: 656, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 114, iters: 736, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 114, iters: 816, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 114, iters: 896, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 114, iters: 976, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 114, iters: 1056, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 114, iters: 1136, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 114, iters: 1216, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 114, iters: 1296, time: 0.093, data: 0.012) loss: 0.087 
(epoch: 114, iters: 1376, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 114, iters: 1456, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 114, iters: 1536, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 114, iters: 1616, time: 0.094, data: 0.000) loss: 0.036 
(epoch: 114, iters: 1696, time: 0.094, data: 0.041) loss: 0.005 
(epoch: 114, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 114, iters: 1856, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 114, iters: 1936, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 114, iters: 2016, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 114, iters: 2096, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 114, iters: 2176, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 114, iters: 2256, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 114, iters: 2336, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 114, iters: 2416, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 114, iters: 2496, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 114, iters: 2576, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 114, iters: 2656, time: 0.095, data: 0.000) loss: 0.218 
(epoch: 114, iters: 2736, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 114, iters: 2816, time: 0.095, data: 0.050) loss: 0.042 
(epoch: 114, iters: 2896, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 114, iters: 2976, time: 0.092, data: 0.011) loss: 0.027 
(epoch: 114, iters: 3056, time: 0.094, data: 0.000) loss: 0.099 
(epoch: 114, iters: 3136, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 114, iters: 3216, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 114, iters: 3296, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 114, iters: 3376, time: 0.095, data: 0.049) loss: 0.005 
(epoch: 114, iters: 3456, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 114, iters: 3536, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 114, iters: 3616, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 114, iters: 3696, time: 0.088, data: 0.011) loss: 0.001 
saving the model at the end of epoch 114, iters 424992
End of epoch 114 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001985
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 114, TEST ACC: [92.716 %]

saving the latest model (epoch 115, total_steps 425008)
(epoch: 115, iters: 48, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 115, iters: 128, time: 0.095, data: 0.042) loss: 0.055 
(epoch: 115, iters: 208, time: 0.095, data: 0.000) loss: 0.175 
(epoch: 115, iters: 288, time: 0.093, data: 0.013) loss: 0.010 
(epoch: 115, iters: 368, time: 0.094, data: 0.000) loss: 0.045 
(epoch: 115, iters: 448, time: 0.093, data: 0.012) loss: 0.073 
(epoch: 115, iters: 528, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 115, iters: 608, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 115, iters: 688, time: 0.094, data: 0.042) loss: 0.006 
(epoch: 115, iters: 768, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 115, iters: 848, time: 0.092, data: 0.012) loss: 0.034 
(epoch: 115, iters: 928, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 115, iters: 1008, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 115, iters: 1088, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 115, iters: 1168, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 115, iters: 1248, time: 0.095, data: 0.050) loss: 0.013 
(epoch: 115, iters: 1328, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 115, iters: 1408, time: 0.093, data: 0.012) loss: 0.043 
(epoch: 115, iters: 1488, time: 0.095, data: 0.000) loss: 0.032 
(epoch: 115, iters: 1568, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 115, iters: 1648, time: 0.095, data: 0.000) loss: 0.030 
(epoch: 115, iters: 1728, time: 0.094, data: 0.000) loss: 0.067 
(epoch: 115, iters: 1808, time: 0.097, data: 0.040) loss: 0.006 
(epoch: 115, iters: 1888, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 115, iters: 1968, time: 0.093, data: 0.012) loss: 0.027 
(epoch: 115, iters: 2048, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 115, iters: 2128, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 115, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 115, iters: 2288, time: 0.094, data: 0.000) loss: 0.047 
(epoch: 115, iters: 2368, time: 0.095, data: 0.041) loss: 0.002 
(epoch: 115, iters: 2448, time: 0.096, data: 0.000) loss: 0.032 
(epoch: 115, iters: 2528, time: 0.095, data: 0.012) loss: 0.015 
(epoch: 115, iters: 2608, time: 0.095, data: 0.030) loss: 0.181 
(epoch: 115, iters: 2688, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 115, iters: 2768, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 115, iters: 2848, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 115, iters: 2928, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 115, iters: 3008, time: 0.096, data: 0.000) loss: 0.147 
(epoch: 115, iters: 3088, time: 0.095, data: 0.000) loss: 0.021 
(epoch: 115, iters: 3168, time: 0.094, data: 0.042) loss: 0.014 
(epoch: 115, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 115, iters: 3328, time: 0.092, data: 0.012) loss: 0.042 
(epoch: 115, iters: 3408, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 115, iters: 3488, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 115, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 115, iters: 3648, time: 0.089, data: 0.000) loss: 0.049 
(epoch: 115, iters: 3728, time: 0.056, data: 0.015) loss: 0.003 
saving the model at the end of epoch 115, iters 428720
End of epoch 115 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001984
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 115, TEST ACC: [94.537 %]

saving the latest model (epoch 116, total_steps 428736)
(epoch: 116, iters: 80, time: 0.096, data: 0.534) loss: 0.001 
(epoch: 116, iters: 160, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 116, iters: 240, time: 0.094, data: 0.040) loss: 0.004 
(epoch: 116, iters: 320, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 116, iters: 400, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 116, iters: 480, time: 0.095, data: 0.000) loss: 0.049 
(epoch: 116, iters: 560, time: 0.094, data: 0.012) loss: 0.005 
(epoch: 116, iters: 640, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 116, iters: 720, time: 0.094, data: 0.000) loss: 0.042 
(epoch: 116, iters: 800, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 116, iters: 880, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 116, iters: 960, time: 0.093, data: 0.011) loss: 0.008 
(epoch: 116, iters: 1040, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 116, iters: 1120, time: 0.102, data: 0.011) loss: 0.026 
(epoch: 116, iters: 1200, time: 0.096, data: 0.000) loss: 0.022 
(epoch: 116, iters: 1280, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 116, iters: 1360, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 116, iters: 1440, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 116, iters: 1520, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 116, iters: 1600, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 116, iters: 1680, time: 0.098, data: 0.021) loss: 0.001 
(epoch: 116, iters: 1760, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 116, iters: 1840, time: 0.097, data: 0.026) loss: 0.020 
(epoch: 116, iters: 1920, time: 0.097, data: 0.027) loss: 0.003 
(epoch: 116, iters: 2000, time: 0.092, data: 0.012) loss: 0.015 
(epoch: 116, iters: 2080, time: 0.094, data: 0.000) loss: 0.089 
(epoch: 116, iters: 2160, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 116, iters: 2240, time: 0.095, data: 0.000) loss: 0.158 
(epoch: 116, iters: 2320, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 116, iters: 2400, time: 0.095, data: 0.039) loss: 0.004 
(epoch: 116, iters: 2480, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 116, iters: 2560, time: 0.099, data: 0.012) loss: 0.057 
(epoch: 116, iters: 2640, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 116, iters: 2720, time: 0.094, data: 0.012) loss: 0.092 
(epoch: 116, iters: 2800, time: 0.095, data: 0.000) loss: 0.158 
(epoch: 116, iters: 2880, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 116, iters: 2960, time: 0.096, data: 0.040) loss: 0.013 
(epoch: 116, iters: 3040, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 116, iters: 3120, time: 0.099, data: 0.011) loss: 0.091 
(epoch: 116, iters: 3200, time: 0.095, data: 0.000) loss: 0.029 
(epoch: 116, iters: 3280, time: 0.101, data: 0.012) loss: 0.002 
(epoch: 116, iters: 3360, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 116, iters: 3440, time: 0.096, data: 0.000) loss: 0.135 
(epoch: 116, iters: 3520, time: 0.097, data: 0.040) loss: 0.001 
(epoch: 116, iters: 3600, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 116, iters: 3680, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 116, iters 432448
End of epoch 116 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001983
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 116, TEST ACC: [95.599 %]

saving the latest model (epoch 117, total_steps 432464)
(epoch: 117, iters: 32, time: 0.094, data: 0.016) loss: 0.000 
(epoch: 117, iters: 112, time: 0.095, data: 0.000) loss: 0.048 
(epoch: 117, iters: 192, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 117, iters: 272, time: 0.095, data: 0.040) loss: 0.006 
(epoch: 117, iters: 352, time: 0.097, data: 0.000) loss: 0.009 
(epoch: 117, iters: 432, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 117, iters: 512, time: 0.094, data: 0.000) loss: 0.065 
(epoch: 117, iters: 592, time: 0.094, data: 0.022) loss: 0.001 
(epoch: 117, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 117, iters: 752, time: 0.094, data: 0.000) loss: 0.059 
(epoch: 117, iters: 832, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 117, iters: 912, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 117, iters: 992, time: 0.093, data: 0.012) loss: 0.080 
(epoch: 117, iters: 1072, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 117, iters: 1152, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 117, iters: 1232, time: 0.096, data: 0.000) loss: 0.054 
(epoch: 117, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 117, iters: 1392, time: 0.097, data: 0.041) loss: 0.007 
(epoch: 117, iters: 1472, time: 0.096, data: 0.000) loss: 0.046 
(epoch: 117, iters: 1552, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 117, iters: 1632, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 117, iters: 1712, time: 0.094, data: 0.012) loss: 0.036 
(epoch: 117, iters: 1792, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 117, iters: 1872, time: 0.095, data: 0.000) loss: 0.030 
(epoch: 117, iters: 1952, time: 0.096, data: 0.041) loss: 0.003 
(epoch: 117, iters: 2032, time: 0.097, data: 0.000) loss: 0.008 
(epoch: 117, iters: 2112, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 117, iters: 2192, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 117, iters: 2272, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 117, iters: 2352, time: 0.093, data: 0.012) loss: 0.016 
(epoch: 117, iters: 2432, time: 0.094, data: 0.026) loss: 0.003 
(epoch: 117, iters: 2512, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 117, iters: 2592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 117, iters: 2672, time: 0.095, data: 0.011) loss: 0.006 
(epoch: 117, iters: 2752, time: 0.094, data: 0.026) loss: 0.002 
(epoch: 117, iters: 2832, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 117, iters: 2912, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 117, iters: 2992, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 117, iters: 3072, time: 0.100, data: 0.027) loss: 0.001 
(epoch: 117, iters: 3152, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 117, iters: 3232, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 117, iters: 3312, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 117, iters: 3392, time: 0.093, data: 0.025) loss: 0.030 
(epoch: 117, iters: 3472, time: 0.097, data: 0.000) loss: 0.137 
(epoch: 117, iters: 3552, time: 0.095, data: 0.000) loss: 0.088 
(epoch: 117, iters: 3632, time: 0.093, data: 0.012) loss: 0.017 
(epoch: 117, iters: 3712, time: 0.090, data: 0.030) loss: 0.001 
saving the model at the end of epoch 117, iters 436176
End of epoch 117 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001982
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 117, TEST ACC: [91.047 %]

saving the latest model (epoch 118, total_steps 436192)
(epoch: 118, iters: 64, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 118, iters: 144, time: 0.096, data: 0.000) loss: 0.091 
(epoch: 118, iters: 224, time: 0.094, data: 0.012) loss: 0.010 
(epoch: 118, iters: 304, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 118, iters: 384, time: 0.095, data: 0.000) loss: 0.039 
(epoch: 118, iters: 464, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 118, iters: 544, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 118, iters: 624, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 118, iters: 704, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 118, iters: 784, time: 0.095, data: 0.012) loss: 0.013 
(epoch: 118, iters: 864, time: 0.097, data: 0.026) loss: 0.008 
(epoch: 118, iters: 944, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 118, iters: 1024, time: 0.096, data: 0.041) loss: 0.001 
(epoch: 118, iters: 1104, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 118, iters: 1184, time: 0.095, data: 0.012) loss: 0.010 
(epoch: 118, iters: 1264, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 118, iters: 1344, time: 0.096, data: 0.011) loss: 0.057 
(epoch: 118, iters: 1424, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 118, iters: 1504, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 118, iters: 1584, time: 0.095, data: 0.000) loss: 0.070 
(epoch: 118, iters: 1664, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 118, iters: 1744, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 118, iters: 1824, time: 0.096, data: 0.050) loss: 0.001 
(epoch: 118, iters: 1904, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 118, iters: 1984, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 118, iters: 2064, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 118, iters: 2144, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 118, iters: 2224, time: 0.098, data: 0.000) loss: 0.034 
(epoch: 118, iters: 2304, time: 0.096, data: 0.000) loss: 0.036 
(epoch: 118, iters: 2384, time: 0.096, data: 0.051) loss: 0.003 
(epoch: 118, iters: 2464, time: 0.098, data: 0.000) loss: 0.013 
(epoch: 118, iters: 2544, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 118, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 118, iters: 2704, time: 0.096, data: 0.012) loss: 0.042 
(epoch: 118, iters: 2784, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 118, iters: 2864, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 118, iters: 2944, time: 0.096, data: 0.050) loss: 0.004 
(epoch: 118, iters: 3024, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 118, iters: 3104, time: 0.094, data: 0.012) loss: 0.016 
(epoch: 118, iters: 3184, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 118, iters: 3264, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 118, iters: 3344, time: 0.096, data: 0.035) loss: 0.011 
(epoch: 118, iters: 3424, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 118, iters: 3504, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 118, iters: 3584, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 118, iters: 3664, time: 0.089, data: 0.026) loss: 0.001 
saving the model at the end of epoch 118, iters 439904
End of epoch 118 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001981
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 118, TEST ACC: [92.868 %]

(epoch: 119, iters: 16, time: 0.109, data: 0.000) loss: 0.001 
saving the latest model (epoch 119, total_steps 439920)
(epoch: 119, iters: 96, time: 0.095, data: 0.044) loss: 0.000 
(epoch: 119, iters: 176, time: 0.102, data: 0.000) loss: 0.000 
(epoch: 119, iters: 256, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 119, iters: 336, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 119, iters: 416, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 119, iters: 496, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 119, iters: 576, time: 0.100, data: 0.000) loss: 0.018 
(epoch: 119, iters: 656, time: 0.097, data: 0.040) loss: 0.003 
(epoch: 119, iters: 736, time: 0.097, data: 0.000) loss: 0.058 
(epoch: 119, iters: 816, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 119, iters: 896, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 119, iters: 976, time: 0.093, data: 0.012) loss: 0.441 
(epoch: 119, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 119, iters: 1136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 119, iters: 1216, time: 0.095, data: 0.049) loss: 0.007 
(epoch: 119, iters: 1296, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 119, iters: 1376, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 119, iters: 1456, time: 0.098, data: 0.000) loss: 0.003 
(epoch: 119, iters: 1536, time: 0.094, data: 0.012) loss: 0.014 
(epoch: 119, iters: 1616, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 119, iters: 1696, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 119, iters: 1776, time: 0.101, data: 0.041) loss: 0.001 
(epoch: 119, iters: 1856, time: 0.096, data: 0.000) loss: 0.439 
(epoch: 119, iters: 1936, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 119, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 119, iters: 2096, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 119, iters: 2176, time: 0.093, data: 0.011) loss: 0.018 
(epoch: 119, iters: 2256, time: 0.092, data: 0.025) loss: 0.097 
(epoch: 119, iters: 2336, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 119, iters: 2416, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 119, iters: 2496, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 119, iters: 2576, time: 0.092, data: 0.027) loss: 0.005 
(epoch: 119, iters: 2656, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 119, iters: 2736, time: 0.095, data: 0.000) loss: 0.098 
(epoch: 119, iters: 2816, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 119, iters: 2896, time: 0.093, data: 0.025) loss: 0.001 
(epoch: 119, iters: 2976, time: 0.094, data: 0.000) loss: 0.291 
(epoch: 119, iters: 3056, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 119, iters: 3136, time: 0.093, data: 0.012) loss: 0.041 
(epoch: 119, iters: 3216, time: 0.095, data: 0.035) loss: 0.040 
(epoch: 119, iters: 3296, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 119, iters: 3376, time: 0.097, data: 0.000) loss: 0.107 
(epoch: 119, iters: 3456, time: 0.094, data: 0.011) loss: 0.036 
(epoch: 119, iters: 3536, time: 0.095, data: 0.025) loss: 0.001 
(epoch: 119, iters: 3616, time: 0.095, data: 0.000) loss: 0.146 
(epoch: 119, iters: 3696, time: 0.089, data: 0.000) loss: 0.001 
saving the model at the end of epoch 119, iters 443632
End of epoch 119 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001980
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 119, TEST ACC: [93.93 %]

saving the latest model (epoch 120, total_steps 443648)
(epoch: 120, iters: 48, time: 0.096, data: 0.004) loss: 0.003 
(epoch: 120, iters: 128, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 120, iters: 208, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 120, iters: 288, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 120, iters: 368, time: 0.095, data: 0.040) loss: 0.019 
(epoch: 120, iters: 448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 120, iters: 528, time: 0.093, data: 0.012) loss: 0.046 
(epoch: 120, iters: 608, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 120, iters: 688, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 120, iters: 768, time: 0.095, data: 0.000) loss: 0.254 
(epoch: 120, iters: 848, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 120, iters: 928, time: 0.096, data: 0.040) loss: 0.017 
(epoch: 120, iters: 1008, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 120, iters: 1088, time: 0.093, data: 0.012) loss: 0.101 
(epoch: 120, iters: 1168, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 120, iters: 1248, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 120, iters: 1328, time: 0.098, data: 0.000) loss: 0.263 
(epoch: 120, iters: 1408, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 120, iters: 1488, time: 0.094, data: 0.041) loss: 0.054 
(epoch: 120, iters: 1568, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 120, iters: 1648, time: 0.092, data: 0.012) loss: 0.267 
(epoch: 120, iters: 1728, time: 0.097, data: 0.000) loss: 0.020 
(epoch: 120, iters: 1808, time: 0.094, data: 0.012) loss: 0.048 
(epoch: 120, iters: 1888, time: 0.096, data: 0.000) loss: 0.039 
(epoch: 120, iters: 1968, time: 0.093, data: 0.000) loss: 0.252 
(epoch: 120, iters: 2048, time: 0.094, data: 0.040) loss: 0.019 
(epoch: 120, iters: 2128, time: 0.097, data: 0.000) loss: 0.013 
(epoch: 120, iters: 2208, time: 0.093, data: 0.013) loss: 0.003 
(epoch: 120, iters: 2288, time: 0.095, data: 0.000) loss: 0.117 
(epoch: 120, iters: 2368, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 120, iters: 2448, time: 0.094, data: 0.000) loss: 0.224 
(epoch: 120, iters: 2528, time: 0.095, data: 0.000) loss: 0.196 
(epoch: 120, iters: 2608, time: 0.096, data: 0.050) loss: 0.025 
(epoch: 120, iters: 2688, time: 0.098, data: 0.000) loss: 0.012 
(epoch: 120, iters: 2768, time: 0.095, data: 0.013) loss: 0.115 
(epoch: 120, iters: 2848, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 120, iters: 2928, time: 0.094, data: 0.012) loss: 0.006 
(epoch: 120, iters: 3008, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 120, iters: 3088, time: 0.094, data: 0.000) loss: 0.040 
(epoch: 120, iters: 3168, time: 0.095, data: 0.049) loss: 0.002 
(epoch: 120, iters: 3248, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 120, iters: 3328, time: 0.093, data: 0.011) loss: 0.180 
(epoch: 120, iters: 3408, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 120, iters: 3488, time: 0.093, data: 0.012) loss: 0.197 
(epoch: 120, iters: 3568, time: 0.096, data: 0.000) loss: 0.046 
(epoch: 120, iters: 3648, time: 0.089, data: 0.000) loss: 0.134 
(epoch: 120, iters: 3728, time: 0.056, data: 0.015) loss: 0.007 
saving the model at the end of epoch 120, iters 447360
End of epoch 120 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001979
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 120, TEST ACC: [95.448 %]

saving the latest model (epoch 121, total_steps 447376)
(epoch: 121, iters: 80, time: 0.095, data: 0.527) loss: 0.008 
(epoch: 121, iters: 160, time: 0.095, data: 0.031) loss: 0.008 
(epoch: 121, iters: 240, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 121, iters: 320, time: 0.092, data: 0.011) loss: 0.300 
(epoch: 121, iters: 400, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 121, iters: 480, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 121, iters: 560, time: 0.094, data: 0.000) loss: 0.038 
(epoch: 121, iters: 640, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 121, iters: 720, time: 0.094, data: 0.041) loss: 0.003 
(epoch: 121, iters: 800, time: 0.098, data: 0.000) loss: 0.005 
(epoch: 121, iters: 880, time: 0.096, data: 0.000) loss: 0.034 
(epoch: 121, iters: 960, time: 0.096, data: 0.041) loss: 0.017 
(epoch: 121, iters: 1040, time: 0.097, data: 0.000) loss: 0.076 
(epoch: 121, iters: 1120, time: 0.094, data: 0.012) loss: 0.016 
(epoch: 121, iters: 1200, time: 0.094, data: 0.000) loss: 0.110 
(epoch: 121, iters: 1280, time: 0.093, data: 0.012) loss: 0.010 
(epoch: 121, iters: 1360, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 121, iters: 1440, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 121, iters: 1520, time: 0.094, data: 0.041) loss: 0.002 
(epoch: 121, iters: 1600, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 121, iters: 1680, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 121, iters: 1760, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 121, iters: 1840, time: 0.094, data: 0.012) loss: 0.014 
(epoch: 121, iters: 1920, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 121, iters: 2000, time: 0.094, data: 0.000) loss: 0.054 
(epoch: 121, iters: 2080, time: 0.093, data: 0.041) loss: 0.002 
(epoch: 121, iters: 2160, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 121, iters: 2240, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 121, iters: 2320, time: 0.096, data: 0.000) loss: 0.016 
(epoch: 121, iters: 2400, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 121, iters: 2480, time: 0.102, data: 0.000) loss: 0.000 
(epoch: 121, iters: 2560, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 121, iters: 2640, time: 0.094, data: 0.000) loss: 0.115 
(epoch: 121, iters: 2720, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 121, iters: 2800, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 121, iters: 2880, time: 0.094, data: 0.000) loss: 0.026 
(epoch: 121, iters: 2960, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 121, iters: 3040, time: 0.094, data: 0.000) loss: 0.077 
(epoch: 121, iters: 3120, time: 0.095, data: 0.051) loss: 0.003 
(epoch: 121, iters: 3200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 121, iters: 3280, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 121, iters: 3360, time: 0.094, data: 0.000) loss: 0.072 
(epoch: 121, iters: 3440, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 121, iters: 3520, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 121, iters: 3600, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 121, iters: 3680, time: 0.090, data: 0.050) loss: 0.001 
saving the model at the end of epoch 121, iters 451088
End of epoch 121 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001978
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 121, TEST ACC: [93.02 %]

saving the latest model (epoch 122, total_steps 451104)
(epoch: 122, iters: 32, time: 0.093, data: 0.000) loss: 0.244 
(epoch: 122, iters: 112, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 122, iters: 192, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 122, iters: 272, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 122, iters: 352, time: 0.102, data: 0.043) loss: 0.125 
(epoch: 122, iters: 432, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 122, iters: 512, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 122, iters: 592, time: 0.095, data: 0.050) loss: 0.001 
(epoch: 122, iters: 672, time: 0.094, data: 0.000) loss: 0.032 
(epoch: 122, iters: 752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 122, iters: 832, time: 0.093, data: 0.000) loss: 0.038 
(epoch: 122, iters: 912, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 122, iters: 992, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 122, iters: 1072, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 122, iters: 1152, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 122, iters: 1232, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 122, iters: 1312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 122, iters: 1392, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 122, iters: 1472, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 122, iters: 1552, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 122, iters: 1632, time: 0.094, data: 0.000) loss: 0.067 
(epoch: 122, iters: 1712, time: 0.094, data: 0.041) loss: 0.033 
(epoch: 122, iters: 1792, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 122, iters: 1872, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 122, iters: 1952, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 122, iters: 2032, time: 0.094, data: 0.012) loss: 0.103 
(epoch: 122, iters: 2112, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 122, iters: 2192, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 122, iters: 2272, time: 0.094, data: 0.040) loss: 0.010 
(epoch: 122, iters: 2352, time: 0.095, data: 0.000) loss: 0.023 
(epoch: 122, iters: 2432, time: 0.093, data: 0.021) loss: 0.002 
(epoch: 122, iters: 2512, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 122, iters: 2592, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 122, iters: 2672, time: 0.099, data: 0.000) loss: 0.002 
(epoch: 122, iters: 2752, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 122, iters: 2832, time: 0.096, data: 0.039) loss: 0.001 
(epoch: 122, iters: 2912, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 122, iters: 2992, time: 0.094, data: 0.012) loss: 0.203 
(epoch: 122, iters: 3072, time: 0.097, data: 0.000) loss: 0.009 
(epoch: 122, iters: 3152, time: 0.096, data: 0.013) loss: 0.001 
(epoch: 122, iters: 3232, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 122, iters: 3312, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 122, iters: 3392, time: 0.097, data: 0.051) loss: 0.002 
(epoch: 122, iters: 3472, time: 0.097, data: 0.000) loss: 0.122 
(epoch: 122, iters: 3552, time: 0.093, data: 0.013) loss: 0.037 
(epoch: 122, iters: 3632, time: 0.095, data: 0.000) loss: 0.186 
(epoch: 122, iters: 3712, time: 0.090, data: 0.012) loss: 0.023 
saving the model at the end of epoch 122, iters 454816
End of epoch 122 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001977
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 122, TEST ACC: [89.681 %]

saving the latest model (epoch 123, total_steps 454832)
(epoch: 123, iters: 64, time: 0.095, data: 0.003) loss: 0.054 
(epoch: 123, iters: 144, time: 0.098, data: 0.000) loss: 0.003 
(epoch: 123, iters: 224, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 123, iters: 304, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 123, iters: 384, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 123, iters: 464, time: 0.096, data: 0.041) loss: 0.085 
(epoch: 123, iters: 544, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 123, iters: 624, time: 0.094, data: 0.022) loss: 0.002 
(epoch: 123, iters: 704, time: 0.098, data: 0.000) loss: 0.292 
(epoch: 123, iters: 784, time: 0.096, data: 0.012) loss: 0.124 
(epoch: 123, iters: 864, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 123, iters: 944, time: 0.095, data: 0.000) loss: 0.319 
(epoch: 123, iters: 1024, time: 0.096, data: 0.037) loss: 0.013 
(epoch: 123, iters: 1104, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 123, iters: 1184, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 123, iters: 1264, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 123, iters: 1344, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 123, iters: 1424, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 123, iters: 1504, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 123, iters: 1584, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 123, iters: 1664, time: 0.095, data: 0.026) loss: 0.014 
(epoch: 123, iters: 1744, time: 0.095, data: 0.000) loss: 0.022 
(epoch: 123, iters: 1824, time: 0.099, data: 0.000) loss: 0.004 
(epoch: 123, iters: 1904, time: 0.098, data: 0.012) loss: 0.002 
(epoch: 123, iters: 1984, time: 0.096, data: 0.026) loss: 0.001 
(epoch: 123, iters: 2064, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 123, iters: 2144, time: 0.104, data: 0.000) loss: 0.004 
(epoch: 123, iters: 2224, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 123, iters: 2304, time: 0.096, data: 0.027) loss: 0.002 
(epoch: 123, iters: 2384, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 123, iters: 2464, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 123, iters: 2544, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 123, iters: 2624, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 123, iters: 2704, time: 0.097, data: 0.000) loss: 0.034 
(epoch: 123, iters: 2784, time: 0.095, data: 0.000) loss: 0.458 
(epoch: 123, iters: 2864, time: 0.094, data: 0.011) loss: 0.037 
(epoch: 123, iters: 2944, time: 0.093, data: 0.026) loss: 0.238 
(epoch: 123, iters: 3024, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 123, iters: 3104, time: 0.096, data: 0.000) loss: 0.086 
(epoch: 123, iters: 3184, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 123, iters: 3264, time: 0.093, data: 0.025) loss: 0.004 
(epoch: 123, iters: 3344, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 123, iters: 3424, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 123, iters: 3504, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 123, iters: 3584, time: 0.094, data: 0.035) loss: 0.004 
(epoch: 123, iters: 3664, time: 0.088, data: 0.000) loss: 0.146 
saving the model at the end of epoch 123, iters 458544
End of epoch 123 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001976
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 123, TEST ACC: [93.323 %]

(epoch: 124, iters: 16, time: 0.112, data: 0.000) loss: 0.006 
saving the latest model (epoch 124, total_steps 458560)
(epoch: 124, iters: 96, time: 0.093, data: 0.011) loss: 0.019 
(epoch: 124, iters: 176, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 124, iters: 256, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 124, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 124, iters: 416, time: 0.093, data: 0.000) loss: 0.010 
(epoch: 124, iters: 496, time: 0.095, data: 0.048) loss: 0.001 
(epoch: 124, iters: 576, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 124, iters: 656, time: 0.093, data: 0.011) loss: 0.025 
(epoch: 124, iters: 736, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 124, iters: 816, time: 0.095, data: 0.013) loss: 0.007 
(epoch: 124, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 124, iters: 976, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 124, iters: 1056, time: 0.095, data: 0.050) loss: 0.001 
(epoch: 124, iters: 1136, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 124, iters: 1216, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 124, iters: 1296, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 124, iters: 1376, time: 0.094, data: 0.011) loss: 0.006 
(epoch: 124, iters: 1456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 124, iters: 1536, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 124, iters: 1616, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 124, iters: 1696, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 124, iters: 1776, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 124, iters: 1856, time: 0.097, data: 0.000) loss: 0.020 
(epoch: 124, iters: 1936, time: 0.100, data: 0.013) loss: 0.004 
(epoch: 124, iters: 2016, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 124, iters: 2096, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 124, iters: 2176, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 124, iters: 2256, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 124, iters: 2336, time: 0.093, data: 0.012) loss: 0.051 
(epoch: 124, iters: 2416, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 124, iters: 2496, time: 0.095, data: 0.011) loss: 0.074 
(epoch: 124, iters: 2576, time: 0.095, data: 0.000) loss: 0.027 
(epoch: 124, iters: 2656, time: 0.100, data: 0.000) loss: 0.090 
(epoch: 124, iters: 2736, time: 0.095, data: 0.039) loss: 0.060 
(epoch: 124, iters: 2816, time: 0.096, data: 0.000) loss: 0.014 
(epoch: 124, iters: 2896, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 124, iters: 2976, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 124, iters: 3056, time: 0.095, data: 0.012) loss: 0.022 
(epoch: 124, iters: 3136, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 124, iters: 3216, time: 0.093, data: 0.000) loss: 0.201 
(epoch: 124, iters: 3296, time: 0.096, data: 0.039) loss: 0.003 
(epoch: 124, iters: 3376, time: 0.098, data: 0.000) loss: 0.003 
(epoch: 124, iters: 3456, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 124, iters: 3536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 124, iters: 3616, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 124, iters: 3696, time: 0.088, data: 0.000) loss: 0.098 
saving the model at the end of epoch 124, iters 462272
End of epoch 124 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001975
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 124, TEST ACC: [93.323 %]

saving the latest model (epoch 125, total_steps 462288)
(epoch: 125, iters: 48, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 125, iters: 128, time: 0.096, data: 0.027) loss: 0.022 
(epoch: 125, iters: 208, time: 0.093, data: 0.011) loss: 0.018 
(epoch: 125, iters: 288, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 125, iters: 368, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 125, iters: 448, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 125, iters: 528, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 125, iters: 608, time: 0.094, data: 0.041) loss: 0.002 
(epoch: 125, iters: 688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 125, iters: 768, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 125, iters: 848, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 125, iters: 928, time: 0.094, data: 0.021) loss: 0.003 
(epoch: 125, iters: 1008, time: 0.095, data: 0.000) loss: 0.027 
(epoch: 125, iters: 1088, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 125, iters: 1168, time: 0.097, data: 0.039) loss: 0.001 
(epoch: 125, iters: 1248, time: 0.104, data: 0.000) loss: 0.002 
(epoch: 125, iters: 1328, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 125, iters: 1408, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 125, iters: 1488, time: 0.094, data: 0.011) loss: 0.034 
(epoch: 125, iters: 1568, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 125, iters: 1648, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 125, iters: 1728, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 125, iters: 1808, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 125, iters: 1888, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 125, iters: 1968, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 125, iters: 2048, time: 0.095, data: 0.011) loss: 0.017 
(epoch: 125, iters: 2128, time: 0.099, data: 0.000) loss: 0.006 
(epoch: 125, iters: 2208, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 125, iters: 2288, time: 0.097, data: 0.040) loss: 0.001 
(epoch: 125, iters: 2368, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 125, iters: 2448, time: 0.096, data: 0.011) loss: 0.009 
(epoch: 125, iters: 2528, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 125, iters: 2608, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 125, iters: 2688, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 125, iters: 2768, time: 0.093, data: 0.000) loss: 0.008 
(epoch: 125, iters: 2848, time: 0.095, data: 0.049) loss: 0.003 
(epoch: 125, iters: 2928, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 125, iters: 3008, time: 0.093, data: 0.012) loss: 0.121 
(epoch: 125, iters: 3088, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 125, iters: 3168, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 125, iters: 3248, time: 0.098, data: 0.000) loss: 0.121 
(epoch: 125, iters: 3328, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 125, iters: 3408, time: 0.096, data: 0.041) loss: 0.011 
(epoch: 125, iters: 3488, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 125, iters: 3568, time: 0.094, data: 0.012) loss: 0.013 
(epoch: 125, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 125, iters: 3728, time: 0.056, data: 0.011) loss: 1.113 
saving the model at the end of epoch 125, iters 466000
End of epoch 125 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001974
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 125, TEST ACC: [93.93 %]

saving the latest model (epoch 126, total_steps 466016)
(epoch: 126, iters: 80, time: 0.097, data: 0.457) loss: 0.002 
(epoch: 126, iters: 160, time: 0.093, data: 0.000) loss: 0.040 
(epoch: 126, iters: 240, time: 0.095, data: 0.040) loss: 0.059 
(epoch: 126, iters: 320, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 126, iters: 400, time: 0.093, data: 0.012) loss: 0.011 
(epoch: 126, iters: 480, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 126, iters: 560, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 126, iters: 640, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 126, iters: 720, time: 0.100, data: 0.000) loss: 0.122 
(epoch: 126, iters: 800, time: 0.095, data: 0.039) loss: 0.003 
(epoch: 126, iters: 880, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 126, iters: 960, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 126, iters: 1040, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 126, iters: 1120, time: 0.094, data: 0.012) loss: 0.078 
(epoch: 126, iters: 1200, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 126, iters: 1280, time: 0.095, data: 0.000) loss: 0.051 
(epoch: 126, iters: 1360, time: 0.097, data: 0.040) loss: 0.003 
(epoch: 126, iters: 1440, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 126, iters: 1520, time: 0.093, data: 0.011) loss: 0.151 
(epoch: 126, iters: 1600, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 126, iters: 1680, time: 0.096, data: 0.012) loss: 0.004 
(epoch: 126, iters: 1760, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 126, iters: 1840, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 126, iters: 1920, time: 0.096, data: 0.041) loss: 0.022 
(epoch: 126, iters: 2000, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 126, iters: 2080, time: 0.094, data: 0.021) loss: 0.001 
(epoch: 126, iters: 2160, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 126, iters: 2240, time: 0.094, data: 0.012) loss: 0.005 
(epoch: 126, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 126, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 126, iters: 2480, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 126, iters: 2560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 126, iters: 2640, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 126, iters: 2720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 126, iters: 2800, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 126, iters: 2880, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 126, iters: 2960, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 126, iters: 3040, time: 0.095, data: 0.052) loss: 0.001 
(epoch: 126, iters: 3120, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 126, iters: 3200, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 126, iters: 3280, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 126, iters: 3360, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 126, iters: 3440, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 126, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 126, iters: 3600, time: 0.095, data: 0.041) loss: 0.002 
(epoch: 126, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 126, iters 469728
End of epoch 126 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001973
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 126, TEST ACC: [93.323 %]

saving the latest model (epoch 127, total_steps 469744)
(epoch: 127, iters: 32, time: 0.093, data: 0.004) loss: 0.003 
(epoch: 127, iters: 112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 127, iters: 192, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 127, iters: 272, time: 0.097, data: 0.000) loss: 0.006 
(epoch: 127, iters: 352, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 127, iters: 432, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 127, iters: 512, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 127, iters: 592, time: 0.093, data: 0.012) loss: 0.134 
(epoch: 127, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 127, iters: 752, time: 0.093, data: 0.021) loss: 0.003 
(epoch: 127, iters: 832, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 127, iters: 912, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 127, iters: 992, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 127, iters: 1072, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 127, iters: 1152, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 127, iters: 1232, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 127, iters: 1312, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 127, iters: 1392, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 127, iters: 1472, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 127, iters: 1552, time: 0.101, data: 0.039) loss: 0.037 
(epoch: 127, iters: 1632, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 127, iters: 1712, time: 0.098, data: 0.012) loss: 0.000 
(epoch: 127, iters: 1792, time: 0.095, data: 0.000) loss: 0.157 
(epoch: 127, iters: 1872, time: 0.100, data: 0.011) loss: 0.068 
(epoch: 127, iters: 1952, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 127, iters: 2032, time: 0.093, data: 0.000) loss: 0.209 
(epoch: 127, iters: 2112, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 127, iters: 2192, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 127, iters: 2272, time: 0.093, data: 0.011) loss: 0.013 
(epoch: 127, iters: 2352, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 127, iters: 2432, time: 0.094, data: 0.011) loss: 0.009 
(epoch: 127, iters: 2512, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 127, iters: 2592, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 127, iters: 2672, time: 0.095, data: 0.039) loss: 0.065 
(epoch: 127, iters: 2752, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 127, iters: 2832, time: 0.093, data: 0.012) loss: 0.033 
(epoch: 127, iters: 2912, time: 0.097, data: 0.000) loss: 0.066 
(epoch: 127, iters: 2992, time: 0.095, data: 0.027) loss: 0.002 
(epoch: 127, iters: 3072, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 127, iters: 3152, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 127, iters: 3232, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 127, iters: 3312, time: 0.103, data: 0.000) loss: 0.026 
(epoch: 127, iters: 3392, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 127, iters: 3472, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 127, iters: 3552, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 127, iters: 3632, time: 0.091, data: 0.012) loss: 0.004 
(epoch: 127, iters: 3712, time: 0.090, data: 0.000) loss: 0.014 
saving the model at the end of epoch 127, iters 473456
End of epoch 127 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001972
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 127, TEST ACC: [94.082 %]

saving the latest model (epoch 128, total_steps 473472)
(epoch: 128, iters: 64, time: 0.094, data: 0.003) loss: 0.001 
(epoch: 128, iters: 144, time: 0.096, data: 0.000) loss: 0.041 
(epoch: 128, iters: 224, time: 0.097, data: 0.000) loss: 0.040 
(epoch: 128, iters: 304, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 128, iters: 384, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 128, iters: 464, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 128, iters: 544, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 128, iters: 624, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 128, iters: 704, time: 0.094, data: 0.012) loss: 0.010 
(epoch: 128, iters: 784, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 128, iters: 864, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 128, iters: 944, time: 0.095, data: 0.040) loss: 0.002 
(epoch: 128, iters: 1024, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 128, iters: 1104, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 128, iters: 1184, time: 0.094, data: 0.000) loss: 0.029 
(epoch: 128, iters: 1264, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 128, iters: 1344, time: 0.095, data: 0.000) loss: 0.104 
(epoch: 128, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 128, iters: 1504, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 128, iters: 1584, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 128, iters: 1664, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 128, iters: 1744, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 128, iters: 1824, time: 0.094, data: 0.012) loss: 0.007 
(epoch: 128, iters: 1904, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 128, iters: 1984, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 128, iters: 2064, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 128, iters: 2144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 128, iters: 2224, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 128, iters: 2304, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 128, iters: 2384, time: 0.093, data: 0.011) loss: 0.096 
(epoch: 128, iters: 2464, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 128, iters: 2544, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 128, iters: 2624, time: 0.095, data: 0.050) loss: 0.001 
(epoch: 128, iters: 2704, time: 0.095, data: 0.000) loss: 0.051 
(epoch: 128, iters: 2784, time: 0.095, data: 0.012) loss: 0.005 
(epoch: 128, iters: 2864, time: 0.096, data: 0.000) loss: 0.166 
(epoch: 128, iters: 2944, time: 0.097, data: 0.011) loss: 0.002 
(epoch: 128, iters: 3024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 128, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 128, iters: 3184, time: 0.094, data: 0.041) loss: 0.170 
(epoch: 128, iters: 3264, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 128, iters: 3344, time: 0.093, data: 0.012) loss: 0.010 
(epoch: 128, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 128, iters: 3504, time: 0.094, data: 0.012) loss: 0.039 
(epoch: 128, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 128, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 128, iters 477184
End of epoch 128 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001971
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 128, TEST ACC: [89.985 %]

(epoch: 129, iters: 16, time: 0.110, data: 0.011) loss: 0.069 
saving the latest model (epoch 129, total_steps 477200)
(epoch: 129, iters: 96, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 129, iters: 176, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 129, iters: 256, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 129, iters: 336, time: 0.093, data: 0.011) loss: 0.005 
(epoch: 129, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 129, iters: 496, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 129, iters: 576, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 129, iters: 656, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 129, iters: 736, time: 0.098, data: 0.012) loss: 0.001 
(epoch: 129, iters: 816, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 129, iters: 896, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 129, iters: 976, time: 0.101, data: 0.000) loss: 0.003 
(epoch: 129, iters: 1056, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 129, iters: 1136, time: 0.094, data: 0.039) loss: 0.017 
(epoch: 129, iters: 1216, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 129, iters: 1296, time: 0.098, data: 0.012) loss: 0.000 
(epoch: 129, iters: 1376, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 129, iters: 1456, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 129, iters: 1536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 129, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 129, iters: 1696, time: 0.095, data: 0.049) loss: 0.069 
(epoch: 129, iters: 1776, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 129, iters: 1856, time: 0.093, data: 0.011) loss: 0.055 
(epoch: 129, iters: 1936, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 129, iters: 2016, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 129, iters: 2096, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 129, iters: 2176, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 129, iters: 2256, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 129, iters: 2336, time: 0.097, data: 0.000) loss: 0.090 
(epoch: 129, iters: 2416, time: 0.094, data: 0.013) loss: 0.011 
(epoch: 129, iters: 2496, time: 0.095, data: 0.000) loss: 0.161 
(epoch: 129, iters: 2576, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 129, iters: 2656, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 129, iters: 2736, time: 0.095, data: 0.000) loss: 0.225 
(epoch: 129, iters: 2816, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 129, iters: 2896, time: 0.097, data: 0.000) loss: 0.018 
(epoch: 129, iters: 2976, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 129, iters: 3056, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 129, iters: 3136, time: 0.095, data: 0.012) loss: 0.010 
(epoch: 129, iters: 3216, time: 0.096, data: 0.000) loss: 0.151 
(epoch: 129, iters: 3296, time: 0.096, data: 0.000) loss: 0.116 
(epoch: 129, iters: 3376, time: 0.096, data: 0.041) loss: 0.005 
(epoch: 129, iters: 3456, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 129, iters: 3536, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 129, iters: 3616, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 129, iters: 3696, time: 0.091, data: 0.000) loss: 0.007 
saving the model at the end of epoch 129, iters 480912
End of epoch 129 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001970
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 129, TEST ACC: [56.904 %]

saving the latest model (epoch 130, total_steps 480928)
(epoch: 130, iters: 48, time: 0.096, data: 0.004) loss: 0.085 
(epoch: 130, iters: 128, time: 0.097, data: 0.026) loss: 0.005 
(epoch: 130, iters: 208, time: 0.101, data: 0.012) loss: 0.000 
(epoch: 130, iters: 288, time: 0.102, data: 0.000) loss: 0.158 
(epoch: 130, iters: 368, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 130, iters: 448, time: 0.095, data: 0.000) loss: 0.075 
(epoch: 130, iters: 528, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 130, iters: 608, time: 0.094, data: 0.041) loss: 0.016 
(epoch: 130, iters: 688, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 130, iters: 768, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 130, iters: 848, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 130, iters: 928, time: 0.094, data: 0.012) loss: 0.014 
(epoch: 130, iters: 1008, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 130, iters: 1088, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 130, iters: 1168, time: 0.096, data: 0.049) loss: 0.006 
(epoch: 130, iters: 1248, time: 0.095, data: 0.000) loss: 0.029 
(epoch: 130, iters: 1328, time: 0.093, data: 0.012) loss: 0.011 
(epoch: 130, iters: 1408, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 130, iters: 1488, time: 0.094, data: 0.012) loss: 0.083 
(epoch: 130, iters: 1568, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 130, iters: 1648, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 130, iters: 1728, time: 0.093, data: 0.040) loss: 0.008 
(epoch: 130, iters: 1808, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 130, iters: 1888, time: 0.093, data: 0.013) loss: 0.002 
(epoch: 130, iters: 1968, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 130, iters: 2048, time: 0.096, data: 0.012) loss: 0.005 
(epoch: 130, iters: 2128, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 130, iters: 2208, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 130, iters: 2288, time: 0.096, data: 0.039) loss: 0.003 
(epoch: 130, iters: 2368, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 130, iters: 2448, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 130, iters: 2528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 130, iters: 2608, time: 0.094, data: 0.021) loss: 0.010 
(epoch: 130, iters: 2688, time: 0.098, data: 0.000) loss: 0.008 
(epoch: 130, iters: 2768, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 130, iters: 2848, time: 0.096, data: 0.039) loss: 0.348 
(epoch: 130, iters: 2928, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 130, iters: 3008, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 130, iters: 3088, time: 0.096, data: 0.000) loss: 0.016 
(epoch: 130, iters: 3168, time: 0.095, data: 0.012) loss: 0.019 
(epoch: 130, iters: 3248, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 130, iters: 3328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 130, iters: 3408, time: 0.096, data: 0.040) loss: 0.025 
(epoch: 130, iters: 3488, time: 0.098, data: 0.000) loss: 0.104 
(epoch: 130, iters: 3568, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 130, iters: 3648, time: 0.090, data: 0.000) loss: 0.084 
(epoch: 130, iters: 3728, time: 0.057, data: 0.012) loss: 0.000 
saving the model at the end of epoch 130, iters 484640
End of epoch 130 / 2100 	 Time Taken: 358 sec
learning rate = 0.0001969
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 130, TEST ACC: [92.261 %]

saving the latest model (epoch 131, total_steps 484656)
(epoch: 131, iters: 80, time: 0.093, data: 0.529) loss: 0.001 
(epoch: 131, iters: 160, time: 0.098, data: 0.000) loss: 0.008 
(epoch: 131, iters: 240, time: 0.096, data: 0.012) loss: 0.011 
(epoch: 131, iters: 320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 131, iters: 400, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 131, iters: 480, time: 0.096, data: 0.050) loss: 0.178 
(epoch: 131, iters: 560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 131, iters: 640, time: 0.093, data: 0.012) loss: 0.383 
(epoch: 131, iters: 720, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 131, iters: 800, time: 0.094, data: 0.013) loss: 0.001 
(epoch: 131, iters: 880, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 131, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 131, iters: 1040, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 131, iters: 1120, time: 0.096, data: 0.000) loss: 0.072 
(epoch: 131, iters: 1200, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 131, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 131, iters: 1360, time: 0.093, data: 0.012) loss: 0.010 
(epoch: 131, iters: 1440, time: 0.101, data: 0.000) loss: 0.003 
(epoch: 131, iters: 1520, time: 0.093, data: 0.000) loss: 0.025 
(epoch: 131, iters: 1600, time: 0.095, data: 0.039) loss: 0.025 
(epoch: 131, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 131, iters: 1760, time: 0.094, data: 0.012) loss: 0.027 
(epoch: 131, iters: 1840, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 131, iters: 1920, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 131, iters: 2000, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 131, iters: 2080, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 131, iters: 2160, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 131, iters: 2240, time: 0.096, data: 0.000) loss: 0.147 
(epoch: 131, iters: 2320, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 131, iters: 2400, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 131, iters: 2480, time: 0.094, data: 0.013) loss: 0.001 
(epoch: 131, iters: 2560, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 131, iters: 2640, time: 0.095, data: 0.000) loss: 0.053 
(epoch: 131, iters: 2720, time: 0.094, data: 0.040) loss: 0.030 
(epoch: 131, iters: 2800, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 131, iters: 2880, time: 0.095, data: 0.012) loss: 0.087 
(epoch: 131, iters: 2960, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 131, iters: 3040, time: 0.094, data: 0.011) loss: 0.006 
(epoch: 131, iters: 3120, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 131, iters: 3200, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 131, iters: 3280, time: 0.095, data: 0.040) loss: 0.004 
(epoch: 131, iters: 3360, time: 0.099, data: 0.000) loss: 0.003 
(epoch: 131, iters: 3440, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 131, iters: 3520, time: 0.094, data: 0.000) loss: 0.056 
(epoch: 131, iters: 3600, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 131, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 131, iters 488368
End of epoch 131 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001968
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 131, TEST ACC: [94.537 %]

saving the latest model (epoch 132, total_steps 488384)
(epoch: 132, iters: 32, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 132, iters: 112, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 132, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 132, iters: 272, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 132, iters: 352, time: 0.094, data: 0.039) loss: 0.007 
(epoch: 132, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 132, iters: 512, time: 0.093, data: 0.022) loss: 0.003 
(epoch: 132, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 132, iters: 672, time: 0.101, data: 0.011) loss: 0.075 
(epoch: 132, iters: 752, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 132, iters: 832, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 132, iters: 912, time: 0.095, data: 0.040) loss: 0.005 
(epoch: 132, iters: 992, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 132, iters: 1072, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 132, iters: 1152, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 132, iters: 1232, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 132, iters: 1312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 132, iters: 1392, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 132, iters: 1472, time: 0.096, data: 0.040) loss: 0.024 
(epoch: 132, iters: 1552, time: 0.095, data: 0.000) loss: 0.026 
(epoch: 132, iters: 1632, time: 0.092, data: 0.011) loss: 0.011 
(epoch: 132, iters: 1712, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 132, iters: 1792, time: 0.094, data: 0.012) loss: 0.053 
(epoch: 132, iters: 1872, time: 0.096, data: 0.000) loss: 0.125 
(epoch: 132, iters: 1952, time: 0.095, data: 0.000) loss: 0.236 
(epoch: 132, iters: 2032, time: 0.094, data: 0.040) loss: 0.005 
(epoch: 132, iters: 2112, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 132, iters: 2192, time: 0.092, data: 0.012) loss: 0.117 
(epoch: 132, iters: 2272, time: 0.095, data: 0.000) loss: 0.077 
(epoch: 132, iters: 2352, time: 0.094, data: 0.013) loss: 0.002 
(epoch: 132, iters: 2432, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 132, iters: 2512, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 132, iters: 2592, time: 0.094, data: 0.049) loss: 0.017 
(epoch: 132, iters: 2672, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 132, iters: 2752, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 132, iters: 2832, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 132, iters: 2912, time: 0.094, data: 0.013) loss: 0.080 
(epoch: 132, iters: 2992, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 132, iters: 3072, time: 0.093, data: 0.000) loss: 0.116 
(epoch: 132, iters: 3152, time: 0.094, data: 0.041) loss: 0.002 
(epoch: 132, iters: 3232, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 132, iters: 3312, time: 0.093, data: 0.011) loss: 0.022 
(epoch: 132, iters: 3392, time: 0.095, data: 0.000) loss: 0.050 
(epoch: 132, iters: 3472, time: 0.096, data: 0.011) loss: 0.172 
(epoch: 132, iters: 3552, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 132, iters: 3632, time: 0.092, data: 0.000) loss: 0.010 
(epoch: 132, iters: 3712, time: 0.089, data: 0.045) loss: 0.260 
saving the model at the end of epoch 132, iters 492096
End of epoch 132 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001967
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 132, TEST ACC: [92.109 %]

saving the latest model (epoch 133, total_steps 492112)
(epoch: 133, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 133, iters: 144, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 133, iters: 224, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 133, iters: 304, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 133, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 133, iters: 464, time: 0.094, data: 0.048) loss: 0.001 
(epoch: 133, iters: 544, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 133, iters: 624, time: 0.094, data: 0.011) loss: 0.010 
(epoch: 133, iters: 704, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 133, iters: 784, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 133, iters: 864, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 133, iters: 944, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 133, iters: 1024, time: 0.094, data: 0.039) loss: 0.004 
(epoch: 133, iters: 1104, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 133, iters: 1184, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 133, iters: 1264, time: 0.096, data: 0.000) loss: 0.031 
(epoch: 133, iters: 1344, time: 0.095, data: 0.012) loss: 0.027 
(epoch: 133, iters: 1424, time: 0.094, data: 0.000) loss: 0.041 
(epoch: 133, iters: 1504, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 133, iters: 1584, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 133, iters: 1664, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 133, iters: 1744, time: 0.095, data: 0.012) loss: 0.059 
(epoch: 133, iters: 1824, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 133, iters: 1904, time: 0.102, data: 0.012) loss: 0.000 
(epoch: 133, iters: 1984, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 133, iters: 2064, time: 0.093, data: 0.000) loss: 0.011 
(epoch: 133, iters: 2144, time: 0.094, data: 0.040) loss: 0.007 
(epoch: 133, iters: 2224, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 133, iters: 2304, time: 0.092, data: 0.012) loss: 0.029 
(epoch: 133, iters: 2384, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 133, iters: 2464, time: 0.093, data: 0.012) loss: 0.058 
(epoch: 133, iters: 2544, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 133, iters: 2624, time: 0.093, data: 0.000) loss: 0.028 
(epoch: 133, iters: 2704, time: 0.095, data: 0.049) loss: 0.009 
(epoch: 133, iters: 2784, time: 0.095, data: 0.000) loss: 0.038 
(epoch: 133, iters: 2864, time: 0.092, data: 0.011) loss: 0.007 
(epoch: 133, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 133, iters: 3024, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 133, iters: 3104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 133, iters: 3184, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 133, iters: 3264, time: 0.094, data: 0.040) loss: 0.055 
(epoch: 133, iters: 3344, time: 0.097, data: 0.000) loss: 0.006 
(epoch: 133, iters: 3424, time: 0.092, data: 0.012) loss: 0.005 
(epoch: 133, iters: 3504, time: 0.094, data: 0.000) loss: 0.036 
(epoch: 133, iters: 3584, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 133, iters: 3664, time: 0.087, data: 0.000) loss: 0.001 
saving the model at the end of epoch 133, iters 495824
End of epoch 133 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001966
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 133, TEST ACC: [89.681 %]

(epoch: 134, iters: 16, time: 0.114, data: 0.000) loss: 0.001 
saving the latest model (epoch 134, total_steps 495840)
(epoch: 134, iters: 96, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 134, iters: 176, time: 0.093, data: 0.012) loss: 0.439 
(epoch: 134, iters: 256, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 134, iters: 336, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 134, iters: 416, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 134, iters: 496, time: 0.094, data: 0.000) loss: 0.055 
(epoch: 134, iters: 576, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 134, iters: 656, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 134, iters: 736, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 134, iters: 816, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 134, iters: 896, time: 0.094, data: 0.012) loss: 0.006 
(epoch: 134, iters: 976, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 134, iters: 1056, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 134, iters: 1136, time: 0.095, data: 0.041) loss: 0.007 
(epoch: 134, iters: 1216, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 134, iters: 1296, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 134, iters: 1376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 134, iters: 1456, time: 0.095, data: 0.012) loss: 0.016 
(epoch: 134, iters: 1536, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 134, iters: 1616, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 134, iters: 1696, time: 0.096, data: 0.041) loss: 0.001 
(epoch: 134, iters: 1776, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 134, iters: 1856, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 134, iters: 1936, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 134, iters: 2016, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 134, iters: 2096, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 134, iters: 2176, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 134, iters: 2256, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 134, iters: 2336, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 134, iters: 2416, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 134, iters: 2496, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 134, iters: 2576, time: 0.096, data: 0.012) loss: 0.038 
(epoch: 134, iters: 2656, time: 0.097, data: 0.000) loss: 0.017 
(epoch: 134, iters: 2736, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 134, iters: 2816, time: 0.095, data: 0.021) loss: 0.001 
(epoch: 134, iters: 2896, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 134, iters: 2976, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 134, iters: 3056, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 134, iters: 3136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 134, iters: 3216, time: 0.093, data: 0.025) loss: 0.021 
(epoch: 134, iters: 3296, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 134, iters: 3376, time: 0.095, data: 0.000) loss: 0.060 
(epoch: 134, iters: 3456, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 134, iters: 3536, time: 0.093, data: 0.036) loss: 0.000 
(epoch: 134, iters: 3616, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 134, iters: 3696, time: 0.088, data: 0.000) loss: 0.002 
saving the model at the end of epoch 134, iters 499552
End of epoch 134 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001965
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 134, TEST ACC: [96.662 %]

saving the latest model (epoch 135, total_steps 499568)
(epoch: 135, iters: 48, time: 0.095, data: 0.005) loss: 0.008 
(epoch: 135, iters: 128, time: 0.093, data: 0.012) loss: 0.007 
(epoch: 135, iters: 208, time: 0.096, data: 0.000) loss: 0.309 
(epoch: 135, iters: 288, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 135, iters: 368, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 135, iters: 448, time: 0.095, data: 0.000) loss: 0.180 
(epoch: 135, iters: 528, time: 0.092, data: 0.012) loss: 0.005 
(epoch: 135, iters: 608, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 135, iters: 688, time: 0.093, data: 0.021) loss: 0.004 
(epoch: 135, iters: 768, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 135, iters: 848, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 135, iters: 928, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 135, iters: 1008, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 135, iters: 1088, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 135, iters: 1168, time: 0.096, data: 0.000) loss: 0.066 
(epoch: 135, iters: 1248, time: 0.094, data: 0.012) loss: 0.006 
(epoch: 135, iters: 1328, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 135, iters: 1408, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 135, iters: 1488, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 135, iters: 1568, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 135, iters: 1648, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 135, iters: 1728, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 135, iters: 1808, time: 0.094, data: 0.012) loss: 0.019 
(epoch: 135, iters: 1888, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 135, iters: 1968, time: 0.094, data: 0.000) loss: 0.088 
(epoch: 135, iters: 2048, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 135, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 135, iters: 2208, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 135, iters: 2288, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 135, iters: 2368, time: 0.096, data: 0.012) loss: 0.006 
(epoch: 135, iters: 2448, time: 0.096, data: 0.000) loss: 0.048 
(epoch: 135, iters: 2528, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 135, iters: 2608, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 135, iters: 2688, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 135, iters: 2768, time: 0.093, data: 0.022) loss: 0.014 
(epoch: 135, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 135, iters: 2928, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 135, iters: 3008, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 135, iters: 3088, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 135, iters: 3168, time: 0.095, data: 0.039) loss: 0.006 
(epoch: 135, iters: 3248, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 135, iters: 3328, time: 0.094, data: 0.011) loss: 0.013 
(epoch: 135, iters: 3408, time: 0.102, data: 0.000) loss: 0.011 
(epoch: 135, iters: 3488, time: 0.093, data: 0.012) loss: 0.017 
(epoch: 135, iters: 3568, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 135, iters: 3648, time: 0.087, data: 0.000) loss: 0.001 
(epoch: 135, iters: 3728, time: 0.056, data: 0.015) loss: 0.000 
saving the model at the end of epoch 135, iters 503280
End of epoch 135 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001964
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 135, TEST ACC: [91.958 %]

saving the latest model (epoch 136, total_steps 503296)
(epoch: 136, iters: 80, time: 0.094, data: 0.516) loss: 0.026 
(epoch: 136, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 136, iters: 240, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 136, iters: 320, time: 0.096, data: 0.000) loss: 0.021 
(epoch: 136, iters: 400, time: 0.092, data: 0.011) loss: 0.006 
(epoch: 136, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 136, iters: 560, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 136, iters: 640, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 136, iters: 720, time: 0.096, data: 0.000) loss: 0.036 
(epoch: 136, iters: 800, time: 0.097, data: 0.040) loss: 0.015 
(epoch: 136, iters: 880, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 136, iters: 960, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 136, iters: 1040, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 136, iters: 1120, time: 0.096, data: 0.012) loss: 0.011 
(epoch: 136, iters: 1200, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 136, iters: 1280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 136, iters: 1360, time: 0.095, data: 0.052) loss: 0.003 
(epoch: 136, iters: 1440, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 136, iters: 1520, time: 0.092, data: 0.011) loss: 0.107 
(epoch: 136, iters: 1600, time: 0.096, data: 0.000) loss: 0.036 
(epoch: 136, iters: 1680, time: 0.096, data: 0.012) loss: 0.039 
(epoch: 136, iters: 1760, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 136, iters: 1840, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 136, iters: 1920, time: 0.097, data: 0.049) loss: 0.002 
(epoch: 136, iters: 2000, time: 0.096, data: 0.000) loss: 0.107 
(epoch: 136, iters: 2080, time: 0.092, data: 0.012) loss: 0.140 
(epoch: 136, iters: 2160, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 136, iters: 2240, time: 0.095, data: 0.012) loss: 0.109 
(epoch: 136, iters: 2320, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 136, iters: 2400, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 136, iters: 2480, time: 0.095, data: 0.048) loss: 0.004 
(epoch: 136, iters: 2560, time: 0.096, data: 0.000) loss: 0.030 
(epoch: 136, iters: 2640, time: 0.093, data: 0.011) loss: 0.013 
(epoch: 136, iters: 2720, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 136, iters: 2800, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 136, iters: 2880, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 136, iters: 2960, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 136, iters: 3040, time: 0.095, data: 0.048) loss: 0.002 
(epoch: 136, iters: 3120, time: 0.095, data: 0.000) loss: 0.020 
(epoch: 136, iters: 3200, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 136, iters: 3280, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 136, iters: 3360, time: 0.095, data: 0.011) loss: 0.021 
(epoch: 136, iters: 3440, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 136, iters: 3520, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 136, iters: 3600, time: 0.097, data: 0.048) loss: 0.004 
(epoch: 136, iters: 3680, time: 0.091, data: 0.000) loss: 0.001 
saving the model at the end of epoch 136, iters 507008
End of epoch 136 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001963
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 136, TEST ACC: [95.903 %]

saving the latest model (epoch 137, total_steps 507024)
(epoch: 137, iters: 32, time: 0.093, data: 0.004) loss: 0.001 
(epoch: 137, iters: 112, time: 0.093, data: 0.027) loss: 0.040 
(epoch: 137, iters: 192, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 137, iters: 272, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 137, iters: 352, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 137, iters: 432, time: 0.095, data: 0.000) loss: 0.041 
(epoch: 137, iters: 512, time: 0.092, data: 0.011) loss: 0.004 
(epoch: 137, iters: 592, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 137, iters: 672, time: 0.094, data: 0.012) loss: 0.019 
(epoch: 137, iters: 752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 137, iters: 832, time: 0.100, data: 0.000) loss: 0.001 
(epoch: 137, iters: 912, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 137, iters: 992, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 137, iters: 1072, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 137, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 137, iters: 1232, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 137, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 137, iters: 1392, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 137, iters: 1472, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 137, iters: 1552, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 137, iters: 1632, time: 0.092, data: 0.011) loss: 0.003 
(epoch: 137, iters: 1712, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 137, iters: 1792, time: 0.096, data: 0.012) loss: 0.006 
(epoch: 137, iters: 1872, time: 0.097, data: 0.000) loss: 0.009 
(epoch: 137, iters: 1952, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 137, iters: 2032, time: 0.094, data: 0.042) loss: 0.001 
(epoch: 137, iters: 2112, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 137, iters: 2192, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 137, iters: 2272, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 137, iters: 2352, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 137, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 137, iters: 2512, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 137, iters: 2592, time: 0.096, data: 0.048) loss: 0.000 
(epoch: 137, iters: 2672, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 137, iters: 2752, time: 0.092, data: 0.011) loss: 0.021 
(epoch: 137, iters: 2832, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 137, iters: 2912, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 137, iters: 2992, time: 0.094, data: 0.000) loss: 0.031 
(epoch: 137, iters: 3072, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 137, iters: 3152, time: 0.095, data: 0.049) loss: 0.216 
(epoch: 137, iters: 3232, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 137, iters: 3312, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 137, iters: 3392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 137, iters: 3472, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 137, iters: 3552, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 137, iters: 3632, time: 0.091, data: 0.000) loss: 0.011 
(epoch: 137, iters: 3712, time: 0.088, data: 0.045) loss: 0.006 
saving the model at the end of epoch 137, iters 510736
End of epoch 137 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001962
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 137, TEST ACC: [93.171 %]

saving the latest model (epoch 138, total_steps 510752)
(epoch: 138, iters: 64, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 138, iters: 144, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 138, iters: 224, time: 0.094, data: 0.011) loss: 0.010 
(epoch: 138, iters: 304, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 138, iters: 384, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 138, iters: 464, time: 0.094, data: 0.040) loss: 0.024 
(epoch: 138, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 138, iters: 624, time: 0.093, data: 0.011) loss: 0.005 
(epoch: 138, iters: 704, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 138, iters: 784, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 138, iters: 864, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 138, iters: 944, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 138, iters: 1024, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 138, iters: 1104, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 138, iters: 1184, time: 0.093, data: 0.011) loss: 0.053 
(epoch: 138, iters: 1264, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 138, iters: 1344, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 138, iters: 1424, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 138, iters: 1504, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 138, iters: 1584, time: 0.094, data: 0.040) loss: 0.016 
(epoch: 138, iters: 1664, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 138, iters: 1744, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 138, iters: 1824, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 138, iters: 1904, time: 0.094, data: 0.011) loss: 0.038 
(epoch: 138, iters: 1984, time: 0.095, data: 0.000) loss: 0.038 
(epoch: 138, iters: 2064, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 138, iters: 2144, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 138, iters: 2224, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 138, iters: 2304, time: 0.095, data: 0.013) loss: 0.001 
(epoch: 138, iters: 2384, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 138, iters: 2464, time: 0.093, data: 0.012) loss: 0.048 
(epoch: 138, iters: 2544, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 138, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 138, iters: 2704, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 138, iters: 2784, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 138, iters: 2864, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 138, iters: 2944, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 138, iters: 3024, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 138, iters: 3104, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 138, iters: 3184, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 138, iters: 3264, time: 0.097, data: 0.041) loss: 0.005 
(epoch: 138, iters: 3344, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 138, iters: 3424, time: 0.095, data: 0.011) loss: 0.008 
(epoch: 138, iters: 3504, time: 0.097, data: 0.000) loss: 0.122 
(epoch: 138, iters: 3584, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 138, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 138, iters 514464
End of epoch 138 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001961
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 138, TEST ACC: [85.888 %]

(epoch: 139, iters: 16, time: 0.109, data: 0.000) loss: 0.001 
saving the latest model (epoch 139, total_steps 514480)
(epoch: 139, iters: 96, time: 0.096, data: 0.000) loss: 0.110 
(epoch: 139, iters: 176, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 139, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 139, iters: 336, time: 0.095, data: 0.021) loss: 0.002 
(epoch: 139, iters: 416, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 139, iters: 496, time: 0.094, data: 0.000) loss: 0.033 
(epoch: 139, iters: 576, time: 0.095, data: 0.040) loss: 0.006 
(epoch: 139, iters: 656, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 139, iters: 736, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 139, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 139, iters: 896, time: 0.094, data: 0.011) loss: 0.138 
(epoch: 139, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 139, iters: 1056, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 139, iters: 1136, time: 0.096, data: 0.038) loss: 0.003 
(epoch: 139, iters: 1216, time: 0.094, data: 0.000) loss: 0.030 
(epoch: 139, iters: 1296, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 139, iters: 1376, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 139, iters: 1456, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 139, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 139, iters: 1616, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 139, iters: 1696, time: 0.094, data: 0.039) loss: 0.010 
(epoch: 139, iters: 1776, time: 0.095, data: 0.000) loss: 0.033 
(epoch: 139, iters: 1856, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 139, iters: 1936, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 139, iters: 2016, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 139, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 139, iters: 2176, time: 0.093, data: 0.000) loss: 0.087 
(epoch: 139, iters: 2256, time: 0.095, data: 0.039) loss: 0.058 
(epoch: 139, iters: 2336, time: 0.095, data: 0.000) loss: 0.067 
(epoch: 139, iters: 2416, time: 0.091, data: 0.013) loss: 0.002 
(epoch: 139, iters: 2496, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 139, iters: 2576, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 139, iters: 2656, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 139, iters: 2736, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 139, iters: 2816, time: 0.094, data: 0.039) loss: 0.035 
(epoch: 139, iters: 2896, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 139, iters: 2976, time: 0.092, data: 0.011) loss: 0.274 
(epoch: 139, iters: 3056, time: 0.094, data: 0.000) loss: 0.041 
(epoch: 139, iters: 3136, time: 0.093, data: 0.011) loss: 0.046 
(epoch: 139, iters: 3216, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 139, iters: 3296, time: 0.093, data: 0.000) loss: 0.041 
(epoch: 139, iters: 3376, time: 0.094, data: 0.039) loss: 0.006 
(epoch: 139, iters: 3456, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 139, iters: 3536, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 139, iters: 3616, time: 0.095, data: 0.000) loss: 0.149 
(epoch: 139, iters: 3696, time: 0.089, data: 0.011) loss: 0.010 
saving the model at the end of epoch 139, iters 518192
End of epoch 139 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001960
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 139, TEST ACC: [92.716 %]

saving the latest model (epoch 140, total_steps 518208)
(epoch: 140, iters: 48, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 140, iters: 128, time: 0.094, data: 0.000) loss: 0.125 
(epoch: 140, iters: 208, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 140, iters: 288, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 140, iters: 368, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 140, iters: 448, time: 0.095, data: 0.000) loss: 0.162 
(epoch: 140, iters: 528, time: 0.094, data: 0.012) loss: 0.005 
(epoch: 140, iters: 608, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 140, iters: 688, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 140, iters: 768, time: 0.095, data: 0.049) loss: 0.022 
(epoch: 140, iters: 848, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 140, iters: 928, time: 0.092, data: 0.011) loss: 0.003 
(epoch: 140, iters: 1008, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 140, iters: 1088, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 140, iters: 1168, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 140, iters: 1248, time: 0.094, data: 0.000) loss: 0.502 
(epoch: 140, iters: 1328, time: 0.095, data: 0.039) loss: 0.011 
(epoch: 140, iters: 1408, time: 0.095, data: 0.000) loss: 0.052 
(epoch: 140, iters: 1488, time: 0.093, data: 0.011) loss: 0.075 
(epoch: 140, iters: 1568, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 140, iters: 1648, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 140, iters: 1728, time: 0.095, data: 0.000) loss: 0.217 
(epoch: 140, iters: 1808, time: 0.092, data: 0.000) loss: 0.084 
(epoch: 140, iters: 1888, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 140, iters: 1968, time: 0.095, data: 0.000) loss: 0.058 
(epoch: 140, iters: 2048, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 140, iters: 2128, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 140, iters: 2208, time: 0.094, data: 0.012) loss: 0.031 
(epoch: 140, iters: 2288, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 140, iters: 2368, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 140, iters: 2448, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 140, iters: 2528, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 140, iters: 2608, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 140, iters: 2688, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 140, iters: 2768, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 140, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 140, iters: 2928, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 140, iters: 3008, time: 0.095, data: 0.049) loss: 0.048 
(epoch: 140, iters: 3088, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 140, iters: 3168, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 140, iters: 3248, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 140, iters: 3328, time: 0.093, data: 0.011) loss: 0.145 
(epoch: 140, iters: 3408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 140, iters: 3488, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 140, iters: 3568, time: 0.101, data: 0.040) loss: 0.030 
(epoch: 140, iters: 3648, time: 0.089, data: 0.000) loss: 0.002 
(epoch: 140, iters: 3728, time: 0.056, data: 0.013) loss: 0.583 
saving the model at the end of epoch 140, iters 521920
End of epoch 140 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001959
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 140, TEST ACC: [79.211 %]

saving the latest model (epoch 141, total_steps 521936)
(epoch: 141, iters: 80, time: 0.095, data: 0.487) loss: 0.001 
(epoch: 141, iters: 160, time: 0.093, data: 0.031) loss: 0.000 
(epoch: 141, iters: 240, time: 0.094, data: 0.000) loss: 0.023 
(epoch: 141, iters: 320, time: 0.092, data: 0.011) loss: 0.008 
(epoch: 141, iters: 400, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 141, iters: 480, time: 0.094, data: 0.012) loss: 0.086 
(epoch: 141, iters: 560, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 141, iters: 640, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 141, iters: 720, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 141, iters: 800, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 141, iters: 880, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 141, iters: 960, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 141, iters: 1040, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 141, iters: 1120, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 141, iters: 1200, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 141, iters: 1280, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 141, iters: 1360, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 141, iters: 1440, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 141, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 141, iters: 1600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 141, iters: 1680, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 141, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 141, iters: 1840, time: 0.094, data: 0.039) loss: 0.012 
(epoch: 141, iters: 1920, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 141, iters: 2000, time: 0.093, data: 0.011) loss: 0.046 
(epoch: 141, iters: 2080, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 141, iters: 2160, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 141, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 141, iters: 2320, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 141, iters: 2400, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 141, iters: 2480, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 141, iters: 2560, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 141, iters: 2640, time: 0.094, data: 0.000) loss: 0.166 
(epoch: 141, iters: 2720, time: 0.094, data: 0.011) loss: 0.022 
(epoch: 141, iters: 2800, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 141, iters: 2880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 141, iters: 2960, time: 0.095, data: 0.049) loss: 0.001 
(epoch: 141, iters: 3040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 141, iters: 3120, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 141, iters: 3200, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 141, iters: 3280, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 141, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 141, iters: 3440, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 141, iters: 3520, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 141, iters: 3600, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 141, iters: 3680, time: 0.088, data: 0.012) loss: 0.022 
saving the model at the end of epoch 141, iters 525648
End of epoch 141 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001958
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 141, TEST ACC: [93.475 %]

saving the latest model (epoch 142, total_steps 525664)
(epoch: 142, iters: 32, time: 0.092, data: 0.006) loss: 0.001 
(epoch: 142, iters: 112, time: 0.094, data: 0.028) loss: 0.017 
(epoch: 142, iters: 192, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 142, iters: 272, time: 0.093, data: 0.000) loss: 0.098 
(epoch: 142, iters: 352, time: 0.094, data: 0.052) loss: 0.002 
(epoch: 142, iters: 432, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 142, iters: 512, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 142, iters: 592, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 142, iters: 672, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 142, iters: 752, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 142, iters: 832, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 142, iters: 912, time: 0.094, data: 0.040) loss: 0.010 
(epoch: 142, iters: 992, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 142, iters: 1072, time: 0.092, data: 0.011) loss: 0.004 
(epoch: 142, iters: 1152, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 142, iters: 1232, time: 0.093, data: 0.012) loss: 0.028 
(epoch: 142, iters: 1312, time: 0.095, data: 0.000) loss: 0.085 
(epoch: 142, iters: 1392, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 142, iters: 1472, time: 0.096, data: 0.048) loss: 0.001 
(epoch: 142, iters: 1552, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 142, iters: 1632, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 142, iters: 1712, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 142, iters: 1792, time: 0.096, data: 0.011) loss: 0.004 
(epoch: 142, iters: 1872, time: 0.095, data: 0.000) loss: 0.029 
(epoch: 142, iters: 1952, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 142, iters: 2032, time: 0.092, data: 0.040) loss: 0.159 
(epoch: 142, iters: 2112, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 142, iters: 2192, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 142, iters: 2272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 142, iters: 2352, time: 0.096, data: 0.012) loss: 0.020 
(epoch: 142, iters: 2432, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 142, iters: 2512, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 142, iters: 2592, time: 0.094, data: 0.040) loss: 0.004 
(epoch: 142, iters: 2672, time: 0.095, data: 0.000) loss: 0.183 
(epoch: 142, iters: 2752, time: 0.092, data: 0.012) loss: 0.021 
(epoch: 142, iters: 2832, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 142, iters: 2912, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 142, iters: 2992, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 142, iters: 3072, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 142, iters: 3152, time: 0.096, data: 0.043) loss: 0.017 
(epoch: 142, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 142, iters: 3312, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 142, iters: 3392, time: 0.095, data: 0.000) loss: 0.041 
(epoch: 142, iters: 3472, time: 0.095, data: 0.013) loss: 0.001 
(epoch: 142, iters: 3552, time: 0.095, data: 0.000) loss: 0.030 
(epoch: 142, iters: 3632, time: 0.093, data: 0.000) loss: 0.081 
(epoch: 142, iters: 3712, time: 0.090, data: 0.035) loss: 0.000 
saving the model at the end of epoch 142, iters 529376
End of epoch 142 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001957
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 142, TEST ACC: [95.144 %]

saving the latest model (epoch 143, total_steps 529392)
(epoch: 143, iters: 64, time: 0.093, data: 0.000) loss: 0.075 
(epoch: 143, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 143, iters: 224, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 143, iters: 304, time: 0.093, data: 0.000) loss: 0.011 
(epoch: 143, iters: 384, time: 0.095, data: 0.039) loss: 0.025 
(epoch: 143, iters: 464, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 143, iters: 544, time: 0.094, data: 0.012) loss: 0.008 
(epoch: 143, iters: 624, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 143, iters: 704, time: 0.094, data: 0.012) loss: 0.005 
(epoch: 143, iters: 784, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 143, iters: 864, time: 0.093, data: 0.000) loss: 0.032 
(epoch: 143, iters: 944, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 143, iters: 1024, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 143, iters: 1104, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 143, iters: 1184, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 143, iters: 1264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 143, iters: 1344, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 143, iters: 1424, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 143, iters: 1504, time: 0.097, data: 0.040) loss: 0.014 
(epoch: 143, iters: 1584, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 143, iters: 1664, time: 0.093, data: 0.012) loss: 0.015 
(epoch: 143, iters: 1744, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 143, iters: 1824, time: 0.094, data: 0.012) loss: 0.019 
(epoch: 143, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 143, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 143, iters: 2064, time: 0.095, data: 0.038) loss: 0.001 
(epoch: 143, iters: 2144, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 143, iters: 2224, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 143, iters: 2304, time: 0.096, data: 0.000) loss: 0.028 
(epoch: 143, iters: 2384, time: 0.094, data: 0.012) loss: 0.184 
(epoch: 143, iters: 2464, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 143, iters: 2544, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 143, iters: 2624, time: 0.094, data: 0.039) loss: 0.028 
(epoch: 143, iters: 2704, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 143, iters: 2784, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 143, iters: 2864, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 143, iters: 2944, time: 0.093, data: 0.012) loss: 0.034 
(epoch: 143, iters: 3024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 143, iters: 3104, time: 0.094, data: 0.000) loss: 0.041 
(epoch: 143, iters: 3184, time: 0.095, data: 0.040) loss: 0.012 
(epoch: 143, iters: 3264, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 143, iters: 3344, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 143, iters: 3424, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 143, iters: 3504, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 143, iters: 3584, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 143, iters: 3664, time: 0.089, data: 0.000) loss: 0.001 
saving the model at the end of epoch 143, iters 533104
End of epoch 143 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001956
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 143, TEST ACC: [96.358 %]

(epoch: 144, iters: 16, time: 0.113, data: 0.014) loss: 0.002 
saving the latest model (epoch 144, total_steps 533120)
(epoch: 144, iters: 96, time: 0.095, data: 0.043) loss: 0.009 
(epoch: 144, iters: 176, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 144, iters: 256, time: 0.092, data: 0.011) loss: 0.026 
(epoch: 144, iters: 336, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 144, iters: 416, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 144, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 144, iters: 576, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 144, iters: 656, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 144, iters: 736, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 144, iters: 816, time: 0.092, data: 0.012) loss: 0.049 
(epoch: 144, iters: 896, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 144, iters: 976, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 144, iters: 1056, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 144, iters: 1136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 144, iters: 1216, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 144, iters: 1296, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 144, iters: 1376, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 144, iters: 1456, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 144, iters: 1536, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 144, iters: 1616, time: 0.095, data: 0.000) loss: 0.057 
(epoch: 144, iters: 1696, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 144, iters: 1776, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 144, iters: 1856, time: 0.096, data: 0.000) loss: 0.061 
(epoch: 144, iters: 1936, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 144, iters: 2016, time: 0.094, data: 0.000) loss: 0.065 
(epoch: 144, iters: 2096, time: 0.093, data: 0.011) loss: 0.739 
(epoch: 144, iters: 2176, time: 0.097, data: 0.000) loss: 0.011 
(epoch: 144, iters: 2256, time: 0.096, data: 0.000) loss: 0.098 
(epoch: 144, iters: 2336, time: 0.096, data: 0.050) loss: 0.001 
(epoch: 144, iters: 2416, time: 0.095, data: 0.000) loss: 0.067 
(epoch: 144, iters: 2496, time: 0.092, data: 0.011) loss: 0.008 
(epoch: 144, iters: 2576, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 144, iters: 2656, time: 0.093, data: 0.012) loss: 0.014 
(epoch: 144, iters: 2736, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 144, iters: 2816, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 144, iters: 2896, time: 0.094, data: 0.039) loss: 0.074 
(epoch: 144, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 144, iters: 3056, time: 0.092, data: 0.011) loss: 0.298 
(epoch: 144, iters: 3136, time: 0.094, data: 0.000) loss: 0.053 
(epoch: 144, iters: 3216, time: 0.093, data: 0.011) loss: 0.039 
(epoch: 144, iters: 3296, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 144, iters: 3376, time: 0.094, data: 0.000) loss: 0.094 
(epoch: 144, iters: 3456, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 144, iters: 3536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 144, iters: 3616, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 144, iters: 3696, time: 0.089, data: 0.000) loss: 0.004 
saving the model at the end of epoch 144, iters 536832
End of epoch 144 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001955
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 144, TEST ACC: [91.654 %]

saving the latest model (epoch 145, total_steps 536848)
(epoch: 145, iters: 48, time: 0.095, data: 0.005) loss: 0.002 
(epoch: 145, iters: 128, time: 0.095, data: 0.057) loss: 0.000 
(epoch: 145, iters: 208, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 145, iters: 288, time: 0.092, data: 0.011) loss: 0.005 
(epoch: 145, iters: 368, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 145, iters: 448, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 145, iters: 528, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 145, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 145, iters: 688, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 145, iters: 768, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 145, iters: 848, time: 0.094, data: 0.011) loss: 0.004 
(epoch: 145, iters: 928, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 145, iters: 1008, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 145, iters: 1088, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 145, iters: 1168, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 145, iters: 1248, time: 0.094, data: 0.041) loss: 0.004 
(epoch: 145, iters: 1328, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 145, iters: 1408, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 145, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 145, iters: 1568, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 145, iters: 1648, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 145, iters: 1728, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 145, iters: 1808, time: 0.093, data: 0.043) loss: 0.000 
(epoch: 145, iters: 1888, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 145, iters: 1968, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 145, iters: 2048, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 145, iters: 2128, time: 0.094, data: 0.012) loss: 0.023 
(epoch: 145, iters: 2208, time: 0.096, data: 0.000) loss: 0.018 
(epoch: 145, iters: 2288, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 145, iters: 2368, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 145, iters: 2448, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 145, iters: 2528, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 145, iters: 2608, time: 0.097, data: 0.000) loss: 0.013 
(epoch: 145, iters: 2688, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 145, iters: 2768, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 145, iters: 2848, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 145, iters: 2928, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 145, iters: 3008, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 145, iters: 3088, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 145, iters: 3168, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 145, iters: 3248, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 145, iters: 3328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 145, iters: 3408, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 145, iters: 3488, time: 0.096, data: 0.042) loss: 0.008 
(epoch: 145, iters: 3568, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 145, iters: 3648, time: 0.088, data: 0.012) loss: 0.037 
(epoch: 145, iters: 3728, time: 0.058, data: 0.000) loss: 0.077 
saving the model at the end of epoch 145, iters 540560
End of epoch 145 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001954
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 145, TEST ACC: [96.055 %]

saving the latest model (epoch 146, total_steps 540576)
(epoch: 146, iters: 80, time: 0.095, data: 0.514) loss: 0.018 
(epoch: 146, iters: 160, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 146, iters: 240, time: 0.093, data: 0.038) loss: 0.435 
(epoch: 146, iters: 320, time: 0.094, data: 0.000) loss: 0.053 
(epoch: 146, iters: 400, time: 0.093, data: 0.011) loss: 0.811 
(epoch: 146, iters: 480, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 146, iters: 560, time: 0.094, data: 0.011) loss: 0.032 
(epoch: 146, iters: 640, time: 0.096, data: 0.000) loss: 0.044 
(epoch: 146, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 146, iters: 800, time: 0.097, data: 0.039) loss: 0.001 
(epoch: 146, iters: 880, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 146, iters: 960, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 146, iters: 1040, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 146, iters: 1120, time: 0.094, data: 0.012) loss: 0.162 
(epoch: 146, iters: 1200, time: 0.094, data: 0.000) loss: 0.066 
(epoch: 146, iters: 1280, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 146, iters: 1360, time: 0.097, data: 0.040) loss: 0.018 
(epoch: 146, iters: 1440, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 146, iters: 1520, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 146, iters: 1600, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 146, iters: 1680, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 146, iters: 1760, time: 0.096, data: 0.000) loss: 0.167 
(epoch: 146, iters: 1840, time: 0.093, data: 0.000) loss: 0.023 
(epoch: 146, iters: 1920, time: 0.094, data: 0.041) loss: 0.135 
(epoch: 146, iters: 2000, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 146, iters: 2080, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 146, iters: 2160, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 146, iters: 2240, time: 0.093, data: 0.013) loss: 0.199 
(epoch: 146, iters: 2320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 146, iters: 2400, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 146, iters: 2480, time: 0.097, data: 0.041) loss: 0.009 
(epoch: 146, iters: 2560, time: 0.097, data: 0.000) loss: 0.018 
(epoch: 146, iters: 2640, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 146, iters: 2720, time: 0.095, data: 0.000) loss: 0.700 
(epoch: 146, iters: 2800, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 146, iters: 2880, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 146, iters: 2960, time: 0.093, data: 0.000) loss: 0.302 
(epoch: 146, iters: 3040, time: 0.101, data: 0.041) loss: 0.001 
(epoch: 146, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 146, iters: 3200, time: 0.093, data: 0.022) loss: 0.001 
(epoch: 146, iters: 3280, time: 0.095, data: 0.000) loss: 0.021 
(epoch: 146, iters: 3360, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 146, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 146, iters: 3520, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 146, iters: 3600, time: 0.094, data: 0.049) loss: 0.001 
(epoch: 146, iters: 3680, time: 0.087, data: 0.000) loss: 0.009 
saving the model at the end of epoch 146, iters 544288
End of epoch 146 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001953
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 146, TEST ACC: [96.813 %]

saving the latest model (epoch 147, total_steps 544304)
(epoch: 147, iters: 32, time: 0.092, data: 0.004) loss: 0.017 
(epoch: 147, iters: 112, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 147, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 147, iters: 272, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 147, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 147, iters: 432, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 147, iters: 512, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 147, iters: 592, time: 0.093, data: 0.012) loss: 0.007 
(epoch: 147, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 147, iters: 752, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 147, iters: 832, time: 0.096, data: 0.049) loss: 0.011 
(epoch: 147, iters: 912, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 147, iters: 992, time: 0.094, data: 0.011) loss: 0.013 
(epoch: 147, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 147, iters: 1152, time: 0.093, data: 0.011) loss: 0.020 
(epoch: 147, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 147, iters: 1312, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 147, iters: 1392, time: 0.095, data: 0.040) loss: 0.007 
(epoch: 147, iters: 1472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 147, iters: 1552, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 147, iters: 1632, time: 0.094, data: 0.000) loss: 0.175 
(epoch: 147, iters: 1712, time: 0.093, data: 0.011) loss: 0.033 
(epoch: 147, iters: 1792, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 147, iters: 1872, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 147, iters: 1952, time: 0.095, data: 0.048) loss: 0.039 
(epoch: 147, iters: 2032, time: 0.095, data: 0.000) loss: 0.018 
(epoch: 147, iters: 2112, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 147, iters: 2192, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 147, iters: 2272, time: 0.093, data: 0.011) loss: 0.097 
(epoch: 147, iters: 2352, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 147, iters: 2432, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 147, iters: 2512, time: 0.095, data: 0.041) loss: 0.005 
(epoch: 147, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 147, iters: 2672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 147, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 147, iters: 2832, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 147, iters: 2912, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 147, iters: 2992, time: 0.094, data: 0.000) loss: 0.057 
(epoch: 147, iters: 3072, time: 0.095, data: 0.039) loss: 0.002 
(epoch: 147, iters: 3152, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 147, iters: 3232, time: 0.093, data: 0.012) loss: 0.013 
(epoch: 147, iters: 3312, time: 0.096, data: 0.000) loss: 0.047 
(epoch: 147, iters: 3392, time: 0.102, data: 0.012) loss: 0.001 
(epoch: 147, iters: 3472, time: 0.097, data: 0.000) loss: 0.012 
(epoch: 147, iters: 3552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 147, iters: 3632, time: 0.094, data: 0.049) loss: 0.001 
(epoch: 147, iters: 3712, time: 0.091, data: 0.000) loss: 0.036 
saving the model at the end of epoch 147, iters 548016
End of epoch 147 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001952
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 147, TEST ACC: [90.744 %]

saving the latest model (epoch 148, total_steps 548032)
(epoch: 148, iters: 64, time: 0.094, data: 0.000) loss: 0.265 
(epoch: 148, iters: 144, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 148, iters: 224, time: 0.094, data: 0.011) loss: 0.006 
(epoch: 148, iters: 304, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 148, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 148, iters: 464, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 148, iters: 544, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 148, iters: 624, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 148, iters: 704, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 148, iters: 784, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 148, iters: 864, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 148, iters: 944, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 148, iters: 1024, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 148, iters: 1104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 148, iters: 1184, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 148, iters: 1264, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 148, iters: 1344, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 148, iters: 1424, time: 0.092, data: 0.020) loss: 0.001 
(epoch: 148, iters: 1504, time: 0.101, data: 0.000) loss: 0.001 
(epoch: 148, iters: 1584, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 148, iters: 1664, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 148, iters: 1744, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 148, iters: 1824, time: 0.095, data: 0.050) loss: 0.003 
(epoch: 148, iters: 1904, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 148, iters: 1984, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 148, iters: 2064, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 148, iters: 2144, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 148, iters: 2224, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 148, iters: 2304, time: 0.093, data: 0.000) loss: 0.097 
(epoch: 148, iters: 2384, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 148, iters: 2464, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 148, iters: 2544, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 148, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 148, iters: 2704, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 148, iters: 2784, time: 0.095, data: 0.000) loss: 0.018 
(epoch: 148, iters: 2864, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 148, iters: 2944, time: 0.096, data: 0.039) loss: 0.001 
(epoch: 148, iters: 3024, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 148, iters: 3104, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 148, iters: 3184, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 148, iters: 3264, time: 0.093, data: 0.012) loss: 0.010 
(epoch: 148, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 148, iters: 3424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 148, iters: 3504, time: 0.095, data: 0.047) loss: 0.001 
(epoch: 148, iters: 3584, time: 0.095, data: 0.000) loss: 0.020 
(epoch: 148, iters: 3664, time: 0.089, data: 0.012) loss: 0.034 
saving the model at the end of epoch 148, iters 551744
End of epoch 148 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001951
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 148, TEST ACC: [95.751 %]

(epoch: 149, iters: 16, time: 0.114, data: 0.011) loss: 0.008 
saving the latest model (epoch 149, total_steps 551760)
(epoch: 149, iters: 96, time: 0.094, data: 0.044) loss: 0.020 
(epoch: 149, iters: 176, time: 0.096, data: 0.000) loss: 0.019 
(epoch: 149, iters: 256, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 149, iters: 336, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 149, iters: 416, time: 0.094, data: 0.012) loss: 0.043 
(epoch: 149, iters: 496, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 149, iters: 576, time: 0.095, data: 0.000) loss: 0.075 
(epoch: 149, iters: 656, time: 0.097, data: 0.040) loss: 0.007 
(epoch: 149, iters: 736, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 149, iters: 816, time: 0.094, data: 0.012) loss: 0.007 
(epoch: 149, iters: 896, time: 0.103, data: 0.000) loss: 0.010 
(epoch: 149, iters: 976, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 149, iters: 1056, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 149, iters: 1136, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 149, iters: 1216, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 149, iters: 1296, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 149, iters: 1376, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 149, iters: 1456, time: 0.098, data: 0.000) loss: 0.991 
(epoch: 149, iters: 1536, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 149, iters: 1616, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 149, iters: 1696, time: 0.096, data: 0.000) loss: 0.023 
(epoch: 149, iters: 1776, time: 0.098, data: 0.040) loss: 0.000 
(epoch: 149, iters: 1856, time: 0.098, data: 0.000) loss: 0.068 
(epoch: 149, iters: 1936, time: 0.094, data: 0.011) loss: 0.005 
(epoch: 149, iters: 2016, time: 0.097, data: 0.000) loss: 0.145 
(epoch: 149, iters: 2096, time: 0.096, data: 0.012) loss: 0.009 
(epoch: 149, iters: 2176, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 149, iters: 2256, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 149, iters: 2336, time: 0.096, data: 0.041) loss: 0.002 
(epoch: 149, iters: 2416, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 149, iters: 2496, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 149, iters: 2576, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 149, iters: 2656, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 149, iters: 2736, time: 0.096, data: 0.000) loss: 0.033 
(epoch: 149, iters: 2816, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 149, iters: 2896, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 149, iters: 2976, time: 0.097, data: 0.000) loss: 0.062 
(epoch: 149, iters: 3056, time: 0.096, data: 0.012) loss: 0.013 
(epoch: 149, iters: 3136, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 149, iters: 3216, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 149, iters: 3296, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 149, iters: 3376, time: 0.095, data: 0.000) loss: 0.042 
(epoch: 149, iters: 3456, time: 0.096, data: 0.049) loss: 0.015 
(epoch: 149, iters: 3536, time: 0.097, data: 0.000) loss: 0.009 
(epoch: 149, iters: 3616, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 149, iters: 3696, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 149, iters 555472
End of epoch 149 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001950
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 149, TEST ACC: [94.537 %]

saving the latest model (epoch 150, total_steps 555488)
(epoch: 150, iters: 48, time: 0.096, data: 0.005) loss: 0.000 
(epoch: 150, iters: 128, time: 0.101, data: 0.042) loss: 0.014 
(epoch: 150, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 150, iters: 288, time: 0.093, data: 0.011) loss: 0.180 
(epoch: 150, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 150, iters: 448, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 150, iters: 528, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 150, iters: 608, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 150, iters: 688, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 150, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 150, iters: 848, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 150, iters: 928, time: 0.094, data: 0.000) loss: 0.168 
(epoch: 150, iters: 1008, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 150, iters: 1088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 150, iters: 1168, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 150, iters: 1248, time: 0.095, data: 0.049) loss: 0.002 
(epoch: 150, iters: 1328, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 150, iters: 1408, time: 0.093, data: 0.012) loss: 0.008 
(epoch: 150, iters: 1488, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 150, iters: 1568, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 150, iters: 1648, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 150, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 150, iters: 1808, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 150, iters: 1888, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 150, iters: 1968, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 150, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 150, iters: 2128, time: 0.095, data: 0.012) loss: 0.006 
(epoch: 150, iters: 2208, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 150, iters: 2288, time: 0.094, data: 0.000) loss: 0.071 
(epoch: 150, iters: 2368, time: 0.096, data: 0.039) loss: 0.002 
(epoch: 150, iters: 2448, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 150, iters: 2528, time: 0.092, data: 0.012) loss: 0.009 
(epoch: 150, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 150, iters: 2688, time: 0.094, data: 0.011) loss: 0.113 
(epoch: 150, iters: 2768, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 150, iters: 2848, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 150, iters: 2928, time: 0.095, data: 0.040) loss: 0.417 
(epoch: 150, iters: 3008, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 150, iters: 3088, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 150, iters: 3168, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 150, iters: 3248, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 150, iters: 3328, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 150, iters: 3408, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 150, iters: 3488, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 150, iters: 3568, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 150, iters: 3648, time: 0.087, data: 0.012) loss: 0.338 
(epoch: 150, iters: 3728, time: 0.056, data: 0.000) loss: 0.003 
saving the model at the end of epoch 150, iters 559200
End of epoch 150 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001949
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 150, TEST ACC: [92.564 %]

saving the latest model (epoch 151, total_steps 559216)
(epoch: 151, iters: 80, time: 0.095, data: 0.435) loss: 0.003 
(epoch: 151, iters: 160, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 151, iters: 240, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 151, iters: 320, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 151, iters: 400, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 151, iters: 480, time: 0.093, data: 0.011) loss: 0.075 
(epoch: 151, iters: 560, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 151, iters: 640, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 151, iters: 720, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 151, iters: 800, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 151, iters: 880, time: 0.095, data: 0.040) loss: 0.003 
(epoch: 151, iters: 960, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 151, iters: 1040, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 151, iters: 1120, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 151, iters: 1200, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 151, iters: 1280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 151, iters: 1360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 151, iters: 1440, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 151, iters: 1520, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 151, iters: 1600, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 151, iters: 1680, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 151, iters: 1760, time: 0.094, data: 0.011) loss: 0.006 
(epoch: 151, iters: 1840, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 151, iters: 1920, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 151, iters: 2000, time: 0.101, data: 0.040) loss: 0.008 
(epoch: 151, iters: 2080, time: 0.102, data: 0.000) loss: 0.001 
(epoch: 151, iters: 2160, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 151, iters: 2240, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 151, iters: 2320, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 151, iters: 2400, time: 0.095, data: 0.000) loss: 0.416 
(epoch: 151, iters: 2480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 151, iters: 2560, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 151, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 151, iters: 2720, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 151, iters: 2800, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 151, iters: 2880, time: 0.095, data: 0.020) loss: 0.001 
(epoch: 151, iters: 2960, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 151, iters: 3040, time: 0.095, data: 0.000) loss: 0.036 
(epoch: 151, iters: 3120, time: 0.097, data: 0.041) loss: 0.002 
(epoch: 151, iters: 3200, time: 0.097, data: 0.000) loss: 0.020 
(epoch: 151, iters: 3280, time: 0.095, data: 0.011) loss: 0.111 
(epoch: 151, iters: 3360, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 151, iters: 3440, time: 0.096, data: 0.011) loss: 0.152 
(epoch: 151, iters: 3520, time: 0.097, data: 0.000) loss: 0.044 
(epoch: 151, iters: 3600, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 151, iters: 3680, time: 0.091, data: 0.041) loss: 0.004 
saving the model at the end of epoch 151, iters 562928
End of epoch 151 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001948
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 151, TEST ACC: [91.502 %]

saving the latest model (epoch 152, total_steps 562944)
(epoch: 152, iters: 32, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 152, iters: 112, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 152, iters: 192, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 152, iters: 272, time: 0.097, data: 0.000) loss: 0.054 
(epoch: 152, iters: 352, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 152, iters: 432, time: 0.095, data: 0.048) loss: 0.020 
(epoch: 152, iters: 512, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 152, iters: 592, time: 0.095, data: 0.012) loss: 0.126 
(epoch: 152, iters: 672, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 152, iters: 752, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 152, iters: 832, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 152, iters: 912, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 152, iters: 992, time: 0.095, data: 0.039) loss: 0.002 
(epoch: 152, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 152, iters: 1152, time: 0.092, data: 0.011) loss: 0.016 
(epoch: 152, iters: 1232, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 152, iters: 1312, time: 0.095, data: 0.011) loss: 0.007 
(epoch: 152, iters: 1392, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 152, iters: 1472, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 152, iters: 1552, time: 0.095, data: 0.038) loss: 0.042 
(epoch: 152, iters: 1632, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 152, iters: 1712, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 152, iters: 1792, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 152, iters: 1872, time: 0.094, data: 0.012) loss: 0.042 
(epoch: 152, iters: 1952, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 152, iters: 2032, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 152, iters: 2112, time: 0.095, data: 0.049) loss: 0.002 
(epoch: 152, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 152, iters: 2272, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 152, iters: 2352, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 152, iters: 2432, time: 0.093, data: 0.012) loss: 0.013 
(epoch: 152, iters: 2512, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 152, iters: 2592, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 152, iters: 2672, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 152, iters: 2752, time: 0.095, data: 0.000) loss: 0.046 
(epoch: 152, iters: 2832, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 152, iters: 2912, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 152, iters: 2992, time: 0.094, data: 0.012) loss: 0.195 
(epoch: 152, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 152, iters: 3152, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 152, iters: 3232, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 152, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 152, iters: 3392, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 152, iters: 3472, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 152, iters: 3552, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 152, iters: 3632, time: 0.092, data: 0.000) loss: 0.017 
(epoch: 152, iters: 3712, time: 0.088, data: 0.000) loss: 0.005 
saving the model at the end of epoch 152, iters 566656
End of epoch 152 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001947
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 152, TEST ACC: [94.234 %]

saving the latest model (epoch 153, total_steps 566672)
(epoch: 153, iters: 64, time: 0.092, data: 0.002) loss: 0.001 
(epoch: 153, iters: 144, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 153, iters: 224, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 153, iters: 304, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 153, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 153, iters: 464, time: 0.094, data: 0.040) loss: 0.093 
(epoch: 153, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 153, iters: 624, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 153, iters: 704, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 153, iters: 784, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 153, iters: 864, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 153, iters: 944, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 153, iters: 1024, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 153, iters: 1104, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 153, iters: 1184, time: 0.091, data: 0.011) loss: 0.005 
(epoch: 153, iters: 1264, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 153, iters: 1344, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 153, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 153, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 153, iters: 1584, time: 0.095, data: 0.039) loss: 0.139 
(epoch: 153, iters: 1664, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 153, iters: 1744, time: 0.093, data: 0.013) loss: 0.011 
(epoch: 153, iters: 1824, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 153, iters: 1904, time: 0.093, data: 0.011) loss: 0.083 
(epoch: 153, iters: 1984, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 153, iters: 2064, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 153, iters: 2144, time: 0.094, data: 0.040) loss: 0.222 
(epoch: 153, iters: 2224, time: 0.094, data: 0.000) loss: 0.025 
(epoch: 153, iters: 2304, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 153, iters: 2384, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 153, iters: 2464, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 153, iters: 2544, time: 0.094, data: 0.000) loss: 0.102 
(epoch: 153, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 153, iters: 2704, time: 0.095, data: 0.039) loss: 0.022 
(epoch: 153, iters: 2784, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 153, iters: 2864, time: 0.092, data: 0.022) loss: 0.002 
(epoch: 153, iters: 2944, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 153, iters: 3024, time: 0.092, data: 0.011) loss: 0.016 
(epoch: 153, iters: 3104, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 153, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 153, iters: 3264, time: 0.094, data: 0.049) loss: 0.005 
(epoch: 153, iters: 3344, time: 0.094, data: 0.000) loss: 0.053 
(epoch: 153, iters: 3424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 153, iters: 3504, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 153, iters: 3584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 153, iters: 3664, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 153, iters 570384
End of epoch 153 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001946
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 153, TEST ACC: [90.44 %]

(epoch: 154, iters: 16, time: 0.110, data: 0.000) loss: 0.003 
saving the latest model (epoch 154, total_steps 570400)
(epoch: 154, iters: 96, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 154, iters: 176, time: 0.091, data: 0.020) loss: 0.003 
(epoch: 154, iters: 256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 154, iters: 336, time: 0.092, data: 0.012) loss: 0.026 
(epoch: 154, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 154, iters: 496, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 154, iters: 576, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 154, iters: 656, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 154, iters: 736, time: 0.095, data: 0.012) loss: 0.017 
(epoch: 154, iters: 816, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 154, iters: 896, time: 0.103, data: 0.012) loss: 0.003 
(epoch: 154, iters: 976, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 154, iters: 1056, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 154, iters: 1136, time: 0.096, data: 0.040) loss: 0.101 
(epoch: 154, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 154, iters: 1296, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 154, iters: 1376, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 154, iters: 1456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 154, iters: 1536, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 154, iters: 1616, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 154, iters: 1696, time: 0.094, data: 0.038) loss: 0.001 
(epoch: 154, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 154, iters: 1856, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 154, iters: 1936, time: 0.094, data: 0.000) loss: 0.368 
(epoch: 154, iters: 2016, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 154, iters: 2096, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 154, iters: 2176, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 154, iters: 2256, time: 0.097, data: 0.049) loss: 0.004 
(epoch: 154, iters: 2336, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 154, iters: 2416, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 154, iters: 2496, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 154, iters: 2576, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 154, iters: 2656, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 154, iters: 2736, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 154, iters: 2816, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 154, iters: 2896, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 154, iters: 2976, time: 0.093, data: 0.012) loss: 0.030 
(epoch: 154, iters: 3056, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 154, iters: 3136, time: 0.097, data: 0.012) loss: 0.016 
(epoch: 154, iters: 3216, time: 0.094, data: 0.000) loss: 0.028 
(epoch: 154, iters: 3296, time: 0.093, data: 0.000) loss: 0.061 
(epoch: 154, iters: 3376, time: 0.094, data: 0.039) loss: 0.002 
(epoch: 154, iters: 3456, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 154, iters: 3536, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 154, iters: 3616, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 154, iters: 3696, time: 0.088, data: 0.013) loss: 0.021 
saving the model at the end of epoch 154, iters 574112
End of epoch 154 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001945
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 154, TEST ACC: [92.413 %]

saving the latest model (epoch 155, total_steps 574128)
(epoch: 155, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 155, iters: 128, time: 0.093, data: 0.043) loss: 0.000 
(epoch: 155, iters: 208, time: 0.095, data: 0.000) loss: 0.047 
(epoch: 155, iters: 288, time: 0.094, data: 0.011) loss: 0.017 
(epoch: 155, iters: 368, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 155, iters: 448, time: 0.096, data: 0.012) loss: 0.006 
(epoch: 155, iters: 528, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 155, iters: 608, time: 0.095, data: 0.000) loss: 0.020 
(epoch: 155, iters: 688, time: 0.094, data: 0.040) loss: 0.006 
(epoch: 155, iters: 768, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 155, iters: 848, time: 0.093, data: 0.012) loss: 0.039 
(epoch: 155, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 155, iters: 1008, time: 0.094, data: 0.011) loss: 0.007 
(epoch: 155, iters: 1088, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 155, iters: 1168, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 155, iters: 1248, time: 0.093, data: 0.021) loss: 0.002 
(epoch: 155, iters: 1328, time: 0.093, data: 0.024) loss: 0.002 
(epoch: 155, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 155, iters: 1488, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 155, iters: 1568, time: 0.093, data: 0.012) loss: 0.096 
(epoch: 155, iters: 1648, time: 0.093, data: 0.025) loss: 0.001 
(epoch: 155, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 155, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 155, iters: 1888, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 155, iters: 1968, time: 0.092, data: 0.026) loss: 0.002 
(epoch: 155, iters: 2048, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 155, iters: 2128, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 155, iters: 2208, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 155, iters: 2288, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 155, iters: 2368, time: 0.101, data: 0.000) loss: 0.001 
(epoch: 155, iters: 2448, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 155, iters: 2528, time: 0.093, data: 0.012) loss: 0.115 
(epoch: 155, iters: 2608, time: 0.092, data: 0.025) loss: 0.062 
(epoch: 155, iters: 2688, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 155, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 155, iters: 2848, time: 0.097, data: 0.020) loss: 0.002 
(epoch: 155, iters: 2928, time: 0.096, data: 0.026) loss: 0.001 
(epoch: 155, iters: 3008, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 155, iters: 3088, time: 0.097, data: 0.000) loss: 0.069 
(epoch: 155, iters: 3168, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 155, iters: 3248, time: 0.096, data: 0.026) loss: 0.001 
(epoch: 155, iters: 3328, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 155, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 155, iters: 3488, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 155, iters: 3568, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 155, iters: 3648, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 155, iters: 3728, time: 0.057, data: 0.000) loss: 0.525 
saving the model at the end of epoch 155, iters 577840
End of epoch 155 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001944
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 155, TEST ACC: [84.37 %]

saving the latest model (epoch 156, total_steps 577856)
(epoch: 156, iters: 80, time: 0.097, data: 0.473) loss: 0.002 
(epoch: 156, iters: 160, time: 0.093, data: 0.000) loss: 0.029 
(epoch: 156, iters: 240, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 156, iters: 320, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 156, iters: 400, time: 0.093, data: 0.011) loss: 0.052 
(epoch: 156, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 156, iters: 560, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 156, iters: 640, time: 0.095, data: 0.000) loss: 0.075 
(epoch: 156, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 156, iters: 800, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 156, iters: 880, time: 0.094, data: 0.000) loss: 0.063 
(epoch: 156, iters: 960, time: 0.092, data: 0.011) loss: 0.088 
(epoch: 156, iters: 1040, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 156, iters: 1120, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 156, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 156, iters: 1280, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 156, iters: 1360, time: 0.094, data: 0.041) loss: 0.008 
(epoch: 156, iters: 1440, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 156, iters: 1520, time: 0.092, data: 0.011) loss: 0.003 
(epoch: 156, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 156, iters: 1680, time: 0.094, data: 0.011) loss: 0.149 
(epoch: 156, iters: 1760, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 156, iters: 1840, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 156, iters: 1920, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 156, iters: 2000, time: 0.095, data: 0.000) loss: 0.025 
(epoch: 156, iters: 2080, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 156, iters: 2160, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 156, iters: 2240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 156, iters: 2320, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 156, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 156, iters: 2480, time: 0.096, data: 0.039) loss: 0.006 
(epoch: 156, iters: 2560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 156, iters: 2640, time: 0.096, data: 0.011) loss: 0.002 
(epoch: 156, iters: 2720, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 156, iters: 2800, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 156, iters: 2880, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 156, iters: 2960, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 156, iters: 3040, time: 0.093, data: 0.039) loss: 0.071 
(epoch: 156, iters: 3120, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 156, iters: 3200, time: 0.094, data: 0.020) loss: 0.002 
(epoch: 156, iters: 3280, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 156, iters: 3360, time: 0.094, data: 0.011) loss: 0.014 
(epoch: 156, iters: 3440, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 156, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 156, iters: 3600, time: 0.096, data: 0.039) loss: 0.008 
(epoch: 156, iters: 3680, time: 0.089, data: 0.000) loss: 0.008 
saving the model at the end of epoch 156, iters 581568
End of epoch 156 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001943
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 156, TEST ACC: [95.144 %]

saving the latest model (epoch 157, total_steps 581584)
(epoch: 157, iters: 32, time: 0.094, data: 0.006) loss: 0.003 
(epoch: 157, iters: 112, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 157, iters: 192, time: 0.094, data: 0.012) loss: 0.011 
(epoch: 157, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 157, iters: 352, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 157, iters: 432, time: 0.094, data: 0.039) loss: 0.020 
(epoch: 157, iters: 512, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 157, iters: 592, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 157, iters: 672, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 157, iters: 752, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 157, iters: 832, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 157, iters: 912, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 157, iters: 992, time: 0.095, data: 0.050) loss: 0.001 
(epoch: 157, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 157, iters: 1152, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 157, iters: 1232, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 157, iters: 1312, time: 0.094, data: 0.011) loss: 0.008 
(epoch: 157, iters: 1392, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 157, iters: 1472, time: 0.093, data: 0.000) loss: 0.110 
(epoch: 157, iters: 1552, time: 0.094, data: 0.040) loss: 0.037 
(epoch: 157, iters: 1632, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 157, iters: 1712, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 157, iters: 1792, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 157, iters: 1872, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 157, iters: 1952, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 157, iters: 2032, time: 0.093, data: 0.000) loss: 0.022 
(epoch: 157, iters: 2112, time: 0.094, data: 0.039) loss: 0.006 
(epoch: 157, iters: 2192, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 157, iters: 2272, time: 0.092, data: 0.011) loss: 0.038 
(epoch: 157, iters: 2352, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 157, iters: 2432, time: 0.093, data: 0.011) loss: 0.005 
(epoch: 157, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 157, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 157, iters: 2672, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 157, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 157, iters: 2832, time: 0.093, data: 0.012) loss: 0.050 
(epoch: 157, iters: 2912, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 157, iters: 2992, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 157, iters: 3072, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 157, iters: 3152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 157, iters: 3232, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 157, iters: 3312, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 157, iters: 3392, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 157, iters: 3472, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 157, iters: 3552, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 157, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 157, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 157, iters 585296
End of epoch 157 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001942
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 157, TEST ACC: [79.211 %]

saving the latest model (epoch 158, total_steps 585312)
(epoch: 158, iters: 64, time: 0.093, data: 0.003) loss: 0.002 
(epoch: 158, iters: 144, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 158, iters: 224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 158, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 158, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 158, iters: 464, time: 0.096, data: 0.039) loss: 0.001 
(epoch: 158, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 158, iters: 624, time: 0.092, data: 0.012) loss: 0.018 
(epoch: 158, iters: 704, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 158, iters: 784, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 158, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 158, iters: 944, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 158, iters: 1024, time: 0.094, data: 0.048) loss: 0.044 
(epoch: 158, iters: 1104, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 158, iters: 1184, time: 0.091, data: 0.012) loss: 0.005 
(epoch: 158, iters: 1264, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 158, iters: 1344, time: 0.094, data: 0.012) loss: 0.787 
(epoch: 158, iters: 1424, time: 0.096, data: 0.000) loss: 0.085 
(epoch: 158, iters: 1504, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 158, iters: 1584, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 158, iters: 1664, time: 0.095, data: 0.000) loss: 0.043 
(epoch: 158, iters: 1744, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 158, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 158, iters: 1904, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 158, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 158, iters: 2064, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 158, iters: 2144, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 158, iters: 2224, time: 0.097, data: 0.000) loss: 0.030 
(epoch: 158, iters: 2304, time: 0.092, data: 0.012) loss: 0.023 
(epoch: 158, iters: 2384, time: 0.095, data: 0.000) loss: 0.024 
(epoch: 158, iters: 2464, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 158, iters: 2544, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 158, iters: 2624, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 158, iters: 2704, time: 0.094, data: 0.050) loss: 0.005 
(epoch: 158, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 158, iters: 2864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 158, iters: 2944, time: 0.095, data: 0.000) loss: 0.134 
(epoch: 158, iters: 3024, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 158, iters: 3104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 158, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 158, iters: 3264, time: 0.095, data: 0.050) loss: 0.008 
(epoch: 158, iters: 3344, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 158, iters: 3424, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 158, iters: 3504, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 158, iters: 3584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 158, iters: 3664, time: 0.089, data: 0.000) loss: 0.001 
saving the model at the end of epoch 158, iters 589024
End of epoch 158 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001941
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 158, TEST ACC: [94.385 %]

(epoch: 159, iters: 16, time: 0.112, data: 0.000) loss: 0.000 
saving the latest model (epoch 159, total_steps 589040)
(epoch: 159, iters: 96, time: 0.095, data: 0.044) loss: 0.001 
(epoch: 159, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 159, iters: 256, time: 0.092, data: 0.012) loss: 0.041 
(epoch: 159, iters: 336, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 159, iters: 416, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 159, iters: 496, time: 0.095, data: 0.000) loss: 0.030 
(epoch: 159, iters: 576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 159, iters: 656, time: 0.094, data: 0.043) loss: 0.002 
(epoch: 159, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 159, iters: 816, time: 0.093, data: 0.020) loss: 0.011 
(epoch: 159, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 159, iters: 976, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 159, iters: 1056, time: 0.096, data: 0.000) loss: 0.068 
(epoch: 159, iters: 1136, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 159, iters: 1216, time: 0.096, data: 0.051) loss: 0.001 
(epoch: 159, iters: 1296, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 159, iters: 1376, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 159, iters: 1456, time: 0.095, data: 0.000) loss: 0.740 
(epoch: 159, iters: 1536, time: 0.094, data: 0.012) loss: 0.011 
(epoch: 159, iters: 1616, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 159, iters: 1696, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 159, iters: 1776, time: 0.095, data: 0.039) loss: 0.019 
(epoch: 159, iters: 1856, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 159, iters: 1936, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 159, iters: 2016, time: 0.095, data: 0.000) loss: 0.144 
(epoch: 159, iters: 2096, time: 0.094, data: 0.011) loss: 0.031 
(epoch: 159, iters: 2176, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 159, iters: 2256, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 159, iters: 2336, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 159, iters: 2416, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 159, iters: 2496, time: 0.093, data: 0.011) loss: 0.250 
(epoch: 159, iters: 2576, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 159, iters: 2656, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 159, iters: 2736, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 159, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 159, iters: 2896, time: 0.095, data: 0.049) loss: 0.001 
(epoch: 159, iters: 2976, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 159, iters: 3056, time: 0.095, data: 0.011) loss: 0.005 
(epoch: 159, iters: 3136, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 159, iters: 3216, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 159, iters: 3296, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 159, iters: 3376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 159, iters: 3456, time: 0.096, data: 0.039) loss: 0.007 
(epoch: 159, iters: 3536, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 159, iters: 3616, time: 0.092, data: 0.013) loss: 0.125 
(epoch: 159, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 159, iters 592752
End of epoch 159 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001940
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 159, TEST ACC: [91.958 %]

saving the latest model (epoch 160, total_steps 592768)
(epoch: 160, iters: 48, time: 0.093, data: 0.012) loss: 0.013 
(epoch: 160, iters: 128, time: 0.095, data: 0.026) loss: 0.004 
(epoch: 160, iters: 208, time: 0.096, data: 0.000) loss: 0.221 
(epoch: 160, iters: 288, time: 0.092, data: 0.013) loss: 0.081 
(epoch: 160, iters: 368, time: 0.094, data: 0.000) loss: 0.024 
(epoch: 160, iters: 448, time: 0.093, data: 0.012) loss: 0.012 
(epoch: 160, iters: 528, time: 0.094, data: 0.000) loss: 0.035 
(epoch: 160, iters: 608, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 160, iters: 688, time: 0.094, data: 0.048) loss: 0.001 
(epoch: 160, iters: 768, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 160, iters: 848, time: 0.092, data: 0.012) loss: 0.014 
(epoch: 160, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 160, iters: 1008, time: 0.093, data: 0.011) loss: 0.092 
(epoch: 160, iters: 1088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 160, iters: 1168, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 160, iters: 1248, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 160, iters: 1328, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 160, iters: 1408, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 160, iters: 1488, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 160, iters: 1568, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 160, iters: 1648, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 160, iters: 1728, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 160, iters: 1808, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 160, iters: 1888, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 160, iters: 1968, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 160, iters: 2048, time: 0.093, data: 0.000) loss: 0.014 
(epoch: 160, iters: 2128, time: 0.093, data: 0.011) loss: 0.008 
(epoch: 160, iters: 2208, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 160, iters: 2288, time: 0.093, data: 0.000) loss: 0.110 
(epoch: 160, iters: 2368, time: 0.094, data: 0.041) loss: 0.005 
(epoch: 160, iters: 2448, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 160, iters: 2528, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 160, iters: 2608, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 160, iters: 2688, time: 0.093, data: 0.012) loss: 0.007 
(epoch: 160, iters: 2768, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 160, iters: 2848, time: 0.096, data: 0.000) loss: 0.017 
(epoch: 160, iters: 2928, time: 0.097, data: 0.052) loss: 0.012 
(epoch: 160, iters: 3008, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 160, iters: 3088, time: 0.091, data: 0.011) loss: 0.021 
(epoch: 160, iters: 3168, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 160, iters: 3248, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 160, iters: 3328, time: 0.096, data: 0.000) loss: 0.032 
(epoch: 160, iters: 3408, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 160, iters: 3488, time: 0.094, data: 0.048) loss: 0.001 
(epoch: 160, iters: 3568, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 160, iters: 3648, time: 0.087, data: 0.011) loss: 0.003 
(epoch: 160, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 160, iters 596480
End of epoch 160 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001939
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 160, TEST ACC: [92.109 %]

saving the latest model (epoch 161, total_steps 596496)
(epoch: 161, iters: 80, time: 0.095, data: 0.512) loss: 0.002 
(epoch: 161, iters: 160, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 161, iters: 240, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 161, iters: 320, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 161, iters: 400, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 161, iters: 480, time: 0.094, data: 0.000) loss: 0.047 
(epoch: 161, iters: 560, time: 0.094, data: 0.012) loss: 0.010 
(epoch: 161, iters: 640, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 161, iters: 720, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 161, iters: 800, time: 0.094, data: 0.040) loss: 0.004 
(epoch: 161, iters: 880, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 161, iters: 960, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 161, iters: 1040, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 161, iters: 1120, time: 0.094, data: 0.012) loss: 0.007 
(epoch: 161, iters: 1200, time: 0.096, data: 0.000) loss: 0.023 
(epoch: 161, iters: 1280, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 161, iters: 1360, time: 0.095, data: 0.049) loss: 0.023 
(epoch: 161, iters: 1440, time: 0.095, data: 0.000) loss: 0.024 
(epoch: 161, iters: 1520, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 161, iters: 1600, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 161, iters: 1680, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 161, iters: 1760, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 161, iters: 1840, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 161, iters: 1920, time: 0.095, data: 0.040) loss: 0.013 
(epoch: 161, iters: 2000, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 161, iters: 2080, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 161, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 161, iters: 2240, time: 0.094, data: 0.020) loss: 0.003 
(epoch: 161, iters: 2320, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 161, iters: 2400, time: 0.094, data: 0.000) loss: 0.075 
(epoch: 161, iters: 2480, time: 0.096, data: 0.039) loss: 0.003 
(epoch: 161, iters: 2560, time: 0.097, data: 0.000) loss: 0.018 
(epoch: 161, iters: 2640, time: 0.094, data: 0.022) loss: 0.001 
(epoch: 161, iters: 2720, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 161, iters: 2800, time: 0.094, data: 0.011) loss: 0.005 
(epoch: 161, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 161, iters: 2960, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 161, iters: 3040, time: 0.095, data: 0.049) loss: 0.001 
(epoch: 161, iters: 3120, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 161, iters: 3200, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 161, iters: 3280, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 161, iters: 3360, time: 0.093, data: 0.012) loss: 0.069 
(epoch: 161, iters: 3440, time: 0.096, data: 0.000) loss: 0.343 
(epoch: 161, iters: 3520, time: 0.094, data: 0.000) loss: 0.028 
(epoch: 161, iters: 3600, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 161, iters: 3680, time: 0.090, data: 0.000) loss: 0.048 
saving the model at the end of epoch 161, iters 600208
End of epoch 161 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001938
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 161, TEST ACC: [94.234 %]

saving the latest model (epoch 162, total_steps 600224)
(epoch: 162, iters: 32, time: 0.092, data: 0.004) loss: 0.009 
(epoch: 162, iters: 112, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 162, iters: 192, time: 0.093, data: 0.011) loss: 0.079 
(epoch: 162, iters: 272, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 162, iters: 352, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 162, iters: 432, time: 0.094, data: 0.048) loss: 0.017 
(epoch: 162, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 162, iters: 592, time: 0.092, data: 0.012) loss: 0.011 
(epoch: 162, iters: 672, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 162, iters: 752, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 162, iters: 832, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 162, iters: 912, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 162, iters: 992, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 162, iters: 1072, time: 0.094, data: 0.000) loss: 0.197 
(epoch: 162, iters: 1152, time: 0.094, data: 0.012) loss: 0.006 
(epoch: 162, iters: 1232, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 162, iters: 1312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 162, iters: 1392, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 162, iters: 1472, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 162, iters: 1552, time: 0.094, data: 0.040) loss: 0.078 
(epoch: 162, iters: 1632, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 162, iters: 1712, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 162, iters: 1792, time: 0.094, data: 0.000) loss: 0.166 
(epoch: 162, iters: 1872, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 162, iters: 1952, time: 0.095, data: 0.000) loss: 0.053 
(epoch: 162, iters: 2032, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 162, iters: 2112, time: 0.095, data: 0.049) loss: 0.324 
(epoch: 162, iters: 2192, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 162, iters: 2272, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 162, iters: 2352, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 162, iters: 2432, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 162, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 162, iters: 2592, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 162, iters: 2672, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 162, iters: 2752, time: 0.095, data: 0.000) loss: 0.030 
(epoch: 162, iters: 2832, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 162, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 162, iters: 2992, time: 0.093, data: 0.012) loss: 0.012 
(epoch: 162, iters: 3072, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 162, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 162, iters: 3232, time: 0.095, data: 0.041) loss: 0.002 
(epoch: 162, iters: 3312, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 162, iters: 3392, time: 0.093, data: 0.013) loss: 0.031 
(epoch: 162, iters: 3472, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 162, iters: 3552, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 162, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 162, iters: 3712, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 162, iters 603936
End of epoch 162 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001937
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 162, TEST ACC: [93.475 %]

saving the latest model (epoch 163, total_steps 603952)
(epoch: 163, iters: 64, time: 0.091, data: 0.003) loss: 0.006 
(epoch: 163, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 163, iters: 224, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 163, iters: 304, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 163, iters: 384, time: 0.093, data: 0.000) loss: 0.020 
(epoch: 163, iters: 464, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 163, iters: 544, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 163, iters: 624, time: 0.092, data: 0.012) loss: 0.030 
(epoch: 163, iters: 704, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 163, iters: 784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 163, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 163, iters: 944, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 163, iters: 1024, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 163, iters: 1104, time: 0.092, data: 0.027) loss: 0.010 
(epoch: 163, iters: 1184, time: 0.094, data: 0.000) loss: 0.022 
(epoch: 163, iters: 1264, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 163, iters: 1344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 163, iters: 1424, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 163, iters: 1504, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 163, iters: 1584, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 163, iters: 1664, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 163, iters: 1744, time: 0.092, data: 0.034) loss: 0.001 
(epoch: 163, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 163, iters: 1904, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 163, iters: 1984, time: 0.095, data: 0.011) loss: 0.162 
(epoch: 163, iters: 2064, time: 0.095, data: 0.038) loss: 0.010 
(epoch: 163, iters: 2144, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 163, iters: 2224, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 163, iters: 2304, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 163, iters: 2384, time: 0.093, data: 0.025) loss: 0.001 
(epoch: 163, iters: 2464, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 163, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 163, iters: 2624, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 163, iters: 2704, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 163, iters: 2784, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 163, iters: 2864, time: 0.097, data: 0.000) loss: 0.009 
(epoch: 163, iters: 2944, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 163, iters: 3024, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 163, iters: 3104, time: 0.094, data: 0.000) loss: 0.036 
(epoch: 163, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 163, iters: 3264, time: 0.094, data: 0.011) loss: 0.012 
(epoch: 163, iters: 3344, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 163, iters: 3424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 163, iters: 3504, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 163, iters: 3584, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 163, iters: 3664, time: 0.087, data: 0.034) loss: 0.000 
saving the model at the end of epoch 163, iters 607664
End of epoch 163 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001936
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 163, TEST ACC: [93.323 %]

(epoch: 164, iters: 16, time: 0.112, data: 0.000) loss: 0.001 
saving the latest model (epoch 164, total_steps 607680)
(epoch: 164, iters: 96, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 164, iters: 176, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 164, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 164, iters: 336, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 164, iters: 416, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 164, iters: 496, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 164, iters: 576, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 164, iters: 656, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 164, iters: 736, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 164, iters: 816, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 164, iters: 896, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 164, iters: 976, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 164, iters: 1056, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 164, iters: 1136, time: 0.096, data: 0.040) loss: 0.002 
(epoch: 164, iters: 1216, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 164, iters: 1296, time: 0.093, data: 0.021) loss: 0.001 
(epoch: 164, iters: 1376, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 164, iters: 1456, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 164, iters: 1536, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 164, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 164, iters: 1696, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 164, iters: 1776, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 164, iters: 1856, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 164, iters: 1936, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 164, iters: 2016, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 164, iters: 2096, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 164, iters: 2176, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 164, iters: 2256, time: 0.094, data: 0.040) loss: 0.006 
(epoch: 164, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 164, iters: 2416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 164, iters: 2496, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 164, iters: 2576, time: 0.094, data: 0.011) loss: 0.008 
(epoch: 164, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 164, iters: 2736, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 164, iters: 2816, time: 0.096, data: 0.040) loss: 0.005 
(epoch: 164, iters: 2896, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 164, iters: 2976, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 164, iters: 3056, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 164, iters: 3136, time: 0.093, data: 0.012) loss: 0.013 
(epoch: 164, iters: 3216, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 164, iters: 3296, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 164, iters: 3376, time: 0.095, data: 0.049) loss: 0.040 
(epoch: 164, iters: 3456, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 164, iters: 3536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 164, iters: 3616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 164, iters: 3696, time: 0.089, data: 0.011) loss: 0.000 
saving the model at the end of epoch 164, iters 611392
End of epoch 164 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001935
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 164, TEST ACC: [92.564 %]

saving the latest model (epoch 165, total_steps 611408)
(epoch: 165, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 165, iters: 128, time: 0.093, data: 0.042) loss: 0.003 
(epoch: 165, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 165, iters: 288, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 165, iters: 368, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 165, iters: 448, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 165, iters: 528, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 165, iters: 608, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 165, iters: 688, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 165, iters: 768, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 165, iters: 848, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 165, iters: 928, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 165, iters: 1008, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 165, iters: 1088, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 165, iters: 1168, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 165, iters: 1248, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 165, iters: 1328, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 165, iters: 1408, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 165, iters: 1488, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 165, iters: 1568, time: 0.094, data: 0.011) loss: 0.067 
(epoch: 165, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 165, iters: 1728, time: 0.099, data: 0.000) loss: 0.037 
(epoch: 165, iters: 1808, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 165, iters: 1888, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 165, iters: 1968, time: 0.093, data: 0.012) loss: 0.039 
(epoch: 165, iters: 2048, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 165, iters: 2128, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 165, iters: 2208, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 165, iters: 2288, time: 0.094, data: 0.000) loss: 0.119 
(epoch: 165, iters: 2368, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 165, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 165, iters: 2528, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 165, iters: 2608, time: 0.095, data: 0.000) loss: 0.296 
(epoch: 165, iters: 2688, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 165, iters: 2768, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 165, iters: 2848, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 165, iters: 2928, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 165, iters: 3008, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 165, iters: 3088, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 165, iters: 3168, time: 0.094, data: 0.000) loss: 0.105 
(epoch: 165, iters: 3248, time: 0.093, data: 0.011) loss: 0.024 
(epoch: 165, iters: 3328, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 165, iters: 3408, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 165, iters: 3488, time: 0.097, data: 0.049) loss: 0.481 
(epoch: 165, iters: 3568, time: 0.097, data: 0.000) loss: 0.006 
(epoch: 165, iters: 3648, time: 0.086, data: 0.012) loss: 0.001 
(epoch: 165, iters: 3728, time: 0.057, data: 0.000) loss: 0.001 
saving the model at the end of epoch 165, iters 615120
End of epoch 165 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001934
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 165, TEST ACC: [93.475 %]

saving the latest model (epoch 166, total_steps 615136)
(epoch: 166, iters: 80, time: 0.097, data: 0.527) loss: 0.000 
(epoch: 166, iters: 160, time: 0.096, data: 0.031) loss: 0.001 
(epoch: 166, iters: 240, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 166, iters: 320, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 166, iters: 400, time: 0.094, data: 0.000) loss: 0.023 
(epoch: 166, iters: 480, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 166, iters: 560, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 166, iters: 640, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 166, iters: 720, time: 0.094, data: 0.040) loss: 0.207 
(epoch: 166, iters: 800, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 166, iters: 880, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 166, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 166, iters: 1040, time: 0.094, data: 0.012) loss: 0.017 
(epoch: 166, iters: 1120, time: 0.095, data: 0.000) loss: 0.057 
(epoch: 166, iters: 1200, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 166, iters: 1280, time: 0.095, data: 0.041) loss: 0.016 
(epoch: 166, iters: 1360, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 166, iters: 1440, time: 0.095, data: 0.012) loss: 0.006 
(epoch: 166, iters: 1520, time: 0.097, data: 0.000) loss: 0.094 
(epoch: 166, iters: 1600, time: 0.095, data: 0.011) loss: 0.033 
(epoch: 166, iters: 1680, time: 0.095, data: 0.000) loss: 0.022 
(epoch: 166, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 166, iters: 1840, time: 0.095, data: 0.039) loss: 0.128 
(epoch: 166, iters: 1920, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 166, iters: 2000, time: 0.092, data: 0.011) loss: 0.150 
(epoch: 166, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 166, iters: 2160, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 166, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 166, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 166, iters: 2400, time: 0.096, data: 0.040) loss: 0.245 
(epoch: 166, iters: 2480, time: 0.094, data: 0.000) loss: 0.046 
(epoch: 166, iters: 2560, time: 0.093, data: 0.011) loss: 0.099 
(epoch: 166, iters: 2640, time: 0.095, data: 0.000) loss: 0.031 
(epoch: 166, iters: 2720, time: 0.093, data: 0.011) loss: 0.040 
(epoch: 166, iters: 2800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 166, iters: 2880, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 166, iters: 2960, time: 0.095, data: 0.040) loss: 0.004 
(epoch: 166, iters: 3040, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 166, iters: 3120, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 166, iters: 3200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 166, iters: 3280, time: 0.095, data: 0.011) loss: 0.019 
(epoch: 166, iters: 3360, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 166, iters: 3440, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 166, iters: 3520, time: 0.101, data: 0.050) loss: 0.001 
(epoch: 166, iters: 3600, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 166, iters: 3680, time: 0.089, data: 0.012) loss: 0.006 
saving the model at the end of epoch 166, iters 618848
End of epoch 166 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001933
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 166, TEST ACC: [94.385 %]

saving the latest model (epoch 167, total_steps 618864)
(epoch: 167, iters: 32, time: 0.094, data: 0.006) loss: 0.047 
(epoch: 167, iters: 112, time: 0.096, data: 0.028) loss: 0.001 
(epoch: 167, iters: 192, time: 0.096, data: 0.000) loss: 0.016 
(epoch: 167, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 167, iters: 352, time: 0.097, data: 0.042) loss: 0.013 
(epoch: 167, iters: 432, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 167, iters: 512, time: 0.095, data: 0.012) loss: 0.015 
(epoch: 167, iters: 592, time: 0.097, data: 0.000) loss: 0.009 
(epoch: 167, iters: 672, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 167, iters: 752, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 167, iters: 832, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 167, iters: 912, time: 0.097, data: 0.040) loss: 0.160 
(epoch: 167, iters: 992, time: 0.098, data: 0.000) loss: 0.026 
(epoch: 167, iters: 1072, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 167, iters: 1152, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 167, iters: 1232, time: 0.095, data: 0.013) loss: 0.084 
(epoch: 167, iters: 1312, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 167, iters: 1392, time: 0.096, data: 0.000) loss: 0.024 
(epoch: 167, iters: 1472, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 167, iters: 1552, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 167, iters: 1632, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 167, iters: 1712, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 167, iters: 1792, time: 0.097, data: 0.012) loss: 0.115 
(epoch: 167, iters: 1872, time: 0.097, data: 0.000) loss: 0.030 
(epoch: 167, iters: 1952, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 167, iters: 2032, time: 0.097, data: 0.039) loss: 0.000 
(epoch: 167, iters: 2112, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 167, iters: 2192, time: 0.096, data: 0.011) loss: 0.113 
(epoch: 167, iters: 2272, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 167, iters: 2352, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 167, iters: 2432, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 167, iters: 2512, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 167, iters: 2592, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 167, iters: 2672, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 167, iters: 2752, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 167, iters: 2832, time: 0.097, data: 0.000) loss: 0.166 
(epoch: 167, iters: 2912, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 167, iters: 2992, time: 0.096, data: 0.000) loss: 0.014 
(epoch: 167, iters: 3072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 167, iters: 3152, time: 0.098, data: 0.050) loss: 0.000 
(epoch: 167, iters: 3232, time: 0.097, data: 0.000) loss: 0.009 
(epoch: 167, iters: 3312, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 167, iters: 3392, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 167, iters: 3472, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 167, iters: 3552, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 167, iters: 3632, time: 0.092, data: 0.000) loss: 0.020 
(epoch: 167, iters: 3712, time: 0.090, data: 0.036) loss: 0.000 
saving the model at the end of epoch 167, iters 622576
End of epoch 167 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001932
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 167, TEST ACC: [93.627 %]

saving the latest model (epoch 168, total_steps 622592)
(epoch: 168, iters: 64, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 168, iters: 144, time: 0.095, data: 0.011) loss: 0.018 
(epoch: 168, iters: 224, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 168, iters: 304, time: 0.095, data: 0.012) loss: 0.117 
(epoch: 168, iters: 384, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 168, iters: 464, time: 0.096, data: 0.000) loss: 0.016 
(epoch: 168, iters: 544, time: 0.097, data: 0.041) loss: 0.002 
(epoch: 168, iters: 624, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 168, iters: 704, time: 0.095, data: 0.011) loss: 0.095 
(epoch: 168, iters: 784, time: 0.096, data: 0.000) loss: 0.093 
(epoch: 168, iters: 864, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 168, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 168, iters: 1024, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 168, iters: 1104, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 168, iters: 1184, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 168, iters: 1264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 168, iters: 1344, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 168, iters: 1424, time: 0.094, data: 0.012) loss: 0.017 
(epoch: 168, iters: 1504, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 168, iters: 1584, time: 0.093, data: 0.000) loss: 0.016 
(epoch: 168, iters: 1664, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 168, iters: 1744, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 168, iters: 1824, time: 0.093, data: 0.011) loss: 0.072 
(epoch: 168, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 168, iters: 1984, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 168, iters: 2064, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 168, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 168, iters: 2224, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 168, iters: 2304, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 168, iters: 2384, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 168, iters: 2464, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 168, iters: 2544, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 168, iters: 2624, time: 0.097, data: 0.000) loss: 0.365 
(epoch: 168, iters: 2704, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 168, iters: 2784, time: 0.096, data: 0.040) loss: 0.009 
(epoch: 168, iters: 2864, time: 0.098, data: 0.000) loss: 0.084 
(epoch: 168, iters: 2944, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 168, iters: 3024, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 168, iters: 3104, time: 0.096, data: 0.012) loss: 0.002 
(epoch: 168, iters: 3184, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 168, iters: 3264, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 168, iters: 3344, time: 0.096, data: 0.050) loss: 0.001 
(epoch: 168, iters: 3424, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 168, iters: 3504, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 168, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 168, iters: 3664, time: 0.088, data: 0.012) loss: 0.019 
saving the model at the end of epoch 168, iters 626304
End of epoch 168 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001931
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 168, TEST ACC: [77.693 %]

(epoch: 169, iters: 16, time: 0.108, data: 0.000) loss: 0.001 
saving the latest model (epoch 169, total_steps 626320)
(epoch: 169, iters: 96, time: 0.092, data: 0.000) loss: 0.004 
(epoch: 169, iters: 176, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 169, iters: 256, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 169, iters: 336, time: 0.095, data: 0.000) loss: 0.072 
(epoch: 169, iters: 416, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 169, iters: 496, time: 0.097, data: 0.040) loss: 0.006 
(epoch: 169, iters: 576, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 169, iters: 656, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 169, iters: 736, time: 0.094, data: 0.000) loss: 0.024 
(epoch: 169, iters: 816, time: 0.093, data: 0.011) loss: 0.028 
(epoch: 169, iters: 896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 169, iters: 976, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 169, iters: 1056, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 169, iters: 1136, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 169, iters: 1216, time: 0.092, data: 0.012) loss: 0.005 
(epoch: 169, iters: 1296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 169, iters: 1376, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 169, iters: 1456, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 169, iters: 1536, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 169, iters: 1616, time: 0.097, data: 0.040) loss: 0.016 
(epoch: 169, iters: 1696, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 169, iters: 1776, time: 0.092, data: 0.022) loss: 0.031 
(epoch: 169, iters: 1856, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 169, iters: 1936, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 169, iters: 2016, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 169, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 169, iters: 2176, time: 0.097, data: 0.051) loss: 0.000 
(epoch: 169, iters: 2256, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 169, iters: 2336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 169, iters: 2416, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 169, iters: 2496, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 169, iters: 2576, time: 0.096, data: 0.000) loss: 0.015 
(epoch: 169, iters: 2656, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 169, iters: 2736, time: 0.097, data: 0.041) loss: 0.001 
(epoch: 169, iters: 2816, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 169, iters: 2896, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 169, iters: 2976, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 169, iters: 3056, time: 0.094, data: 0.012) loss: 0.106 
(epoch: 169, iters: 3136, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 169, iters: 3216, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 169, iters: 3296, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 169, iters: 3376, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 169, iters: 3456, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 169, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 169, iters: 3616, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 169, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 169, iters 630032
End of epoch 169 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001930
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 169, TEST ACC: [94.082 %]

saving the latest model (epoch 170, total_steps 630048)
(epoch: 170, iters: 48, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 170, iters: 128, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 170, iters: 208, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 170, iters: 288, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 170, iters: 368, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 170, iters: 448, time: 0.095, data: 0.012) loss: 0.017 
(epoch: 170, iters: 528, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 170, iters: 608, time: 0.093, data: 0.000) loss: 0.024 
(epoch: 170, iters: 688, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 170, iters: 768, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 170, iters: 848, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 170, iters: 928, time: 0.096, data: 0.000) loss: 0.015 
(epoch: 170, iters: 1008, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 170, iters: 1088, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 170, iters: 1168, time: 0.093, data: 0.000) loss: 0.014 
(epoch: 170, iters: 1248, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 170, iters: 1328, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 170, iters: 1408, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 170, iters: 1488, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 170, iters: 1568, time: 0.095, data: 0.012) loss: 0.006 
(epoch: 170, iters: 1648, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 170, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 170, iters: 1808, time: 0.095, data: 0.041) loss: 0.005 
(epoch: 170, iters: 1888, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 170, iters: 1968, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 170, iters: 2048, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 170, iters: 2128, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 170, iters: 2208, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 170, iters: 2288, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 170, iters: 2368, time: 0.094, data: 0.039) loss: 0.008 
(epoch: 170, iters: 2448, time: 0.094, data: 0.000) loss: 0.264 
(epoch: 170, iters: 2528, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 170, iters: 2608, time: 0.095, data: 0.000) loss: 0.029 
(epoch: 170, iters: 2688, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 170, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 170, iters: 2848, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 170, iters: 2928, time: 0.094, data: 0.041) loss: 0.011 
(epoch: 170, iters: 3008, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 170, iters: 3088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 170, iters: 3168, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 170, iters: 3248, time: 0.093, data: 0.013) loss: 0.010 
(epoch: 170, iters: 3328, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 170, iters: 3408, time: 0.093, data: 0.000) loss: 0.016 
(epoch: 170, iters: 3488, time: 0.094, data: 0.039) loss: 0.002 
(epoch: 170, iters: 3568, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 170, iters: 3648, time: 0.086, data: 0.012) loss: 0.012 
(epoch: 170, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 170, iters 633760
End of epoch 170 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001929
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 170, TEST ACC: [94.689 %]

saving the latest model (epoch 171, total_steps 633776)
(epoch: 171, iters: 80, time: 0.095, data: 0.501) loss: 0.001 
(epoch: 171, iters: 160, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 171, iters: 240, time: 0.094, data: 0.040) loss: 0.011 
(epoch: 171, iters: 320, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 171, iters: 400, time: 0.092, data: 0.023) loss: 0.005 
(epoch: 171, iters: 480, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 171, iters: 560, time: 0.093, data: 0.012) loss: 0.015 
(epoch: 171, iters: 640, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 171, iters: 720, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 171, iters: 800, time: 0.094, data: 0.051) loss: 0.015 
(epoch: 171, iters: 880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 171, iters: 960, time: 0.092, data: 0.011) loss: 0.007 
(epoch: 171, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 171, iters: 1120, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 171, iters: 1200, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 171, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 171, iters: 1360, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 171, iters: 1440, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 171, iters: 1520, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 171, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 171, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 171, iters: 1760, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 171, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 171, iters: 1920, time: 0.095, data: 0.040) loss: 0.002 
(epoch: 171, iters: 2000, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 171, iters: 2080, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 171, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 171, iters: 2240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 171, iters: 2320, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 171, iters: 2400, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 171, iters: 2480, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 171, iters: 2560, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 171, iters: 2640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 171, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 171, iters: 2800, time: 0.093, data: 0.011) loss: 0.005 
(epoch: 171, iters: 2880, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 171, iters: 2960, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 171, iters: 3040, time: 0.096, data: 0.039) loss: 0.001 
(epoch: 171, iters: 3120, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 171, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 171, iters: 3280, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 171, iters: 3360, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 171, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 171, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 171, iters: 3600, time: 0.095, data: 0.039) loss: 0.006 
(epoch: 171, iters: 3680, time: 0.090, data: 0.000) loss: 0.001 
saving the model at the end of epoch 171, iters 637488
End of epoch 171 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001928
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 171, TEST ACC: [95.296 %]

saving the latest model (epoch 172, total_steps 637504)
(epoch: 172, iters: 32, time: 0.092, data: 0.005) loss: 0.000 
(epoch: 172, iters: 112, time: 0.096, data: 0.014) loss: 0.000 
(epoch: 172, iters: 192, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 172, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 172, iters: 352, time: 0.093, data: 0.012) loss: 0.007 
(epoch: 172, iters: 432, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 172, iters: 512, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 172, iters: 592, time: 0.095, data: 0.042) loss: 0.002 
(epoch: 172, iters: 672, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 172, iters: 752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 172, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 172, iters: 912, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 172, iters: 992, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 172, iters: 1072, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 172, iters: 1152, time: 0.096, data: 0.043) loss: 0.001 
(epoch: 172, iters: 1232, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 172, iters: 1312, time: 0.094, data: 0.012) loss: 0.013 
(epoch: 172, iters: 1392, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 172, iters: 1472, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 172, iters: 1552, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 172, iters: 1632, time: 0.094, data: 0.000) loss: 0.641 
(epoch: 172, iters: 1712, time: 0.096, data: 0.040) loss: 0.027 
(epoch: 172, iters: 1792, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 172, iters: 1872, time: 0.095, data: 0.012) loss: 0.007 
(epoch: 172, iters: 1952, time: 0.097, data: 0.000) loss: 0.079 
(epoch: 172, iters: 2032, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 172, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 172, iters: 2192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 172, iters: 2272, time: 0.098, data: 0.050) loss: 0.000 
(epoch: 172, iters: 2352, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 172, iters: 2432, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 172, iters: 2512, time: 0.096, data: 0.000) loss: 0.136 
(epoch: 172, iters: 2592, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 172, iters: 2672, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 172, iters: 2752, time: 0.096, data: 0.000) loss: 0.072 
(epoch: 172, iters: 2832, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 172, iters: 2912, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 172, iters: 2992, time: 0.095, data: 0.012) loss: 0.057 
(epoch: 172, iters: 3072, time: 0.097, data: 0.000) loss: 0.028 
(epoch: 172, iters: 3152, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 172, iters: 3232, time: 0.097, data: 0.000) loss: 0.009 
(epoch: 172, iters: 3312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 172, iters: 3392, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 172, iters: 3472, time: 0.097, data: 0.000) loss: 0.006 
(epoch: 172, iters: 3552, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 172, iters: 3632, time: 0.093, data: 0.000) loss: 0.008 
(epoch: 172, iters: 3712, time: 0.090, data: 0.012) loss: 0.000 
saving the model at the end of epoch 172, iters 641216
End of epoch 172 / 2100 	 Time Taken: 358 sec
learning rate = 0.0001927
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 172, TEST ACC: [82.094 %]

saving the latest model (epoch 173, total_steps 641232)
(epoch: 173, iters: 64, time: 0.094, data: 0.003) loss: 0.001 
(epoch: 173, iters: 144, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 173, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 173, iters: 304, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 173, iters: 384, time: 0.098, data: 0.049) loss: 0.005 
(epoch: 173, iters: 464, time: 0.095, data: 0.000) loss: 0.020 
(epoch: 173, iters: 544, time: 0.094, data: 0.012) loss: 0.021 
(epoch: 173, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 173, iters: 704, time: 0.094, data: 0.012) loss: 0.007 
(epoch: 173, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 173, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 173, iters: 944, time: 0.094, data: 0.039) loss: 0.010 
(epoch: 173, iters: 1024, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 173, iters: 1104, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 173, iters: 1184, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 173, iters: 1264, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 173, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 173, iters: 1424, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 173, iters: 1504, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 173, iters: 1584, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 173, iters: 1664, time: 0.092, data: 0.011) loss: 0.003 
(epoch: 173, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 173, iters: 1824, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 173, iters: 1904, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 173, iters: 1984, time: 0.093, data: 0.000) loss: 0.063 
(epoch: 173, iters: 2064, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 173, iters: 2144, time: 0.094, data: 0.000) loss: 0.083 
(epoch: 173, iters: 2224, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 173, iters: 2304, time: 0.094, data: 0.000) loss: 0.040 
(epoch: 173, iters: 2384, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 173, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 173, iters: 2544, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 173, iters: 2624, time: 0.095, data: 0.039) loss: 0.011 
(epoch: 173, iters: 2704, time: 0.098, data: 0.000) loss: 0.043 
(epoch: 173, iters: 2784, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 173, iters: 2864, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 173, iters: 2944, time: 0.096, data: 0.012) loss: 0.004 
(epoch: 173, iters: 3024, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 173, iters: 3104, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 173, iters: 3184, time: 0.096, data: 0.041) loss: 0.003 
(epoch: 173, iters: 3264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 173, iters: 3344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 173, iters: 3424, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 173, iters: 3504, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 173, iters: 3584, time: 0.097, data: 0.000) loss: 0.006 
(epoch: 173, iters: 3664, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 173, iters 644944
End of epoch 173 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001926
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 173, TEST ACC: [94.689 %]

(epoch: 174, iters: 16, time: 0.111, data: 0.014) loss: 0.000 
saving the latest model (epoch 174, total_steps 644960)
(epoch: 174, iters: 96, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 174, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 174, iters: 256, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 174, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 174, iters: 416, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 174, iters: 496, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 174, iters: 576, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 174, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 174, iters: 736, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 174, iters: 816, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 174, iters: 896, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 174, iters: 976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 174, iters: 1056, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 174, iters: 1136, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 174, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 174, iters: 1296, time: 0.094, data: 0.000) loss: 0.058 
(epoch: 174, iters: 1376, time: 0.095, data: 0.051) loss: 0.013 
(epoch: 174, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 174, iters: 1536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 174, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 174, iters: 1696, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 174, iters: 1776, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 174, iters: 1856, time: 0.093, data: 0.000) loss: 0.056 
(epoch: 174, iters: 1936, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 174, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 174, iters: 2096, time: 0.092, data: 0.012) loss: 0.008 
(epoch: 174, iters: 2176, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 174, iters: 2256, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 174, iters: 2336, time: 0.095, data: 0.000) loss: 0.109 
(epoch: 174, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 174, iters: 2496, time: 0.094, data: 0.040) loss: 0.006 
(epoch: 174, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 174, iters: 2656, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 174, iters: 2736, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 174, iters: 2816, time: 0.093, data: 0.012) loss: 0.144 
(epoch: 174, iters: 2896, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 174, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 174, iters: 3056, time: 0.095, data: 0.051) loss: 0.007 
(epoch: 174, iters: 3136, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 174, iters: 3216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 174, iters: 3296, time: 0.093, data: 0.000) loss: 0.022 
(epoch: 174, iters: 3376, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 174, iters: 3456, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 174, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 174, iters: 3616, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 174, iters: 3696, time: 0.089, data: 0.000) loss: 0.004 
saving the model at the end of epoch 174, iters 648672
End of epoch 174 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001925
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 174, TEST ACC: [96.662 %]

saving the latest model (epoch 175, total_steps 648688)
(epoch: 175, iters: 48, time: 0.093, data: 0.000) loss: 0.079 
(epoch: 175, iters: 128, time: 0.095, data: 0.058) loss: 0.000 
(epoch: 175, iters: 208, time: 0.094, data: 0.000) loss: 0.038 
(epoch: 175, iters: 288, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 175, iters: 368, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 175, iters: 448, time: 0.094, data: 0.012) loss: 0.030 
(epoch: 175, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 175, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 175, iters: 688, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 175, iters: 768, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 175, iters: 848, time: 0.092, data: 0.011) loss: 0.021 
(epoch: 175, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 175, iters: 1008, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 175, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 175, iters: 1168, time: 0.093, data: 0.000) loss: 0.459 
(epoch: 175, iters: 1248, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 175, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 175, iters: 1408, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 175, iters: 1488, time: 0.095, data: 0.000) loss: 0.037 
(epoch: 175, iters: 1568, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 175, iters: 1648, time: 0.095, data: 0.000) loss: 0.030 
(epoch: 175, iters: 1728, time: 0.094, data: 0.000) loss: 0.049 
(epoch: 175, iters: 1808, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 175, iters: 1888, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 175, iters: 1968, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 175, iters: 2048, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 175, iters: 2128, time: 0.095, data: 0.012) loss: 0.004 
(epoch: 175, iters: 2208, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 175, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 175, iters: 2368, time: 0.095, data: 0.050) loss: 0.046 
(epoch: 175, iters: 2448, time: 0.096, data: 0.000) loss: 0.015 
(epoch: 175, iters: 2528, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 175, iters: 2608, time: 0.096, data: 0.000) loss: 0.019 
(epoch: 175, iters: 2688, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 175, iters: 2768, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 175, iters: 2848, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 175, iters: 2928, time: 0.096, data: 0.041) loss: 0.004 
(epoch: 175, iters: 3008, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 175, iters: 3088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 175, iters: 3168, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 175, iters: 3248, time: 0.094, data: 0.011) loss: 0.016 
(epoch: 175, iters: 3328, time: 0.095, data: 0.000) loss: 0.095 
(epoch: 175, iters: 3408, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 175, iters: 3488, time: 0.093, data: 0.050) loss: 0.002 
(epoch: 175, iters: 3568, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 175, iters: 3648, time: 0.086, data: 0.011) loss: 0.001 
(epoch: 175, iters: 3728, time: 0.056, data: 0.000) loss: 0.001 
saving the model at the end of epoch 175, iters 652400
End of epoch 175 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001924
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 175, TEST ACC: [96.206 %]

saving the latest model (epoch 176, total_steps 652416)
(epoch: 176, iters: 80, time: 0.095, data: 0.515) loss: 0.000 
(epoch: 176, iters: 160, time: 0.094, data: 0.032) loss: 0.016 
(epoch: 176, iters: 240, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 176, iters: 320, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 176, iters: 400, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 176, iters: 480, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 176, iters: 560, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 176, iters: 640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 176, iters: 720, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 176, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 176, iters: 880, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 176, iters: 960, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 176, iters: 1040, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 176, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 176, iters: 1200, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 176, iters: 1280, time: 0.094, data: 0.040) loss: 0.061 
(epoch: 176, iters: 1360, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 176, iters: 1440, time: 0.093, data: 0.011) loss: 0.008 
(epoch: 176, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 176, iters: 1600, time: 0.093, data: 0.021) loss: 0.001 
(epoch: 176, iters: 1680, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 176, iters: 1760, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 176, iters: 1840, time: 0.094, data: 0.040) loss: 0.011 
(epoch: 176, iters: 1920, time: 0.096, data: 0.000) loss: 0.054 
(epoch: 176, iters: 2000, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 176, iters: 2080, time: 0.094, data: 0.000) loss: 0.820 
(epoch: 176, iters: 2160, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 176, iters: 2240, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 176, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 176, iters: 2400, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 176, iters: 2480, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 176, iters: 2560, time: 0.092, data: 0.012) loss: 0.005 
(epoch: 176, iters: 2640, time: 0.093, data: 0.000) loss: 0.037 
(epoch: 176, iters: 2720, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 176, iters: 2800, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 176, iters: 2880, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 176, iters: 2960, time: 0.094, data: 0.041) loss: 0.008 
(epoch: 176, iters: 3040, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 176, iters: 3120, time: 0.091, data: 0.012) loss: 0.006 
(epoch: 176, iters: 3200, time: 0.094, data: 0.000) loss: 0.177 
(epoch: 176, iters: 3280, time: 0.095, data: 0.013) loss: 0.001 
(epoch: 176, iters: 3360, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 176, iters: 3440, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 176, iters: 3520, time: 0.094, data: 0.041) loss: 0.019 
(epoch: 176, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 176, iters: 3680, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 176, iters 656128
End of epoch 176 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001923
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 176, TEST ACC: [89.681 %]

saving the latest model (epoch 177, total_steps 656144)
(epoch: 177, iters: 32, time: 0.092, data: 0.006) loss: 0.005 
(epoch: 177, iters: 112, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 177, iters: 192, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 177, iters: 272, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 177, iters: 352, time: 0.095, data: 0.041) loss: 0.220 
(epoch: 177, iters: 432, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 177, iters: 512, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 177, iters: 592, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 177, iters: 672, time: 0.095, data: 0.011) loss: 0.006 
(epoch: 177, iters: 752, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 177, iters: 832, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 177, iters: 912, time: 0.096, data: 0.038) loss: 0.001 
(epoch: 177, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 177, iters: 1072, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 177, iters: 1152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 177, iters: 1232, time: 0.095, data: 0.013) loss: 0.369 
(epoch: 177, iters: 1312, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 177, iters: 1392, time: 0.093, data: 0.000) loss: 0.046 
(epoch: 177, iters: 1472, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 177, iters: 1552, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 177, iters: 1632, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 177, iters: 1712, time: 0.094, data: 0.000) loss: 0.042 
(epoch: 177, iters: 1792, time: 0.092, data: 0.012) loss: 0.024 
(epoch: 177, iters: 1872, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 177, iters: 1952, time: 0.094, data: 0.000) loss: 0.026 
(epoch: 177, iters: 2032, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 177, iters: 2112, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 177, iters: 2192, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 177, iters: 2272, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 177, iters: 2352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 177, iters: 2432, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 177, iters: 2512, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 177, iters: 2592, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 177, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 177, iters: 2752, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 177, iters: 2832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 177, iters: 2912, time: 0.095, data: 0.012) loss: 0.006 
(epoch: 177, iters: 2992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 177, iters: 3072, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 177, iters: 3152, time: 0.097, data: 0.041) loss: 0.003 
(epoch: 177, iters: 3232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 177, iters: 3312, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 177, iters: 3392, time: 0.096, data: 0.000) loss: 0.053 
(epoch: 177, iters: 3472, time: 0.095, data: 0.012) loss: 0.076 
(epoch: 177, iters: 3552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 177, iters: 3632, time: 0.093, data: 0.000) loss: 0.033 
(epoch: 177, iters: 3712, time: 0.090, data: 0.035) loss: 0.002 
saving the model at the end of epoch 177, iters 659856
End of epoch 177 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001922
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 177, TEST ACC: [92.109 %]

saving the latest model (epoch 178, total_steps 659872)
(epoch: 178, iters: 64, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 178, iters: 144, time: 0.098, data: 0.000) loss: 0.005 
(epoch: 178, iters: 224, time: 0.095, data: 0.013) loss: 0.003 
(epoch: 178, iters: 304, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 178, iters: 384, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 178, iters: 464, time: 0.098, data: 0.051) loss: 0.003 
(epoch: 178, iters: 544, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 178, iters: 624, time: 0.095, data: 0.013) loss: 0.008 
(epoch: 178, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 178, iters: 784, time: 0.094, data: 0.013) loss: 0.015 
(epoch: 178, iters: 864, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 178, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 178, iters: 1024, time: 0.096, data: 0.041) loss: 0.003 
(epoch: 178, iters: 1104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 178, iters: 1184, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 178, iters: 1264, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 178, iters: 1344, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 178, iters: 1424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 178, iters: 1504, time: 0.094, data: 0.000) loss: 0.038 
(epoch: 178, iters: 1584, time: 0.097, data: 0.040) loss: 0.001 
(epoch: 178, iters: 1664, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 178, iters: 1744, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 178, iters: 1824, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 178, iters: 1904, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 178, iters: 1984, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 178, iters: 2064, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 178, iters: 2144, time: 0.097, data: 0.041) loss: 0.003 
(epoch: 178, iters: 2224, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 178, iters: 2304, time: 0.092, data: 0.012) loss: 0.179 
(epoch: 178, iters: 2384, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 178, iters: 2464, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 178, iters: 2544, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 178, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 178, iters: 2704, time: 0.095, data: 0.052) loss: 0.003 
(epoch: 178, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 178, iters: 2864, time: 0.093, data: 0.012) loss: 0.017 
(epoch: 178, iters: 2944, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 178, iters: 3024, time: 0.095, data: 0.011) loss: 0.011 
(epoch: 178, iters: 3104, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 178, iters: 3184, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 178, iters: 3264, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 178, iters: 3344, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 178, iters: 3424, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 178, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 178, iters: 3584, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 178, iters: 3664, time: 0.088, data: 0.000) loss: 0.008 
saving the model at the end of epoch 178, iters 663584
End of epoch 178 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001921
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 178, TEST ACC: [94.234 %]

(epoch: 179, iters: 16, time: 0.113, data: 0.000) loss: 0.031 
saving the latest model (epoch 179, total_steps 663600)
(epoch: 179, iters: 96, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 179, iters: 176, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 179, iters: 256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 179, iters: 336, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 179, iters: 416, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 179, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 179, iters: 576, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 179, iters: 656, time: 0.098, data: 0.000) loss: 0.011 
(epoch: 179, iters: 736, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 179, iters: 816, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 179, iters: 896, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 179, iters: 976, time: 0.094, data: 0.000) loss: 0.084 
(epoch: 179, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 179, iters: 1136, time: 0.094, data: 0.040) loss: 0.004 
(epoch: 179, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 179, iters: 1296, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 179, iters: 1376, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 179, iters: 1456, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 179, iters: 1536, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 179, iters: 1616, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 179, iters: 1696, time: 0.094, data: 0.040) loss: 0.244 
(epoch: 179, iters: 1776, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 179, iters: 1856, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 179, iters: 1936, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 179, iters: 2016, time: 0.093, data: 0.012) loss: 0.055 
(epoch: 179, iters: 2096, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 179, iters: 2176, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 179, iters: 2256, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 179, iters: 2336, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 179, iters: 2416, time: 0.094, data: 0.012) loss: 0.013 
(epoch: 179, iters: 2496, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 179, iters: 2576, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 179, iters: 2656, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 179, iters: 2736, time: 0.094, data: 0.000) loss: 0.074 
(epoch: 179, iters: 2816, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 179, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 179, iters: 2976, time: 0.092, data: 0.013) loss: 0.003 
(epoch: 179, iters: 3056, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 179, iters: 3136, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 179, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 179, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 179, iters: 3376, time: 0.096, data: 0.040) loss: 0.003 
(epoch: 179, iters: 3456, time: 0.097, data: 0.000) loss: 0.048 
(epoch: 179, iters: 3536, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 179, iters: 3616, time: 0.094, data: 0.000) loss: 0.075 
(epoch: 179, iters: 3696, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 179, iters 667312
End of epoch 179 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001920
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 179, TEST ACC: [95.296 %]

saving the latest model (epoch 180, total_steps 667328)
(epoch: 180, iters: 48, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 180, iters: 128, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 180, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 180, iters: 288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 180, iters: 368, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 180, iters: 448, time: 0.094, data: 0.000) loss: 0.138 
(epoch: 180, iters: 528, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 180, iters: 608, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 180, iters: 688, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 180, iters: 768, time: 0.094, data: 0.000) loss: 0.022 
(epoch: 180, iters: 848, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 180, iters: 928, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 180, iters: 1008, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 180, iters: 1088, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 180, iters: 1168, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 180, iters: 1248, time: 0.094, data: 0.011) loss: 0.059 
(epoch: 180, iters: 1328, time: 0.096, data: 0.000) loss: 0.214 
(epoch: 180, iters: 1408, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 180, iters: 1488, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 180, iters: 1568, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 180, iters: 1648, time: 0.094, data: 0.012) loss: 0.006 
(epoch: 180, iters: 1728, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 180, iters: 1808, time: 0.094, data: 0.012) loss: 0.007 
(epoch: 180, iters: 1888, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 180, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 180, iters: 2048, time: 0.095, data: 0.041) loss: 0.024 
(epoch: 180, iters: 2128, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 180, iters: 2208, time: 0.091, data: 0.012) loss: 0.011 
(epoch: 180, iters: 2288, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 180, iters: 2368, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 180, iters: 2448, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 180, iters: 2528, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 180, iters: 2608, time: 0.094, data: 0.040) loss: 0.174 
(epoch: 180, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 180, iters: 2768, time: 0.091, data: 0.012) loss: 0.006 
(epoch: 180, iters: 2848, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 180, iters: 2928, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 180, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 180, iters: 3088, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 180, iters: 3168, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 180, iters: 3248, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 180, iters: 3328, time: 0.094, data: 0.012) loss: 0.033 
(epoch: 180, iters: 3408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 180, iters: 3488, time: 0.092, data: 0.012) loss: 0.005 
(epoch: 180, iters: 3568, time: 0.095, data: 0.000) loss: 0.046 
(epoch: 180, iters: 3648, time: 0.087, data: 0.000) loss: 0.000 
(epoch: 180, iters: 3728, time: 0.057, data: 0.016) loss: 0.001 
saving the model at the end of epoch 180, iters 671040
End of epoch 180 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001919
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 180, TEST ACC: [93.02 %]

saving the latest model (epoch 181, total_steps 671056)
(epoch: 181, iters: 80, time: 0.095, data: 0.515) loss: 0.001 
(epoch: 181, iters: 160, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 181, iters: 240, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 181, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 181, iters: 400, time: 0.093, data: 0.012) loss: 0.023 
(epoch: 181, iters: 480, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 181, iters: 560, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 181, iters: 640, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 181, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 181, iters: 800, time: 0.097, data: 0.051) loss: 0.089 
(epoch: 181, iters: 880, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 181, iters: 960, time: 0.094, data: 0.013) loss: 0.001 
(epoch: 181, iters: 1040, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 181, iters: 1120, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 181, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 181, iters: 1280, time: 0.093, data: 0.000) loss: 0.018 
(epoch: 181, iters: 1360, time: 0.094, data: 0.040) loss: 0.019 
(epoch: 181, iters: 1440, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 181, iters: 1520, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 181, iters: 1600, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 181, iters: 1680, time: 0.092, data: 0.012) loss: 0.006 
(epoch: 181, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 181, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 181, iters: 1920, time: 0.096, data: 0.050) loss: 0.001 
(epoch: 181, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 181, iters: 2080, time: 0.092, data: 0.011) loss: 0.088 
(epoch: 181, iters: 2160, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 181, iters: 2240, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 181, iters: 2320, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 181, iters: 2400, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 181, iters: 2480, time: 0.094, data: 0.039) loss: 0.016 
(epoch: 181, iters: 2560, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 181, iters: 2640, time: 0.092, data: 0.012) loss: 0.005 
(epoch: 181, iters: 2720, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 181, iters: 2800, time: 0.094, data: 0.011) loss: 0.006 
(epoch: 181, iters: 2880, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 181, iters: 2960, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 181, iters: 3040, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 181, iters: 3120, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 181, iters: 3200, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 181, iters: 3280, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 181, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 181, iters: 3440, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 181, iters: 3520, time: 0.095, data: 0.000) loss: 0.052 
(epoch: 181, iters: 3600, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 181, iters: 3680, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 181, iters 674768
End of epoch 181 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001918
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 181, TEST ACC: [90.592 %]

saving the latest model (epoch 182, total_steps 674784)
(epoch: 182, iters: 32, time: 0.094, data: 0.004) loss: 0.000 
(epoch: 182, iters: 112, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 182, iters: 192, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 182, iters: 272, time: 0.097, data: 0.000) loss: 0.027 
(epoch: 182, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 182, iters: 432, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 182, iters: 512, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 182, iters: 592, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 182, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 182, iters: 752, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 182, iters: 832, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 182, iters: 912, time: 0.095, data: 0.000) loss: 0.033 
(epoch: 182, iters: 992, time: 0.093, data: 0.048) loss: 0.003 
(epoch: 182, iters: 1072, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 182, iters: 1152, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 182, iters: 1232, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 182, iters: 1312, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 182, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 182, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 182, iters: 1552, time: 0.096, data: 0.040) loss: 0.109 
(epoch: 182, iters: 1632, time: 0.094, data: 0.000) loss: 0.240 
(epoch: 182, iters: 1712, time: 0.091, data: 0.020) loss: 0.001 
(epoch: 182, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 182, iters: 1872, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 182, iters: 1952, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 182, iters: 2032, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 182, iters: 2112, time: 0.094, data: 0.048) loss: 0.005 
(epoch: 182, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 182, iters: 2272, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 182, iters: 2352, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 182, iters: 2432, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 182, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 182, iters: 2592, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 182, iters: 2672, time: 0.095, data: 0.041) loss: 0.044 
(epoch: 182, iters: 2752, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 182, iters: 2832, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 182, iters: 2912, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 182, iters: 2992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 182, iters: 3072, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 182, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 182, iters: 3232, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 182, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 182, iters: 3392, time: 0.091, data: 0.011) loss: 0.009 
(epoch: 182, iters: 3472, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 182, iters: 3552, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 182, iters: 3632, time: 0.092, data: 0.000) loss: 0.004 
(epoch: 182, iters: 3712, time: 0.088, data: 0.000) loss: 0.004 
saving the model at the end of epoch 182, iters 678496
End of epoch 182 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001917
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 182, TEST ACC: [95.144 %]

saving the latest model (epoch 183, total_steps 678512)
(epoch: 183, iters: 64, time: 0.092, data: 0.003) loss: 0.011 
(epoch: 183, iters: 144, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 183, iters: 224, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 183, iters: 304, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 183, iters: 384, time: 0.095, data: 0.040) loss: 0.002 
(epoch: 183, iters: 464, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 183, iters: 544, time: 0.095, data: 0.012) loss: 0.004 
(epoch: 183, iters: 624, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 183, iters: 704, time: 0.095, data: 0.011) loss: 0.018 
(epoch: 183, iters: 784, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 183, iters: 864, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 183, iters: 944, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 183, iters: 1024, time: 0.097, data: 0.000) loss: 0.036 
(epoch: 183, iters: 1104, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 183, iters: 1184, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 183, iters: 1264, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 183, iters: 1344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 183, iters: 1424, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 183, iters: 1504, time: 0.097, data: 0.042) loss: 0.044 
(epoch: 183, iters: 1584, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 183, iters: 1664, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 183, iters: 1744, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 183, iters: 1824, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 183, iters: 1904, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 183, iters: 1984, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 183, iters: 2064, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 183, iters: 2144, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 183, iters: 2224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 183, iters: 2304, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 183, iters: 2384, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 183, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 183, iters: 2544, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 183, iters: 2624, time: 0.094, data: 0.039) loss: 0.012 
(epoch: 183, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 183, iters: 2784, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 183, iters: 2864, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 183, iters: 2944, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 183, iters: 3024, time: 0.094, data: 0.000) loss: 0.095 
(epoch: 183, iters: 3104, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 183, iters: 3184, time: 0.094, data: 0.041) loss: 0.045 
(epoch: 183, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 183, iters: 3344, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 183, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 183, iters: 3504, time: 0.094, data: 0.012) loss: 0.151 
(epoch: 183, iters: 3584, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 183, iters: 3664, time: 0.089, data: 0.000) loss: 0.018 
saving the model at the end of epoch 183, iters 682224
End of epoch 183 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001916
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 183, TEST ACC: [93.627 %]

(epoch: 184, iters: 16, time: 0.111, data: 0.013) loss: 0.001 
saving the latest model (epoch 184, total_steps 682240)
(epoch: 184, iters: 96, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 184, iters: 176, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 184, iters: 256, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 184, iters: 336, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 184, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 184, iters: 496, time: 0.093, data: 0.000) loss: 0.025 
(epoch: 184, iters: 576, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 184, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 184, iters: 736, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 184, iters: 816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 184, iters: 896, time: 0.094, data: 0.012) loss: 0.026 
(epoch: 184, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 184, iters: 1056, time: 0.094, data: 0.000) loss: 0.227 
(epoch: 184, iters: 1136, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 184, iters: 1216, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 184, iters: 1296, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 184, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 184, iters: 1456, time: 0.093, data: 0.020) loss: 0.001 
(epoch: 184, iters: 1536, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 184, iters: 1616, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 184, iters: 1696, time: 0.094, data: 0.039) loss: 0.002 
(epoch: 184, iters: 1776, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 184, iters: 1856, time: 0.092, data: 0.011) loss: 0.004 
(epoch: 184, iters: 1936, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 184, iters: 2016, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 184, iters: 2096, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 184, iters: 2176, time: 0.093, data: 0.000) loss: 0.010 
(epoch: 184, iters: 2256, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 184, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 184, iters: 2416, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 184, iters: 2496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 184, iters: 2576, time: 0.095, data: 0.012) loss: 0.007 
(epoch: 184, iters: 2656, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 184, iters: 2736, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 184, iters: 2816, time: 0.094, data: 0.040) loss: 0.005 
(epoch: 184, iters: 2896, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 184, iters: 2976, time: 0.091, data: 0.012) loss: 0.026 
(epoch: 184, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 184, iters: 3136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 184, iters: 3216, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 184, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 184, iters: 3376, time: 0.097, data: 0.040) loss: 0.040 
(epoch: 184, iters: 3456, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 184, iters: 3536, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 184, iters: 3616, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 184, iters: 3696, time: 0.090, data: 0.013) loss: 0.000 
saving the model at the end of epoch 184, iters 685952
End of epoch 184 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001915
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 184, TEST ACC: [90.895 %]

saving the latest model (epoch 185, total_steps 685968)
(epoch: 185, iters: 48, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 185, iters: 128, time: 0.094, data: 0.042) loss: 0.009 
(epoch: 185, iters: 208, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 185, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 185, iters: 368, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 185, iters: 448, time: 0.093, data: 0.011) loss: 0.024 
(epoch: 185, iters: 528, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 185, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 185, iters: 688, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 185, iters: 768, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 185, iters: 848, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 185, iters: 928, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 185, iters: 1008, time: 0.093, data: 0.011) loss: 0.019 
(epoch: 185, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 185, iters: 1168, time: 0.093, data: 0.000) loss: 0.465 
(epoch: 185, iters: 1248, time: 0.094, data: 0.039) loss: 0.020 
(epoch: 185, iters: 1328, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 185, iters: 1408, time: 0.092, data: 0.011) loss: 0.177 
(epoch: 185, iters: 1488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 185, iters: 1568, time: 0.094, data: 0.012) loss: 0.077 
(epoch: 185, iters: 1648, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 185, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 185, iters: 1808, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 185, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 185, iters: 1968, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 185, iters: 2048, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 185, iters: 2128, time: 0.093, data: 0.011) loss: 0.012 
(epoch: 185, iters: 2208, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 185, iters: 2288, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 185, iters: 2368, time: 0.095, data: 0.041) loss: 0.010 
(epoch: 185, iters: 2448, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 185, iters: 2528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 185, iters: 2608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 185, iters: 2688, time: 0.093, data: 0.012) loss: 0.054 
(epoch: 185, iters: 2768, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 185, iters: 2848, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 185, iters: 2928, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 185, iters: 3008, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 185, iters: 3088, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 185, iters: 3168, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 185, iters: 3248, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 185, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 185, iters: 3408, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 185, iters: 3488, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 185, iters: 3568, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 185, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 185, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 185, iters 689680
End of epoch 185 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001914
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 185, TEST ACC: [90.44 %]

saving the latest model (epoch 186, total_steps 689696)
(epoch: 186, iters: 80, time: 0.097, data: 0.509) loss: 0.001 
(epoch: 186, iters: 160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 186, iters: 240, time: 0.094, data: 0.050) loss: 0.044 
(epoch: 186, iters: 320, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 186, iters: 400, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 186, iters: 480, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 186, iters: 560, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 186, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 186, iters: 720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 186, iters: 800, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 186, iters: 880, time: 0.095, data: 0.000) loss: 0.055 
(epoch: 186, iters: 960, time: 0.093, data: 0.011) loss: 0.298 
(epoch: 186, iters: 1040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 186, iters: 1120, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 186, iters: 1200, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 186, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 186, iters: 1360, time: 0.095, data: 0.049) loss: 0.001 
(epoch: 186, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 186, iters: 1520, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 186, iters: 1600, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 186, iters: 1680, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 186, iters: 1760, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 186, iters: 1840, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 186, iters: 1920, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 186, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 186, iters: 2080, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 186, iters: 2160, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 186, iters: 2240, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 186, iters: 2320, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 186, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 186, iters: 2480, time: 0.095, data: 0.050) loss: 0.002 
(epoch: 186, iters: 2560, time: 0.094, data: 0.000) loss: 0.139 
(epoch: 186, iters: 2640, time: 0.093, data: 0.013) loss: 0.020 
(epoch: 186, iters: 2720, time: 0.094, data: 0.000) loss: 0.233 
(epoch: 186, iters: 2800, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 186, iters: 2880, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 186, iters: 2960, time: 0.092, data: 0.000) loss: 0.015 
(epoch: 186, iters: 3040, time: 0.094, data: 0.039) loss: 0.228 
(epoch: 186, iters: 3120, time: 0.094, data: 0.000) loss: 0.025 
(epoch: 186, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 186, iters: 3280, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 186, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 186, iters: 3440, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 186, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 186, iters: 3600, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 186, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 186, iters 693408
End of epoch 186 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001913
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 186, TEST ACC: [93.627 %]

saving the latest model (epoch 187, total_steps 693424)
(epoch: 187, iters: 32, time: 0.093, data: 0.005) loss: 0.001 
(epoch: 187, iters: 112, time: 0.095, data: 0.000) loss: 0.156 
(epoch: 187, iters: 192, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 187, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 187, iters: 352, time: 0.094, data: 0.039) loss: 0.002 
(epoch: 187, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 187, iters: 512, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 187, iters: 592, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 187, iters: 672, time: 0.094, data: 0.012) loss: 0.008 
(epoch: 187, iters: 752, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 187, iters: 832, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 187, iters: 912, time: 0.094, data: 0.039) loss: 0.006 
(epoch: 187, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 187, iters: 1072, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 187, iters: 1152, time: 0.094, data: 0.000) loss: 0.075 
(epoch: 187, iters: 1232, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 187, iters: 1312, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 187, iters: 1392, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 187, iters: 1472, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 187, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 187, iters: 1632, time: 0.092, data: 0.011) loss: 0.010 
(epoch: 187, iters: 1712, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 187, iters: 1792, time: 0.094, data: 0.011) loss: 0.040 
(epoch: 187, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 187, iters: 1952, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 187, iters: 2032, time: 0.094, data: 0.040) loss: 0.006 
(epoch: 187, iters: 2112, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 187, iters: 2192, time: 0.094, data: 0.011) loss: 0.046 
(epoch: 187, iters: 2272, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 187, iters: 2352, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 187, iters: 2432, time: 0.096, data: 0.000) loss: 0.083 
(epoch: 187, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 187, iters: 2592, time: 0.097, data: 0.050) loss: 0.002 
(epoch: 187, iters: 2672, time: 0.095, data: 0.000) loss: 0.030 
(epoch: 187, iters: 2752, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 187, iters: 2832, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 187, iters: 2912, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 187, iters: 2992, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 187, iters: 3072, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 187, iters: 3152, time: 0.094, data: 0.041) loss: 0.005 
(epoch: 187, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 187, iters: 3312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 187, iters: 3392, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 187, iters: 3472, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 187, iters: 3552, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 187, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 187, iters: 3712, time: 0.089, data: 0.045) loss: 0.000 
saving the model at the end of epoch 187, iters 697136
End of epoch 187 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001912
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 187, TEST ACC: [97.269 %]

saving the latest model (epoch 188, total_steps 697152)
(epoch: 188, iters: 64, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 188, iters: 144, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 188, iters: 224, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 188, iters: 304, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 188, iters: 384, time: 0.093, data: 0.000) loss: 0.093 
(epoch: 188, iters: 464, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 188, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 188, iters: 624, time: 0.095, data: 0.012) loss: 0.009 
(epoch: 188, iters: 704, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 188, iters: 784, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 188, iters: 864, time: 0.094, data: 0.000) loss: 0.069 
(epoch: 188, iters: 944, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 188, iters: 1024, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 188, iters: 1104, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 188, iters: 1184, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 188, iters: 1264, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 188, iters: 1344, time: 0.095, data: 0.012) loss: 0.006 
(epoch: 188, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 188, iters: 1504, time: 0.093, data: 0.000) loss: 0.032 
(epoch: 188, iters: 1584, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 188, iters: 1664, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 188, iters: 1744, time: 0.092, data: 0.011) loss: 0.006 
(epoch: 188, iters: 1824, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 188, iters: 1904, time: 0.094, data: 0.012) loss: 0.005 
(epoch: 188, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 188, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 188, iters: 2144, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 188, iters: 2224, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 188, iters: 2304, time: 0.092, data: 0.012) loss: 0.007 
(epoch: 188, iters: 2384, time: 0.095, data: 0.000) loss: 0.027 
(epoch: 188, iters: 2464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 188, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 188, iters: 2624, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 188, iters: 2704, time: 0.096, data: 0.039) loss: 0.035 
(epoch: 188, iters: 2784, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 188, iters: 2864, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 188, iters: 2944, time: 0.094, data: 0.000) loss: 0.017 
(epoch: 188, iters: 3024, time: 0.094, data: 0.021) loss: 0.001 
(epoch: 188, iters: 3104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 188, iters: 3184, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 188, iters: 3264, time: 0.095, data: 0.039) loss: 0.044 
(epoch: 188, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 188, iters: 3424, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 188, iters: 3504, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 188, iters: 3584, time: 0.093, data: 0.012) loss: 0.071 
(epoch: 188, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 188, iters 700864
End of epoch 188 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001911
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 188, TEST ACC: [95.144 %]

(epoch: 189, iters: 16, time: 0.109, data: 0.000) loss: 0.003 
saving the latest model (epoch 189, total_steps 700880)
(epoch: 189, iters: 96, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 189, iters: 176, time: 0.095, data: 0.011) loss: 0.019 
(epoch: 189, iters: 256, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 189, iters: 336, time: 0.092, data: 0.012) loss: 0.177 
(epoch: 189, iters: 416, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 189, iters: 496, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 189, iters: 576, time: 0.095, data: 0.050) loss: 0.002 
(epoch: 189, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 189, iters: 736, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 189, iters: 816, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 189, iters: 896, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 189, iters: 976, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 189, iters: 1056, time: 0.093, data: 0.000) loss: 0.057 
(epoch: 189, iters: 1136, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 189, iters: 1216, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 189, iters: 1296, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 189, iters: 1376, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 189, iters: 1456, time: 0.096, data: 0.011) loss: 0.002 
(epoch: 189, iters: 1536, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 189, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 189, iters: 1696, time: 0.094, data: 0.050) loss: 0.001 
(epoch: 189, iters: 1776, time: 0.097, data: 0.000) loss: 0.032 
(epoch: 189, iters: 1856, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 189, iters: 1936, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 189, iters: 2016, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 189, iters: 2096, time: 0.094, data: 0.000) loss: 0.209 
(epoch: 189, iters: 2176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 189, iters: 2256, time: 0.096, data: 0.040) loss: 0.008 
(epoch: 189, iters: 2336, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 189, iters: 2416, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 189, iters: 2496, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 189, iters: 2576, time: 0.093, data: 0.012) loss: 0.404 
(epoch: 189, iters: 2656, time: 0.095, data: 0.000) loss: 0.099 
(epoch: 189, iters: 2736, time: 0.093, data: 0.000) loss: 0.044 
(epoch: 189, iters: 2816, time: 0.096, data: 0.039) loss: 0.001 
(epoch: 189, iters: 2896, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 189, iters: 2976, time: 0.094, data: 0.011) loss: 0.006 
(epoch: 189, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 189, iters: 3136, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 189, iters: 3216, time: 0.094, data: 0.000) loss: 0.049 
(epoch: 189, iters: 3296, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 189, iters: 3376, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 189, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 189, iters: 3536, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 189, iters: 3616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 189, iters: 3696, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 189, iters 704592
End of epoch 189 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001910
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 189, TEST ACC: [94.537 %]

saving the latest model (epoch 190, total_steps 704608)
(epoch: 190, iters: 48, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 190, iters: 128, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 190, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 190, iters: 288, time: 0.092, data: 0.012) loss: 0.087 
(epoch: 190, iters: 368, time: 0.094, data: 0.000) loss: 0.023 
(epoch: 190, iters: 448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 190, iters: 528, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 190, iters: 608, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 190, iters: 688, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 190, iters: 768, time: 0.097, data: 0.000) loss: 0.016 
(epoch: 190, iters: 848, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 190, iters: 928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 190, iters: 1008, time: 0.095, data: 0.012) loss: 0.043 
(epoch: 190, iters: 1088, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 190, iters: 1168, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 190, iters: 1248, time: 0.094, data: 0.041) loss: 0.003 
(epoch: 190, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 190, iters: 1408, time: 0.092, data: 0.012) loss: 0.014 
(epoch: 190, iters: 1488, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 190, iters: 1568, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 190, iters: 1648, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 190, iters: 1728, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 190, iters: 1808, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 190, iters: 1888, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 190, iters: 1968, time: 0.095, data: 0.012) loss: 0.011 
(epoch: 190, iters: 2048, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 190, iters: 2128, time: 0.097, data: 0.011) loss: 0.280 
(epoch: 190, iters: 2208, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 190, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 190, iters: 2368, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 190, iters: 2448, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 190, iters: 2528, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 190, iters: 2608, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 190, iters: 2688, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 190, iters: 2768, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 190, iters: 2848, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 190, iters: 2928, time: 0.097, data: 0.040) loss: 0.008 
(epoch: 190, iters: 3008, time: 0.097, data: 0.000) loss: 0.016 
(epoch: 190, iters: 3088, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 190, iters: 3168, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 190, iters: 3248, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 190, iters: 3328, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 190, iters: 3408, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 190, iters: 3488, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 190, iters: 3568, time: 0.095, data: 0.000) loss: 0.080 
(epoch: 190, iters: 3648, time: 0.086, data: 0.011) loss: 0.001 
(epoch: 190, iters: 3728, time: 0.058, data: 0.000) loss: 0.000 
saving the model at the end of epoch 190, iters 708320
End of epoch 190 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001909
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 190, TEST ACC: [96.055 %]

saving the latest model (epoch 191, total_steps 708336)
(epoch: 191, iters: 80, time: 0.091, data: 0.525) loss: 0.000 
(epoch: 191, iters: 160, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 191, iters: 240, time: 0.093, data: 0.011) loss: 0.007 
(epoch: 191, iters: 320, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 191, iters: 400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 191, iters: 480, time: 0.096, data: 0.040) loss: 0.005 
(epoch: 191, iters: 560, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 191, iters: 640, time: 0.092, data: 0.020) loss: 0.020 
(epoch: 191, iters: 720, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 191, iters: 800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 191, iters: 880, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 191, iters: 960, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 191, iters: 1040, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 191, iters: 1120, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 191, iters: 1200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 191, iters: 1280, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 191, iters: 1360, time: 0.096, data: 0.011) loss: 0.004 
(epoch: 191, iters: 1440, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 191, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 191, iters: 1600, time: 0.094, data: 0.041) loss: 0.009 
(epoch: 191, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 191, iters: 1760, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 191, iters: 1840, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 191, iters: 1920, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 191, iters: 2000, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 191, iters: 2080, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 191, iters: 2160, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 191, iters: 2240, time: 0.095, data: 0.000) loss: 0.189 
(epoch: 191, iters: 2320, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 191, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 191, iters: 2480, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 191, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 191, iters: 2640, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 191, iters: 2720, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 191, iters: 2800, time: 0.095, data: 0.000) loss: 0.025 
(epoch: 191, iters: 2880, time: 0.093, data: 0.011) loss: 0.033 
(epoch: 191, iters: 2960, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 191, iters: 3040, time: 0.093, data: 0.012) loss: 0.127 
(epoch: 191, iters: 3120, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 191, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 191, iters: 3280, time: 0.095, data: 0.040) loss: 0.004 
(epoch: 191, iters: 3360, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 191, iters: 3440, time: 0.092, data: 0.011) loss: 0.101 
(epoch: 191, iters: 3520, time: 0.094, data: 0.000) loss: 0.197 
(epoch: 191, iters: 3600, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 191, iters: 3680, time: 0.087, data: 0.000) loss: 0.102 
saving the model at the end of epoch 191, iters 712048
End of epoch 191 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001908
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 191, TEST ACC: [95.903 %]

saving the latest model (epoch 192, total_steps 712064)
(epoch: 192, iters: 32, time: 0.092, data: 0.000) loss: 0.199 
(epoch: 192, iters: 112, time: 0.094, data: 0.012) loss: 0.132 
(epoch: 192, iters: 192, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 192, iters: 272, time: 0.092, data: 0.000) loss: 0.007 
(epoch: 192, iters: 352, time: 0.094, data: 0.039) loss: 0.002 
(epoch: 192, iters: 432, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 192, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 192, iters: 592, time: 0.095, data: 0.000) loss: 0.061 
(epoch: 192, iters: 672, time: 0.093, data: 0.013) loss: 0.024 
(epoch: 192, iters: 752, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 192, iters: 832, time: 0.093, data: 0.000) loss: 0.014 
(epoch: 192, iters: 912, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 192, iters: 992, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 192, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 192, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 192, iters: 1232, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 192, iters: 1312, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 192, iters: 1392, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 192, iters: 1472, time: 0.094, data: 0.039) loss: 0.015 
(epoch: 192, iters: 1552, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 192, iters: 1632, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 192, iters: 1712, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 192, iters: 1792, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 192, iters: 1872, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 192, iters: 1952, time: 0.093, data: 0.000) loss: 0.013 
(epoch: 192, iters: 2032, time: 0.093, data: 0.038) loss: 0.001 
(epoch: 192, iters: 2112, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 192, iters: 2192, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 192, iters: 2272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 192, iters: 2352, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 192, iters: 2432, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 192, iters: 2512, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 192, iters: 2592, time: 0.094, data: 0.049) loss: 0.001 
(epoch: 192, iters: 2672, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 192, iters: 2752, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 192, iters: 2832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 192, iters: 2912, time: 0.094, data: 0.011) loss: 0.020 
(epoch: 192, iters: 2992, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 192, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 192, iters: 3152, time: 0.094, data: 0.039) loss: 0.006 
(epoch: 192, iters: 3232, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 192, iters: 3312, time: 0.092, data: 0.011) loss: 0.008 
(epoch: 192, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 192, iters: 3472, time: 0.093, data: 0.011) loss: 0.012 
(epoch: 192, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 192, iters: 3632, time: 0.091, data: 0.000) loss: 0.003 
(epoch: 192, iters: 3712, time: 0.088, data: 0.037) loss: 0.000 
saving the model at the end of epoch 192, iters 715776
End of epoch 192 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001907
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 192, TEST ACC: [61.608 %]

saving the latest model (epoch 193, total_steps 715792)
(epoch: 193, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 193, iters: 144, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 193, iters: 224, time: 0.094, data: 0.011) loss: 0.025 
(epoch: 193, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 193, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 193, iters: 464, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 193, iters: 544, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 193, iters: 624, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 193, iters: 704, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 193, iters: 784, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 193, iters: 864, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 193, iters: 944, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 193, iters: 1024, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 193, iters: 1104, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 193, iters: 1184, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 193, iters: 1264, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 193, iters: 1344, time: 0.092, data: 0.012) loss: 0.011 
(epoch: 193, iters: 1424, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 193, iters: 1504, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 193, iters: 1584, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 193, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 193, iters: 1744, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 193, iters: 1824, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 193, iters: 1904, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 193, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 193, iters: 2064, time: 0.093, data: 0.000) loss: 0.029 
(epoch: 193, iters: 2144, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 193, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 193, iters: 2304, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 193, iters: 2384, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 193, iters: 2464, time: 0.095, data: 0.011) loss: 0.026 
(epoch: 193, iters: 2544, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 193, iters: 2624, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 193, iters: 2704, time: 0.094, data: 0.049) loss: 0.019 
(epoch: 193, iters: 2784, time: 0.094, data: 0.000) loss: 0.046 
(epoch: 193, iters: 2864, time: 0.092, data: 0.012) loss: 0.047 
(epoch: 193, iters: 2944, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 193, iters: 3024, time: 0.093, data: 0.011) loss: 0.023 
(epoch: 193, iters: 3104, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 193, iters: 3184, time: 0.092, data: 0.000) loss: 0.032 
(epoch: 193, iters: 3264, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 193, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 193, iters: 3424, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 193, iters: 3504, time: 0.094, data: 0.000) loss: 0.111 
(epoch: 193, iters: 3584, time: 0.095, data: 0.012) loss: 0.045 
(epoch: 193, iters: 3664, time: 0.089, data: 0.000) loss: 0.028 
saving the model at the end of epoch 193, iters 719504
End of epoch 193 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001906
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 193, TEST ACC: [96.813 %]

(epoch: 194, iters: 16, time: 0.108, data: 0.000) loss: 0.005 
saving the latest model (epoch 194, total_steps 719520)
(epoch: 194, iters: 96, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 194, iters: 176, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 194, iters: 256, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 194, iters: 336, time: 0.094, data: 0.011) loss: 0.177 
(epoch: 194, iters: 416, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 194, iters: 496, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 194, iters: 576, time: 0.095, data: 0.049) loss: 0.211 
(epoch: 194, iters: 656, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 194, iters: 736, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 194, iters: 816, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 194, iters: 896, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 194, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 194, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 194, iters: 1136, time: 0.095, data: 0.040) loss: 0.011 
(epoch: 194, iters: 1216, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 194, iters: 1296, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 194, iters: 1376, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 194, iters: 1456, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 194, iters: 1536, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 194, iters: 1616, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 194, iters: 1696, time: 0.097, data: 0.050) loss: 0.001 
(epoch: 194, iters: 1776, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 194, iters: 1856, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 194, iters: 1936, time: 0.094, data: 0.012) loss: 0.011 
(epoch: 194, iters: 2016, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 194, iters: 2096, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 194, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 194, iters: 2256, time: 0.093, data: 0.011) loss: 0.189 
(epoch: 194, iters: 2336, time: 0.093, data: 0.025) loss: 0.040 
(epoch: 194, iters: 2416, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 194, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 194, iters: 2576, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 194, iters: 2656, time: 0.093, data: 0.025) loss: 0.002 
(epoch: 194, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 194, iters: 2816, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 194, iters: 2896, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 194, iters: 2976, time: 0.092, data: 0.026) loss: 0.011 
(epoch: 194, iters: 3056, time: 0.097, data: 0.000) loss: 0.044 
(epoch: 194, iters: 3136, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 194, iters: 3216, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 194, iters: 3296, time: 0.092, data: 0.025) loss: 0.002 
(epoch: 194, iters: 3376, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 194, iters: 3456, time: 0.095, data: 0.000) loss: 0.141 
(epoch: 194, iters: 3536, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 194, iters: 3616, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 194, iters: 3696, time: 0.088, data: 0.000) loss: 0.079 
saving the model at the end of epoch 194, iters 723232
End of epoch 194 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001905
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 194, TEST ACC: [94.385 %]

saving the latest model (epoch 195, total_steps 723248)
(epoch: 195, iters: 48, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 195, iters: 128, time: 0.095, data: 0.042) loss: 0.002 
(epoch: 195, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 195, iters: 288, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 195, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 195, iters: 448, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 195, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 195, iters: 608, time: 0.094, data: 0.000) loss: 0.341 
(epoch: 195, iters: 688, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 195, iters: 768, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 195, iters: 848, time: 0.093, data: 0.012) loss: 0.028 
(epoch: 195, iters: 928, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 195, iters: 1008, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 195, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 195, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 195, iters: 1248, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 195, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 195, iters: 1408, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 195, iters: 1488, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 195, iters: 1568, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 195, iters: 1648, time: 0.098, data: 0.000) loss: 0.004 
(epoch: 195, iters: 1728, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 195, iters: 1808, time: 0.094, data: 0.040) loss: 0.023 
(epoch: 195, iters: 1888, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 195, iters: 1968, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 195, iters: 2048, time: 0.094, data: 0.000) loss: 0.116 
(epoch: 195, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 195, iters: 2208, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 195, iters: 2288, time: 0.093, data: 0.000) loss: 0.036 
(epoch: 195, iters: 2368, time: 0.095, data: 0.039) loss: 0.025 
(epoch: 195, iters: 2448, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 195, iters: 2528, time: 0.092, data: 0.012) loss: 0.011 
(epoch: 195, iters: 2608, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 195, iters: 2688, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 195, iters: 2768, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 195, iters: 2848, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 195, iters: 2928, time: 0.093, data: 0.039) loss: 0.017 
(epoch: 195, iters: 3008, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 195, iters: 3088, time: 0.092, data: 0.021) loss: 0.003 
(epoch: 195, iters: 3168, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 195, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 195, iters: 3328, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 195, iters: 3408, time: 0.094, data: 0.000) loss: 0.068 
(epoch: 195, iters: 3488, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 195, iters: 3568, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 195, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 195, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 195, iters 726960
End of epoch 195 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001904
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 195, TEST ACC: [94.234 %]

saving the latest model (epoch 196, total_steps 726976)
(epoch: 196, iters: 80, time: 0.097, data: 0.511) loss: 0.008 
(epoch: 196, iters: 160, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 196, iters: 240, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 196, iters: 320, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 196, iters: 400, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 196, iters: 480, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 196, iters: 560, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 196, iters: 640, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 196, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 196, iters: 800, time: 0.093, data: 0.041) loss: 0.009 
(epoch: 196, iters: 880, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 196, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 196, iters: 1040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 196, iters: 1120, time: 0.094, data: 0.011) loss: 0.021 
(epoch: 196, iters: 1200, time: 0.094, data: 0.000) loss: 0.090 
(epoch: 196, iters: 1280, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 196, iters: 1360, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 196, iters: 1440, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 196, iters: 1520, time: 0.092, data: 0.012) loss: 0.005 
(epoch: 196, iters: 1600, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 196, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 196, iters: 1760, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 196, iters: 1840, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 196, iters: 1920, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 196, iters: 2000, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 196, iters: 2080, time: 0.092, data: 0.011) loss: 0.005 
(epoch: 196, iters: 2160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 196, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 196, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 196, iters: 2400, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 196, iters: 2480, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 196, iters: 2560, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 196, iters: 2640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 196, iters: 2720, time: 0.094, data: 0.000) loss: 0.036 
(epoch: 196, iters: 2800, time: 0.093, data: 0.012) loss: 0.011 
(epoch: 196, iters: 2880, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 196, iters: 2960, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 196, iters: 3040, time: 0.093, data: 0.039) loss: 0.222 
(epoch: 196, iters: 3120, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 196, iters: 3200, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 196, iters: 3280, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 196, iters: 3360, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 196, iters: 3440, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 196, iters: 3520, time: 0.093, data: 0.000) loss: 0.172 
(epoch: 196, iters: 3600, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 196, iters: 3680, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 196, iters 730688
End of epoch 196 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001903
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 196, TEST ACC: [75.873 %]

saving the latest model (epoch 197, total_steps 730704)
(epoch: 197, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 197, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 197, iters: 192, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 197, iters: 272, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 197, iters: 352, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 197, iters: 432, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 197, iters: 512, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 197, iters: 592, time: 0.093, data: 0.012) loss: 0.025 
(epoch: 197, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 197, iters: 752, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 197, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 197, iters: 912, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 197, iters: 992, time: 0.094, data: 0.048) loss: 0.004 
(epoch: 197, iters: 1072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 197, iters: 1152, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 197, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 197, iters: 1312, time: 0.094, data: 0.012) loss: 0.037 
(epoch: 197, iters: 1392, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 197, iters: 1472, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 197, iters: 1552, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 197, iters: 1632, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 197, iters: 1712, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 197, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 197, iters: 1872, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 197, iters: 1952, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 197, iters: 2032, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 197, iters: 2112, time: 0.093, data: 0.039) loss: 0.004 
(epoch: 197, iters: 2192, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 197, iters: 2272, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 197, iters: 2352, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 197, iters: 2432, time: 0.093, data: 0.013) loss: 0.004 
(epoch: 197, iters: 2512, time: 0.094, data: 0.000) loss: 0.020 
(epoch: 197, iters: 2592, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 197, iters: 2672, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 197, iters: 2752, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 197, iters: 2832, time: 0.092, data: 0.011) loss: 0.004 
(epoch: 197, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 197, iters: 2992, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 197, iters: 3072, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 197, iters: 3152, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 197, iters: 3232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 197, iters: 3312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 197, iters: 3392, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 197, iters: 3472, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 197, iters: 3552, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 197, iters: 3632, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 197, iters: 3712, time: 0.089, data: 0.000) loss: 0.001 
saving the model at the end of epoch 197, iters 734416
End of epoch 197 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001902
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 197, TEST ACC: [97.572 %]

saving the latest model (epoch 198, total_steps 734432)
(epoch: 198, iters: 64, time: 0.092, data: 0.003) loss: 0.004 
(epoch: 198, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 198, iters: 224, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 198, iters: 304, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 198, iters: 384, time: 0.093, data: 0.048) loss: 0.004 
(epoch: 198, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 198, iters: 544, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 198, iters: 624, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 198, iters: 704, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 198, iters: 784, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 198, iters: 864, time: 0.092, data: 0.000) loss: 0.004 
(epoch: 198, iters: 944, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 198, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 198, iters: 1104, time: 0.093, data: 0.012) loss: 0.015 
(epoch: 198, iters: 1184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 198, iters: 1264, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 198, iters: 1344, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 198, iters: 1424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 198, iters: 1504, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 198, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 198, iters: 1664, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 198, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 198, iters: 1824, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 198, iters: 1904, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 198, iters: 1984, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 198, iters: 2064, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 198, iters: 2144, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 198, iters: 2224, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 198, iters: 2304, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 198, iters: 2384, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 198, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 198, iters: 2544, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 198, iters: 2624, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 198, iters: 2704, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 198, iters: 2784, time: 0.094, data: 0.012) loss: 0.126 
(epoch: 198, iters: 2864, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 198, iters: 2944, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 198, iters: 3024, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 198, iters: 3104, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 198, iters: 3184, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 198, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 198, iters: 3344, time: 0.092, data: 0.012) loss: 0.081 
(epoch: 198, iters: 3424, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 198, iters: 3504, time: 0.093, data: 0.012) loss: 0.008 
(epoch: 198, iters: 3584, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 198, iters: 3664, time: 0.086, data: 0.000) loss: 0.001 
saving the model at the end of epoch 198, iters 738144
End of epoch 198 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001901
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 198, TEST ACC: [95.448 %]

(epoch: 199, iters: 16, time: 0.109, data: 0.012) loss: 0.002 
saving the latest model (epoch 199, total_steps 738160)
(epoch: 199, iters: 96, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 199, iters: 176, time: 0.093, data: 0.012) loss: 0.020 
(epoch: 199, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 199, iters: 336, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 199, iters: 416, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 199, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 199, iters: 576, time: 0.094, data: 0.049) loss: 0.002 
(epoch: 199, iters: 656, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 199, iters: 736, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 199, iters: 816, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 199, iters: 896, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 199, iters: 976, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 199, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 199, iters: 1136, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 199, iters: 1216, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 199, iters: 1296, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 199, iters: 1376, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 199, iters: 1456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 199, iters: 1536, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 199, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 199, iters: 1696, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 199, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 199, iters: 1856, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 199, iters: 1936, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 199, iters: 2016, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 199, iters: 2096, time: 0.094, data: 0.000) loss: 0.517 
(epoch: 199, iters: 2176, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 199, iters: 2256, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 199, iters: 2336, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 199, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 199, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 199, iters: 2576, time: 0.096, data: 0.013) loss: 0.001 
(epoch: 199, iters: 2656, time: 0.094, data: 0.000) loss: 0.051 
(epoch: 199, iters: 2736, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 199, iters: 2816, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 199, iters: 2896, time: 0.094, data: 0.000) loss: 0.163 
(epoch: 199, iters: 2976, time: 0.093, data: 0.021) loss: 0.001 
(epoch: 199, iters: 3056, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 199, iters: 3136, time: 0.095, data: 0.013) loss: 0.001 
(epoch: 199, iters: 3216, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 199, iters: 3296, time: 0.096, data: 0.000) loss: 0.043 
(epoch: 199, iters: 3376, time: 0.093, data: 0.041) loss: 0.053 
(epoch: 199, iters: 3456, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 199, iters: 3536, time: 0.093, data: 0.011) loss: 0.051 
(epoch: 199, iters: 3616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 199, iters: 3696, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 199, iters 741872
End of epoch 199 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001900
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 199, TEST ACC: [95.599 %]

saving the latest model (epoch 200, total_steps 741888)
(epoch: 200, iters: 48, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 200, iters: 128, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 200, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 200, iters: 288, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 200, iters: 368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 200, iters: 448, time: 0.092, data: 0.011) loss: 0.007 
(epoch: 200, iters: 528, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 200, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 200, iters: 688, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 200, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 200, iters: 848, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 200, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 200, iters: 1008, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 200, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 200, iters: 1168, time: 0.093, data: 0.000) loss: 0.023 
(epoch: 200, iters: 1248, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 200, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 200, iters: 1408, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 200, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 200, iters: 1568, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 200, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 200, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 200, iters: 1808, time: 0.094, data: 0.048) loss: 0.001 
(epoch: 200, iters: 1888, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 200, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 200, iters: 2048, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 200, iters: 2128, time: 0.093, data: 0.012) loss: 0.054 
(epoch: 200, iters: 2208, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 200, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 200, iters: 2368, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 200, iters: 2448, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 200, iters: 2528, time: 0.091, data: 0.011) loss: 0.001 
(epoch: 200, iters: 2608, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 200, iters: 2688, time: 0.093, data: 0.011) loss: 0.032 
(epoch: 200, iters: 2768, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 200, iters: 2848, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 200, iters: 2928, time: 0.094, data: 0.038) loss: 0.001 
(epoch: 200, iters: 3008, time: 0.094, data: 0.000) loss: 0.026 
(epoch: 200, iters: 3088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 200, iters: 3168, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 200, iters: 3248, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 200, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 200, iters: 3408, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 200, iters: 3488, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 200, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 200, iters: 3648, time: 0.086, data: 0.011) loss: 0.067 
(epoch: 200, iters: 3728, time: 0.056, data: 0.000) loss: 0.001 
saving the model at the end of epoch 200, iters 745600
End of epoch 200 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001899
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 200, TEST ACC: [93.323 %]

saving the latest model (epoch 201, total_steps 745616)
(epoch: 201, iters: 80, time: 0.093, data: 0.482) loss: 0.002 
(epoch: 201, iters: 160, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 201, iters: 240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 201, iters: 320, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 201, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 201, iters: 480, time: 0.091, data: 0.021) loss: 0.000 
(epoch: 201, iters: 560, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 201, iters: 640, time: 0.093, data: 0.012) loss: 0.089 
(epoch: 201, iters: 720, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 201, iters: 800, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 201, iters: 880, time: 0.094, data: 0.040) loss: 0.006 
(epoch: 201, iters: 960, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 201, iters: 1040, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 201, iters: 1120, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 201, iters: 1200, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 201, iters: 1280, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 201, iters: 1360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 201, iters: 1440, time: 0.094, data: 0.052) loss: 0.002 
(epoch: 201, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 201, iters: 1600, time: 0.092, data: 0.011) loss: 0.021 
(epoch: 201, iters: 1680, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 201, iters: 1760, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 201, iters: 1840, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 201, iters: 1920, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 201, iters: 2000, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 201, iters: 2080, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 201, iters: 2160, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 201, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 201, iters: 2320, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 201, iters: 2400, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 201, iters: 2480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 201, iters: 2560, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 201, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 201, iters: 2720, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 201, iters: 2800, time: 0.094, data: 0.000) loss: 0.022 
(epoch: 201, iters: 2880, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 201, iters: 2960, time: 0.094, data: 0.000) loss: 0.024 
(epoch: 201, iters: 3040, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 201, iters: 3120, time: 0.095, data: 0.048) loss: 0.032 
(epoch: 201, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 201, iters: 3280, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 201, iters: 3360, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 201, iters: 3440, time: 0.094, data: 0.012) loss: 0.006 
(epoch: 201, iters: 3520, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 201, iters: 3600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 201, iters: 3680, time: 0.088, data: 0.040) loss: 0.000 
saving the model at the end of epoch 201, iters 749328
End of epoch 201 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001898
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 201, TEST ACC: [86.495 %]

saving the latest model (epoch 202, total_steps 749344)
(epoch: 202, iters: 32, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 202, iters: 112, time: 0.093, data: 0.000) loss: 0.084 
(epoch: 202, iters: 192, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 202, iters: 272, time: 0.093, data: 0.000) loss: 0.012 
(epoch: 202, iters: 352, time: 0.094, data: 0.041) loss: 0.010 
(epoch: 202, iters: 432, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 202, iters: 512, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 202, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 202, iters: 672, time: 0.094, data: 0.011) loss: 0.136 
(epoch: 202, iters: 752, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 202, iters: 832, time: 0.094, data: 0.000) loss: 0.111 
(epoch: 202, iters: 912, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 202, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 202, iters: 1072, time: 0.092, data: 0.011) loss: 0.015 
(epoch: 202, iters: 1152, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 202, iters: 1232, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 202, iters: 1312, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 202, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 202, iters: 1472, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 202, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 202, iters: 1632, time: 0.093, data: 0.013) loss: 0.010 
(epoch: 202, iters: 1712, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 202, iters: 1792, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 202, iters: 1872, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 202, iters: 1952, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 202, iters: 2032, time: 0.093, data: 0.045) loss: 0.000 
(epoch: 202, iters: 2112, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 202, iters: 2192, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 202, iters: 2272, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 202, iters: 2352, time: 0.093, data: 0.025) loss: 0.005 
(epoch: 202, iters: 2432, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 202, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 202, iters: 2592, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 202, iters: 2672, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 202, iters: 2752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 202, iters: 2832, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 202, iters: 2912, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 202, iters: 2992, time: 0.092, data: 0.025) loss: 0.001 
(epoch: 202, iters: 3072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 202, iters: 3152, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 202, iters: 3232, time: 0.093, data: 0.013) loss: 0.008 
(epoch: 202, iters: 3312, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 202, iters: 3392, time: 0.095, data: 0.000) loss: 0.037 
(epoch: 202, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 202, iters: 3552, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 202, iters: 3632, time: 0.091, data: 0.025) loss: 0.000 
(epoch: 202, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 202, iters 753056
End of epoch 202 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001897
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 202, TEST ACC: [94.385 %]

saving the latest model (epoch 203, total_steps 753072)
(epoch: 203, iters: 64, time: 0.091, data: 0.000) loss: 0.003 
(epoch: 203, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 203, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 203, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 203, iters: 384, time: 0.094, data: 0.000) loss: 0.038 
(epoch: 203, iters: 464, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 203, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 203, iters: 624, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 203, iters: 704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 203, iters: 784, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 203, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 203, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 203, iters: 1024, time: 0.094, data: 0.047) loss: 0.063 
(epoch: 203, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 203, iters: 1184, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 203, iters: 1264, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 203, iters: 1344, time: 0.094, data: 0.012) loss: 0.007 
(epoch: 203, iters: 1424, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 203, iters: 1504, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 203, iters: 1584, time: 0.096, data: 0.041) loss: 0.012 
(epoch: 203, iters: 1664, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 203, iters: 1744, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 203, iters: 1824, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 203, iters: 1904, time: 0.095, data: 0.011) loss: 0.034 
(epoch: 203, iters: 1984, time: 0.095, data: 0.000) loss: 0.024 
(epoch: 203, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 203, iters: 2144, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 203, iters: 2224, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 203, iters: 2304, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 203, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 203, iters: 2464, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 203, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 203, iters: 2624, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 203, iters: 2704, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 203, iters: 2784, time: 0.094, data: 0.000) loss: 0.028 
(epoch: 203, iters: 2864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 203, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 203, iters: 3024, time: 0.095, data: 0.011) loss: 0.007 
(epoch: 203, iters: 3104, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 203, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 203, iters: 3264, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 203, iters: 3344, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 203, iters: 3424, time: 0.092, data: 0.024) loss: 0.000 
(epoch: 203, iters: 3504, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 203, iters: 3584, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 203, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 203, iters 756784
End of epoch 203 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001896
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 203, TEST ACC: [95.144 %]

(epoch: 204, iters: 16, time: 0.112, data: 0.000) loss: 0.000 
saving the latest model (epoch 204, total_steps 756800)
(epoch: 204, iters: 96, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 204, iters: 176, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 204, iters: 256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 204, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 204, iters: 416, time: 0.097, data: 0.000) loss: 0.009 
(epoch: 204, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 204, iters: 576, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 204, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 204, iters: 736, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 204, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 204, iters: 896, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 204, iters: 976, time: 0.094, data: 0.000) loss: 0.231 
(epoch: 204, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 204, iters: 1136, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 204, iters: 1216, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 204, iters: 1296, time: 0.092, data: 0.011) loss: 0.192 
(epoch: 204, iters: 1376, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 204, iters: 1456, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 204, iters: 1536, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 204, iters: 1616, time: 0.093, data: 0.000) loss: 0.022 
(epoch: 204, iters: 1696, time: 0.097, data: 0.039) loss: 0.007 
(epoch: 204, iters: 1776, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 204, iters: 1856, time: 0.093, data: 0.012) loss: 0.011 
(epoch: 204, iters: 1936, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 204, iters: 2016, time: 0.094, data: 0.012) loss: 0.130 
(epoch: 204, iters: 2096, time: 0.094, data: 0.000) loss: 0.443 
(epoch: 204, iters: 2176, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 204, iters: 2256, time: 0.094, data: 0.048) loss: 0.012 
(epoch: 204, iters: 2336, time: 0.095, data: 0.000) loss: 0.086 
(epoch: 204, iters: 2416, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 204, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 204, iters: 2576, time: 0.095, data: 0.012) loss: 0.112 
(epoch: 204, iters: 2656, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 204, iters: 2736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 204, iters: 2816, time: 0.096, data: 0.041) loss: 0.010 
(epoch: 204, iters: 2896, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 204, iters: 2976, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 204, iters: 3056, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 204, iters: 3136, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 204, iters: 3216, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 204, iters: 3296, time: 0.095, data: 0.000) loss: 0.051 
(epoch: 204, iters: 3376, time: 0.095, data: 0.050) loss: 0.001 
(epoch: 204, iters: 3456, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 204, iters: 3536, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 204, iters: 3616, time: 0.095, data: 0.000) loss: 0.023 
(epoch: 204, iters: 3696, time: 0.088, data: 0.011) loss: 0.001 
saving the model at the end of epoch 204, iters 760512
End of epoch 204 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001895
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 204, TEST ACC: [92.564 %]

saving the latest model (epoch 205, total_steps 760528)
(epoch: 205, iters: 48, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 205, iters: 128, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 205, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 205, iters: 288, time: 0.093, data: 0.012) loss: 0.043 
(epoch: 205, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 205, iters: 448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 205, iters: 528, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 205, iters: 608, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 205, iters: 688, time: 0.093, data: 0.039) loss: 0.003 
(epoch: 205, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 205, iters: 848, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 205, iters: 928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 205, iters: 1008, time: 0.093, data: 0.012) loss: 0.007 
(epoch: 205, iters: 1088, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 205, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 205, iters: 1248, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 205, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 205, iters: 1408, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 205, iters: 1488, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 205, iters: 1568, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 205, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 205, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 205, iters: 1808, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 205, iters: 1888, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 205, iters: 1968, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 205, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 205, iters: 2128, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 205, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 205, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 205, iters: 2368, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 205, iters: 2448, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 205, iters: 2528, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 205, iters: 2608, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 205, iters: 2688, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 205, iters: 2768, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 205, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 205, iters: 2928, time: 0.094, data: 0.050) loss: 0.002 
(epoch: 205, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 205, iters: 3088, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 205, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 205, iters: 3248, time: 0.097, data: 0.011) loss: 0.005 
(epoch: 205, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 205, iters: 3408, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 205, iters: 3488, time: 0.094, data: 0.041) loss: 0.002 
(epoch: 205, iters: 3568, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 205, iters: 3648, time: 0.086, data: 0.012) loss: 0.001 
(epoch: 205, iters: 3728, time: 0.057, data: 0.000) loss: 0.001 
saving the model at the end of epoch 205, iters 764240
End of epoch 205 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001894
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 205, TEST ACC: [93.627 %]

saving the latest model (epoch 206, total_steps 764256)
(epoch: 206, iters: 80, time: 0.096, data: 0.462) loss: 0.000 
(epoch: 206, iters: 160, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 206, iters: 240, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 206, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 206, iters: 400, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 206, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 206, iters: 560, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 206, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 206, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 206, iters: 800, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 206, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 206, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 206, iters: 1040, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 206, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 206, iters: 1200, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 206, iters: 1280, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 206, iters: 1360, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 206, iters: 1440, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 206, iters: 1520, time: 0.093, data: 0.011) loss: 0.048 
(epoch: 206, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 206, iters: 1680, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 206, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 206, iters: 1840, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 206, iters: 1920, time: 0.096, data: 0.049) loss: 0.001 
(epoch: 206, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 206, iters: 2080, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 206, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 206, iters: 2240, time: 0.094, data: 0.011) loss: 0.186 
(epoch: 206, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 206, iters: 2400, time: 0.093, data: 0.000) loss: 0.038 
(epoch: 206, iters: 2480, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 206, iters: 2560, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 206, iters: 2640, time: 0.092, data: 0.011) loss: 0.022 
(epoch: 206, iters: 2720, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 206, iters: 2800, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 206, iters: 2880, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 206, iters: 2960, time: 0.093, data: 0.000) loss: 0.105 
(epoch: 206, iters: 3040, time: 0.095, data: 0.049) loss: 0.004 
(epoch: 206, iters: 3120, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 206, iters: 3200, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 206, iters: 3280, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 206, iters: 3360, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 206, iters: 3440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 206, iters: 3520, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 206, iters: 3600, time: 0.094, data: 0.040) loss: 0.106 
(epoch: 206, iters: 3680, time: 0.090, data: 0.000) loss: 0.044 
saving the model at the end of epoch 206, iters 767968
End of epoch 206 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001893
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 206, TEST ACC: [95.144 %]

saving the latest model (epoch 207, total_steps 767984)
(epoch: 207, iters: 32, time: 0.093, data: 0.004) loss: 0.001 
(epoch: 207, iters: 112, time: 0.097, data: 0.000) loss: 0.009 
(epoch: 207, iters: 192, time: 0.095, data: 0.000) loss: 0.224 
(epoch: 207, iters: 272, time: 0.094, data: 0.054) loss: 0.001 
(epoch: 207, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 207, iters: 432, time: 0.092, data: 0.012) loss: 0.029 
(epoch: 207, iters: 512, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 207, iters: 592, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 207, iters: 672, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 207, iters: 752, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 207, iters: 832, time: 0.094, data: 0.039) loss: 0.004 
(epoch: 207, iters: 912, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 207, iters: 992, time: 0.092, data: 0.011) loss: 0.014 
(epoch: 207, iters: 1072, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 207, iters: 1152, time: 0.094, data: 0.011) loss: 0.008 
(epoch: 207, iters: 1232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 207, iters: 1312, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 207, iters: 1392, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 207, iters: 1472, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 207, iters: 1552, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 207, iters: 1632, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 207, iters: 1712, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 207, iters: 1792, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 207, iters: 1872, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 207, iters: 1952, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 207, iters: 2032, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 207, iters: 2112, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 207, iters: 2192, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 207, iters: 2272, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 207, iters: 2352, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 207, iters: 2432, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 207, iters: 2512, time: 0.096, data: 0.039) loss: 0.003 
(epoch: 207, iters: 2592, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 207, iters: 2672, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 207, iters: 2752, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 207, iters: 2832, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 207, iters: 2912, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 207, iters: 2992, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 207, iters: 3072, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 207, iters: 3152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 207, iters: 3232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 207, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 207, iters: 3392, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 207, iters: 3472, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 207, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 207, iters: 3632, time: 0.092, data: 0.039) loss: 0.000 
(epoch: 207, iters: 3712, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 207, iters 771696
End of epoch 207 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001892
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 207, TEST ACC: [93.02 %]

saving the latest model (epoch 208, total_steps 771712)
(epoch: 208, iters: 64, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 208, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 208, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 208, iters: 304, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 208, iters: 384, time: 0.095, data: 0.000) loss: 0.034 
(epoch: 208, iters: 464, time: 0.095, data: 0.040) loss: 0.013 
(epoch: 208, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 208, iters: 624, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 208, iters: 704, time: 0.097, data: 0.000) loss: 0.033 
(epoch: 208, iters: 784, time: 0.095, data: 0.011) loss: 0.010 
(epoch: 208, iters: 864, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 208, iters: 944, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 208, iters: 1024, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 208, iters: 1104, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 208, iters: 1184, time: 0.093, data: 0.013) loss: 0.002 
(epoch: 208, iters: 1264, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 208, iters: 1344, time: 0.096, data: 0.012) loss: 0.003 
(epoch: 208, iters: 1424, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 208, iters: 1504, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 208, iters: 1584, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 208, iters: 1664, time: 0.097, data: 0.000) loss: 0.035 
(epoch: 208, iters: 1744, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 208, iters: 1824, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 208, iters: 1904, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 208, iters: 1984, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 208, iters: 2064, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 208, iters: 2144, time: 0.097, data: 0.050) loss: 0.000 
(epoch: 208, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 208, iters: 2304, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 208, iters: 2384, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 208, iters: 2464, time: 0.096, data: 0.012) loss: 0.002 
(epoch: 208, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 208, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 208, iters: 2704, time: 0.097, data: 0.040) loss: 0.003 
(epoch: 208, iters: 2784, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 208, iters: 2864, time: 0.095, data: 0.011) loss: 0.005 
(epoch: 208, iters: 2944, time: 0.096, data: 0.000) loss: 0.095 
(epoch: 208, iters: 3024, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 208, iters: 3104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 208, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 208, iters: 3264, time: 0.096, data: 0.039) loss: 0.002 
(epoch: 208, iters: 3344, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 208, iters: 3424, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 208, iters: 3504, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 208, iters: 3584, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 208, iters: 3664, time: 0.089, data: 0.000) loss: 0.001 
saving the model at the end of epoch 208, iters 775424
End of epoch 208 / 2100 	 Time Taken: 358 sec
learning rate = 0.0001891
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 208, TEST ACC: [95.144 %]

(epoch: 209, iters: 16, time: 0.112, data: 0.000) loss: 0.008 
saving the latest model (epoch 209, total_steps 775440)
(epoch: 209, iters: 96, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 209, iters: 176, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 209, iters: 256, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 209, iters: 336, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 209, iters: 416, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 209, iters: 496, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 209, iters: 576, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 209, iters: 656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 209, iters: 736, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 209, iters: 816, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 209, iters: 896, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 209, iters: 976, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 209, iters: 1056, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 209, iters: 1136, time: 0.095, data: 0.040) loss: 0.004 
(epoch: 209, iters: 1216, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 209, iters: 1296, time: 0.093, data: 0.011) loss: 0.142 
(epoch: 209, iters: 1376, time: 0.098, data: 0.000) loss: 0.005 
(epoch: 209, iters: 1456, time: 0.096, data: 0.011) loss: 0.002 
(epoch: 209, iters: 1536, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 209, iters: 1616, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 209, iters: 1696, time: 0.097, data: 0.051) loss: 0.002 
(epoch: 209, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 209, iters: 1856, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 209, iters: 1936, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 209, iters: 2016, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 209, iters: 2096, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 209, iters: 2176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 209, iters: 2256, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 209, iters: 2336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 209, iters: 2416, time: 0.094, data: 0.012) loss: 0.094 
(epoch: 209, iters: 2496, time: 0.096, data: 0.000) loss: 0.025 
(epoch: 209, iters: 2576, time: 0.095, data: 0.011) loss: 0.128 
(epoch: 209, iters: 2656, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 209, iters: 2736, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 209, iters: 2816, time: 0.096, data: 0.052) loss: 0.007 
(epoch: 209, iters: 2896, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 209, iters: 2976, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 209, iters: 3056, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 209, iters: 3136, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 209, iters: 3216, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 209, iters: 3296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 209, iters: 3376, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 209, iters: 3456, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 209, iters: 3536, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 209, iters: 3616, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 209, iters: 3696, time: 0.091, data: 0.011) loss: 0.551 
saving the model at the end of epoch 209, iters 779152
End of epoch 209 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001890
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 209, TEST ACC: [95.296 %]

saving the latest model (epoch 210, total_steps 779168)
(epoch: 210, iters: 48, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 210, iters: 128, time: 0.097, data: 0.027) loss: 0.000 
(epoch: 210, iters: 208, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 210, iters: 288, time: 0.096, data: 0.000) loss: 0.062 
(epoch: 210, iters: 368, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 210, iters: 448, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 210, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 210, iters: 608, time: 0.096, data: 0.048) loss: 0.001 
(epoch: 210, iters: 688, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 210, iters: 768, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 210, iters: 848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 210, iters: 928, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 210, iters: 1008, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 210, iters: 1088, time: 0.096, data: 0.000) loss: 0.020 
(epoch: 210, iters: 1168, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 210, iters: 1248, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 210, iters: 1328, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 210, iters: 1408, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 210, iters: 1488, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 210, iters: 1568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 210, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 210, iters: 1728, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 210, iters: 1808, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 210, iters: 1888, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 210, iters: 1968, time: 0.097, data: 0.000) loss: 0.010 
(epoch: 210, iters: 2048, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 210, iters: 2128, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 210, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 210, iters: 2288, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 210, iters: 2368, time: 0.097, data: 0.000) loss: 0.011 
(epoch: 210, iters: 2448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 210, iters: 2528, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 210, iters: 2608, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 210, iters: 2688, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 210, iters: 2768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 210, iters: 2848, time: 0.097, data: 0.042) loss: 0.000 
(epoch: 210, iters: 2928, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 210, iters: 3008, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 210, iters: 3088, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 210, iters: 3168, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 210, iters: 3248, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 210, iters: 3328, time: 0.093, data: 0.000) loss: 0.017 
(epoch: 210, iters: 3408, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 210, iters: 3488, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 210, iters: 3568, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 210, iters: 3648, time: 0.090, data: 0.000) loss: 0.157 
(epoch: 210, iters: 3728, time: 0.056, data: 0.012) loss: 0.000 
saving the model at the end of epoch 210, iters 782880
End of epoch 210 / 2100 	 Time Taken: 358 sec
learning rate = 0.0001889
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 210, TEST ACC: [96.206 %]

saving the latest model (epoch 211, total_steps 782896)
(epoch: 211, iters: 80, time: 0.094, data: 0.531) loss: 0.002 
(epoch: 211, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 211, iters: 240, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 211, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 211, iters: 400, time: 0.092, data: 0.000) loss: 0.534 
(epoch: 211, iters: 480, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 211, iters: 560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 211, iters: 640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 211, iters: 720, time: 0.094, data: 0.000) loss: 0.020 
(epoch: 211, iters: 800, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 211, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 211, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 211, iters: 1040, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 211, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 211, iters: 1200, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 211, iters: 1280, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 211, iters: 1360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 211, iters: 1440, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 211, iters: 1520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 211, iters: 1600, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 211, iters: 1680, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 211, iters: 1760, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 211, iters: 1840, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 211, iters: 1920, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 211, iters: 2000, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 211, iters: 2080, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 211, iters: 2160, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 211, iters: 2240, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 211, iters: 2320, time: 0.094, data: 0.012) loss: 0.011 
(epoch: 211, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 211, iters: 2480, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 211, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 211, iters: 2640, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 211, iters: 2720, time: 0.094, data: 0.049) loss: 0.001 
(epoch: 211, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 211, iters: 2880, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 211, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 211, iters: 3040, time: 0.093, data: 0.020) loss: 0.001 
(epoch: 211, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 211, iters: 3200, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 211, iters: 3280, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 211, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 211, iters: 3440, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 211, iters: 3520, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 211, iters: 3600, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 211, iters: 3680, time: 0.087, data: 0.000) loss: 0.001 
saving the model at the end of epoch 211, iters 786608
End of epoch 211 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001888
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 211, TEST ACC: [96.055 %]

saving the latest model (epoch 212, total_steps 786624)
(epoch: 212, iters: 32, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 212, iters: 112, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 212, iters: 192, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 212, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 212, iters: 352, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 212, iters: 432, time: 0.093, data: 0.039) loss: 0.006 
(epoch: 212, iters: 512, time: 0.095, data: 0.000) loss: 0.030 
(epoch: 212, iters: 592, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 212, iters: 672, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 212, iters: 752, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 212, iters: 832, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 212, iters: 912, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 212, iters: 992, time: 0.095, data: 0.039) loss: 0.012 
(epoch: 212, iters: 1072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 212, iters: 1152, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 212, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 212, iters: 1312, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 212, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 212, iters: 1472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 212, iters: 1552, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 212, iters: 1632, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 212, iters: 1712, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 212, iters: 1792, time: 0.096, data: 0.000) loss: 0.018 
(epoch: 212, iters: 1872, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 212, iters: 1952, time: 0.096, data: 0.000) loss: 0.061 
(epoch: 212, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 212, iters: 2112, time: 0.096, data: 0.040) loss: 0.026 
(epoch: 212, iters: 2192, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 212, iters: 2272, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 212, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 212, iters: 2432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 212, iters: 2512, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 212, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 212, iters: 2672, time: 0.095, data: 0.049) loss: 0.010 
(epoch: 212, iters: 2752, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 212, iters: 2832, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 212, iters: 2912, time: 0.094, data: 0.000) loss: 0.052 
(epoch: 212, iters: 2992, time: 0.094, data: 0.012) loss: 0.008 
(epoch: 212, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 212, iters: 3152, time: 0.093, data: 0.000) loss: 0.013 
(epoch: 212, iters: 3232, time: 0.094, data: 0.038) loss: 0.003 
(epoch: 212, iters: 3312, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 212, iters: 3392, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 212, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 212, iters: 3552, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 212, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 212, iters: 3712, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 212, iters 790336
End of epoch 212 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001887
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 212, TEST ACC: [83.915 %]

saving the latest model (epoch 213, total_steps 790352)
(epoch: 213, iters: 64, time: 0.092, data: 0.003) loss: 0.008 
(epoch: 213, iters: 144, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 213, iters: 224, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 213, iters: 304, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 213, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 213, iters: 464, time: 0.093, data: 0.011) loss: 0.009 
(epoch: 213, iters: 544, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 213, iters: 624, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 213, iters: 704, time: 0.097, data: 0.051) loss: 0.001 
(epoch: 213, iters: 784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 213, iters: 864, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 213, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 213, iters: 1024, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 213, iters: 1104, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 213, iters: 1184, time: 0.093, data: 0.000) loss: 0.040 
(epoch: 213, iters: 1264, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 213, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 213, iters: 1424, time: 0.092, data: 0.011) loss: 0.066 
(epoch: 213, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 213, iters: 1584, time: 0.095, data: 0.012) loss: 0.004 
(epoch: 213, iters: 1664, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 213, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 213, iters: 1824, time: 0.096, data: 0.052) loss: 0.000 
(epoch: 213, iters: 1904, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 213, iters: 1984, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 213, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 213, iters: 2144, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 213, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 213, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 213, iters: 2384, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 213, iters: 2464, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 213, iters: 2544, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 213, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 213, iters: 2704, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 213, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 213, iters: 2864, time: 0.093, data: 0.000) loss: 0.008 
(epoch: 213, iters: 2944, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 213, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 213, iters: 3104, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 213, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 213, iters: 3264, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 213, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 213, iters: 3424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 213, iters: 3504, time: 0.094, data: 0.039) loss: 0.476 
(epoch: 213, iters: 3584, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 213, iters: 3664, time: 0.086, data: 0.012) loss: 0.017 
saving the model at the end of epoch 213, iters 794064
End of epoch 213 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001886
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 213, TEST ACC: [93.02 %]

(epoch: 214, iters: 16, time: 0.109, data: 0.021) loss: 0.079 
saving the latest model (epoch 214, total_steps 794080)
(epoch: 214, iters: 96, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 214, iters: 176, time: 0.094, data: 0.011) loss: 0.024 
(epoch: 214, iters: 256, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 214, iters: 336, time: 0.093, data: 0.020) loss: 0.002 
(epoch: 214, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 214, iters: 496, time: 0.094, data: 0.000) loss: 0.272 
(epoch: 214, iters: 576, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 214, iters: 656, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 214, iters: 736, time: 0.092, data: 0.012) loss: 0.013 
(epoch: 214, iters: 816, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 214, iters: 896, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 214, iters: 976, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 214, iters: 1056, time: 0.095, data: 0.000) loss: 0.020 
(epoch: 214, iters: 1136, time: 0.095, data: 0.051) loss: 0.066 
(epoch: 214, iters: 1216, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 214, iters: 1296, time: 0.094, data: 0.012) loss: 0.033 
(epoch: 214, iters: 1376, time: 0.096, data: 0.000) loss: 0.117 
(epoch: 214, iters: 1456, time: 0.097, data: 0.011) loss: 0.009 
(epoch: 214, iters: 1536, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 214, iters: 1616, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 214, iters: 1696, time: 0.096, data: 0.041) loss: 0.003 
(epoch: 214, iters: 1776, time: 0.097, data: 0.000) loss: 0.105 
(epoch: 214, iters: 1856, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 214, iters: 1936, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 214, iters: 2016, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 214, iters: 2096, time: 0.095, data: 0.000) loss: 0.335 
(epoch: 214, iters: 2176, time: 0.097, data: 0.000) loss: 0.006 
(epoch: 214, iters: 2256, time: 0.096, data: 0.040) loss: 0.009 
(epoch: 214, iters: 2336, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 214, iters: 2416, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 214, iters: 2496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 214, iters: 2576, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 214, iters: 2656, time: 0.098, data: 0.000) loss: 0.018 
(epoch: 214, iters: 2736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 214, iters: 2816, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 214, iters: 2896, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 214, iters: 2976, time: 0.094, data: 0.011) loss: 0.005 
(epoch: 214, iters: 3056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 214, iters: 3136, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 214, iters: 3216, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 214, iters: 3296, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 214, iters: 3376, time: 0.096, data: 0.050) loss: 0.001 
(epoch: 214, iters: 3456, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 214, iters: 3536, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 214, iters: 3616, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 214, iters: 3696, time: 0.091, data: 0.012) loss: 0.007 
saving the model at the end of epoch 214, iters 797792
End of epoch 214 / 2100 	 Time Taken: 358 sec
learning rate = 0.0001885
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 214, TEST ACC: [91.654 %]

saving the latest model (epoch 215, total_steps 797808)
(epoch: 215, iters: 48, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 215, iters: 128, time: 0.096, data: 0.042) loss: 0.155 
(epoch: 215, iters: 208, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 215, iters: 288, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 215, iters: 368, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 215, iters: 448, time: 0.094, data: 0.011) loss: 0.016 
(epoch: 215, iters: 528, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 215, iters: 608, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 215, iters: 688, time: 0.094, data: 0.039) loss: 0.007 
(epoch: 215, iters: 768, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 215, iters: 848, time: 0.092, data: 0.012) loss: 0.006 
(epoch: 215, iters: 928, time: 0.095, data: 0.000) loss: 0.194 
(epoch: 215, iters: 1008, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 215, iters: 1088, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 215, iters: 1168, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 215, iters: 1248, time: 0.096, data: 0.050) loss: 0.127 
(epoch: 215, iters: 1328, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 215, iters: 1408, time: 0.092, data: 0.012) loss: 0.027 
(epoch: 215, iters: 1488, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 215, iters: 1568, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 215, iters: 1648, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 215, iters: 1728, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 215, iters: 1808, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 215, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 215, iters: 1968, time: 0.093, data: 0.011) loss: 0.007 
(epoch: 215, iters: 2048, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 215, iters: 2128, time: 0.095, data: 0.011) loss: 0.025 
(epoch: 215, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 215, iters: 2288, time: 0.095, data: 0.000) loss: 0.025 
(epoch: 215, iters: 2368, time: 0.094, data: 0.040) loss: 0.005 
(epoch: 215, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 215, iters: 2528, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 215, iters: 2608, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 215, iters: 2688, time: 0.094, data: 0.012) loss: 0.007 
(epoch: 215, iters: 2768, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 215, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 215, iters: 2928, time: 0.094, data: 0.050) loss: 0.008 
(epoch: 215, iters: 3008, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 215, iters: 3088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 215, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 215, iters: 3248, time: 0.095, data: 0.012) loss: 0.007 
(epoch: 215, iters: 3328, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 215, iters: 3408, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 215, iters: 3488, time: 0.095, data: 0.039) loss: 0.271 
(epoch: 215, iters: 3568, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 215, iters: 3648, time: 0.087, data: 0.012) loss: 0.010 
(epoch: 215, iters: 3728, time: 0.057, data: 0.000) loss: 0.001 
saving the model at the end of epoch 215, iters 801520
End of epoch 215 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001884
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 215, TEST ACC: [94.234 %]

saving the latest model (epoch 216, total_steps 801536)
(epoch: 216, iters: 80, time: 0.095, data: 0.522) loss: 0.003 
(epoch: 216, iters: 160, time: 0.095, data: 0.031) loss: 0.001 
(epoch: 216, iters: 240, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 216, iters: 320, time: 0.095, data: 0.012) loss: 0.061 
(epoch: 216, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 216, iters: 480, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 216, iters: 560, time: 0.096, data: 0.000) loss: 0.149 
(epoch: 216, iters: 640, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 216, iters: 720, time: 0.094, data: 0.040) loss: 0.005 
(epoch: 216, iters: 800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 216, iters: 880, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 216, iters: 960, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 216, iters: 1040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 216, iters: 1120, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 216, iters: 1200, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 216, iters: 1280, time: 0.094, data: 0.040) loss: 0.005 
(epoch: 216, iters: 1360, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 216, iters: 1440, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 216, iters: 1520, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 216, iters: 1600, time: 0.094, data: 0.011) loss: 0.045 
(epoch: 216, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 216, iters: 1760, time: 0.093, data: 0.000) loss: 0.027 
(epoch: 216, iters: 1840, time: 0.097, data: 0.047) loss: 0.007 
(epoch: 216, iters: 1920, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 216, iters: 2000, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 216, iters: 2080, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 216, iters: 2160, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 216, iters: 2240, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 216, iters: 2320, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 216, iters: 2400, time: 0.097, data: 0.039) loss: 0.003 
(epoch: 216, iters: 2480, time: 0.094, data: 0.000) loss: 0.167 
(epoch: 216, iters: 2560, time: 0.094, data: 0.012) loss: 0.147 
(epoch: 216, iters: 2640, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 216, iters: 2720, time: 0.097, data: 0.011) loss: 0.022 
(epoch: 216, iters: 2800, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 216, iters: 2880, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 216, iters: 2960, time: 0.097, data: 0.040) loss: 0.009 
(epoch: 216, iters: 3040, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 216, iters: 3120, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 216, iters: 3200, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 216, iters: 3280, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 216, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 216, iters: 3440, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 216, iters: 3520, time: 0.097, data: 0.040) loss: 0.008 
(epoch: 216, iters: 3600, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 216, iters: 3680, time: 0.089, data: 0.012) loss: 0.000 
saving the model at the end of epoch 216, iters 805248
End of epoch 216 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001883
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 216, TEST ACC: [91.806 %]

saving the latest model (epoch 217, total_steps 805264)
(epoch: 217, iters: 32, time: 0.094, data: 0.006) loss: 0.001 
(epoch: 217, iters: 112, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 217, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 217, iters: 272, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 217, iters: 352, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 217, iters: 432, time: 0.095, data: 0.012) loss: 0.007 
(epoch: 217, iters: 512, time: 0.096, data: 0.000) loss: 0.069 
(epoch: 217, iters: 592, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 217, iters: 672, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 217, iters: 752, time: 0.096, data: 0.000) loss: 0.611 
(epoch: 217, iters: 832, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 217, iters: 912, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 217, iters: 992, time: 0.095, data: 0.011) loss: 0.009 
(epoch: 217, iters: 1072, time: 0.097, data: 0.000) loss: 0.298 
(epoch: 217, iters: 1152, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 217, iters: 1232, time: 0.097, data: 0.000) loss: 0.140 
(epoch: 217, iters: 1312, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 217, iters: 1392, time: 0.096, data: 0.040) loss: 0.144 
(epoch: 217, iters: 1472, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 217, iters: 1552, time: 0.093, data: 0.012) loss: 0.022 
(epoch: 217, iters: 1632, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 217, iters: 1712, time: 0.096, data: 0.012) loss: 0.003 
(epoch: 217, iters: 1792, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 217, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 217, iters: 1952, time: 0.096, data: 0.041) loss: 0.001 
(epoch: 217, iters: 2032, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 217, iters: 2112, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 217, iters: 2192, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 217, iters: 2272, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 217, iters: 2352, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 217, iters: 2432, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 217, iters: 2512, time: 0.095, data: 0.041) loss: 0.002 
(epoch: 217, iters: 2592, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 217, iters: 2672, time: 0.093, data: 0.020) loss: 0.078 
(epoch: 217, iters: 2752, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 217, iters: 2832, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 217, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 217, iters: 2992, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 217, iters: 3072, time: 0.094, data: 0.051) loss: 0.001 
(epoch: 217, iters: 3152, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 217, iters: 3232, time: 0.094, data: 0.012) loss: 0.019 
(epoch: 217, iters: 3312, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 217, iters: 3392, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 217, iters: 3472, time: 0.098, data: 0.000) loss: 0.008 
(epoch: 217, iters: 3552, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 217, iters: 3632, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 217, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 217, iters 808976
End of epoch 217 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001882
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 217, TEST ACC: [94.537 %]

saving the latest model (epoch 218, total_steps 808992)
(epoch: 218, iters: 64, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 218, iters: 144, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 218, iters: 224, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 218, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 218, iters: 384, time: 0.095, data: 0.000) loss: 0.040 
(epoch: 218, iters: 464, time: 0.095, data: 0.051) loss: 0.005 
(epoch: 218, iters: 544, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 218, iters: 624, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 218, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 218, iters: 784, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 218, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 218, iters: 944, time: 0.094, data: 0.000) loss: 0.524 
(epoch: 218, iters: 1024, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 218, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 218, iters: 1184, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 218, iters: 1264, time: 0.094, data: 0.000) loss: 0.060 
(epoch: 218, iters: 1344, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 218, iters: 1424, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 218, iters: 1504, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 218, iters: 1584, time: 0.096, data: 0.041) loss: 0.127 
(epoch: 218, iters: 1664, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 218, iters: 1744, time: 0.093, data: 0.012) loss: 0.025 
(epoch: 218, iters: 1824, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 218, iters: 1904, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 218, iters: 1984, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 218, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 218, iters: 2144, time: 0.094, data: 0.039) loss: 0.007 
(epoch: 218, iters: 2224, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 218, iters: 2304, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 218, iters: 2384, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 218, iters: 2464, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 218, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 218, iters: 2624, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 218, iters: 2704, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 218, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 218, iters: 2864, time: 0.092, data: 0.021) loss: 0.007 
(epoch: 218, iters: 2944, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 218, iters: 3024, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 218, iters: 3104, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 218, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 218, iters: 3264, time: 0.093, data: 0.039) loss: 0.006 
(epoch: 218, iters: 3344, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 218, iters: 3424, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 218, iters: 3504, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 218, iters: 3584, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 218, iters: 3664, time: 0.088, data: 0.000) loss: 0.245 
saving the model at the end of epoch 218, iters 812704
End of epoch 218 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001881
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 218, TEST ACC: [94.234 %]

(epoch: 219, iters: 16, time: 0.109, data: 0.000) loss: 0.001 
saving the latest model (epoch 219, total_steps 812720)
(epoch: 219, iters: 96, time: 0.095, data: 0.044) loss: 0.001 
(epoch: 219, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 219, iters: 256, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 219, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 219, iters: 416, time: 0.094, data: 0.012) loss: 0.092 
(epoch: 219, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 219, iters: 576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 219, iters: 656, time: 0.096, data: 0.038) loss: 0.001 
(epoch: 219, iters: 736, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 219, iters: 816, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 219, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 219, iters: 976, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 219, iters: 1056, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 219, iters: 1136, time: 0.093, data: 0.000) loss: 0.041 
(epoch: 219, iters: 1216, time: 0.095, data: 0.049) loss: 0.001 
(epoch: 219, iters: 1296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 219, iters: 1376, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 219, iters: 1456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 219, iters: 1536, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 219, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 219, iters: 1696, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 219, iters: 1776, time: 0.095, data: 0.048) loss: 0.016 
(epoch: 219, iters: 1856, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 219, iters: 1936, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 219, iters: 2016, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 219, iters: 2096, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 219, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 219, iters: 2256, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 219, iters: 2336, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 219, iters: 2416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 219, iters: 2496, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 219, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 219, iters: 2656, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 219, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 219, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 219, iters: 2896, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 219, iters: 2976, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 219, iters: 3056, time: 0.093, data: 0.011) loss: 0.007 
(epoch: 219, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 219, iters: 3216, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 219, iters: 3296, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 219, iters: 3376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 219, iters: 3456, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 219, iters: 3536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 219, iters: 3616, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 219, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 219, iters 816432
End of epoch 219 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001880
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 219, TEST ACC: [95.144 %]

saving the latest model (epoch 220, total_steps 816448)
(epoch: 220, iters: 48, time: 0.095, data: 0.014) loss: 0.001 
(epoch: 220, iters: 128, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 220, iters: 208, time: 0.094, data: 0.042) loss: 0.194 
(epoch: 220, iters: 288, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 220, iters: 368, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 220, iters: 448, time: 0.094, data: 0.000) loss: 0.114 
(epoch: 220, iters: 528, time: 0.094, data: 0.012) loss: 0.044 
(epoch: 220, iters: 608, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 220, iters: 688, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 220, iters: 768, time: 0.095, data: 0.047) loss: 0.006 
(epoch: 220, iters: 848, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 220, iters: 928, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 220, iters: 1008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 220, iters: 1088, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 220, iters: 1168, time: 0.097, data: 0.000) loss: 0.023 
(epoch: 220, iters: 1248, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 220, iters: 1328, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 220, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 220, iters: 1488, time: 0.092, data: 0.011) loss: 0.032 
(epoch: 220, iters: 1568, time: 0.095, data: 0.000) loss: 0.057 
(epoch: 220, iters: 1648, time: 0.095, data: 0.012) loss: 0.498 
(epoch: 220, iters: 1728, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 220, iters: 1808, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 220, iters: 1888, time: 0.097, data: 0.039) loss: 0.000 
(epoch: 220, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 220, iters: 2048, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 220, iters: 2128, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 220, iters: 2208, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 220, iters: 2288, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 220, iters: 2368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 220, iters: 2448, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 220, iters: 2528, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 220, iters: 2608, time: 0.092, data: 0.020) loss: 0.003 
(epoch: 220, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 220, iters: 2768, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 220, iters: 2848, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 220, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 220, iters: 3008, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 220, iters: 3088, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 220, iters: 3168, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 220, iters: 3248, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 220, iters: 3328, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 220, iters: 3408, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 220, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 220, iters: 3568, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 220, iters: 3648, time: 0.091, data: 0.000) loss: 0.066 
(epoch: 220, iters: 3728, time: 0.057, data: 0.012) loss: 0.004 
saving the model at the end of epoch 220, iters 820160
End of epoch 220 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001879
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 220, TEST ACC: [96.206 %]

saving the latest model (epoch 221, total_steps 820176)
(epoch: 221, iters: 80, time: 0.097, data: 0.449) loss: 0.000 
(epoch: 221, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 221, iters: 240, time: 0.096, data: 0.039) loss: 0.066 
(epoch: 221, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 221, iters: 400, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 221, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 221, iters: 560, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 221, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 221, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 221, iters: 800, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 221, iters: 880, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 221, iters: 960, time: 0.094, data: 0.012) loss: 0.018 
(epoch: 221, iters: 1040, time: 0.095, data: 0.000) loss: 0.055 
(epoch: 221, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 221, iters: 1200, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 221, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 221, iters: 1360, time: 0.094, data: 0.040) loss: 0.008 
(epoch: 221, iters: 1440, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 221, iters: 1520, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 221, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 221, iters: 1680, time: 0.093, data: 0.012) loss: 0.009 
(epoch: 221, iters: 1760, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 221, iters: 1840, time: 0.094, data: 0.000) loss: 0.022 
(epoch: 221, iters: 1920, time: 0.096, data: 0.050) loss: 0.019 
(epoch: 221, iters: 2000, time: 0.094, data: 0.000) loss: 0.020 
(epoch: 221, iters: 2080, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 221, iters: 2160, time: 0.094, data: 0.000) loss: 0.020 
(epoch: 221, iters: 2240, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 221, iters: 2320, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 221, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 221, iters: 2480, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 221, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 221, iters: 2640, time: 0.092, data: 0.013) loss: 0.004 
(epoch: 221, iters: 2720, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 221, iters: 2800, time: 0.094, data: 0.011) loss: 0.013 
(epoch: 221, iters: 2880, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 221, iters: 2960, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 221, iters: 3040, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 221, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 221, iters: 3200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 221, iters: 3280, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 221, iters: 3360, time: 0.093, data: 0.012) loss: 0.012 
(epoch: 221, iters: 3440, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 221, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 221, iters: 3600, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 221, iters: 3680, time: 0.088, data: 0.000) loss: 0.209 
saving the model at the end of epoch 221, iters 823888
End of epoch 221 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001878
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 221, TEST ACC: [93.627 %]

saving the latest model (epoch 222, total_steps 823904)
(epoch: 222, iters: 32, time: 0.092, data: 0.004) loss: 0.005 
(epoch: 222, iters: 112, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 222, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 222, iters: 272, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 222, iters: 352, time: 0.096, data: 0.047) loss: 0.000 
(epoch: 222, iters: 432, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 222, iters: 512, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 222, iters: 592, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 222, iters: 672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 222, iters: 752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 222, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 222, iters: 912, time: 0.094, data: 0.041) loss: 0.005 
(epoch: 222, iters: 992, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 222, iters: 1072, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 222, iters: 1152, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 222, iters: 1232, time: 0.094, data: 0.011) loss: 0.005 
(epoch: 222, iters: 1312, time: 0.096, data: 0.000) loss: 0.112 
(epoch: 222, iters: 1392, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 222, iters: 1472, time: 0.095, data: 0.050) loss: 0.059 
(epoch: 222, iters: 1552, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 222, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 222, iters: 1712, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 222, iters: 1792, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 222, iters: 1872, time: 0.095, data: 0.000) loss: 0.227 
(epoch: 222, iters: 1952, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 222, iters: 2032, time: 0.097, data: 0.050) loss: 0.009 
(epoch: 222, iters: 2112, time: 0.096, data: 0.000) loss: 0.191 
(epoch: 222, iters: 2192, time: 0.094, data: 0.011) loss: 0.104 
(epoch: 222, iters: 2272, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 222, iters: 2352, time: 0.094, data: 0.012) loss: 0.033 
(epoch: 222, iters: 2432, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 222, iters: 2512, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 222, iters: 2592, time: 0.096, data: 0.050) loss: 0.002 
(epoch: 222, iters: 2672, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 222, iters: 2752, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 222, iters: 2832, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 222, iters: 2912, time: 0.093, data: 0.012) loss: 0.008 
(epoch: 222, iters: 2992, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 222, iters: 3072, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 222, iters: 3152, time: 0.096, data: 0.041) loss: 0.001 
(epoch: 222, iters: 3232, time: 0.098, data: 0.000) loss: 0.244 
(epoch: 222, iters: 3312, time: 0.095, data: 0.012) loss: 0.028 
(epoch: 222, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 222, iters: 3472, time: 0.093, data: 0.011) loss: 0.035 
(epoch: 222, iters: 3552, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 222, iters: 3632, time: 0.092, data: 0.000) loss: 0.003 
(epoch: 222, iters: 3712, time: 0.091, data: 0.036) loss: 0.000 
saving the model at the end of epoch 222, iters 827616
End of epoch 222 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001877
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 222, TEST ACC: [94.537 %]

saving the latest model (epoch 223, total_steps 827632)
(epoch: 223, iters: 64, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 223, iters: 144, time: 0.093, data: 0.025) loss: 0.002 
(epoch: 223, iters: 224, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 223, iters: 304, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 223, iters: 384, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 223, iters: 464, time: 0.094, data: 0.011) loss: 0.204 
(epoch: 223, iters: 544, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 223, iters: 624, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 223, iters: 704, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 223, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 223, iters: 864, time: 0.093, data: 0.011) loss: 0.007 
(epoch: 223, iters: 944, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 223, iters: 1024, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 223, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 223, iters: 1184, time: 0.095, data: 0.000) loss: 0.023 
(epoch: 223, iters: 1264, time: 0.094, data: 0.040) loss: 0.008 
(epoch: 223, iters: 1344, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 223, iters: 1424, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 223, iters: 1504, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 223, iters: 1584, time: 0.097, data: 0.013) loss: 0.000 
(epoch: 223, iters: 1664, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 223, iters: 1744, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 223, iters: 1824, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 223, iters: 1904, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 223, iters: 1984, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 223, iters: 2064, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 223, iters: 2144, time: 0.094, data: 0.011) loss: 0.060 
(epoch: 223, iters: 2224, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 223, iters: 2304, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 223, iters: 2384, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 223, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 223, iters: 2544, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 223, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 223, iters: 2704, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 223, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 223, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 223, iters: 2944, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 223, iters: 3024, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 223, iters: 3104, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 223, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 223, iters: 3264, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 223, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 223, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 223, iters: 3504, time: 0.097, data: 0.051) loss: 0.000 
(epoch: 223, iters: 3584, time: 0.095, data: 0.000) loss: 0.029 
(epoch: 223, iters: 3664, time: 0.087, data: 0.012) loss: 0.004 
saving the model at the end of epoch 223, iters 831344
End of epoch 223 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001876
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 223, TEST ACC: [71.624 %]

(epoch: 224, iters: 16, time: 0.108, data: 0.012) loss: 0.000 
saving the latest model (epoch 224, total_steps 831360)
(epoch: 224, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 224, iters: 176, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 224, iters: 256, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 224, iters: 336, time: 0.097, data: 0.011) loss: 0.044 
(epoch: 224, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 224, iters: 496, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 224, iters: 576, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 224, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 224, iters: 736, time: 0.093, data: 0.012) loss: 0.026 
(epoch: 224, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 224, iters: 896, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 224, iters: 976, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 224, iters: 1056, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 224, iters: 1136, time: 0.094, data: 0.039) loss: 0.047 
(epoch: 224, iters: 1216, time: 0.095, data: 0.000) loss: 0.041 
(epoch: 224, iters: 1296, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 224, iters: 1376, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 224, iters: 1456, time: 0.093, data: 0.011) loss: 0.005 
(epoch: 224, iters: 1536, time: 0.095, data: 0.000) loss: 0.050 
(epoch: 224, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 224, iters: 1696, time: 0.095, data: 0.040) loss: 0.106 
(epoch: 224, iters: 1776, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 224, iters: 1856, time: 0.092, data: 0.011) loss: 0.006 
(epoch: 224, iters: 1936, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 224, iters: 2016, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 224, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 224, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 224, iters: 2256, time: 0.095, data: 0.039) loss: 0.007 
(epoch: 224, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 224, iters: 2416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 224, iters: 2496, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 224, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 224, iters: 2656, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 224, iters: 2736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 224, iters: 2816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 224, iters: 2896, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 224, iters: 2976, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 224, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 224, iters: 3136, time: 0.095, data: 0.011) loss: 0.081 
(epoch: 224, iters: 3216, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 224, iters: 3296, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 224, iters: 3376, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 224, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 224, iters: 3536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 224, iters: 3616, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 224, iters: 3696, time: 0.088, data: 0.012) loss: 0.002 
saving the model at the end of epoch 224, iters 835072
End of epoch 224 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001875
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 224, TEST ACC: [85.888 %]

saving the latest model (epoch 225, total_steps 835088)
(epoch: 225, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 225, iters: 128, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 225, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 225, iters: 288, time: 0.091, data: 0.011) loss: 0.015 
(epoch: 225, iters: 368, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 225, iters: 448, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 225, iters: 528, time: 0.095, data: 0.000) loss: 0.264 
(epoch: 225, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 225, iters: 688, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 225, iters: 768, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 225, iters: 848, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 225, iters: 928, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 225, iters: 1008, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 225, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 225, iters: 1168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 225, iters: 1248, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 225, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 225, iters: 1408, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 225, iters: 1488, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 225, iters: 1568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 225, iters: 1648, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 225, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 225, iters: 1808, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 225, iters: 1888, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 225, iters: 1968, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 225, iters: 2048, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 225, iters: 2128, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 225, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 225, iters: 2288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 225, iters: 2368, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 225, iters: 2448, time: 0.096, data: 0.000) loss: 0.017 
(epoch: 225, iters: 2528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 225, iters: 2608, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 225, iters: 2688, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 225, iters: 2768, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 225, iters: 2848, time: 0.093, data: 0.000) loss: 0.035 
(epoch: 225, iters: 2928, time: 0.094, data: 0.038) loss: 0.006 
(epoch: 225, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 225, iters: 3088, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 225, iters: 3168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 225, iters: 3248, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 225, iters: 3328, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 225, iters: 3408, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 225, iters: 3488, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 225, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 225, iters: 3648, time: 0.086, data: 0.011) loss: 0.000 
(epoch: 225, iters: 3728, time: 0.056, data: 0.000) loss: 0.004 
saving the model at the end of epoch 225, iters 838800
End of epoch 225 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001874
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 225, TEST ACC: [94.537 %]

saving the latest model (epoch 226, total_steps 838816)
(epoch: 226, iters: 80, time: 0.093, data: 0.442) loss: 0.000 
(epoch: 226, iters: 160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 226, iters: 240, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 226, iters: 320, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 226, iters: 400, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 226, iters: 480, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 226, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 226, iters: 640, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 226, iters: 720, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 226, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 226, iters: 880, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 226, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 226, iters: 1040, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 226, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 226, iters: 1200, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 226, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 226, iters: 1360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 226, iters: 1440, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 226, iters: 1520, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 226, iters: 1600, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 226, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 226, iters: 1760, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 226, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 226, iters: 1920, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 226, iters: 2000, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 226, iters: 2080, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 226, iters: 2160, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 226, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 226, iters: 2320, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 226, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 226, iters: 2480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 226, iters: 2560, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 226, iters: 2640, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 226, iters: 2720, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 226, iters: 2800, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 226, iters: 2880, time: 0.098, data: 0.011) loss: 0.000 
(epoch: 226, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 226, iters: 3040, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 226, iters: 3120, time: 0.094, data: 0.038) loss: 0.036 
(epoch: 226, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 226, iters: 3280, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 226, iters: 3360, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 226, iters: 3440, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 226, iters: 3520, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 226, iters: 3600, time: 0.093, data: 0.000) loss: 0.012 
(epoch: 226, iters: 3680, time: 0.090, data: 0.039) loss: 0.001 
saving the model at the end of epoch 226, iters 842528
End of epoch 226 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001873
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 226, TEST ACC: [93.475 %]

saving the latest model (epoch 227, total_steps 842544)
(epoch: 227, iters: 32, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 227, iters: 112, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 227, iters: 192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 227, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 227, iters: 352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 227, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 227, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 227, iters: 592, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 227, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 227, iters: 752, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 227, iters: 832, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 227, iters: 912, time: 0.095, data: 0.011) loss: 0.020 
(epoch: 227, iters: 992, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 227, iters: 1072, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 227, iters: 1152, time: 0.095, data: 0.038) loss: 0.001 
(epoch: 227, iters: 1232, time: 0.095, data: 0.000) loss: 0.047 
(epoch: 227, iters: 1312, time: 0.092, data: 0.012) loss: 0.015 
(epoch: 227, iters: 1392, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 227, iters: 1472, time: 0.093, data: 0.021) loss: 0.001 
(epoch: 227, iters: 1552, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 227, iters: 1632, time: 0.094, data: 0.000) loss: 0.083 
(epoch: 227, iters: 1712, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 227, iters: 1792, time: 0.095, data: 0.000) loss: 0.018 
(epoch: 227, iters: 1872, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 227, iters: 1952, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 227, iters: 2032, time: 0.094, data: 0.020) loss: 0.006 
(epoch: 227, iters: 2112, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 227, iters: 2192, time: 0.094, data: 0.000) loss: 0.046 
(epoch: 227, iters: 2272, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 227, iters: 2352, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 227, iters: 2432, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 227, iters: 2512, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 227, iters: 2592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 227, iters: 2672, time: 0.096, data: 0.000) loss: 0.065 
(epoch: 227, iters: 2752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 227, iters: 2832, time: 0.094, data: 0.039) loss: 0.005 
(epoch: 227, iters: 2912, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 227, iters: 2992, time: 0.093, data: 0.022) loss: 0.042 
(epoch: 227, iters: 3072, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 227, iters: 3152, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 227, iters: 3232, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 227, iters: 3312, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 227, iters: 3392, time: 0.095, data: 0.050) loss: 0.099 
(epoch: 227, iters: 3472, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 227, iters: 3552, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 227, iters: 3632, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 227, iters: 3712, time: 0.090, data: 0.012) loss: 0.000 
saving the model at the end of epoch 227, iters 846256
End of epoch 227 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001872
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 227, TEST ACC: [92.413 %]

saving the latest model (epoch 228, total_steps 846272)
(epoch: 228, iters: 64, time: 0.093, data: 0.003) loss: 0.000 
(epoch: 228, iters: 144, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 228, iters: 224, time: 0.097, data: 0.000) loss: 0.017 
(epoch: 228, iters: 304, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 228, iters: 384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 228, iters: 464, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 228, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 228, iters: 624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 228, iters: 704, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 228, iters: 784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 228, iters: 864, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 228, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 228, iters: 1024, time: 0.093, data: 0.012) loss: 0.040 
(epoch: 228, iters: 1104, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 228, iters: 1184, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 228, iters: 1264, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 228, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 228, iters: 1424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 228, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 228, iters: 1584, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 228, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 228, iters: 1744, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 228, iters: 1824, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 228, iters: 1904, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 228, iters: 1984, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 228, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 228, iters: 2144, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 228, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 228, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 228, iters: 2384, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 228, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 228, iters: 2544, time: 0.092, data: 0.021) loss: 0.001 
(epoch: 228, iters: 2624, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 228, iters: 2704, time: 0.093, data: 0.011) loss: 0.009 
(epoch: 228, iters: 2784, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 228, iters: 2864, time: 0.093, data: 0.000) loss: 0.439 
(epoch: 228, iters: 2944, time: 0.095, data: 0.048) loss: 0.002 
(epoch: 228, iters: 3024, time: 0.094, data: 0.000) loss: 0.241 
(epoch: 228, iters: 3104, time: 0.095, data: 0.012) loss: 0.038 
(epoch: 228, iters: 3184, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 228, iters: 3264, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 228, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 228, iters: 3424, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 228, iters: 3504, time: 0.097, data: 0.040) loss: 0.151 
(epoch: 228, iters: 3584, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 228, iters: 3664, time: 0.088, data: 0.013) loss: 0.000 
saving the model at the end of epoch 228, iters 849984
End of epoch 228 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001871
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 228, TEST ACC: [65.402 %]

(epoch: 229, iters: 16, time: 0.113, data: 0.012) loss: 0.000 
saving the latest model (epoch 229, total_steps 850000)
(epoch: 229, iters: 96, time: 0.094, data: 0.059) loss: 0.433 
(epoch: 229, iters: 176, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 229, iters: 256, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 229, iters: 336, time: 0.094, data: 0.000) loss: 0.209 
(epoch: 229, iters: 416, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 229, iters: 496, time: 0.095, data: 0.000) loss: 0.023 
(epoch: 229, iters: 576, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 229, iters: 656, time: 0.095, data: 0.039) loss: 0.124 
(epoch: 229, iters: 736, time: 0.096, data: 0.000) loss: 0.062 
(epoch: 229, iters: 816, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 229, iters: 896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 229, iters: 976, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 229, iters: 1056, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 229, iters: 1136, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 229, iters: 1216, time: 0.094, data: 0.039) loss: 0.141 
(epoch: 229, iters: 1296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 229, iters: 1376, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 229, iters: 1456, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 229, iters: 1536, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 229, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 229, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 229, iters: 1776, time: 0.096, data: 0.049) loss: 0.042 
(epoch: 229, iters: 1856, time: 0.098, data: 0.000) loss: 0.025 
(epoch: 229, iters: 1936, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 229, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 229, iters: 2096, time: 0.094, data: 0.011) loss: 0.006 
(epoch: 229, iters: 2176, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 229, iters: 2256, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 229, iters: 2336, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 229, iters: 2416, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 229, iters: 2496, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 229, iters: 2576, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 229, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 229, iters: 2736, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 229, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 229, iters: 2896, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 229, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 229, iters: 3056, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 229, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 229, iters: 3216, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 229, iters: 3296, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 229, iters: 3376, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 229, iters: 3456, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 229, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 229, iters: 3616, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 229, iters: 3696, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 229, iters 853712
End of epoch 229 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001870
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 229, TEST ACC: [94.992 %]

saving the latest model (epoch 230, total_steps 853728)
(epoch: 230, iters: 48, time: 0.092, data: 0.014) loss: 0.002 
(epoch: 230, iters: 128, time: 0.094, data: 0.041) loss: 0.016 
(epoch: 230, iters: 208, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 230, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 230, iters: 368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 230, iters: 448, time: 0.095, data: 0.021) loss: 0.000 
(epoch: 230, iters: 528, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 230, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 230, iters: 688, time: 0.094, data: 0.040) loss: 0.016 
(epoch: 230, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 230, iters: 848, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 230, iters: 928, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 230, iters: 1008, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 230, iters: 1088, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 230, iters: 1168, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 230, iters: 1248, time: 0.095, data: 0.053) loss: 0.000 
(epoch: 230, iters: 1328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 230, iters: 1408, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 230, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 230, iters: 1568, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 230, iters: 1648, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 230, iters: 1728, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 230, iters: 1808, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 230, iters: 1888, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 230, iters: 1968, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 230, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 230, iters: 2128, time: 0.095, data: 0.011) loss: 0.020 
(epoch: 230, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 230, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 230, iters: 2368, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 230, iters: 2448, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 230, iters: 2528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 230, iters: 2608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 230, iters: 2688, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 230, iters: 2768, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 230, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 230, iters: 2928, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 230, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 230, iters: 3088, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 230, iters: 3168, time: 0.094, data: 0.000) loss: 0.035 
(epoch: 230, iters: 3248, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 230, iters: 3328, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 230, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 230, iters: 3488, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 230, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 230, iters: 3648, time: 0.086, data: 0.011) loss: 0.000 
(epoch: 230, iters: 3728, time: 0.055, data: 0.000) loss: 0.000 
saving the model at the end of epoch 230, iters 857440
End of epoch 230 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001869
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 230, TEST ACC: [94.082 %]

saving the latest model (epoch 231, total_steps 857456)
(epoch: 231, iters: 80, time: 0.094, data: 0.452) loss: 0.000 
(epoch: 231, iters: 160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 231, iters: 240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 231, iters: 320, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 231, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 231, iters: 480, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 231, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 231, iters: 640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 231, iters: 720, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 231, iters: 800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 231, iters: 880, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 231, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 231, iters: 1040, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 231, iters: 1120, time: 0.093, data: 0.000) loss: 0.018 
(epoch: 231, iters: 1200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 231, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 231, iters: 1360, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 231, iters: 1440, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 231, iters: 1520, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 231, iters: 1600, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 231, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 231, iters: 1760, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 231, iters: 1840, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 231, iters: 1920, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 231, iters: 2000, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 231, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 231, iters: 2160, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 231, iters: 2240, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 231, iters: 2320, time: 0.094, data: 0.020) loss: 0.001 
(epoch: 231, iters: 2400, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 231, iters: 2480, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 231, iters: 2560, time: 0.094, data: 0.039) loss: 0.002 
(epoch: 231, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 231, iters: 2720, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 231, iters: 2800, time: 0.094, data: 0.000) loss: 0.092 
(epoch: 231, iters: 2880, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 231, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 231, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 231, iters: 3120, time: 0.095, data: 0.049) loss: 0.003 
(epoch: 231, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 231, iters: 3280, time: 0.092, data: 0.011) loss: 0.008 
(epoch: 231, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 231, iters: 3440, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 231, iters: 3520, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 231, iters: 3600, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 231, iters: 3680, time: 0.088, data: 0.040) loss: 0.000 
saving the model at the end of epoch 231, iters 861168
End of epoch 231 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001868
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 231, TEST ACC: [96.055 %]

saving the latest model (epoch 232, total_steps 861184)
(epoch: 232, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 232, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 232, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 232, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 232, iters: 352, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 232, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 232, iters: 512, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 232, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 232, iters: 672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 232, iters: 752, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 232, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 232, iters: 912, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 232, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 232, iters: 1072, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 232, iters: 1152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 232, iters: 1232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 232, iters: 1312, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 232, iters: 1392, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 232, iters: 1472, time: 0.095, data: 0.039) loss: 0.002 
(epoch: 232, iters: 1552, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 232, iters: 1632, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 232, iters: 1712, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 232, iters: 1792, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 232, iters: 1872, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 232, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 232, iters: 2032, time: 0.094, data: 0.048) loss: 0.010 
(epoch: 232, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 232, iters: 2192, time: 0.092, data: 0.011) loss: 0.012 
(epoch: 232, iters: 2272, time: 0.097, data: 0.000) loss: 0.009 
(epoch: 232, iters: 2352, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 232, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 232, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 232, iters: 2592, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 232, iters: 2672, time: 0.095, data: 0.000) loss: 0.183 
(epoch: 232, iters: 2752, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 232, iters: 2832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 232, iters: 2912, time: 0.093, data: 0.011) loss: 0.062 
(epoch: 232, iters: 2992, time: 0.095, data: 0.000) loss: 0.144 
(epoch: 232, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 232, iters: 3152, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 232, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 232, iters: 3312, time: 0.092, data: 0.021) loss: 0.001 
(epoch: 232, iters: 3392, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 232, iters: 3472, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 232, iters: 3552, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 232, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 232, iters: 3712, time: 0.088, data: 0.045) loss: 0.064 
saving the model at the end of epoch 232, iters 864896
End of epoch 232 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001867
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 232, TEST ACC: [94.234 %]

saving the latest model (epoch 233, total_steps 864912)
(epoch: 233, iters: 64, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 233, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 233, iters: 224, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 233, iters: 304, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 233, iters: 384, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 233, iters: 464, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 233, iters: 544, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 233, iters: 624, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 233, iters: 704, time: 0.096, data: 0.012) loss: 0.003 
(epoch: 233, iters: 784, time: 0.097, data: 0.000) loss: 0.022 
(epoch: 233, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 233, iters: 944, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 233, iters: 1024, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 233, iters: 1104, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 233, iters: 1184, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 233, iters: 1264, time: 0.095, data: 0.013) loss: 0.001 
(epoch: 233, iters: 1344, time: 0.097, data: 0.000) loss: 0.006 
(epoch: 233, iters: 1424, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 233, iters: 1504, time: 0.097, data: 0.041) loss: 0.001 
(epoch: 233, iters: 1584, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 233, iters: 1664, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 233, iters: 1744, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 233, iters: 1824, time: 0.095, data: 0.012) loss: 0.009 
(epoch: 233, iters: 1904, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 233, iters: 1984, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 233, iters: 2064, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 233, iters: 2144, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 233, iters: 2224, time: 0.096, data: 0.011) loss: 0.036 
(epoch: 233, iters: 2304, time: 0.097, data: 0.000) loss: 0.009 
(epoch: 233, iters: 2384, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 233, iters: 2464, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 233, iters: 2544, time: 0.097, data: 0.000) loss: 0.009 
(epoch: 233, iters: 2624, time: 0.095, data: 0.043) loss: 0.011 
(epoch: 233, iters: 2704, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 233, iters: 2784, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 233, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 233, iters: 2944, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 233, iters: 3024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 233, iters: 3104, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 233, iters: 3184, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 233, iters: 3264, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 233, iters: 3344, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 233, iters: 3424, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 233, iters: 3504, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 233, iters: 3584, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 233, iters: 3664, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 233, iters 868624
End of epoch 233 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001866
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 233, TEST ACC: [94.537 %]

(epoch: 234, iters: 16, time: 0.108, data: 0.021) loss: 0.000 
saving the latest model (epoch 234, total_steps 868640)
(epoch: 234, iters: 96, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 234, iters: 176, time: 0.092, data: 0.012) loss: 0.020 
(epoch: 234, iters: 256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 234, iters: 336, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 234, iters: 416, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 234, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 234, iters: 576, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 234, iters: 656, time: 0.096, data: 0.000) loss: 0.015 
(epoch: 234, iters: 736, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 234, iters: 816, time: 0.096, data: 0.000) loss: 0.222 
(epoch: 234, iters: 896, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 234, iters: 976, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 234, iters: 1056, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 234, iters: 1136, time: 0.094, data: 0.040) loss: 0.068 
(epoch: 234, iters: 1216, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 234, iters: 1296, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 234, iters: 1376, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 234, iters: 1456, time: 0.093, data: 0.012) loss: 0.021 
(epoch: 234, iters: 1536, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 234, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 234, iters: 1696, time: 0.094, data: 0.039) loss: 0.085 
(epoch: 234, iters: 1776, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 234, iters: 1856, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 234, iters: 1936, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 234, iters: 2016, time: 0.093, data: 0.012) loss: 0.022 
(epoch: 234, iters: 2096, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 234, iters: 2176, time: 0.093, data: 0.000) loss: 0.023 
(epoch: 234, iters: 2256, time: 0.096, data: 0.051) loss: 0.004 
(epoch: 234, iters: 2336, time: 0.094, data: 0.000) loss: 0.157 
(epoch: 234, iters: 2416, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 234, iters: 2496, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 234, iters: 2576, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 234, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 234, iters: 2736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 234, iters: 2816, time: 0.094, data: 0.041) loss: 0.019 
(epoch: 234, iters: 2896, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 234, iters: 2976, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 234, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 234, iters: 3136, time: 0.094, data: 0.012) loss: 0.006 
(epoch: 234, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 234, iters: 3296, time: 0.093, data: 0.000) loss: 0.008 
(epoch: 234, iters: 3376, time: 0.094, data: 0.038) loss: 0.014 
(epoch: 234, iters: 3456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 234, iters: 3536, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 234, iters: 3616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 234, iters: 3696, time: 0.088, data: 0.012) loss: 0.003 
saving the model at the end of epoch 234, iters 872352
End of epoch 234 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001865
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 234, TEST ACC: [93.02 %]

saving the latest model (epoch 235, total_steps 872368)
(epoch: 235, iters: 48, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 235, iters: 128, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 235, iters: 208, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 235, iters: 288, time: 0.095, data: 0.000) loss: 0.027 
(epoch: 235, iters: 368, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 235, iters: 448, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 235, iters: 528, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 235, iters: 608, time: 0.097, data: 0.050) loss: 0.020 
(epoch: 235, iters: 688, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 235, iters: 768, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 235, iters: 848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 235, iters: 928, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 235, iters: 1008, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 235, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 235, iters: 1168, time: 0.096, data: 0.041) loss: 0.007 
(epoch: 235, iters: 1248, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 235, iters: 1328, time: 0.094, data: 0.011) loss: 0.004 
(epoch: 235, iters: 1408, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 235, iters: 1488, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 235, iters: 1568, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 235, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 235, iters: 1728, time: 0.096, data: 0.040) loss: 0.003 
(epoch: 235, iters: 1808, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 235, iters: 1888, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 235, iters: 1968, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 235, iters: 2048, time: 0.096, data: 0.011) loss: 0.140 
(epoch: 235, iters: 2128, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 235, iters: 2208, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 235, iters: 2288, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 235, iters: 2368, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 235, iters: 2448, time: 0.095, data: 0.011) loss: 0.016 
(epoch: 235, iters: 2528, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 235, iters: 2608, time: 0.095, data: 0.021) loss: 0.031 
(epoch: 235, iters: 2688, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 235, iters: 2768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 235, iters: 2848, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 235, iters: 2928, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 235, iters: 3008, time: 0.095, data: 0.012) loss: 0.009 
(epoch: 235, iters: 3088, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 235, iters: 3168, time: 0.096, data: 0.012) loss: 0.013 
(epoch: 235, iters: 3248, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 235, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 235, iters: 3408, time: 0.098, data: 0.041) loss: 0.000 
(epoch: 235, iters: 3488, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 235, iters: 3568, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 235, iters: 3648, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 235, iters: 3728, time: 0.057, data: 0.012) loss: 0.000 
saving the model at the end of epoch 235, iters 876080
End of epoch 235 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001864
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 235, TEST ACC: [94.234 %]

saving the latest model (epoch 236, total_steps 876096)
(epoch: 236, iters: 80, time: 0.096, data: 0.449) loss: 0.000 
(epoch: 236, iters: 160, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 236, iters: 240, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 236, iters: 320, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 236, iters: 400, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 236, iters: 480, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 236, iters: 560, time: 0.097, data: 0.000) loss: 0.032 
(epoch: 236, iters: 640, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 236, iters: 720, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 236, iters: 800, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 236, iters: 880, time: 0.096, data: 0.040) loss: 0.002 
(epoch: 236, iters: 960, time: 0.099, data: 0.000) loss: 0.006 
(epoch: 236, iters: 1040, time: 0.096, data: 0.012) loss: 0.154 
(epoch: 236, iters: 1120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 236, iters: 1200, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 236, iters: 1280, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 236, iters: 1360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 236, iters: 1440, time: 0.096, data: 0.041) loss: 0.003 
(epoch: 236, iters: 1520, time: 0.097, data: 0.000) loss: 0.008 
(epoch: 236, iters: 1600, time: 0.095, data: 0.012) loss: 0.054 
(epoch: 236, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 236, iters: 1760, time: 0.095, data: 0.011) loss: 0.025 
(epoch: 236, iters: 1840, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 236, iters: 1920, time: 0.096, data: 0.000) loss: 0.046 
(epoch: 236, iters: 2000, time: 0.096, data: 0.041) loss: 0.002 
(epoch: 236, iters: 2080, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 236, iters: 2160, time: 0.096, data: 0.012) loss: 0.002 
(epoch: 236, iters: 2240, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 236, iters: 2320, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 236, iters: 2400, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 236, iters: 2480, time: 0.095, data: 0.000) loss: 0.027 
(epoch: 236, iters: 2560, time: 0.096, data: 0.040) loss: 0.012 
(epoch: 236, iters: 2640, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 236, iters: 2720, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 236, iters: 2800, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 236, iters: 2880, time: 0.097, data: 0.012) loss: 0.001 
(epoch: 236, iters: 2960, time: 0.098, data: 0.000) loss: 0.149 
(epoch: 236, iters: 3040, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 236, iters: 3120, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 236, iters: 3200, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 236, iters: 3280, time: 0.095, data: 0.013) loss: 0.031 
(epoch: 236, iters: 3360, time: 0.097, data: 0.000) loss: 0.023 
(epoch: 236, iters: 3440, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 236, iters: 3520, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 236, iters: 3600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 236, iters: 3680, time: 0.090, data: 0.040) loss: 0.000 
saving the model at the end of epoch 236, iters 879808
End of epoch 236 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001863
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 236, TEST ACC: [94.841 %]

saving the latest model (epoch 237, total_steps 879824)
(epoch: 237, iters: 32, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 237, iters: 112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 237, iters: 192, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 237, iters: 272, time: 0.096, data: 0.000) loss: 0.045 
(epoch: 237, iters: 352, time: 0.098, data: 0.040) loss: 0.000 
(epoch: 237, iters: 432, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 237, iters: 512, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 237, iters: 592, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 237, iters: 672, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 237, iters: 752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 237, iters: 832, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 237, iters: 912, time: 0.095, data: 0.039) loss: 0.065 
(epoch: 237, iters: 992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 237, iters: 1072, time: 0.097, data: 0.011) loss: 0.005 
(epoch: 237, iters: 1152, time: 0.094, data: 0.027) loss: 0.004 
(epoch: 237, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 237, iters: 1312, time: 0.098, data: 0.000) loss: 0.034 
(epoch: 237, iters: 1392, time: 0.097, data: 0.013) loss: 0.000 
(epoch: 237, iters: 1472, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 237, iters: 1552, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 237, iters: 1632, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 237, iters: 1712, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 237, iters: 1792, time: 0.094, data: 0.037) loss: 0.000 
(epoch: 237, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 237, iters: 1952, time: 0.096, data: 0.000) loss: 0.016 
(epoch: 237, iters: 2032, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 237, iters: 2112, time: 0.094, data: 0.025) loss: 0.046 
(epoch: 237, iters: 2192, time: 0.099, data: 0.000) loss: 0.009 
(epoch: 237, iters: 2272, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 237, iters: 2352, time: 0.095, data: 0.012) loss: 0.094 
(epoch: 237, iters: 2432, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 237, iters: 2512, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 237, iters: 2592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 237, iters: 2672, time: 0.096, data: 0.021) loss: 0.000 
(epoch: 237, iters: 2752, time: 0.094, data: 0.026) loss: 0.035 
(epoch: 237, iters: 2832, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 237, iters: 2912, time: 0.097, data: 0.000) loss: 0.023 
(epoch: 237, iters: 2992, time: 0.096, data: 0.012) loss: 0.003 
(epoch: 237, iters: 3072, time: 0.096, data: 0.027) loss: 0.001 
(epoch: 237, iters: 3152, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 237, iters: 3232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 237, iters: 3312, time: 0.097, data: 0.012) loss: 0.001 
(epoch: 237, iters: 3392, time: 0.095, data: 0.035) loss: 0.003 
(epoch: 237, iters: 3472, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 237, iters: 3552, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 237, iters: 3632, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 237, iters: 3712, time: 0.090, data: 0.031) loss: 0.000 
saving the model at the end of epoch 237, iters 883536
End of epoch 237 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001862
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 237, TEST ACC: [95.144 %]

saving the latest model (epoch 238, total_steps 883552)
(epoch: 238, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 238, iters: 144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 238, iters: 224, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 238, iters: 304, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 238, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 238, iters: 464, time: 0.097, data: 0.040) loss: 0.005 
(epoch: 238, iters: 544, time: 0.096, data: 0.000) loss: 0.028 
(epoch: 238, iters: 624, time: 0.095, data: 0.012) loss: 0.130 
(epoch: 238, iters: 704, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 238, iters: 784, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 238, iters: 864, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 238, iters: 944, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 238, iters: 1024, time: 0.097, data: 0.041) loss: 0.002 
(epoch: 238, iters: 1104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 238, iters: 1184, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 238, iters: 1264, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 238, iters: 1344, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 238, iters: 1424, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 238, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 238, iters: 1584, time: 0.096, data: 0.041) loss: 0.004 
(epoch: 238, iters: 1664, time: 0.097, data: 0.000) loss: 0.056 
(epoch: 238, iters: 1744, time: 0.095, data: 0.012) loss: 0.026 
(epoch: 238, iters: 1824, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 238, iters: 1904, time: 0.096, data: 0.011) loss: 0.002 
(epoch: 238, iters: 1984, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 238, iters: 2064, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 238, iters: 2144, time: 0.096, data: 0.039) loss: 0.002 
(epoch: 238, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 238, iters: 2304, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 238, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 238, iters: 2464, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 238, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 238, iters: 2624, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 238, iters: 2704, time: 0.094, data: 0.039) loss: 0.016 
(epoch: 238, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 238, iters: 2864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 238, iters: 2944, time: 0.094, data: 0.000) loss: 0.096 
(epoch: 238, iters: 3024, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 238, iters: 3104, time: 0.096, data: 0.000) loss: 0.154 
(epoch: 238, iters: 3184, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 238, iters: 3264, time: 0.095, data: 0.041) loss: 0.022 
(epoch: 238, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 238, iters: 3424, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 238, iters: 3504, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 238, iters: 3584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 238, iters: 3664, time: 0.088, data: 0.000) loss: 0.002 
saving the model at the end of epoch 238, iters 887264
End of epoch 238 / 2100 	 Time Taken: 358 sec
learning rate = 0.0001861
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 238, TEST ACC: [93.93 %]

(epoch: 239, iters: 16, time: 0.138, data: 0.000) loss: 0.003 
saving the latest model (epoch 239, total_steps 887280)
(epoch: 239, iters: 96, time: 0.093, data: 0.020) loss: 0.009 
(epoch: 239, iters: 176, time: 0.094, data: 0.030) loss: 0.001 
(epoch: 239, iters: 256, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 239, iters: 336, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 239, iters: 416, time: 0.092, data: 0.000) loss: 0.003 
(epoch: 239, iters: 496, time: 0.095, data: 0.000) loss: 0.064 
(epoch: 239, iters: 576, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 239, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 239, iters: 736, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 239, iters: 816, time: 0.092, data: 0.014) loss: 0.000 
(epoch: 239, iters: 896, time: 0.090, data: 0.000) loss: 0.115 
(epoch: 239, iters: 976, time: 0.092, data: 0.000) loss: 0.008 
(epoch: 239, iters: 1056, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 239, iters: 1136, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 239, iters: 1216, time: 0.096, data: 0.026) loss: 0.004 
(epoch: 239, iters: 1296, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 239, iters: 1376, time: 0.097, data: 0.011) loss: 0.002 
(epoch: 239, iters: 1456, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 239, iters: 1536, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 239, iters: 1616, time: 0.095, data: 0.047) loss: 0.001 
(epoch: 239, iters: 1696, time: 0.094, data: 0.028) loss: 0.001 
(epoch: 239, iters: 1776, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 239, iters: 1856, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 239, iters: 1936, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 239, iters: 2016, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 239, iters: 2096, time: 0.097, data: 0.000) loss: 0.025 
(epoch: 239, iters: 2176, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 239, iters: 2256, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 239, iters: 2336, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 239, iters: 2416, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 239, iters: 2496, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 239, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 239, iters: 2656, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 239, iters: 2736, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 239, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 239, iters: 2896, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 239, iters: 2976, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 239, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 239, iters: 3136, time: 0.095, data: 0.025) loss: 0.006 
(epoch: 239, iters: 3216, time: 0.097, data: 0.025) loss: 0.001 
(epoch: 239, iters: 3296, time: 0.094, data: 0.020) loss: 0.002 
(epoch: 239, iters: 3376, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 239, iters: 3456, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 239, iters: 3536, time: 0.094, data: 0.025) loss: 0.008 
(epoch: 239, iters: 3616, time: 0.095, data: 0.031) loss: 0.001 
(epoch: 239, iters: 3696, time: 0.089, data: 0.011) loss: 0.002 
saving the model at the end of epoch 239, iters 890992
End of epoch 239 / 2100 	 Time Taken: 364 sec
learning rate = 0.0001860
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 239, TEST ACC: [92.261 %]

saving the latest model (epoch 240, total_steps 891008)
(epoch: 240, iters: 48, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 240, iters: 128, time: 0.095, data: 0.042) loss: 0.001 
(epoch: 240, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 240, iters: 288, time: 0.093, data: 0.014) loss: 0.001 
(epoch: 240, iters: 368, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 240, iters: 448, time: 0.095, data: 0.000) loss: 0.121 
(epoch: 240, iters: 528, time: 0.092, data: 0.000) loss: 0.152 
(epoch: 240, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 240, iters: 688, time: 0.095, data: 0.032) loss: 0.000 
(epoch: 240, iters: 768, time: 0.094, data: 0.026) loss: 0.022 
(epoch: 240, iters: 848, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 240, iters: 928, time: 0.094, data: 0.000) loss: 0.020 
(epoch: 240, iters: 1008, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 240, iters: 1088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 240, iters: 1168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 240, iters: 1248, time: 0.095, data: 0.026) loss: 0.087 
(epoch: 240, iters: 1328, time: 0.096, data: 0.032) loss: 0.000 
(epoch: 240, iters: 1408, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 240, iters: 1488, time: 0.095, data: 0.000) loss: 0.185 
(epoch: 240, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 240, iters: 1648, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 240, iters: 1728, time: 0.094, data: 0.000) loss: 0.058 
(epoch: 240, iters: 1808, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 240, iters: 1888, time: 0.097, data: 0.025) loss: 0.000 
(epoch: 240, iters: 1968, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 240, iters: 2048, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 240, iters: 2128, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 240, iters: 2208, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 240, iters: 2288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 240, iters: 2368, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 240, iters: 2448, time: 0.096, data: 0.026) loss: 0.001 
(epoch: 240, iters: 2528, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 240, iters: 2608, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 240, iters: 2688, time: 0.092, data: 0.000) loss: 0.061 
(epoch: 240, iters: 2768, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 240, iters: 2848, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 240, iters: 2928, time: 0.095, data: 0.035) loss: 0.000 
(epoch: 240, iters: 3008, time: 0.096, data: 0.026) loss: 0.007 
(epoch: 240, iters: 3088, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 240, iters: 3168, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 240, iters: 3248, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 240, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 240, iters: 3408, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 240, iters: 3488, time: 0.096, data: 0.025) loss: 0.003 
(epoch: 240, iters: 3568, time: 0.091, data: 0.012) loss: 0.002 
(epoch: 240, iters: 3648, time: 0.087, data: 0.000) loss: 0.001 
(epoch: 240, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 240, iters 894720
End of epoch 240 / 2100 	 Time Taken: 365 sec
learning rate = 0.0001859
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 240, TEST ACC: [91.351 %]

saving the latest model (epoch 241, total_steps 894736)
(epoch: 241, iters: 80, time: 0.094, data: 0.860) loss: 0.007 
(epoch: 241, iters: 160, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 241, iters: 240, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 241, iters: 320, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 241, iters: 400, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 241, iters: 480, time: 0.094, data: 0.035) loss: 0.000 
(epoch: 241, iters: 560, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 241, iters: 640, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 241, iters: 720, time: 0.093, data: 0.000) loss: 0.010 
(epoch: 241, iters: 800, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 241, iters: 880, time: 0.097, data: 0.027) loss: 0.000 
(epoch: 241, iters: 960, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 241, iters: 1040, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 241, iters: 1120, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 241, iters: 1200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 241, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 241, iters: 1360, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 241, iters: 1440, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 241, iters: 1520, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 241, iters: 1600, time: 0.092, data: 0.000) loss: 0.030 
(epoch: 241, iters: 1680, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 241, iters: 1760, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 241, iters: 1840, time: 0.094, data: 0.000) loss: 0.068 
(epoch: 241, iters: 1920, time: 0.095, data: 0.025) loss: 0.001 
(epoch: 241, iters: 2000, time: 0.098, data: 0.039) loss: 0.001 
(epoch: 241, iters: 2080, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 241, iters: 2160, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 241, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 241, iters: 2320, time: 0.095, data: 0.032) loss: 0.000 
(epoch: 241, iters: 2400, time: 0.096, data: 0.037) loss: 0.000 
(epoch: 241, iters: 2480, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 241, iters: 2560, time: 0.091, data: 0.000) loss: 0.004 
(epoch: 241, iters: 2640, time: 0.092, data: 0.000) loss: 0.005 
(epoch: 241, iters: 2720, time: 0.093, data: 0.052) loss: 0.000 
(epoch: 241, iters: 2800, time: 0.093, data: 0.037) loss: 0.019 
(epoch: 241, iters: 2880, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 241, iters: 2960, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 241, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 241, iters: 3120, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 241, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 241, iters: 3280, time: 0.095, data: 0.031) loss: 0.000 
(epoch: 241, iters: 3360, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 241, iters: 3440, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 241, iters: 3520, time: 0.093, data: 0.000) loss: 0.076 
(epoch: 241, iters: 3600, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 241, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 241, iters 898448
End of epoch 241 / 2100 	 Time Taken: 359 sec
learning rate = 0.0001858
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 241, TEST ACC: [93.171 %]

saving the latest model (epoch 242, total_steps 898464)
(epoch: 242, iters: 32, time: 0.102, data: 0.000) loss: 0.000 
(epoch: 242, iters: 112, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 242, iters: 192, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 242, iters: 272, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 242, iters: 352, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 242, iters: 432, time: 0.095, data: 0.025) loss: 0.275 
(epoch: 242, iters: 512, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 242, iters: 592, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 242, iters: 672, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 242, iters: 752, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 242, iters: 832, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 242, iters: 912, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 242, iters: 992, time: 0.094, data: 0.025) loss: 0.011 
(epoch: 242, iters: 1072, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 242, iters: 1152, time: 0.091, data: 0.000) loss: 0.007 
(epoch: 242, iters: 1232, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 242, iters: 1312, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 242, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 242, iters: 1472, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 242, iters: 1552, time: 0.096, data: 0.034) loss: 0.093 
(epoch: 242, iters: 1632, time: 0.093, data: 0.017) loss: 0.000 
(epoch: 242, iters: 1712, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 242, iters: 1792, time: 0.093, data: 0.000) loss: 0.008 
(epoch: 242, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 242, iters: 1952, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 242, iters: 2032, time: 0.094, data: 0.026) loss: 0.025 
(epoch: 242, iters: 2112, time: 0.097, data: 0.026) loss: 0.107 
(epoch: 242, iters: 2192, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 242, iters: 2272, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 242, iters: 2352, time: 0.096, data: 0.000) loss: 0.127 
(epoch: 242, iters: 2432, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 242, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 242, iters: 2592, time: 0.097, data: 0.026) loss: 0.004 
(epoch: 242, iters: 2672, time: 0.096, data: 0.032) loss: 0.001 
(epoch: 242, iters: 2752, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 242, iters: 2832, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 242, iters: 2912, time: 0.093, data: 0.000) loss: 0.036 
(epoch: 242, iters: 2992, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 242, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 242, iters: 3152, time: 0.095, data: 0.028) loss: 0.025 
(epoch: 242, iters: 3232, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 242, iters: 3312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 242, iters: 3392, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 242, iters: 3472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 242, iters: 3552, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 242, iters: 3632, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 242, iters: 3712, time: 0.091, data: 0.040) loss: 0.005 
saving the model at the end of epoch 242, iters 902176
End of epoch 242 / 2100 	 Time Taken: 366 sec
learning rate = 0.0001857
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 242, TEST ACC: [93.778 %]

saving the latest model (epoch 243, total_steps 902192)
(epoch: 243, iters: 64, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 243, iters: 144, time: 0.095, data: 0.022) loss: 0.000 
(epoch: 243, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 243, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 243, iters: 384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 243, iters: 464, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 243, iters: 544, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 243, iters: 624, time: 0.097, data: 0.025) loss: 0.001 
(epoch: 243, iters: 704, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 243, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 243, iters: 864, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 243, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 243, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 243, iters: 1104, time: 0.097, data: 0.025) loss: 0.000 
(epoch: 243, iters: 1184, time: 0.095, data: 0.032) loss: 0.003 
(epoch: 243, iters: 1264, time: 0.098, data: 0.012) loss: 0.000 
(epoch: 243, iters: 1344, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 243, iters: 1424, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 243, iters: 1504, time: 0.096, data: 0.038) loss: 0.001 
(epoch: 243, iters: 1584, time: 0.095, data: 0.038) loss: 0.001 
(epoch: 243, iters: 1664, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 243, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 243, iters: 1824, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 243, iters: 1904, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 243, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 243, iters: 2064, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 243, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 243, iters: 2224, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 243, iters: 2304, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 243, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 243, iters: 2464, time: 0.094, data: 0.031) loss: 0.000 
(epoch: 243, iters: 2544, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 243, iters: 2624, time: 0.092, data: 0.017) loss: 0.000 
(epoch: 243, iters: 2704, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 243, iters: 2784, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 243, iters: 2864, time: 0.097, data: 0.000) loss: 0.019 
(epoch: 243, iters: 2944, time: 0.101, data: 0.000) loss: 0.000 
(epoch: 243, iters: 3024, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 243, iters: 3104, time: 0.097, data: 0.026) loss: 0.040 
(epoch: 243, iters: 3184, time: 0.092, data: 0.019) loss: 0.000 
(epoch: 243, iters: 3264, time: 0.095, data: 0.000) loss: 0.172 
(epoch: 243, iters: 3344, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 243, iters: 3424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 243, iters: 3504, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 243, iters: 3584, time: 0.095, data: 0.026) loss: 0.003 
(epoch: 243, iters: 3664, time: 0.088, data: 0.026) loss: 0.001 
saving the model at the end of epoch 243, iters 905904
End of epoch 243 / 2100 	 Time Taken: 365 sec
learning rate = 0.0001856
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 243, TEST ACC: [95.144 %]

(epoch: 244, iters: 16, time: 0.147, data: 0.009) loss: 0.000 
saving the latest model (epoch 244, total_steps 905920)
(epoch: 244, iters: 96, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 244, iters: 176, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 244, iters: 256, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 244, iters: 336, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 244, iters: 416, time: 0.099, data: 0.000) loss: 0.001 
(epoch: 244, iters: 496, time: 0.097, data: 0.000) loss: 0.023 
(epoch: 244, iters: 576, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 244, iters: 656, time: 0.095, data: 0.033) loss: 0.000 
(epoch: 244, iters: 736, time: 0.096, data: 0.027) loss: 0.003 
(epoch: 244, iters: 816, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 244, iters: 896, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 244, iters: 976, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 244, iters: 1056, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 244, iters: 1136, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 244, iters: 1216, time: 0.094, data: 0.038) loss: 0.003 
(epoch: 244, iters: 1296, time: 0.094, data: 0.032) loss: 0.011 
(epoch: 244, iters: 1376, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 244, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 244, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 244, iters: 1616, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 244, iters: 1696, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 244, iters: 1776, time: 0.095, data: 0.031) loss: 0.001 
(epoch: 244, iters: 1856, time: 0.096, data: 0.025) loss: 0.015 
(epoch: 244, iters: 1936, time: 0.096, data: 0.021) loss: 0.000 
(epoch: 244, iters: 2016, time: 0.091, data: 0.000) loss: 0.001 
(epoch: 244, iters: 2096, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 244, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 244, iters: 2256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 244, iters: 2336, time: 0.096, data: 0.025) loss: 0.000 
(epoch: 244, iters: 2416, time: 0.095, data: 0.035) loss: 0.002 
(epoch: 244, iters: 2496, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 244, iters: 2576, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 244, iters: 2656, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 244, iters: 2736, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 244, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 244, iters: 2896, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 244, iters: 2976, time: 0.094, data: 0.025) loss: 0.005 
(epoch: 244, iters: 3056, time: 0.094, data: 0.032) loss: 0.000 
(epoch: 244, iters: 3136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 244, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 244, iters: 3296, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 244, iters: 3376, time: 0.095, data: 0.000) loss: 0.048 
(epoch: 244, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 244, iters: 3536, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 244, iters: 3616, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 244, iters: 3696, time: 0.089, data: 0.012) loss: 0.004 
saving the model at the end of epoch 244, iters 909632
End of epoch 244 / 2100 	 Time Taken: 366 sec
learning rate = 0.0001855
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 244, TEST ACC: [87.86 %]

saving the latest model (epoch 245, total_steps 909648)
(epoch: 245, iters: 48, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 245, iters: 128, time: 0.095, data: 0.016) loss: 0.001 
(epoch: 245, iters: 208, time: 0.094, data: 0.030) loss: 0.003 
(epoch: 245, iters: 288, time: 0.096, data: 0.028) loss: 0.025 
(epoch: 245, iters: 368, time: 0.094, data: 0.011) loss: 0.046 
(epoch: 245, iters: 448, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 245, iters: 528, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 245, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 245, iters: 688, time: 0.095, data: 0.000) loss: 0.025 
(epoch: 245, iters: 768, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 245, iters: 848, time: 0.094, data: 0.028) loss: 0.011 
(epoch: 245, iters: 928, time: 0.095, data: 0.025) loss: 0.055 
(epoch: 245, iters: 1008, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 245, iters: 1088, time: 0.091, data: 0.000) loss: 0.267 
(epoch: 245, iters: 1168, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 245, iters: 1248, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 245, iters: 1328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 245, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 245, iters: 1488, time: 0.096, data: 0.035) loss: 0.000 
(epoch: 245, iters: 1568, time: 0.097, data: 0.028) loss: 0.000 
(epoch: 245, iters: 1648, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 245, iters: 1728, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 245, iters: 1808, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 245, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 245, iters: 1968, time: 0.096, data: 0.000) loss: 0.024 
(epoch: 245, iters: 2048, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 245, iters: 2128, time: 0.093, data: 0.012) loss: 0.007 
(epoch: 245, iters: 2208, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 245, iters: 2288, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 245, iters: 2368, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 245, iters: 2448, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 245, iters: 2528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 245, iters: 2608, time: 0.095, data: 0.030) loss: 0.000 
(epoch: 245, iters: 2688, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 245, iters: 2768, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 245, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 245, iters: 2928, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 245, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 245, iters: 3088, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 245, iters: 3168, time: 0.094, data: 0.027) loss: 0.001 
(epoch: 245, iters: 3248, time: 0.094, data: 0.034) loss: 0.000 
(epoch: 245, iters: 3328, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 245, iters: 3408, time: 0.094, data: 0.000) loss: 0.054 
(epoch: 245, iters: 3488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 245, iters: 3568, time: 0.095, data: 0.030) loss: 0.000 
(epoch: 245, iters: 3648, time: 0.090, data: 0.027) loss: 0.000 
(epoch: 245, iters: 3728, time: 0.057, data: 0.012) loss: 0.048 
saving the model at the end of epoch 245, iters 913360
End of epoch 245 / 2100 	 Time Taken: 364 sec
learning rate = 0.0001854
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 245, TEST ACC: [95.144 %]

saving the latest model (epoch 246, total_steps 913376)
(epoch: 246, iters: 80, time: 0.094, data: 2.259) loss: 0.000 
(epoch: 246, iters: 160, time: 0.093, data: 0.013) loss: 0.053 
(epoch: 246, iters: 240, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 246, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 246, iters: 400, time: 0.092, data: 0.041) loss: 0.001 
(epoch: 246, iters: 480, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 246, iters: 560, time: 0.093, data: 0.017) loss: 0.003 
(epoch: 246, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 246, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 246, iters: 800, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 246, iters: 880, time: 0.093, data: 0.026) loss: 0.046 
(epoch: 246, iters: 960, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 246, iters: 1040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 246, iters: 1120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 246, iters: 1200, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 246, iters: 1280, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 246, iters: 1360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 246, iters: 1440, time: 0.096, data: 0.031) loss: 0.001 
(epoch: 246, iters: 1520, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 246, iters: 1600, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 246, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 246, iters: 1760, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 246, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 246, iters: 1920, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 246, iters: 2000, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 246, iters: 2080, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 246, iters: 2160, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 246, iters: 2240, time: 0.092, data: 0.000) loss: 0.131 
(epoch: 246, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 246, iters: 2400, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 246, iters: 2480, time: 0.097, data: 0.000) loss: 0.035 
(epoch: 246, iters: 2560, time: 0.093, data: 0.028) loss: 0.045 
(epoch: 246, iters: 2640, time: 0.093, data: 0.069) loss: 0.071 
(epoch: 246, iters: 2720, time: 0.091, data: 0.000) loss: 0.013 
(epoch: 246, iters: 2800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 246, iters: 2880, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 246, iters: 2960, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 246, iters: 3040, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 246, iters: 3120, time: 0.096, data: 0.037) loss: 0.000 
(epoch: 246, iters: 3200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 246, iters: 3280, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 246, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 246, iters: 3440, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 246, iters: 3520, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 246, iters: 3600, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 246, iters: 3680, time: 0.089, data: 0.000) loss: 0.027 
saving the model at the end of epoch 246, iters 917088
End of epoch 246 / 2100 	 Time Taken: 362 sec
learning rate = 0.0001853
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 246, TEST ACC: [95.599 %]

saving the latest model (epoch 247, total_steps 917104)
(epoch: 247, iters: 32, time: 0.118, data: 0.000) loss: 0.000 
(epoch: 247, iters: 112, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 247, iters: 192, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 247, iters: 272, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 247, iters: 352, time: 0.095, data: 0.031) loss: 0.003 
(epoch: 247, iters: 432, time: 0.094, data: 0.035) loss: 0.000 
(epoch: 247, iters: 512, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 247, iters: 592, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 247, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 247, iters: 752, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 247, iters: 832, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 247, iters: 912, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 247, iters: 992, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 247, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 247, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 247, iters: 1232, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 247, iters: 1312, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 247, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 247, iters: 1472, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 247, iters: 1552, time: 0.092, data: 0.000) loss: 0.005 
(epoch: 247, iters: 1632, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 247, iters: 1712, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 247, iters: 1792, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 247, iters: 1872, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 247, iters: 1952, time: 0.096, data: 0.027) loss: 0.011 
(epoch: 247, iters: 2032, time: 0.091, data: 0.013) loss: 0.001 
(epoch: 247, iters: 2112, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 247, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 247, iters: 2272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 247, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 247, iters: 2432, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 247, iters: 2512, time: 0.095, data: 0.037) loss: 0.000 
(epoch: 247, iters: 2592, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 247, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 247, iters: 2752, time: 0.094, data: 0.000) loss: 0.023 
(epoch: 247, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 247, iters: 2912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 247, iters: 2992, time: 0.093, data: 0.044) loss: 0.001 
(epoch: 247, iters: 3072, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 247, iters: 3152, time: 0.093, data: 0.021) loss: 0.016 
(epoch: 247, iters: 3232, time: 0.091, data: 0.000) loss: 0.002 
(epoch: 247, iters: 3312, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 247, iters: 3392, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 247, iters: 3472, time: 0.096, data: 0.000) loss: 0.064 
(epoch: 247, iters: 3552, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 247, iters: 3632, time: 0.095, data: 0.043) loss: 0.002 
(epoch: 247, iters: 3712, time: 0.088, data: 0.011) loss: 0.005 
saving the model at the end of epoch 247, iters 920816
End of epoch 247 / 2100 	 Time Taken: 362 sec
learning rate = 0.0001852
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 247, TEST ACC: [95.144 %]

saving the latest model (epoch 248, total_steps 920832)
(epoch: 248, iters: 64, time: 0.094, data: 0.004) loss: 0.010 
(epoch: 248, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 248, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 248, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 248, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 248, iters: 464, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 248, iters: 544, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 248, iters: 624, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 248, iters: 704, time: 0.093, data: 0.044) loss: 0.000 
(epoch: 248, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 248, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 248, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 248, iters: 1024, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 248, iters: 1104, time: 0.094, data: 0.026) loss: 0.011 
(epoch: 248, iters: 1184, time: 0.093, data: 0.035) loss: 0.000 
(epoch: 248, iters: 1264, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 248, iters: 1344, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 248, iters: 1424, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 248, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 248, iters: 1584, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 248, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 248, iters: 1744, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 248, iters: 1824, time: 0.094, data: 0.030) loss: 0.003 
(epoch: 248, iters: 1904, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 248, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 248, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 248, iters: 2144, time: 0.096, data: 0.000) loss: 0.100 
(epoch: 248, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 248, iters: 2304, time: 0.095, data: 0.027) loss: 0.001 
(epoch: 248, iters: 2384, time: 0.095, data: 0.026) loss: 0.005 
(epoch: 248, iters: 2464, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 248, iters: 2544, time: 0.090, data: 0.000) loss: 0.013 
(epoch: 248, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 248, iters: 2704, time: 0.097, data: 0.030) loss: 0.000 
(epoch: 248, iters: 2784, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 248, iters: 2864, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 248, iters: 2944, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 248, iters: 3024, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 248, iters: 3104, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 248, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 248, iters: 3264, time: 0.095, data: 0.015) loss: 0.000 
(epoch: 248, iters: 3344, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 248, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 248, iters: 3504, time: 0.094, data: 0.025) loss: 0.001 
(epoch: 248, iters: 3584, time: 0.096, data: 0.035) loss: 0.000 
(epoch: 248, iters: 3664, time: 0.086, data: 0.012) loss: 0.000 
saving the model at the end of epoch 248, iters 924544
End of epoch 248 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001851
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 248, TEST ACC: [94.992 %]

(epoch: 249, iters: 16, time: 0.147, data: 0.000) loss: 0.000 
saving the latest model (epoch 249, total_steps 924560)
(epoch: 249, iters: 96, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 249, iters: 176, time: 0.095, data: 0.057) loss: 0.000 
(epoch: 249, iters: 256, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 249, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 249, iters: 416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 249, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 249, iters: 576, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 249, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 249, iters: 736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 249, iters: 816, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 249, iters: 896, time: 0.093, data: 0.000) loss: 0.011 
(epoch: 249, iters: 976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 249, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 249, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 249, iters: 1216, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 249, iters: 1296, time: 0.098, data: 0.027) loss: 0.011 
(epoch: 249, iters: 1376, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 249, iters: 1456, time: 0.094, data: 0.011) loss: 0.008 
(epoch: 249, iters: 1536, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 249, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 249, iters: 1696, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 249, iters: 1776, time: 0.094, data: 0.034) loss: 0.002 
(epoch: 249, iters: 1856, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 249, iters: 1936, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 249, iters: 2016, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 249, iters: 2096, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 249, iters: 2176, time: 0.096, data: 0.000) loss: 0.895 
(epoch: 249, iters: 2256, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 249, iters: 2336, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 249, iters: 2416, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 249, iters: 2496, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 249, iters: 2576, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 249, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 249, iters: 2736, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 249, iters: 2816, time: 0.095, data: 0.026) loss: 0.009 
(epoch: 249, iters: 2896, time: 0.095, data: 0.026) loss: 0.026 
(epoch: 249, iters: 2976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 249, iters: 3056, time: 0.091, data: 0.000) loss: 0.018 
(epoch: 249, iters: 3136, time: 0.092, data: 0.000) loss: 0.015 
(epoch: 249, iters: 3216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 249, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 249, iters: 3376, time: 0.095, data: 0.014) loss: 0.060 
(epoch: 249, iters: 3456, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 249, iters: 3536, time: 0.096, data: 0.000) loss: 0.157 
(epoch: 249, iters: 3616, time: 0.092, data: 0.025) loss: 0.009 
(epoch: 249, iters: 3696, time: 0.088, data: 0.026) loss: 0.001 
saving the model at the end of epoch 249, iters 928272
End of epoch 249 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001850
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 249, TEST ACC: [95.751 %]

saving the latest model (epoch 250, total_steps 928288)
(epoch: 250, iters: 48, time: 0.094, data: 0.004) loss: 0.001 
(epoch: 250, iters: 128, time: 0.095, data: 0.036) loss: 0.061 
(epoch: 250, iters: 208, time: 0.094, data: 0.036) loss: 0.000 
(epoch: 250, iters: 288, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 250, iters: 368, time: 0.094, data: 0.012) loss: 0.007 
(epoch: 250, iters: 448, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 250, iters: 528, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 250, iters: 608, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 250, iters: 688, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 250, iters: 768, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 250, iters: 848, time: 0.093, data: 0.026) loss: 0.002 
(epoch: 250, iters: 928, time: 0.096, data: 0.026) loss: 0.002 
(epoch: 250, iters: 1008, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 250, iters: 1088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 250, iters: 1168, time: 0.092, data: 0.000) loss: 0.010 
(epoch: 250, iters: 1248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 250, iters: 1328, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 250, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 250, iters: 1488, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 250, iters: 1568, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 250, iters: 1648, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 250, iters: 1728, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 250, iters: 1808, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 250, iters: 1888, time: 0.095, data: 0.033) loss: 0.001 
(epoch: 250, iters: 1968, time: 0.095, data: 0.037) loss: 0.000 
(epoch: 250, iters: 2048, time: 0.095, data: 0.011) loss: 0.012 
(epoch: 250, iters: 2128, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 250, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 250, iters: 2288, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 250, iters: 2368, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 250, iters: 2448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 250, iters: 2528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 250, iters: 2608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 250, iters: 2688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 250, iters: 2768, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 250, iters: 2848, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 250, iters: 2928, time: 0.095, data: 0.036) loss: 0.012 
(epoch: 250, iters: 3008, time: 0.095, data: 0.026) loss: 0.002 
(epoch: 250, iters: 3088, time: 0.092, data: 0.012) loss: 0.025 
(epoch: 250, iters: 3168, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 250, iters: 3248, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 250, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 250, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 250, iters: 3488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 250, iters: 3568, time: 0.094, data: 0.026) loss: 0.032 
(epoch: 250, iters: 3648, time: 0.088, data: 0.026) loss: 0.001 
(epoch: 250, iters: 3728, time: 0.057, data: 0.011) loss: 0.000 
saving the model at the end of epoch 250, iters 932000
End of epoch 250 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001849
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 250, TEST ACC: [97.42 %]

saving the latest model (epoch 251, total_steps 932016)
(epoch: 251, iters: 80, time: 0.096, data: 2.317) loss: 0.004 
(epoch: 251, iters: 160, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 251, iters: 240, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 251, iters: 320, time: 0.094, data: 0.027) loss: 0.001 
(epoch: 251, iters: 400, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 251, iters: 480, time: 0.093, data: 0.000) loss: 0.134 
(epoch: 251, iters: 560, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 251, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 251, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 251, iters: 800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 251, iters: 880, time: 0.093, data: 0.000) loss: 0.012 
(epoch: 251, iters: 960, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 251, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 251, iters: 1120, time: 0.096, data: 0.000) loss: 0.036 
(epoch: 251, iters: 1200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 251, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 251, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 251, iters: 1440, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 251, iters: 1520, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 251, iters: 1600, time: 0.096, data: 0.026) loss: 0.002 
(epoch: 251, iters: 1680, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 251, iters: 1760, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 251, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 251, iters: 1920, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 251, iters: 2000, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 251, iters: 2080, time: 0.095, data: 0.015) loss: 0.002 
(epoch: 251, iters: 2160, time: 0.095, data: 0.039) loss: 0.003 
(epoch: 251, iters: 2240, time: 0.096, data: 0.026) loss: 0.001 
(epoch: 251, iters: 2320, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 251, iters: 2400, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 251, iters: 2480, time: 0.096, data: 0.000) loss: 0.086 
(epoch: 251, iters: 2560, time: 0.096, data: 0.000) loss: 0.077 
(epoch: 251, iters: 2640, time: 0.094, data: 0.000) loss: 0.232 
(epoch: 251, iters: 2720, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 251, iters: 2800, time: 0.096, data: 0.026) loss: 0.015 
(epoch: 251, iters: 2880, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 251, iters: 2960, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 251, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 251, iters: 3120, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 251, iters: 3200, time: 0.096, data: 0.000) loss: 0.024 
(epoch: 251, iters: 3280, time: 0.093, data: 0.029) loss: 0.000 
(epoch: 251, iters: 3360, time: 0.094, data: 0.025) loss: 0.001 
(epoch: 251, iters: 3440, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 251, iters: 3520, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 251, iters: 3600, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 251, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 251, iters 935728
End of epoch 251 / 2100 	 Time Taken: 364 sec
learning rate = 0.0001848
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 251, TEST ACC: [96.358 %]

saving the latest model (epoch 252, total_steps 935744)
(epoch: 252, iters: 32, time: 0.116, data: 0.000) loss: 0.001 
(epoch: 252, iters: 112, time: 0.095, data: 0.012) loss: 0.006 
(epoch: 252, iters: 192, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 252, iters: 272, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 252, iters: 352, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 252, iters: 432, time: 0.093, data: 0.040) loss: 0.003 
(epoch: 252, iters: 512, time: 0.098, data: 0.037) loss: 0.002 
(epoch: 252, iters: 592, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 252, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 252, iters: 752, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 252, iters: 832, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 252, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 252, iters: 992, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 252, iters: 1072, time: 0.095, data: 0.027) loss: 0.001 
(epoch: 252, iters: 1152, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 252, iters: 1232, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 252, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 252, iters: 1392, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 252, iters: 1472, time: 0.092, data: 0.000) loss: 0.011 
(epoch: 252, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 252, iters: 1632, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 252, iters: 1712, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 252, iters: 1792, time: 0.095, data: 0.026) loss: 0.015 
(epoch: 252, iters: 1872, time: 0.092, data: 0.021) loss: 0.001 
(epoch: 252, iters: 1952, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 252, iters: 2032, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 252, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 252, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 252, iters: 2272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 252, iters: 2352, time: 0.093, data: 0.031) loss: 0.001 
(epoch: 252, iters: 2432, time: 0.094, data: 0.027) loss: 0.001 
(epoch: 252, iters: 2512, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 252, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 252, iters: 2672, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 252, iters: 2752, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 252, iters: 2832, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 252, iters: 2912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 252, iters: 2992, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 252, iters: 3072, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 252, iters: 3152, time: 0.097, data: 0.035) loss: 0.000 
(epoch: 252, iters: 3232, time: 0.096, data: 0.028) loss: 0.001 
(epoch: 252, iters: 3312, time: 0.095, data: 0.018) loss: 0.001 
(epoch: 252, iters: 3392, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 252, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 252, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 252, iters: 3632, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 252, iters: 3712, time: 0.091, data: 0.029) loss: 0.000 
saving the model at the end of epoch 252, iters 939456
End of epoch 252 / 2100 	 Time Taken: 364 sec
learning rate = 0.0001847
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 252, TEST ACC: [96.662 %]

saving the latest model (epoch 253, total_steps 939472)
(epoch: 253, iters: 64, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 253, iters: 144, time: 0.094, data: 0.016) loss: 0.001 
(epoch: 253, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 253, iters: 304, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 253, iters: 384, time: 0.096, data: 0.000) loss: 0.027 
(epoch: 253, iters: 464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 253, iters: 544, time: 0.096, data: 0.028) loss: 0.001 
(epoch: 253, iters: 624, time: 0.094, data: 0.045) loss: 0.000 
(epoch: 253, iters: 704, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 253, iters: 784, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 253, iters: 864, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 253, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 253, iters: 1024, time: 0.096, data: 0.033) loss: 0.035 
(epoch: 253, iters: 1104, time: 0.097, data: 0.048) loss: 0.001 
(epoch: 253, iters: 1184, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 253, iters: 1264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 253, iters: 1344, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 253, iters: 1424, time: 0.096, data: 0.000) loss: 0.019 
(epoch: 253, iters: 1504, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 253, iters: 1584, time: 0.098, data: 0.027) loss: 0.000 
(epoch: 253, iters: 1664, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 253, iters: 1744, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 253, iters: 1824, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 253, iters: 1904, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 253, iters: 1984, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 253, iters: 2064, time: 0.095, data: 0.055) loss: 0.317 
(epoch: 253, iters: 2144, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 253, iters: 2224, time: 0.094, data: 0.018) loss: 0.000 
(epoch: 253, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 253, iters: 2384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 253, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 253, iters: 2544, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 253, iters: 2624, time: 0.096, data: 0.026) loss: 0.002 
(epoch: 253, iters: 2704, time: 0.096, data: 0.031) loss: 0.001 
(epoch: 253, iters: 2784, time: 0.095, data: 0.013) loss: 0.003 
(epoch: 253, iters: 2864, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 253, iters: 2944, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 253, iters: 3024, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 253, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 253, iters: 3184, time: 0.097, data: 0.030) loss: 0.000 
(epoch: 253, iters: 3264, time: 0.094, data: 0.033) loss: 0.048 
(epoch: 253, iters: 3344, time: 0.094, data: 0.012) loss: 0.005 
(epoch: 253, iters: 3424, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 253, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 253, iters: 3584, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 253, iters: 3664, time: 0.088, data: 0.000) loss: 0.018 
saving the model at the end of epoch 253, iters 943184
End of epoch 253 / 2100 	 Time Taken: 367 sec
learning rate = 0.0001846
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 253, TEST ACC: [94.537 %]

(epoch: 254, iters: 16, time: 0.150, data: 0.012) loss: 0.002 
saving the latest model (epoch 254, total_steps 943200)
(epoch: 254, iters: 96, time: 0.094, data: 0.055) loss: 0.000 
(epoch: 254, iters: 176, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 254, iters: 256, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 254, iters: 336, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 254, iters: 416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 254, iters: 496, time: 0.095, data: 0.000) loss: 0.103 
(epoch: 254, iters: 576, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 254, iters: 656, time: 0.098, data: 0.030) loss: 0.000 
(epoch: 254, iters: 736, time: 0.095, data: 0.029) loss: 0.000 
(epoch: 254, iters: 816, time: 0.094, data: 0.012) loss: 0.014 
(epoch: 254, iters: 896, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 254, iters: 976, time: 0.093, data: 0.000) loss: 0.242 
(epoch: 254, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 254, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 254, iters: 1216, time: 0.094, data: 0.026) loss: 0.004 
(epoch: 254, iters: 1296, time: 0.096, data: 0.034) loss: 0.000 
(epoch: 254, iters: 1376, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 254, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 254, iters: 1536, time: 0.094, data: 0.000) loss: 0.142 
(epoch: 254, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 254, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 254, iters: 1776, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 254, iters: 1856, time: 0.093, data: 0.026) loss: 0.002 
(epoch: 254, iters: 1936, time: 0.093, data: 0.012) loss: 0.009 
(epoch: 254, iters: 2016, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 254, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 254, iters: 2176, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 254, iters: 2256, time: 0.095, data: 0.025) loss: 0.043 
(epoch: 254, iters: 2336, time: 0.096, data: 0.030) loss: 0.000 
(epoch: 254, iters: 2416, time: 0.097, data: 0.036) loss: 0.001 
(epoch: 254, iters: 2496, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 254, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 254, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 254, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 254, iters: 2816, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 254, iters: 2896, time: 0.095, data: 0.028) loss: 0.000 
(epoch: 254, iters: 2976, time: 0.095, data: 0.027) loss: 0.011 
(epoch: 254, iters: 3056, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 254, iters: 3136, time: 0.093, data: 0.000) loss: 0.061 
(epoch: 254, iters: 3216, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 254, iters: 3296, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 254, iters: 3376, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 254, iters: 3456, time: 0.094, data: 0.000) loss: 0.071 
(epoch: 254, iters: 3536, time: 0.095, data: 0.044) loss: 0.015 
(epoch: 254, iters: 3616, time: 0.095, data: 0.033) loss: 0.000 
(epoch: 254, iters: 3696, time: 0.089, data: 0.014) loss: 0.000 
saving the model at the end of epoch 254, iters 946912
End of epoch 254 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001845
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 254, TEST ACC: [93.627 %]

saving the latest model (epoch 255, total_steps 946928)
(epoch: 255, iters: 48, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 255, iters: 128, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 255, iters: 208, time: 0.093, data: 0.014) loss: 0.001 
(epoch: 255, iters: 288, time: 0.092, data: 0.000) loss: 0.003 
(epoch: 255, iters: 368, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 255, iters: 448, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 255, iters: 528, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 255, iters: 608, time: 0.092, data: 0.026) loss: 0.005 
(epoch: 255, iters: 688, time: 0.091, data: 0.019) loss: 0.002 
(epoch: 255, iters: 768, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 255, iters: 848, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 255, iters: 928, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 255, iters: 1008, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 255, iters: 1088, time: 0.095, data: 0.052) loss: 0.050 
(epoch: 255, iters: 1168, time: 0.095, data: 0.032) loss: 0.057 
(epoch: 255, iters: 1248, time: 0.093, data: 0.012) loss: 0.016 
(epoch: 255, iters: 1328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 255, iters: 1408, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 255, iters: 1488, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 255, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 255, iters: 1648, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 255, iters: 1728, time: 0.094, data: 0.032) loss: 0.001 
(epoch: 255, iters: 1808, time: 0.094, data: 0.026) loss: 0.002 
(epoch: 255, iters: 1888, time: 0.095, data: 0.013) loss: 0.065 
(epoch: 255, iters: 1968, time: 0.093, data: 0.000) loss: 0.036 
(epoch: 255, iters: 2048, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 255, iters: 2128, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 255, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 255, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 255, iters: 2368, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 255, iters: 2448, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 255, iters: 2528, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 255, iters: 2608, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 255, iters: 2688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 255, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 255, iters: 2848, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 255, iters: 2928, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 255, iters: 3008, time: 0.096, data: 0.028) loss: 0.001 
(epoch: 255, iters: 3088, time: 0.093, data: 0.012) loss: 0.428 
(epoch: 255, iters: 3168, time: 0.093, data: 0.000) loss: 0.039 
(epoch: 255, iters: 3248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 255, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 255, iters: 3408, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 255, iters: 3488, time: 0.098, data: 0.037) loss: 0.000 
(epoch: 255, iters: 3568, time: 0.099, data: 0.033) loss: 0.005 
(epoch: 255, iters: 3648, time: 0.087, data: 0.012) loss: 0.001 
(epoch: 255, iters: 3728, time: 0.056, data: 0.000) loss: 0.002 
saving the model at the end of epoch 255, iters 950640
End of epoch 255 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001844
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 255, TEST ACC: [93.778 %]

saving the latest model (epoch 256, total_steps 950656)
(epoch: 256, iters: 80, time: 0.097, data: 2.606) loss: 0.002 
(epoch: 256, iters: 160, time: 0.095, data: 0.027) loss: 0.076 
(epoch: 256, iters: 240, time: 0.094, data: 0.044) loss: 0.000 
(epoch: 256, iters: 320, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 256, iters: 400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 256, iters: 480, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 256, iters: 560, time: 0.098, data: 0.000) loss: 0.012 
(epoch: 256, iters: 640, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 256, iters: 720, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 256, iters: 800, time: 0.094, data: 0.013) loss: 0.001 
(epoch: 256, iters: 880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 256, iters: 960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 256, iters: 1040, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 256, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 256, iters: 1200, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 256, iters: 1280, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 256, iters: 1360, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 256, iters: 1440, time: 0.094, data: 0.000) loss: 0.017 
(epoch: 256, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 256, iters: 1600, time: 0.097, data: 0.030) loss: 0.008 
(epoch: 256, iters: 1680, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 256, iters: 1760, time: 0.095, data: 0.012) loss: 0.030 
(epoch: 256, iters: 1840, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 256, iters: 1920, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 256, iters: 2000, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 256, iters: 2080, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 256, iters: 2160, time: 0.093, data: 0.027) loss: 0.322 
(epoch: 256, iters: 2240, time: 0.096, data: 0.043) loss: 0.000 
(epoch: 256, iters: 2320, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 256, iters: 2400, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 256, iters: 2480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 256, iters: 2560, time: 0.096, data: 0.000) loss: 0.279 
(epoch: 256, iters: 2640, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 256, iters: 2720, time: 0.095, data: 0.026) loss: 0.173 
(epoch: 256, iters: 2800, time: 0.097, data: 0.027) loss: 0.000 
(epoch: 256, iters: 2880, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 256, iters: 2960, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 256, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 256, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 256, iters: 3200, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 256, iters: 3280, time: 0.092, data: 0.032) loss: 0.000 
(epoch: 256, iters: 3360, time: 0.095, data: 0.032) loss: 0.001 
(epoch: 256, iters: 3440, time: 0.092, data: 0.011) loss: 0.095 
(epoch: 256, iters: 3520, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 256, iters: 3600, time: 0.091, data: 0.000) loss: 0.005 
(epoch: 256, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 256, iters 954368
End of epoch 256 / 2100 	 Time Taken: 365 sec
learning rate = 0.0001843
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 256, TEST ACC: [96.662 %]

saving the latest model (epoch 257, total_steps 954384)
(epoch: 257, iters: 32, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 257, iters: 112, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 257, iters: 192, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 257, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 257, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 257, iters: 432, time: 0.094, data: 0.031) loss: 0.001 
(epoch: 257, iters: 512, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 257, iters: 592, time: 0.095, data: 0.014) loss: 0.001 
(epoch: 257, iters: 672, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 257, iters: 752, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 257, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 257, iters: 912, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 257, iters: 992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 257, iters: 1072, time: 0.094, data: 0.032) loss: 0.001 
(epoch: 257, iters: 1152, time: 0.097, data: 0.042) loss: 0.002 
(epoch: 257, iters: 1232, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 257, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 257, iters: 1392, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 257, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 257, iters: 1552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 257, iters: 1632, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 257, iters: 1712, time: 0.097, data: 0.027) loss: 0.000 
(epoch: 257, iters: 1792, time: 0.096, data: 0.027) loss: 0.001 
(epoch: 257, iters: 1872, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 257, iters: 1952, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 257, iters: 2032, time: 0.095, data: 0.000) loss: 0.210 
(epoch: 257, iters: 2112, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 257, iters: 2192, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 257, iters: 2272, time: 0.096, data: 0.025) loss: 0.000 
(epoch: 257, iters: 2352, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 257, iters: 2432, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 257, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 257, iters: 2592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 257, iters: 2672, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 257, iters: 2752, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 257, iters: 2832, time: 0.097, data: 0.027) loss: 0.002 
(epoch: 257, iters: 2912, time: 0.097, data: 0.037) loss: 0.000 
(epoch: 257, iters: 2992, time: 0.096, data: 0.013) loss: 2.075 
(epoch: 257, iters: 3072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 257, iters: 3152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 257, iters: 3232, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 257, iters: 3312, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 257, iters: 3392, time: 0.096, data: 0.027) loss: 0.001 
(epoch: 257, iters: 3472, time: 0.096, data: 0.039) loss: 0.004 
(epoch: 257, iters: 3552, time: 0.093, data: 0.013) loss: 0.002 
(epoch: 257, iters: 3632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 257, iters: 3712, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 257, iters 958096
End of epoch 257 / 2100 	 Time Taken: 366 sec
learning rate = 0.0001842
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 257, TEST ACC: [96.206 %]

saving the latest model (epoch 258, total_steps 958112)
(epoch: 258, iters: 64, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 258, iters: 144, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 258, iters: 224, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 258, iters: 304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 258, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 258, iters: 464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 258, iters: 544, time: 0.096, data: 0.027) loss: 0.001 
(epoch: 258, iters: 624, time: 0.098, data: 0.027) loss: 0.404 
(epoch: 258, iters: 704, time: 0.095, data: 0.013) loss: 0.020 
(epoch: 258, iters: 784, time: 0.093, data: 0.020) loss: 0.001 
(epoch: 258, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 258, iters: 944, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 258, iters: 1024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 258, iters: 1104, time: 0.097, data: 0.000) loss: 0.015 
(epoch: 258, iters: 1184, time: 0.097, data: 0.036) loss: 0.000 
(epoch: 258, iters: 1264, time: 0.099, data: 0.031) loss: 0.001 
(epoch: 258, iters: 1344, time: 0.094, data: 0.014) loss: 0.001 
(epoch: 258, iters: 1424, time: 0.093, data: 0.000) loss: 0.035 
(epoch: 258, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 258, iters: 1584, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 258, iters: 1664, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 258, iters: 1744, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 258, iters: 1824, time: 0.098, data: 0.031) loss: 0.000 
(epoch: 258, iters: 1904, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 258, iters: 1984, time: 0.096, data: 0.012) loss: 0.030 
(epoch: 258, iters: 2064, time: 0.099, data: 0.000) loss: 0.039 
(epoch: 258, iters: 2144, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 258, iters: 2224, time: 0.093, data: 0.026) loss: 0.025 
(epoch: 258, iters: 2304, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 258, iters: 2384, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 258, iters: 2464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 258, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 258, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 258, iters: 2704, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 258, iters: 2784, time: 0.093, data: 0.024) loss: 0.001 
(epoch: 258, iters: 2864, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 258, iters: 2944, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 258, iters: 3024, time: 0.096, data: 0.000) loss: 0.448 
(epoch: 258, iters: 3104, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 258, iters: 3184, time: 0.095, data: 0.035) loss: 0.000 
(epoch: 258, iters: 3264, time: 0.094, data: 0.031) loss: 0.001 
(epoch: 258, iters: 3344, time: 0.095, data: 0.012) loss: 0.010 
(epoch: 258, iters: 3424, time: 0.097, data: 0.000) loss: 0.081 
(epoch: 258, iters: 3504, time: 0.095, data: 0.000) loss: 0.170 
(epoch: 258, iters: 3584, time: 0.096, data: 0.000) loss: 0.305 
(epoch: 258, iters: 3664, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 258, iters 961824
End of epoch 258 / 2100 	 Time Taken: 369 sec
learning rate = 0.0001841
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 258, TEST ACC: [93.475 %]

(epoch: 259, iters: 16, time: 0.133, data: 0.013) loss: 0.000 
saving the latest model (epoch 259, total_steps 961840)
(epoch: 259, iters: 96, time: 0.096, data: 0.012) loss: 0.002 
(epoch: 259, iters: 176, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 259, iters: 256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 259, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 259, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 259, iters: 496, time: 0.098, data: 0.026) loss: 0.000 
(epoch: 259, iters: 576, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 259, iters: 656, time: 0.098, data: 0.018) loss: 0.001 
(epoch: 259, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 259, iters: 816, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 259, iters: 896, time: 0.093, data: 0.032) loss: 0.000 
(epoch: 259, iters: 976, time: 0.097, data: 0.025) loss: 0.002 
(epoch: 259, iters: 1056, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 259, iters: 1136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 259, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 259, iters: 1296, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 259, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 259, iters: 1456, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 259, iters: 1536, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 259, iters: 1616, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 259, iters: 1696, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 259, iters: 1776, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 259, iters: 1856, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 259, iters: 1936, time: 0.093, data: 0.029) loss: 0.000 
(epoch: 259, iters: 2016, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 259, iters: 2096, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 259, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 259, iters: 2256, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 259, iters: 2336, time: 0.096, data: 0.000) loss: 0.248 
(epoch: 259, iters: 2416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 259, iters: 2496, time: 0.095, data: 0.027) loss: 0.059 
(epoch: 259, iters: 2576, time: 0.095, data: 0.026) loss: 0.029 
(epoch: 259, iters: 2656, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 259, iters: 2736, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 259, iters: 2816, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 259, iters: 2896, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 259, iters: 2976, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 259, iters: 3056, time: 0.094, data: 0.027) loss: 0.001 
(epoch: 259, iters: 3136, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 259, iters: 3216, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 259, iters: 3296, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 259, iters: 3376, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 259, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 259, iters: 3536, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 259, iters: 3616, time: 0.094, data: 0.060) loss: 0.000 
(epoch: 259, iters: 3696, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 259, iters 965552
End of epoch 259 / 2100 	 Time Taken: 362 sec
learning rate = 0.0001840
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 259, TEST ACC: [96.206 %]

saving the latest model (epoch 260, total_steps 965568)
(epoch: 260, iters: 48, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 260, iters: 128, time: 0.096, data: 0.026) loss: 0.001 
(epoch: 260, iters: 208, time: 0.096, data: 0.017) loss: 0.001 
(epoch: 260, iters: 288, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 260, iters: 368, time: 0.094, data: 0.000) loss: 0.187 
(epoch: 260, iters: 448, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 260, iters: 528, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 260, iters: 608, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 260, iters: 688, time: 0.093, data: 0.032) loss: 0.036 
(epoch: 260, iters: 768, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 260, iters: 848, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 260, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 260, iters: 1008, time: 0.094, data: 0.026) loss: 0.270 
(epoch: 260, iters: 1088, time: 0.096, data: 0.035) loss: 0.001 
(epoch: 260, iters: 1168, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 260, iters: 1248, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 260, iters: 1328, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 260, iters: 1408, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 260, iters: 1488, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 260, iters: 1568, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 260, iters: 1648, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 260, iters: 1728, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 260, iters: 1808, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 260, iters: 1888, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 260, iters: 1968, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 260, iters: 2048, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 260, iters: 2128, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 260, iters: 2208, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 260, iters: 2288, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 260, iters: 2368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 260, iters: 2448, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 260, iters: 2528, time: 0.095, data: 0.039) loss: 0.043 
(epoch: 260, iters: 2608, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 260, iters: 2688, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 260, iters: 2768, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 260, iters: 2848, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 260, iters: 2928, time: 0.095, data: 0.031) loss: 0.001 
(epoch: 260, iters: 3008, time: 0.094, data: 0.026) loss: 0.010 
(epoch: 260, iters: 3088, time: 0.093, data: 0.022) loss: 0.010 
(epoch: 260, iters: 3168, time: 0.094, data: 0.000) loss: 0.027 
(epoch: 260, iters: 3248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 260, iters: 3328, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 260, iters: 3408, time: 0.093, data: 0.046) loss: 0.001 
(epoch: 260, iters: 3488, time: 0.095, data: 0.035) loss: 0.000 
(epoch: 260, iters: 3568, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 260, iters: 3648, time: 0.087, data: 0.000) loss: 0.001 
(epoch: 260, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 260, iters 969280
End of epoch 260 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001839
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 260, TEST ACC: [95.599 %]

saving the latest model (epoch 261, total_steps 969296)
(epoch: 261, iters: 80, time: 0.094, data: 2.068) loss: 0.007 
(epoch: 261, iters: 160, time: 0.095, data: 0.000) loss: 0.018 
(epoch: 261, iters: 240, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 261, iters: 320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 261, iters: 400, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 261, iters: 480, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 261, iters: 560, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 261, iters: 640, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 261, iters: 720, time: 0.095, data: 0.026) loss: 0.238 
(epoch: 261, iters: 800, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 261, iters: 880, time: 0.094, data: 0.000) loss: 0.022 
(epoch: 261, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 261, iters: 1040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 261, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 261, iters: 1200, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 261, iters: 1280, time: 0.094, data: 0.029) loss: 0.002 
(epoch: 261, iters: 1360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 261, iters: 1440, time: 0.094, data: 0.011) loss: 0.006 
(epoch: 261, iters: 1520, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 261, iters: 1600, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 261, iters: 1680, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 261, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 261, iters: 1840, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 261, iters: 1920, time: 0.094, data: 0.038) loss: 0.004 
(epoch: 261, iters: 2000, time: 0.093, data: 0.018) loss: 0.000 
(epoch: 261, iters: 2080, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 261, iters: 2160, time: 0.092, data: 0.000) loss: 0.015 
(epoch: 261, iters: 2240, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 261, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 261, iters: 2400, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 261, iters: 2480, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 261, iters: 2560, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 261, iters: 2640, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 261, iters: 2720, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 261, iters: 2800, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 261, iters: 2880, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 261, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 261, iters: 3040, time: 0.095, data: 0.038) loss: 0.005 
(epoch: 261, iters: 3120, time: 0.096, data: 0.035) loss: 0.000 
(epoch: 261, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 261, iters: 3280, time: 0.091, data: 0.000) loss: 0.001 
(epoch: 261, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 261, iters: 3440, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 261, iters: 3520, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 261, iters: 3600, time: 0.096, data: 0.043) loss: 0.000 
(epoch: 261, iters: 3680, time: 0.087, data: 0.026) loss: 0.017 
saving the model at the end of epoch 261, iters 973008
End of epoch 261 / 2100 	 Time Taken: 359 sec
learning rate = 0.0001838
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 261, TEST ACC: [94.385 %]

saving the latest model (epoch 262, total_steps 973024)
(epoch: 262, iters: 32, time: 0.119, data: 0.004) loss: 0.000 
(epoch: 262, iters: 112, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 262, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 262, iters: 272, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 262, iters: 352, time: 0.093, data: 0.025) loss: 0.049 
(epoch: 262, iters: 432, time: 0.093, data: 0.035) loss: 0.000 
(epoch: 262, iters: 512, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 262, iters: 592, time: 0.091, data: 0.000) loss: 0.002 
(epoch: 262, iters: 672, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 262, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 262, iters: 832, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 262, iters: 912, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 262, iters: 992, time: 0.096, data: 0.032) loss: 0.000 
(epoch: 262, iters: 1072, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 262, iters: 1152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 262, iters: 1232, time: 0.092, data: 0.000) loss: 0.003 
(epoch: 262, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 262, iters: 1392, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 262, iters: 1472, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 262, iters: 1552, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 262, iters: 1632, time: 0.092, data: 0.011) loss: 0.013 
(epoch: 262, iters: 1712, time: 0.091, data: 0.000) loss: 0.001 
(epoch: 262, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 262, iters: 1872, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 262, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 262, iters: 2032, time: 0.095, data: 0.032) loss: 0.000 
(epoch: 262, iters: 2112, time: 0.096, data: 0.032) loss: 0.000 
(epoch: 262, iters: 2192, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 262, iters: 2272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 262, iters: 2352, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 262, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 262, iters: 2512, time: 0.096, data: 0.000) loss: 0.014 
(epoch: 262, iters: 2592, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 262, iters: 2672, time: 0.094, data: 0.029) loss: 0.000 
(epoch: 262, iters: 2752, time: 0.097, data: 0.025) loss: 0.000 
(epoch: 262, iters: 2832, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 262, iters: 2912, time: 0.091, data: 0.000) loss: 0.001 
(epoch: 262, iters: 2992, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 262, iters: 3072, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 262, iters: 3152, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 262, iters: 3232, time: 0.100, data: 0.041) loss: 0.000 
(epoch: 262, iters: 3312, time: 0.097, data: 0.031) loss: 0.004 
(epoch: 262, iters: 3392, time: 0.095, data: 0.032) loss: 0.000 
(epoch: 262, iters: 3472, time: 0.094, data: 0.012) loss: 0.008 
(epoch: 262, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 262, iters: 3632, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 262, iters: 3712, time: 0.091, data: 0.000) loss: 0.002 
saving the model at the end of epoch 262, iters 976736
End of epoch 262 / 2100 	 Time Taken: 365 sec
learning rate = 0.0001837
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 262, TEST ACC: [95.144 %]

saving the latest model (epoch 263, total_steps 976752)
(epoch: 263, iters: 64, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 263, iters: 144, time: 0.093, data: 0.016) loss: 0.000 
(epoch: 263, iters: 224, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 263, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 263, iters: 384, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 263, iters: 464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 263, iters: 544, time: 0.094, data: 0.043) loss: 0.001 
(epoch: 263, iters: 624, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 263, iters: 704, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 263, iters: 784, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 263, iters: 864, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 263, iters: 944, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 263, iters: 1024, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 263, iters: 1104, time: 0.096, data: 0.026) loss: 0.001 
(epoch: 263, iters: 1184, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 263, iters: 1264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 263, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 263, iters: 1424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 263, iters: 1504, time: 0.094, data: 0.025) loss: 0.001 
(epoch: 263, iters: 1584, time: 0.095, data: 0.033) loss: 0.062 
(epoch: 263, iters: 1664, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 263, iters: 1744, time: 0.093, data: 0.000) loss: 0.028 
(epoch: 263, iters: 1824, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 263, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 263, iters: 1984, time: 0.092, data: 0.000) loss: 0.004 
(epoch: 263, iters: 2064, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 263, iters: 2144, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 263, iters: 2224, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 263, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 263, iters: 2384, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 263, iters: 2464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 263, iters: 2544, time: 0.094, data: 0.045) loss: 0.000 
(epoch: 263, iters: 2624, time: 0.096, data: 0.063) loss: 0.015 
(epoch: 263, iters: 2704, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 263, iters: 2784, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 263, iters: 2864, time: 0.091, data: 0.000) loss: 0.013 
(epoch: 263, iters: 2944, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 263, iters: 3024, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 263, iters: 3104, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 263, iters: 3184, time: 0.094, data: 0.025) loss: 0.007 
(epoch: 263, iters: 3264, time: 0.094, data: 0.035) loss: 0.000 
(epoch: 263, iters: 3344, time: 0.096, data: 0.047) loss: 0.000 
(epoch: 263, iters: 3424, time: 0.093, data: 0.012) loss: 0.029 
(epoch: 263, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 263, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 263, iters: 3664, time: 0.089, data: 0.000) loss: 0.030 
saving the model at the end of epoch 263, iters 980464
End of epoch 263 / 2100 	 Time Taken: 365 sec
learning rate = 0.0001836
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 263, TEST ACC: [96.206 %]

(epoch: 264, iters: 16, time: 0.144, data: 0.000) loss: 0.010 
saving the latest model (epoch 264, total_steps 980480)
(epoch: 264, iters: 96, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 264, iters: 176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 264, iters: 256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 264, iters: 336, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 264, iters: 416, time: 0.096, data: 0.037) loss: 0.000 
(epoch: 264, iters: 496, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 264, iters: 576, time: 0.090, data: 0.000) loss: 0.001 
(epoch: 264, iters: 656, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 264, iters: 736, time: 0.091, data: 0.000) loss: 0.003 
(epoch: 264, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 264, iters: 896, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 264, iters: 976, time: 0.091, data: 0.018) loss: 0.000 
(epoch: 264, iters: 1056, time: 0.095, data: 0.029) loss: 0.000 
(epoch: 264, iters: 1136, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 264, iters: 1216, time: 0.097, data: 0.013) loss: 0.000 
(epoch: 264, iters: 1296, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 264, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 264, iters: 1456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 264, iters: 1536, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 264, iters: 1616, time: 0.095, data: 0.061) loss: 0.001 
(epoch: 264, iters: 1696, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 264, iters: 1776, time: 0.094, data: 0.012) loss: 0.116 
(epoch: 264, iters: 1856, time: 0.092, data: 0.000) loss: 0.040 
(epoch: 264, iters: 1936, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 264, iters: 2016, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 264, iters: 2096, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 264, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 264, iters: 2256, time: 0.094, data: 0.026) loss: 0.002 
(epoch: 264, iters: 2336, time: 0.095, data: 0.034) loss: 0.000 
(epoch: 264, iters: 2416, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 264, iters: 2496, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 264, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 264, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 264, iters: 2736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 264, iters: 2816, time: 0.093, data: 0.038) loss: 0.012 
(epoch: 264, iters: 2896, time: 0.097, data: 0.029) loss: 0.000 
(epoch: 264, iters: 2976, time: 0.095, data: 0.012) loss: 0.007 
(epoch: 264, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 264, iters: 3136, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 264, iters: 3216, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 264, iters: 3296, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 264, iters: 3376, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 264, iters: 3456, time: 0.095, data: 0.032) loss: 0.000 
(epoch: 264, iters: 3536, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 264, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 264, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 264, iters 984192
End of epoch 264 / 2100 	 Time Taken: 364 sec
learning rate = 0.0001835
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 264, TEST ACC: [95.903 %]

saving the latest model (epoch 265, total_steps 984208)
(epoch: 265, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 265, iters: 128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 265, iters: 208, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 265, iters: 288, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 265, iters: 368, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 265, iters: 448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 265, iters: 528, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 265, iters: 608, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 265, iters: 688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 265, iters: 768, time: 0.094, data: 0.029) loss: 0.001 
(epoch: 265, iters: 848, time: 0.095, data: 0.034) loss: 0.000 
(epoch: 265, iters: 928, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 265, iters: 1008, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 265, iters: 1088, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 265, iters: 1168, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 265, iters: 1248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 265, iters: 1328, time: 0.093, data: 0.037) loss: 0.000 
(epoch: 265, iters: 1408, time: 0.094, data: 0.026) loss: 0.005 
(epoch: 265, iters: 1488, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 265, iters: 1568, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 265, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 265, iters: 1728, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 265, iters: 1808, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 265, iters: 1888, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 265, iters: 1968, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 265, iters: 2048, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 265, iters: 2128, time: 0.094, data: 0.000) loss: 0.038 
(epoch: 265, iters: 2208, time: 0.094, data: 0.032) loss: 0.000 
(epoch: 265, iters: 2288, time: 0.095, data: 0.035) loss: 0.000 
(epoch: 265, iters: 2368, time: 0.093, data: 0.012) loss: 0.079 
(epoch: 265, iters: 2448, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 265, iters: 2528, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 265, iters: 2608, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 265, iters: 2688, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 265, iters: 2768, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 265, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 265, iters: 2928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 265, iters: 3008, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 265, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 265, iters: 3168, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 265, iters: 3248, time: 0.095, data: 0.025) loss: 0.001 
(epoch: 265, iters: 3328, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 265, iters: 3408, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 265, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 265, iters: 3568, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 265, iters: 3648, time: 0.087, data: 0.000) loss: 0.006 
(epoch: 265, iters: 3728, time: 0.057, data: 0.029) loss: 0.000 
saving the model at the end of epoch 265, iters 987920
End of epoch 265 / 2100 	 Time Taken: 359 sec
learning rate = 0.0001834
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 265, TEST ACC: [97.117 %]

saving the latest model (epoch 266, total_steps 987936)
(epoch: 266, iters: 80, time: 0.097, data: 3.495) loss: 0.000 
(epoch: 266, iters: 160, time: 0.095, data: 0.030) loss: 0.008 
(epoch: 266, iters: 240, time: 0.097, data: 0.038) loss: 0.000 
(epoch: 266, iters: 320, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 266, iters: 400, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 266, iters: 480, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 266, iters: 560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 266, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 266, iters: 720, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 266, iters: 800, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 266, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 266, iters: 960, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 266, iters: 1040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 266, iters: 1120, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 266, iters: 1200, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 266, iters: 1280, time: 0.096, data: 0.032) loss: 0.000 
(epoch: 266, iters: 1360, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 266, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 266, iters: 1520, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 266, iters: 1600, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 266, iters: 1680, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 266, iters: 1760, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 266, iters: 1840, time: 0.096, data: 0.026) loss: 0.001 
(epoch: 266, iters: 1920, time: 0.097, data: 0.012) loss: 0.001 
(epoch: 266, iters: 2000, time: 0.094, data: 0.000) loss: 0.285 
(epoch: 266, iters: 2080, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 266, iters: 2160, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 266, iters: 2240, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 266, iters: 2320, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 266, iters: 2400, time: 0.093, data: 0.000) loss: 0.010 
(epoch: 266, iters: 2480, time: 0.097, data: 0.000) loss: 0.047 
(epoch: 266, iters: 2560, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 266, iters: 2640, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 266, iters: 2720, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 266, iters: 2800, time: 0.093, data: 0.000) loss: 0.010 
(epoch: 266, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 266, iters: 2960, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 266, iters: 3040, time: 0.094, data: 0.000) loss: 0.220 
(epoch: 266, iters: 3120, time: 0.093, data: 0.031) loss: 0.000 
(epoch: 266, iters: 3200, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 266, iters: 3280, time: 0.093, data: 0.012) loss: 0.028 
(epoch: 266, iters: 3360, time: 0.093, data: 0.015) loss: 0.008 
(epoch: 266, iters: 3440, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 266, iters: 3520, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 266, iters: 3600, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 266, iters: 3680, time: 0.086, data: 0.000) loss: 0.010 
saving the model at the end of epoch 266, iters 991648
End of epoch 266 / 2100 	 Time Taken: 368 sec
learning rate = 0.0001833
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 266, TEST ACC: [93.171 %]

saving the latest model (epoch 267, total_steps 991664)
(epoch: 267, iters: 32, time: 0.098, data: 0.008) loss: 0.001 
(epoch: 267, iters: 112, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 267, iters: 192, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 267, iters: 272, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 267, iters: 352, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 267, iters: 432, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 267, iters: 512, time: 0.096, data: 0.047) loss: 0.000 
(epoch: 267, iters: 592, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 267, iters: 672, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 267, iters: 752, time: 0.092, data: 0.000) loss: 0.018 
(epoch: 267, iters: 832, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 267, iters: 912, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 267, iters: 992, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 267, iters: 1072, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 267, iters: 1152, time: 0.098, data: 0.026) loss: 0.000 
(epoch: 267, iters: 1232, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 267, iters: 1312, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 267, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 267, iters: 1472, time: 0.094, data: 0.000) loss: 0.031 
(epoch: 267, iters: 1552, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 267, iters: 1632, time: 0.093, data: 0.032) loss: 0.000 
(epoch: 267, iters: 1712, time: 0.094, data: 0.037) loss: 0.001 
(epoch: 267, iters: 1792, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 267, iters: 1872, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 267, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 267, iters: 2032, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 267, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 267, iters: 2192, time: 0.096, data: 0.033) loss: 0.000 
(epoch: 267, iters: 2272, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 267, iters: 2352, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 267, iters: 2432, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 267, iters: 2512, time: 0.093, data: 0.000) loss: 0.025 
(epoch: 267, iters: 2592, time: 0.097, data: 0.000) loss: 0.027 
(epoch: 267, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 267, iters: 2752, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 267, iters: 2832, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 267, iters: 2912, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 267, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 267, iters: 3072, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 267, iters: 3152, time: 0.093, data: 0.030) loss: 0.007 
(epoch: 267, iters: 3232, time: 0.098, data: 0.025) loss: 0.001 
(epoch: 267, iters: 3312, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 267, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 267, iters: 3472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 267, iters: 3552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 267, iters: 3632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 267, iters: 3712, time: 0.088, data: 0.028) loss: 0.000 
saving the model at the end of epoch 267, iters 995376
End of epoch 267 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001832
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 267, TEST ACC: [96.662 %]

saving the latest model (epoch 268, total_steps 995392)
(epoch: 268, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 268, iters: 144, time: 0.092, data: 0.016) loss: 0.000 
(epoch: 268, iters: 224, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 268, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 268, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 268, iters: 464, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 268, iters: 544, time: 0.094, data: 0.031) loss: 0.047 
(epoch: 268, iters: 624, time: 0.093, data: 0.031) loss: 0.003 
(epoch: 268, iters: 704, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 268, iters: 784, time: 0.093, data: 0.017) loss: 0.002 
(epoch: 268, iters: 864, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 268, iters: 944, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 268, iters: 1024, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 268, iters: 1104, time: 0.096, data: 0.026) loss: 0.008 
(epoch: 268, iters: 1184, time: 0.097, data: 0.011) loss: 0.001 
(epoch: 268, iters: 1264, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 268, iters: 1344, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 268, iters: 1424, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 268, iters: 1504, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 268, iters: 1584, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 268, iters: 1664, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 268, iters: 1744, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 268, iters: 1824, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 268, iters: 1904, time: 0.094, data: 0.032) loss: 0.003 
(epoch: 268, iters: 1984, time: 0.095, data: 0.027) loss: 0.001 
(epoch: 268, iters: 2064, time: 0.091, data: 0.021) loss: 0.003 
(epoch: 268, iters: 2144, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 268, iters: 2224, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 268, iters: 2304, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 268, iters: 2384, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 268, iters: 2464, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 268, iters: 2544, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 268, iters: 2624, time: 0.094, data: 0.013) loss: 0.016 
(epoch: 268, iters: 2704, time: 0.099, data: 0.000) loss: 0.001 
(epoch: 268, iters: 2784, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 268, iters: 2864, time: 0.096, data: 0.027) loss: 0.001 
(epoch: 268, iters: 2944, time: 0.099, data: 0.026) loss: 0.000 
(epoch: 268, iters: 3024, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 268, iters: 3104, time: 0.093, data: 0.000) loss: 0.023 
(epoch: 268, iters: 3184, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 268, iters: 3264, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 268, iters: 3344, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 268, iters: 3424, time: 0.095, data: 0.026) loss: 0.002 
(epoch: 268, iters: 3504, time: 0.098, data: 0.030) loss: 0.000 
(epoch: 268, iters: 3584, time: 0.098, data: 0.011) loss: 0.000 
(epoch: 268, iters: 3664, time: 0.090, data: 0.000) loss: 0.002 
saving the model at the end of epoch 268, iters 999104
End of epoch 268 / 2100 	 Time Taken: 365 sec
learning rate = 0.0001831
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 268, TEST ACC: [91.958 %]

(epoch: 269, iters: 16, time: 0.143, data: 0.000) loss: 0.002 
saving the latest model (epoch 269, total_steps 999120)
(epoch: 269, iters: 96, time: 0.094, data: 0.013) loss: 0.001 
(epoch: 269, iters: 176, time: 0.095, data: 0.000) loss: 0.048 
(epoch: 269, iters: 256, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 269, iters: 336, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 269, iters: 416, time: 0.098, data: 0.026) loss: 0.000 
(epoch: 269, iters: 496, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 269, iters: 576, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 269, iters: 656, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 269, iters: 736, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 269, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 269, iters: 896, time: 0.096, data: 0.027) loss: 0.162 
(epoch: 269, iters: 976, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 269, iters: 1056, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 269, iters: 1136, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 269, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 269, iters: 1296, time: 0.099, data: 0.000) loss: 0.001 
(epoch: 269, iters: 1376, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 269, iters: 1456, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 269, iters: 1536, time: 0.092, data: 0.000) loss: 0.044 
(epoch: 269, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 269, iters: 1696, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 269, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 269, iters: 1856, time: 0.095, data: 0.027) loss: 0.001 
(epoch: 269, iters: 1936, time: 0.093, data: 0.026) loss: 0.002 
(epoch: 269, iters: 2016, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 269, iters: 2096, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 269, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 269, iters: 2256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 269, iters: 2336, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 269, iters: 2416, time: 0.098, data: 0.026) loss: 0.000 
(epoch: 269, iters: 2496, time: 0.095, data: 0.033) loss: 0.000 
(epoch: 269, iters: 2576, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 269, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 269, iters: 2736, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 269, iters: 2816, time: 0.094, data: 0.034) loss: 0.000 
(epoch: 269, iters: 2896, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 269, iters: 2976, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 269, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 269, iters: 3136, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 269, iters: 3216, time: 0.096, data: 0.000) loss: 0.019 
(epoch: 269, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 269, iters: 3376, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 269, iters: 3456, time: 0.095, data: 0.037) loss: 0.000 
(epoch: 269, iters: 3536, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 269, iters: 3616, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 269, iters: 3696, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 269, iters 1002832
End of epoch 269 / 2100 	 Time Taken: 364 sec
learning rate = 0.0001830
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 269, TEST ACC: [98.483 %]

saving the latest model (epoch 270, total_steps 1002848)
(epoch: 270, iters: 48, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 270, iters: 128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 270, iters: 208, time: 0.092, data: 0.031) loss: 0.000 
(epoch: 270, iters: 288, time: 0.094, data: 0.030) loss: 0.014 
(epoch: 270, iters: 368, time: 0.093, data: 0.011) loss: 0.013 
(epoch: 270, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 270, iters: 528, time: 0.094, data: 0.013) loss: 0.001 
(epoch: 270, iters: 608, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 270, iters: 688, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 270, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 270, iters: 848, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 270, iters: 928, time: 0.096, data: 0.027) loss: 0.001 
(epoch: 270, iters: 1008, time: 0.093, data: 0.011) loss: 0.005 
(epoch: 270, iters: 1088, time: 0.092, data: 0.000) loss: 0.004 
(epoch: 270, iters: 1168, time: 0.092, data: 0.000) loss: 0.048 
(epoch: 270, iters: 1248, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 270, iters: 1328, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 270, iters: 1408, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 270, iters: 1488, time: 0.095, data: 0.027) loss: 0.024 
(epoch: 270, iters: 1568, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 270, iters: 1648, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 270, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 270, iters: 1808, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 270, iters: 1888, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 270, iters: 1968, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 270, iters: 2048, time: 0.096, data: 0.035) loss: 0.000 
(epoch: 270, iters: 2128, time: 0.093, data: 0.012) loss: 0.021 
(epoch: 270, iters: 2208, time: 0.093, data: 0.000) loss: 0.014 
(epoch: 270, iters: 2288, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 270, iters: 2368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 270, iters: 2448, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 270, iters: 2528, time: 0.094, data: 0.026) loss: 0.004 
(epoch: 270, iters: 2608, time: 0.093, data: 0.026) loss: 0.131 
(epoch: 270, iters: 2688, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 270, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 270, iters: 2848, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 270, iters: 2928, time: 0.095, data: 0.025) loss: 0.037 
(epoch: 270, iters: 3008, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 270, iters: 3088, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 270, iters: 3168, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 270, iters: 3248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 270, iters: 3328, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 270, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 270, iters: 3488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 270, iters: 3568, time: 0.097, data: 0.044) loss: 0.020 
(epoch: 270, iters: 3648, time: 0.089, data: 0.039) loss: 0.000 
(epoch: 270, iters: 3728, time: 0.056, data: 0.011) loss: 0.000 
saving the model at the end of epoch 270, iters 1006560
End of epoch 270 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001829
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 270, TEST ACC: [96.206 %]

saving the latest model (epoch 271, total_steps 1006576)
(epoch: 271, iters: 80, time: 0.094, data: 2.264) loss: 0.001 
(epoch: 271, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 271, iters: 240, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 271, iters: 320, time: 0.094, data: 0.028) loss: 0.002 
(epoch: 271, iters: 400, time: 0.094, data: 0.045) loss: 0.000 
(epoch: 271, iters: 480, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 271, iters: 560, time: 0.090, data: 0.000) loss: 0.006 
(epoch: 271, iters: 640, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 271, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 271, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 271, iters: 880, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 271, iters: 960, time: 0.094, data: 0.031) loss: 0.000 
(epoch: 271, iters: 1040, time: 0.095, data: 0.037) loss: 0.000 
(epoch: 271, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 271, iters: 1200, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 271, iters: 1280, time: 0.097, data: 0.000) loss: 0.008 
(epoch: 271, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 271, iters: 1440, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 271, iters: 1520, time: 0.092, data: 0.037) loss: 0.001 
(epoch: 271, iters: 1600, time: 0.095, data: 0.030) loss: 0.000 
(epoch: 271, iters: 1680, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 271, iters: 1760, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 271, iters: 1840, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 271, iters: 1920, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 271, iters: 2000, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 271, iters: 2080, time: 0.094, data: 0.036) loss: 0.098 
(epoch: 271, iters: 2160, time: 0.094, data: 0.030) loss: 0.011 
(epoch: 271, iters: 2240, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 271, iters: 2320, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 271, iters: 2400, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 271, iters: 2480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 271, iters: 2560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 271, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 271, iters: 2720, time: 0.095, data: 0.011) loss: 0.027 
(epoch: 271, iters: 2800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 271, iters: 2880, time: 0.098, data: 0.000) loss: 0.003 
(epoch: 271, iters: 2960, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 271, iters: 3040, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 271, iters: 3120, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 271, iters: 3200, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 271, iters: 3280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 271, iters: 3360, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 271, iters: 3440, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 271, iters: 3520, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 271, iters: 3600, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 271, iters: 3680, time: 0.087, data: 0.012) loss: 0.003 
saving the model at the end of epoch 271, iters 1010288
End of epoch 271 / 2100 	 Time Taken: 362 sec
learning rate = 0.0001828
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 271, TEST ACC: [95.751 %]

saving the latest model (epoch 272, total_steps 1010304)
(epoch: 272, iters: 32, time: 0.126, data: 0.000) loss: 0.000 
(epoch: 272, iters: 112, time: 0.095, data: 0.014) loss: 0.000 
(epoch: 272, iters: 192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 272, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 272, iters: 352, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 272, iters: 432, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 272, iters: 512, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 272, iters: 592, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 272, iters: 672, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 272, iters: 752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 272, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 272, iters: 912, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 272, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 272, iters: 1072, time: 0.093, data: 0.025) loss: 0.001 
(epoch: 272, iters: 1152, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 272, iters: 1232, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 272, iters: 1312, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 272, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 272, iters: 1472, time: 0.096, data: 0.000) loss: 0.103 
(epoch: 272, iters: 1552, time: 0.094, data: 0.033) loss: 0.003 
(epoch: 272, iters: 1632, time: 0.095, data: 0.037) loss: 0.009 
(epoch: 272, iters: 1712, time: 0.094, data: 0.011) loss: 0.065 
(epoch: 272, iters: 1792, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 272, iters: 1872, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 272, iters: 1952, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 272, iters: 2032, time: 0.095, data: 0.000) loss: 0.035 
(epoch: 272, iters: 2112, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 272, iters: 2192, time: 0.096, data: 0.026) loss: 0.096 
(epoch: 272, iters: 2272, time: 0.094, data: 0.013) loss: 0.002 
(epoch: 272, iters: 2352, time: 0.092, data: 0.000) loss: 0.007 
(epoch: 272, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 272, iters: 2512, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 272, iters: 2592, time: 0.097, data: 0.000) loss: 0.011 
(epoch: 272, iters: 2672, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 272, iters: 2752, time: 0.096, data: 0.037) loss: 0.037 
(epoch: 272, iters: 2832, time: 0.096, data: 0.012) loss: 0.005 
(epoch: 272, iters: 2912, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 272, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 272, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 272, iters: 3152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 272, iters: 3232, time: 0.095, data: 0.026) loss: 0.022 
(epoch: 272, iters: 3312, time: 0.095, data: 0.026) loss: 0.010 
(epoch: 272, iters: 3392, time: 0.092, data: 0.014) loss: 0.000 
(epoch: 272, iters: 3472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 272, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 272, iters: 3632, time: 0.095, data: 0.000) loss: 0.025 
(epoch: 272, iters: 3712, time: 0.089, data: 0.000) loss: 0.001 
saving the model at the end of epoch 272, iters 1014016
End of epoch 272 / 2100 	 Time Taken: 364 sec
learning rate = 0.0001827
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 272, TEST ACC: [98.179 %]

saving the latest model (epoch 273, total_steps 1014032)
(epoch: 273, iters: 64, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 273, iters: 144, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 273, iters: 224, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 273, iters: 304, time: 0.094, data: 0.000) loss: 0.042 
(epoch: 273, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 273, iters: 464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 273, iters: 544, time: 0.093, data: 0.030) loss: 0.000 
(epoch: 273, iters: 624, time: 0.093, data: 0.025) loss: 0.003 
(epoch: 273, iters: 704, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 273, iters: 784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 273, iters: 864, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 273, iters: 944, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 273, iters: 1024, time: 0.093, data: 0.000) loss: 0.017 
(epoch: 273, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 273, iters: 1184, time: 0.095, data: 0.034) loss: 0.000 
(epoch: 273, iters: 1264, time: 0.094, data: 0.027) loss: 0.001 
(epoch: 273, iters: 1344, time: 0.094, data: 0.018) loss: 0.001 
(epoch: 273, iters: 1424, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 273, iters: 1504, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 273, iters: 1584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 273, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 273, iters: 1744, time: 0.093, data: 0.032) loss: 0.001 
(epoch: 273, iters: 1824, time: 0.097, data: 0.038) loss: 0.001 
(epoch: 273, iters: 1904, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 273, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 273, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 273, iters: 2144, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 273, iters: 2224, time: 0.097, data: 0.034) loss: 0.001 
(epoch: 273, iters: 2304, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 273, iters: 2384, time: 0.094, data: 0.000) loss: 0.017 
(epoch: 273, iters: 2464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 273, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 273, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 273, iters: 2704, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 273, iters: 2784, time: 0.095, data: 0.026) loss: 0.002 
(epoch: 273, iters: 2864, time: 0.094, data: 0.011) loss: 0.017 
(epoch: 273, iters: 2944, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 273, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 273, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 273, iters: 3184, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 273, iters: 3264, time: 0.095, data: 0.035) loss: 0.000 
(epoch: 273, iters: 3344, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 273, iters: 3424, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 273, iters: 3504, time: 0.093, data: 0.011) loss: 0.022 
(epoch: 273, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 273, iters: 3664, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 273, iters 1017744
End of epoch 273 / 2100 	 Time Taken: 364 sec
learning rate = 0.0001826
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 273, TEST ACC: [97.572 %]

(epoch: 274, iters: 16, time: 0.137, data: 0.012) loss: 0.000 
saving the latest model (epoch 274, total_steps 1017760)
(epoch: 274, iters: 96, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 274, iters: 176, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 274, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 274, iters: 336, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 274, iters: 416, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 274, iters: 496, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 274, iters: 576, time: 0.094, data: 0.031) loss: 0.001 
(epoch: 274, iters: 656, time: 0.097, data: 0.032) loss: 0.000 
(epoch: 274, iters: 736, time: 0.096, data: 0.012) loss: 0.006 
(epoch: 274, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 274, iters: 896, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 274, iters: 976, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 274, iters: 1056, time: 0.098, data: 0.026) loss: 0.003 
(epoch: 274, iters: 1136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 274, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 274, iters: 1296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 274, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 274, iters: 1456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 274, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 274, iters: 1616, time: 0.096, data: 0.026) loss: 0.002 
(epoch: 274, iters: 1696, time: 0.098, data: 0.026) loss: 0.002 
(epoch: 274, iters: 1776, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 274, iters: 1856, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 274, iters: 1936, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 274, iters: 2016, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 274, iters: 2096, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 274, iters: 2176, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 274, iters: 2256, time: 0.096, data: 0.026) loss: 0.006 
(epoch: 274, iters: 2336, time: 0.094, data: 0.012) loss: 0.040 
(epoch: 274, iters: 2416, time: 0.093, data: 0.000) loss: 0.011 
(epoch: 274, iters: 2496, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 274, iters: 2576, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 274, iters: 2656, time: 0.094, data: 0.042) loss: 0.002 
(epoch: 274, iters: 2736, time: 0.093, data: 0.026) loss: 0.067 
(epoch: 274, iters: 2816, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 274, iters: 2896, time: 0.091, data: 0.000) loss: 0.006 
(epoch: 274, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 274, iters: 3056, time: 0.098, data: 0.000) loss: 0.011 
(epoch: 274, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 274, iters: 3216, time: 0.097, data: 0.027) loss: 0.043 
(epoch: 274, iters: 3296, time: 0.097, data: 0.026) loss: 0.003 
(epoch: 274, iters: 3376, time: 0.092, data: 0.011) loss: 0.004 
(epoch: 274, iters: 3456, time: 0.092, data: 0.000) loss: 0.006 
(epoch: 274, iters: 3536, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 274, iters: 3616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 274, iters: 3696, time: 0.090, data: 0.000) loss: 0.002 
saving the model at the end of epoch 274, iters 1021472
End of epoch 274 / 2100 	 Time Taken: 365 sec
learning rate = 0.0001825
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 274, TEST ACC: [97.876 %]

saving the latest model (epoch 275, total_steps 1021488)
(epoch: 275, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 275, iters: 128, time: 0.096, data: 0.030) loss: 0.000 
(epoch: 275, iters: 208, time: 0.096, data: 0.026) loss: 0.001 
(epoch: 275, iters: 288, time: 0.093, data: 0.017) loss: 0.001 
(epoch: 275, iters: 368, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 275, iters: 448, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 275, iters: 528, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 275, iters: 608, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 275, iters: 688, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 275, iters: 768, time: 0.093, data: 0.047) loss: 0.000 
(epoch: 275, iters: 848, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 275, iters: 928, time: 0.091, data: 0.000) loss: 0.006 
(epoch: 275, iters: 1008, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 275, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 275, iters: 1168, time: 0.093, data: 0.000) loss: 0.024 
(epoch: 275, iters: 1248, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 275, iters: 1328, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 275, iters: 1408, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 275, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 275, iters: 1568, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 275, iters: 1648, time: 0.093, data: 0.037) loss: 0.000 
(epoch: 275, iters: 1728, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 275, iters: 1808, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 275, iters: 1888, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 275, iters: 1968, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 275, iters: 2048, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 275, iters: 2128, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 275, iters: 2208, time: 0.095, data: 0.030) loss: 0.001 
(epoch: 275, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 275, iters: 2368, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 275, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 275, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 275, iters: 2608, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 275, iters: 2688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 275, iters: 2768, time: 0.092, data: 0.011) loss: 0.011 
(epoch: 275, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 275, iters: 2928, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 275, iters: 3008, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 275, iters: 3088, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 275, iters: 3168, time: 0.092, data: 0.026) loss: 0.003 
(epoch: 275, iters: 3248, time: 0.096, data: 0.026) loss: 0.016 
(epoch: 275, iters: 3328, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 275, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 275, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 275, iters: 3568, time: 0.095, data: 0.031) loss: 0.000 
(epoch: 275, iters: 3648, time: 0.089, data: 0.048) loss: 0.000 
(epoch: 275, iters: 3728, time: 0.056, data: 0.012) loss: 0.000 
saving the model at the end of epoch 275, iters 1025200
End of epoch 275 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001824
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 275, TEST ACC: [95.903 %]

saving the latest model (epoch 276, total_steps 1025216)
(epoch: 276, iters: 80, time: 0.094, data: 1.523) loss: 0.000 
(epoch: 276, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 276, iters: 240, time: 0.094, data: 0.054) loss: 0.002 
(epoch: 276, iters: 320, time: 0.096, data: 0.026) loss: 0.004 
(epoch: 276, iters: 400, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 276, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 276, iters: 560, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 276, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 276, iters: 720, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 276, iters: 800, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 276, iters: 880, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 276, iters: 960, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 276, iters: 1040, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 276, iters: 1120, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 276, iters: 1200, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 276, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 276, iters: 1360, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 276, iters: 1440, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 276, iters: 1520, time: 0.092, data: 0.000) loss: 0.005 
(epoch: 276, iters: 1600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 276, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 276, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 276, iters: 1840, time: 0.094, data: 0.043) loss: 0.000 
(epoch: 276, iters: 1920, time: 0.094, data: 0.043) loss: 0.000 
(epoch: 276, iters: 2000, time: 0.094, data: 0.014) loss: 0.000 
(epoch: 276, iters: 2080, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 276, iters: 2160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 276, iters: 2240, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 276, iters: 2320, time: 0.093, data: 0.032) loss: 0.000 
(epoch: 276, iters: 2400, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 276, iters: 2480, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 276, iters: 2560, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 276, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 276, iters: 2720, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 276, iters: 2800, time: 0.094, data: 0.035) loss: 0.000 
(epoch: 276, iters: 2880, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 276, iters: 2960, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 276, iters: 3040, time: 0.095, data: 0.000) loss: 0.057 
(epoch: 276, iters: 3120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 276, iters: 3200, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 276, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 276, iters: 3360, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 276, iters: 3440, time: 0.095, data: 0.026) loss: 0.097 
(epoch: 276, iters: 3520, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 276, iters: 3600, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 276, iters: 3680, time: 0.087, data: 0.000) loss: 0.056 
saving the model at the end of epoch 276, iters 1028928
End of epoch 276 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001823
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 276, TEST ACC: [96.813 %]

saving the latest model (epoch 277, total_steps 1028944)
(epoch: 277, iters: 32, time: 0.104, data: 0.000) loss: 0.000 
(epoch: 277, iters: 112, time: 0.093, data: 0.041) loss: 0.001 
(epoch: 277, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 277, iters: 272, time: 0.092, data: 0.000) loss: 0.029 
(epoch: 277, iters: 352, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 277, iters: 432, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 277, iters: 512, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 277, iters: 592, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 277, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 277, iters: 752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 277, iters: 832, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 277, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 277, iters: 992, time: 0.094, data: 0.027) loss: 0.001 
(epoch: 277, iters: 1072, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 277, iters: 1152, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 277, iters: 1232, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 277, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 277, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 277, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 277, iters: 1552, time: 0.092, data: 0.000) loss: 0.023 
(epoch: 277, iters: 1632, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 277, iters: 1712, time: 0.095, data: 0.037) loss: 0.019 
(epoch: 277, iters: 1792, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 277, iters: 1872, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 277, iters: 1952, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 277, iters: 2032, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 277, iters: 2112, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 277, iters: 2192, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 277, iters: 2272, time: 0.097, data: 0.037) loss: 0.003 
(epoch: 277, iters: 2352, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 277, iters: 2432, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 277, iters: 2512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 277, iters: 2592, time: 0.097, data: 0.044) loss: 0.000 
(epoch: 277, iters: 2672, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 277, iters: 2752, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 277, iters: 2832, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 277, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 277, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 277, iters: 3072, time: 0.097, data: 0.000) loss: 0.396 
(epoch: 277, iters: 3152, time: 0.095, data: 0.026) loss: 0.003 
(epoch: 277, iters: 3232, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 277, iters: 3312, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 277, iters: 3392, time: 0.094, data: 0.012) loss: 0.015 
(epoch: 277, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 277, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 277, iters: 3632, time: 0.095, data: 0.030) loss: 0.001 
(epoch: 277, iters: 3712, time: 0.088, data: 0.026) loss: 0.000 
saving the model at the end of epoch 277, iters 1032656
End of epoch 277 / 2100 	 Time Taken: 359 sec
learning rate = 0.0001822
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 277, TEST ACC: [94.689 %]

saving the latest model (epoch 278, total_steps 1032672)
(epoch: 278, iters: 64, time: 0.093, data: 0.004) loss: 0.000 
(epoch: 278, iters: 144, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 278, iters: 224, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 278, iters: 304, time: 0.093, data: 0.000) loss: 0.017 
(epoch: 278, iters: 384, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 278, iters: 464, time: 0.093, data: 0.030) loss: 0.076 
(epoch: 278, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 278, iters: 624, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 278, iters: 704, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 278, iters: 784, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 278, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 278, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 278, iters: 1024, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 278, iters: 1104, time: 0.096, data: 0.025) loss: 0.364 
(epoch: 278, iters: 1184, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 278, iters: 1264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 278, iters: 1344, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 278, iters: 1424, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 278, iters: 1504, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 278, iters: 1584, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 278, iters: 1664, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 278, iters: 1744, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 278, iters: 1824, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 278, iters: 1904, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 278, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 278, iters: 2064, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 278, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 278, iters: 2224, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 278, iters: 2304, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 278, iters: 2384, time: 0.095, data: 0.011) loss: 0.007 
(epoch: 278, iters: 2464, time: 0.093, data: 0.000) loss: 0.018 
(epoch: 278, iters: 2544, time: 0.091, data: 0.000) loss: 0.002 
(epoch: 278, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 278, iters: 2704, time: 0.092, data: 0.000) loss: 0.349 
(epoch: 278, iters: 2784, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 278, iters: 2864, time: 0.094, data: 0.035) loss: 0.000 
(epoch: 278, iters: 2944, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 278, iters: 3024, time: 0.095, data: 0.000) loss: 0.163 
(epoch: 278, iters: 3104, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 278, iters: 3184, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 278, iters: 3264, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 278, iters: 3344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 278, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 278, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 278, iters: 3584, time: 0.094, data: 0.034) loss: 0.001 
(epoch: 278, iters: 3664, time: 0.088, data: 0.038) loss: 0.000 
saving the model at the end of epoch 278, iters 1036384
End of epoch 278 / 2100 	 Time Taken: 362 sec
learning rate = 0.0001821
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 278, TEST ACC: [95.448 %]

(epoch: 279, iters: 16, time: 0.145, data: 0.009) loss: 0.001 
saving the latest model (epoch 279, total_steps 1036400)
(epoch: 279, iters: 96, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 279, iters: 176, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 279, iters: 256, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 279, iters: 336, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 279, iters: 416, time: 0.094, data: 0.038) loss: 0.246 
(epoch: 279, iters: 496, time: 0.092, data: 0.011) loss: 0.003 
(epoch: 279, iters: 576, time: 0.091, data: 0.000) loss: 0.001 
(epoch: 279, iters: 656, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 279, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 279, iters: 816, time: 0.094, data: 0.000) loss: 0.106 
(epoch: 279, iters: 896, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 279, iters: 976, time: 0.095, data: 0.026) loss: 0.002 
(epoch: 279, iters: 1056, time: 0.096, data: 0.025) loss: 0.000 
(epoch: 279, iters: 1136, time: 0.090, data: 0.012) loss: 0.000 
(epoch: 279, iters: 1216, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 279, iters: 1296, time: 0.095, data: 0.012) loss: 0.007 
(epoch: 279, iters: 1376, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 279, iters: 1456, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 279, iters: 1536, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 279, iters: 1616, time: 0.093, data: 0.043) loss: 0.000 
(epoch: 279, iters: 1696, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 279, iters: 1776, time: 0.092, data: 0.012) loss: 0.011 
(epoch: 279, iters: 1856, time: 0.093, data: 0.000) loss: 0.020 
(epoch: 279, iters: 1936, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 279, iters: 2016, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 279, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 279, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 279, iters: 2256, time: 0.092, data: 0.039) loss: 0.000 
(epoch: 279, iters: 2336, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 279, iters: 2416, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 279, iters: 2496, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 279, iters: 2576, time: 0.091, data: 0.000) loss: 0.002 
(epoch: 279, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 279, iters: 2736, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 279, iters: 2816, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 279, iters: 2896, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 279, iters: 2976, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 279, iters: 3056, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 279, iters: 3136, time: 0.095, data: 0.000) loss: 0.020 
(epoch: 279, iters: 3216, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 279, iters: 3296, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 279, iters: 3376, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 279, iters: 3456, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 279, iters: 3536, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 279, iters: 3616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 279, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 279, iters 1040112
End of epoch 279 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001820
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 279, TEST ACC: [92.868 %]

saving the latest model (epoch 280, total_steps 1040128)
(epoch: 280, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 280, iters: 128, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 280, iters: 208, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 280, iters: 288, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 280, iters: 368, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 280, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 280, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 280, iters: 608, time: 0.096, data: 0.025) loss: 0.000 
(epoch: 280, iters: 688, time: 0.095, data: 0.026) loss: 0.011 
(epoch: 280, iters: 768, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 280, iters: 848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 280, iters: 928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 280, iters: 1008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 280, iters: 1088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 280, iters: 1168, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 280, iters: 1248, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 280, iters: 1328, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 280, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 280, iters: 1488, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 280, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 280, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 280, iters: 1728, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 280, iters: 1808, time: 0.093, data: 0.033) loss: 0.002 
(epoch: 280, iters: 1888, time: 0.091, data: 0.014) loss: 0.000 
(epoch: 280, iters: 1968, time: 0.091, data: 0.000) loss: 0.003 
(epoch: 280, iters: 2048, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 280, iters: 2128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 280, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 280, iters: 2288, time: 0.095, data: 0.045) loss: 0.000 
(epoch: 280, iters: 2368, time: 0.094, data: 0.025) loss: 0.001 
(epoch: 280, iters: 2448, time: 0.091, data: 0.013) loss: 0.077 
(epoch: 280, iters: 2528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 280, iters: 2608, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 280, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 280, iters: 2768, time: 0.090, data: 0.012) loss: 0.002 
(epoch: 280, iters: 2848, time: 0.091, data: 0.000) loss: 0.002 
(epoch: 280, iters: 2928, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 280, iters: 3008, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 280, iters: 3088, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 280, iters: 3168, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 280, iters: 3248, time: 0.091, data: 0.011) loss: 0.001 
(epoch: 280, iters: 3328, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 280, iters: 3408, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 280, iters: 3488, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 280, iters: 3568, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 280, iters: 3648, time: 0.088, data: 0.012) loss: 0.001 
(epoch: 280, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 280, iters 1043840
End of epoch 280 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001819
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 280, TEST ACC: [94.385 %]

saving the latest model (epoch 281, total_steps 1043856)
(epoch: 281, iters: 80, time: 0.094, data: 2.484) loss: 0.002 
(epoch: 281, iters: 160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 281, iters: 240, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 281, iters: 320, time: 0.094, data: 0.032) loss: 0.001 
(epoch: 281, iters: 400, time: 0.093, data: 0.043) loss: 0.000 
(epoch: 281, iters: 480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 281, iters: 560, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 281, iters: 640, time: 0.098, data: 0.000) loss: 0.020 
(epoch: 281, iters: 720, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 281, iters: 800, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 281, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 281, iters: 960, time: 0.097, data: 0.026) loss: 0.058 
(epoch: 281, iters: 1040, time: 0.096, data: 0.026) loss: 0.020 
(epoch: 281, iters: 1120, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 281, iters: 1200, time: 0.093, data: 0.000) loss: 0.010 
(epoch: 281, iters: 1280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 281, iters: 1360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 281, iters: 1440, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 281, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 281, iters: 1600, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 281, iters: 1680, time: 0.097, data: 0.032) loss: 0.002 
(epoch: 281, iters: 1760, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 281, iters: 1840, time: 0.092, data: 0.000) loss: 0.004 
(epoch: 281, iters: 1920, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 281, iters: 2000, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 281, iters: 2080, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 281, iters: 2160, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 281, iters: 2240, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 281, iters: 2320, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 281, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 281, iters: 2480, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 281, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 281, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 281, iters: 2720, time: 0.094, data: 0.025) loss: 0.020 
(epoch: 281, iters: 2800, time: 0.096, data: 0.035) loss: 0.002 
(epoch: 281, iters: 2880, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 281, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 281, iters: 3040, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 281, iters: 3120, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 281, iters: 3200, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 281, iters: 3280, time: 0.098, data: 0.026) loss: 0.051 
(epoch: 281, iters: 3360, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 281, iters: 3440, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 281, iters: 3520, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 281, iters: 3600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 281, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 281, iters 1047568
End of epoch 281 / 2100 	 Time Taken: 367 sec
learning rate = 0.0001818
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 281, TEST ACC: [95.903 %]

saving the latest model (epoch 282, total_steps 1047584)
(epoch: 282, iters: 32, time: 0.102, data: 0.000) loss: 0.001 
(epoch: 282, iters: 112, time: 0.094, data: 0.011) loss: 0.019 
(epoch: 282, iters: 192, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 282, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 282, iters: 352, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 282, iters: 432, time: 0.093, data: 0.025) loss: 0.004 
(epoch: 282, iters: 512, time: 0.095, data: 0.034) loss: 0.000 
(epoch: 282, iters: 592, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 282, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 282, iters: 752, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 282, iters: 832, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 282, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 282, iters: 992, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 282, iters: 1072, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 282, iters: 1152, time: 0.095, data: 0.037) loss: 0.242 
(epoch: 282, iters: 1232, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 282, iters: 1312, time: 0.096, data: 0.012) loss: 0.004 
(epoch: 282, iters: 1392, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 282, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 282, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 282, iters: 1632, time: 0.094, data: 0.037) loss: 0.006 
(epoch: 282, iters: 1712, time: 0.094, data: 0.031) loss: 0.000 
(epoch: 282, iters: 1792, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 282, iters: 1872, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 282, iters: 1952, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 282, iters: 2032, time: 0.094, data: 0.042) loss: 0.001 
(epoch: 282, iters: 2112, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 282, iters: 2192, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 282, iters: 2272, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 282, iters: 2352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 282, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 282, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 282, iters: 2592, time: 0.093, data: 0.030) loss: 0.000 
(epoch: 282, iters: 2672, time: 0.095, data: 0.057) loss: 0.000 
(epoch: 282, iters: 2752, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 282, iters: 2832, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 282, iters: 2912, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 282, iters: 2992, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 282, iters: 3072, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 282, iters: 3152, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 282, iters: 3232, time: 0.097, data: 0.039) loss: 0.002 
(epoch: 282, iters: 3312, time: 0.094, data: 0.061) loss: 0.000 
(epoch: 282, iters: 3392, time: 0.098, data: 0.026) loss: 0.000 
(epoch: 282, iters: 3472, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 282, iters: 3552, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 282, iters: 3632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 282, iters: 3712, time: 0.090, data: 0.000) loss: 0.075 
saving the model at the end of epoch 282, iters 1051296
End of epoch 282 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001817
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 282, TEST ACC: [75.114 %]

saving the latest model (epoch 283, total_steps 1051312)
(epoch: 283, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 283, iters: 144, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 283, iters: 224, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 283, iters: 304, time: 0.097, data: 0.047) loss: 0.005 
(epoch: 283, iters: 384, time: 0.093, data: 0.026) loss: 0.002 
(epoch: 283, iters: 464, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 283, iters: 544, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 283, iters: 624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 283, iters: 704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 283, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 283, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 283, iters: 944, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 283, iters: 1024, time: 0.097, data: 0.035) loss: 0.000 
(epoch: 283, iters: 1104, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 283, iters: 1184, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 283, iters: 1264, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 283, iters: 1344, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 283, iters: 1424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 283, iters: 1504, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 283, iters: 1584, time: 0.095, data: 0.032) loss: 0.000 
(epoch: 283, iters: 1664, time: 0.095, data: 0.017) loss: 0.000 
(epoch: 283, iters: 1744, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 283, iters: 1824, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 283, iters: 1904, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 283, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 283, iters: 2064, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 283, iters: 2144, time: 0.095, data: 0.035) loss: 0.000 
(epoch: 283, iters: 2224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 283, iters: 2304, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 283, iters: 2384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 283, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 283, iters: 2544, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 283, iters: 2624, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 283, iters: 2704, time: 0.095, data: 0.026) loss: 0.073 
(epoch: 283, iters: 2784, time: 0.092, data: 0.011) loss: 0.007 
(epoch: 283, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 283, iters: 2944, time: 0.091, data: 0.000) loss: 0.006 
(epoch: 283, iters: 3024, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 283, iters: 3104, time: 0.096, data: 0.000) loss: 0.016 
(epoch: 283, iters: 3184, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 283, iters: 3264, time: 0.098, data: 0.026) loss: 0.000 
(epoch: 283, iters: 3344, time: 0.095, data: 0.030) loss: 0.000 
(epoch: 283, iters: 3424, time: 0.094, data: 0.027) loss: 0.001 
(epoch: 283, iters: 3504, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 283, iters: 3584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 283, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 283, iters 1055024
End of epoch 283 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001816
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 283, TEST ACC: [96.51 %]

(epoch: 284, iters: 16, time: 0.139, data: 0.000) loss: 0.000 
saving the latest model (epoch 284, total_steps 1055040)
(epoch: 284, iters: 96, time: 0.097, data: 0.030) loss: 0.000 
(epoch: 284, iters: 176, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 284, iters: 256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 284, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 284, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 284, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 284, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 284, iters: 656, time: 0.094, data: 0.045) loss: 0.000 
(epoch: 284, iters: 736, time: 0.094, data: 0.031) loss: 0.000 
(epoch: 284, iters: 816, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 284, iters: 896, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 284, iters: 976, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 284, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 284, iters: 1136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 284, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 284, iters: 1296, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 284, iters: 1376, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 284, iters: 1456, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 284, iters: 1536, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 284, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 284, iters: 1696, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 284, iters: 1776, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 284, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 284, iters: 1936, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 284, iters: 2016, time: 0.095, data: 0.029) loss: 0.002 
(epoch: 284, iters: 2096, time: 0.095, data: 0.035) loss: 0.003 
(epoch: 284, iters: 2176, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 284, iters: 2256, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 284, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 284, iters: 2416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 284, iters: 2496, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 284, iters: 2576, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 284, iters: 2656, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 284, iters: 2736, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 284, iters: 2816, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 284, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 284, iters: 2976, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 284, iters: 3056, time: 0.094, data: 0.027) loss: 0.001 
(epoch: 284, iters: 3136, time: 0.095, data: 0.037) loss: 0.003 
(epoch: 284, iters: 3216, time: 0.098, data: 0.012) loss: 0.000 
(epoch: 284, iters: 3296, time: 0.094, data: 0.014) loss: 0.001 
(epoch: 284, iters: 3376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 284, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 284, iters: 3536, time: 0.095, data: 0.037) loss: 0.045 
(epoch: 284, iters: 3616, time: 0.096, data: 0.027) loss: 0.001 
(epoch: 284, iters: 3696, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 284, iters 1058752
End of epoch 284 / 2100 	 Time Taken: 364 sec
learning rate = 0.0001815
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 284, TEST ACC: [88.316 %]

saving the latest model (epoch 285, total_steps 1058768)
(epoch: 285, iters: 48, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 285, iters: 128, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 285, iters: 208, time: 0.095, data: 0.032) loss: 0.001 
(epoch: 285, iters: 288, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 285, iters: 368, time: 0.095, data: 0.021) loss: 0.002 
(epoch: 285, iters: 448, time: 0.091, data: 0.000) loss: 0.001 
(epoch: 285, iters: 528, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 285, iters: 608, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 285, iters: 688, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 285, iters: 768, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 285, iters: 848, time: 0.094, data: 0.037) loss: 0.000 
(epoch: 285, iters: 928, time: 0.094, data: 0.031) loss: 0.001 
(epoch: 285, iters: 1008, time: 0.093, data: 0.011) loss: 0.064 
(epoch: 285, iters: 1088, time: 0.092, data: 0.000) loss: 0.006 
(epoch: 285, iters: 1168, time: 0.094, data: 0.000) loss: 0.017 
(epoch: 285, iters: 1248, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 285, iters: 1328, time: 0.094, data: 0.000) loss: 0.099 
(epoch: 285, iters: 1408, time: 0.095, data: 0.047) loss: 0.008 
(epoch: 285, iters: 1488, time: 0.094, data: 0.044) loss: 0.118 
(epoch: 285, iters: 1568, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 285, iters: 1648, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 285, iters: 1728, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 285, iters: 1808, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 285, iters: 1888, time: 0.093, data: 0.000) loss: 0.054 
(epoch: 285, iters: 1968, time: 0.094, data: 0.032) loss: 0.019 
(epoch: 285, iters: 2048, time: 0.092, data: 0.025) loss: 0.001 
(epoch: 285, iters: 2128, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 285, iters: 2208, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 285, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 285, iters: 2368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 285, iters: 2448, time: 0.097, data: 0.000) loss: 0.012 
(epoch: 285, iters: 2528, time: 0.094, data: 0.032) loss: 0.001 
(epoch: 285, iters: 2608, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 285, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 285, iters: 2768, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 285, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 285, iters: 2928, time: 0.093, data: 0.025) loss: 0.005 
(epoch: 285, iters: 3008, time: 0.095, data: 0.031) loss: 0.013 
(epoch: 285, iters: 3088, time: 0.093, data: 0.018) loss: 0.000 
(epoch: 285, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 285, iters: 3248, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 285, iters: 3328, time: 0.095, data: 0.000) loss: 0.022 
(epoch: 285, iters: 3408, time: 0.094, data: 0.027) loss: 0.008 
(epoch: 285, iters: 3488, time: 0.097, data: 0.025) loss: 0.000 
(epoch: 285, iters: 3568, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 285, iters: 3648, time: 0.086, data: 0.000) loss: 0.000 
(epoch: 285, iters: 3728, time: 0.056, data: 0.000) loss: 0.001 
saving the model at the end of epoch 285, iters 1062480
End of epoch 285 / 2100 	 Time Taken: 359 sec
learning rate = 0.0001814
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 285, TEST ACC: [97.42 %]

saving the latest model (epoch 286, total_steps 1062496)
(epoch: 286, iters: 80, time: 0.095, data: 1.606) loss: 0.000 
(epoch: 286, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 286, iters: 240, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 286, iters: 320, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 286, iters: 400, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 286, iters: 480, time: 0.094, data: 0.000) loss: 0.025 
(epoch: 286, iters: 560, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 286, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 286, iters: 720, time: 0.094, data: 0.000) loss: 0.198 
(epoch: 286, iters: 800, time: 0.093, data: 0.038) loss: 0.002 
(epoch: 286, iters: 880, time: 0.095, data: 0.031) loss: 0.000 
(epoch: 286, iters: 960, time: 0.094, data: 0.017) loss: 0.005 
(epoch: 286, iters: 1040, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 286, iters: 1120, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 286, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 286, iters: 1280, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 286, iters: 1360, time: 0.094, data: 0.037) loss: 0.011 
(epoch: 286, iters: 1440, time: 0.095, data: 0.034) loss: 0.000 
(epoch: 286, iters: 1520, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 286, iters: 1600, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 286, iters: 1680, time: 0.092, data: 0.000) loss: 0.060 
(epoch: 286, iters: 1760, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 286, iters: 1840, time: 0.096, data: 0.000) loss: 0.022 
(epoch: 286, iters: 1920, time: 0.096, data: 0.030) loss: 0.001 
(epoch: 286, iters: 2000, time: 0.096, data: 0.000) loss: 0.286 
(epoch: 286, iters: 2080, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 286, iters: 2160, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 286, iters: 2240, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 286, iters: 2320, time: 0.093, data: 0.025) loss: 0.060 
(epoch: 286, iters: 2400, time: 0.095, data: 0.026) loss: 0.004 
(epoch: 286, iters: 2480, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 286, iters: 2560, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 286, iters: 2640, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 286, iters: 2720, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 286, iters: 2800, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 286, iters: 2880, time: 0.095, data: 0.047) loss: 0.002 
(epoch: 286, iters: 2960, time: 0.092, data: 0.013) loss: 0.005 
(epoch: 286, iters: 3040, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 286, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 286, iters: 3200, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 286, iters: 3280, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 286, iters: 3360, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 286, iters: 3440, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 286, iters: 3520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 286, iters: 3600, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 286, iters: 3680, time: 0.086, data: 0.000) loss: 0.002 
saving the model at the end of epoch 286, iters 1066208
End of epoch 286 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001813
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 286, TEST ACC: [97.269 %]

saving the latest model (epoch 287, total_steps 1066224)
(epoch: 287, iters: 32, time: 0.105, data: 0.000) loss: 0.007 
(epoch: 287, iters: 112, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 287, iters: 192, time: 0.093, data: 0.012) loss: 0.014 
(epoch: 287, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 287, iters: 352, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 287, iters: 432, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 287, iters: 512, time: 0.097, data: 0.032) loss: 0.003 
(epoch: 287, iters: 592, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 287, iters: 672, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 287, iters: 752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 287, iters: 832, time: 0.098, data: 0.000) loss: 0.055 
(epoch: 287, iters: 912, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 287, iters: 992, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 287, iters: 1072, time: 0.096, data: 0.026) loss: 0.053 
(epoch: 287, iters: 1152, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 287, iters: 1232, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 287, iters: 1312, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 287, iters: 1392, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 287, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 287, iters: 1552, time: 0.096, data: 0.025) loss: 0.003 
(epoch: 287, iters: 1632, time: 0.098, data: 0.026) loss: 0.000 
(epoch: 287, iters: 1712, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 287, iters: 1792, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 287, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 287, iters: 1952, time: 0.097, data: 0.000) loss: 0.008 
(epoch: 287, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 287, iters: 2112, time: 0.094, data: 0.026) loss: 0.151 
(epoch: 287, iters: 2192, time: 0.094, data: 0.026) loss: 0.002 
(epoch: 287, iters: 2272, time: 0.094, data: 0.011) loss: 0.014 
(epoch: 287, iters: 2352, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 287, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 287, iters: 2512, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 287, iters: 2592, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 287, iters: 2672, time: 0.096, data: 0.034) loss: 0.000 
(epoch: 287, iters: 2752, time: 0.097, data: 0.026) loss: 0.021 
(epoch: 287, iters: 2832, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 287, iters: 2912, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 287, iters: 2992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 287, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 287, iters: 3152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 287, iters: 3232, time: 0.096, data: 0.025) loss: 0.000 
(epoch: 287, iters: 3312, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 287, iters: 3392, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 287, iters: 3472, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 287, iters: 3552, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 287, iters: 3632, time: 0.095, data: 0.028) loss: 0.003 
(epoch: 287, iters: 3712, time: 0.091, data: 0.035) loss: 0.002 
saving the model at the end of epoch 287, iters 1069936
End of epoch 287 / 2100 	 Time Taken: 364 sec
learning rate = 0.0001812
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 287, TEST ACC: [97.269 %]

saving the latest model (epoch 288, total_steps 1069952)
(epoch: 288, iters: 64, time: 0.093, data: 0.003) loss: 0.000 
(epoch: 288, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 288, iters: 224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 288, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 288, iters: 384, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 288, iters: 464, time: 0.095, data: 0.031) loss: 0.000 
(epoch: 288, iters: 544, time: 0.095, data: 0.030) loss: 0.024 
(epoch: 288, iters: 624, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 288, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 288, iters: 784, time: 0.094, data: 0.000) loss: 0.033 
(epoch: 288, iters: 864, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 288, iters: 944, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 288, iters: 1024, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 288, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 288, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 288, iters: 1264, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 288, iters: 1344, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 288, iters: 1424, time: 0.093, data: 0.030) loss: 0.000 
(epoch: 288, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 288, iters: 1584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 288, iters: 1664, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 288, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 288, iters: 1824, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 288, iters: 1904, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 288, iters: 1984, time: 0.094, data: 0.030) loss: 0.014 
(epoch: 288, iters: 2064, time: 0.094, data: 0.034) loss: 0.392 
(epoch: 288, iters: 2144, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 288, iters: 2224, time: 0.095, data: 0.000) loss: 0.239 
(epoch: 288, iters: 2304, time: 0.092, data: 0.000) loss: 0.057 
(epoch: 288, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 288, iters: 2464, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 288, iters: 2544, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 288, iters: 2624, time: 0.094, data: 0.025) loss: 0.001 
(epoch: 288, iters: 2704, time: 0.093, data: 0.018) loss: 0.015 
(epoch: 288, iters: 2784, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 288, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 288, iters: 2944, time: 0.094, data: 0.000) loss: 0.159 
(epoch: 288, iters: 3024, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 288, iters: 3104, time: 0.095, data: 0.036) loss: 0.000 
(epoch: 288, iters: 3184, time: 0.095, data: 0.025) loss: 0.007 
(epoch: 288, iters: 3264, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 288, iters: 3344, time: 0.091, data: 0.000) loss: 0.002 
(epoch: 288, iters: 3424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 288, iters: 3504, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 288, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 288, iters: 3664, time: 0.088, data: 0.025) loss: 0.009 
saving the model at the end of epoch 288, iters 1073664
End of epoch 288 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001811
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 288, TEST ACC: [94.234 %]

(epoch: 289, iters: 16, time: 0.142, data: 0.024) loss: 0.007 
saving the latest model (epoch 289, total_steps 1073680)
(epoch: 289, iters: 96, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 289, iters: 176, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 289, iters: 256, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 289, iters: 336, time: 0.092, data: 0.000) loss: 0.034 
(epoch: 289, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 289, iters: 496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 289, iters: 576, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 289, iters: 656, time: 0.099, data: 0.026) loss: 0.000 
(epoch: 289, iters: 736, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 289, iters: 816, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 289, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 289, iters: 976, time: 0.093, data: 0.029) loss: 0.000 
(epoch: 289, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 289, iters: 1136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 289, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 289, iters: 1296, time: 0.096, data: 0.000) loss: 0.158 
(epoch: 289, iters: 1376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 289, iters: 1456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 289, iters: 1536, time: 0.094, data: 0.029) loss: 0.004 
(epoch: 289, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 289, iters: 1696, time: 0.098, data: 0.012) loss: 0.000 
(epoch: 289, iters: 1776, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 289, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 289, iters: 1936, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 289, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 289, iters: 2096, time: 0.094, data: 0.044) loss: 0.000 
(epoch: 289, iters: 2176, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 289, iters: 2256, time: 0.093, data: 0.017) loss: 0.017 
(epoch: 289, iters: 2336, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 289, iters: 2416, time: 0.094, data: 0.000) loss: 0.054 
(epoch: 289, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 289, iters: 2576, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 289, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 289, iters: 2736, time: 0.093, data: 0.014) loss: 0.010 
(epoch: 289, iters: 2816, time: 0.091, data: 0.000) loss: 0.004 
(epoch: 289, iters: 2896, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 289, iters: 2976, time: 0.093, data: 0.000) loss: 0.096 
(epoch: 289, iters: 3056, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 289, iters: 3136, time: 0.094, data: 0.038) loss: 0.001 
(epoch: 289, iters: 3216, time: 0.093, data: 0.028) loss: 0.000 
(epoch: 289, iters: 3296, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 289, iters: 3376, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 289, iters: 3456, time: 0.092, data: 0.000) loss: 0.227 
(epoch: 289, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 289, iters: 3616, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 289, iters: 3696, time: 0.090, data: 0.032) loss: 0.001 
saving the model at the end of epoch 289, iters 1077392
End of epoch 289 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001810
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 289, TEST ACC: [95.448 %]

saving the latest model (epoch 290, total_steps 1077408)
(epoch: 290, iters: 48, time: 0.094, data: 0.015) loss: 0.001 
(epoch: 290, iters: 128, time: 0.095, data: 0.042) loss: 0.002 
(epoch: 290, iters: 208, time: 0.094, data: 0.035) loss: 0.033 
(epoch: 290, iters: 288, time: 0.091, data: 0.012) loss: 0.167 
(epoch: 290, iters: 368, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 290, iters: 448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 290, iters: 528, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 290, iters: 608, time: 0.092, data: 0.000) loss: 0.009 
(epoch: 290, iters: 688, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 290, iters: 768, time: 0.094, data: 0.029) loss: 0.005 
(epoch: 290, iters: 848, time: 0.095, data: 0.032) loss: 0.000 
(epoch: 290, iters: 928, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 290, iters: 1008, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 290, iters: 1088, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 290, iters: 1168, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 290, iters: 1248, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 290, iters: 1328, time: 0.094, data: 0.025) loss: 0.002 
(epoch: 290, iters: 1408, time: 0.093, data: 0.026) loss: 0.003 
(epoch: 290, iters: 1488, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 290, iters: 1568, time: 0.091, data: 0.000) loss: 0.012 
(epoch: 290, iters: 1648, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 290, iters: 1728, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 290, iters: 1808, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 290, iters: 1888, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 290, iters: 1968, time: 0.094, data: 0.038) loss: 0.001 
(epoch: 290, iters: 2048, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 290, iters: 2128, time: 0.093, data: 0.000) loss: 0.013 
(epoch: 290, iters: 2208, time: 0.092, data: 0.000) loss: 0.022 
(epoch: 290, iters: 2288, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 290, iters: 2368, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 290, iters: 2448, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 290, iters: 2528, time: 0.095, data: 0.032) loss: 0.001 
(epoch: 290, iters: 2608, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 290, iters: 2688, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 290, iters: 2768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 290, iters: 2848, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 290, iters: 2928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 290, iters: 3008, time: 0.093, data: 0.026) loss: 0.002 
(epoch: 290, iters: 3088, time: 0.098, data: 0.026) loss: 0.001 
(epoch: 290, iters: 3168, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 290, iters: 3248, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 290, iters: 3328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 290, iters: 3408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 290, iters: 3488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 290, iters: 3568, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 290, iters: 3648, time: 0.089, data: 0.039) loss: 0.000 
(epoch: 290, iters: 3728, time: 0.057, data: 0.022) loss: 0.000 
saving the model at the end of epoch 290, iters 1081120
End of epoch 290 / 2100 	 Time Taken: 362 sec
learning rate = 0.0001809
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 290, TEST ACC: [96.965 %]

saving the latest model (epoch 291, total_steps 1081136)
(epoch: 291, iters: 80, time: 0.093, data: 2.844) loss: 0.000 
(epoch: 291, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 291, iters: 240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 291, iters: 320, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 291, iters: 400, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 291, iters: 480, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 291, iters: 560, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 291, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 291, iters: 720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 291, iters: 800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 291, iters: 880, time: 0.092, data: 0.000) loss: 0.006 
(epoch: 291, iters: 960, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 291, iters: 1040, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 291, iters: 1120, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 291, iters: 1200, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 291, iters: 1280, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 291, iters: 1360, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 291, iters: 1440, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 291, iters: 1520, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 291, iters: 1600, time: 0.094, data: 0.000) loss: 0.036 
(epoch: 291, iters: 1680, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 291, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 291, iters: 1840, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 291, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 291, iters: 2000, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 291, iters: 2080, time: 0.096, data: 0.048) loss: 0.000 
(epoch: 291, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 291, iters: 2240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 291, iters: 2320, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 291, iters: 2400, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 291, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 291, iters: 2560, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 291, iters: 2640, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 291, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 291, iters: 2800, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 291, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 291, iters: 2960, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 291, iters: 3040, time: 0.093, data: 0.000) loss: 0.022 
(epoch: 291, iters: 3120, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 291, iters: 3200, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 291, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 291, iters: 3360, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 291, iters: 3440, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 291, iters: 3520, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 291, iters: 3600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 291, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 291, iters 1084848
End of epoch 291 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001808
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 291, TEST ACC: [93.93 %]

saving the latest model (epoch 292, total_steps 1084864)
(epoch: 292, iters: 32, time: 0.095, data: 0.007) loss: 0.000 
(epoch: 292, iters: 112, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 292, iters: 192, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 292, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 292, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 292, iters: 432, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 292, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 292, iters: 592, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 292, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 292, iters: 752, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 292, iters: 832, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 292, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 292, iters: 992, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 292, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 292, iters: 1152, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 292, iters: 1232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 292, iters: 1312, time: 0.094, data: 0.013) loss: 0.015 
(epoch: 292, iters: 1392, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 292, iters: 1472, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 292, iters: 1552, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 292, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 292, iters: 1712, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 292, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 292, iters: 1872, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 292, iters: 1952, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 292, iters: 2032, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 292, iters: 2112, time: 0.094, data: 0.051) loss: 0.013 
(epoch: 292, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 292, iters: 2272, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 292, iters: 2352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 292, iters: 2432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 292, iters: 2512, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 292, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 292, iters: 2672, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 292, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 292, iters: 2832, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 292, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 292, iters: 2992, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 292, iters: 3072, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 292, iters: 3152, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 292, iters: 3232, time: 0.096, data: 0.040) loss: 0.026 
(epoch: 292, iters: 3312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 292, iters: 3392, time: 0.092, data: 0.012) loss: 0.051 
(epoch: 292, iters: 3472, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 292, iters: 3552, time: 0.093, data: 0.012) loss: 0.024 
(epoch: 292, iters: 3632, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 292, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 292, iters 1088576
End of epoch 292 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001807
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 292, TEST ACC: [97.876 %]

saving the latest model (epoch 293, total_steps 1088592)
(epoch: 293, iters: 64, time: 0.093, data: 0.002) loss: 0.000 
(epoch: 293, iters: 144, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 293, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 293, iters: 304, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 293, iters: 384, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 293, iters: 464, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 293, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 293, iters: 624, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 293, iters: 704, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 293, iters: 784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 293, iters: 864, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 293, iters: 944, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 293, iters: 1024, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 293, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 293, iters: 1184, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 293, iters: 1264, time: 0.095, data: 0.050) loss: 0.003 
(epoch: 293, iters: 1344, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 293, iters: 1424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 293, iters: 1504, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 293, iters: 1584, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 293, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 293, iters: 1744, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 293, iters: 1824, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 293, iters: 1904, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 293, iters: 1984, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 293, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 293, iters: 2144, time: 0.093, data: 0.011) loss: 0.019 
(epoch: 293, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 293, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 293, iters: 2384, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 293, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 293, iters: 2544, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 293, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 293, iters: 2704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 293, iters: 2784, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 293, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 293, iters: 2944, time: 0.096, data: 0.039) loss: 0.199 
(epoch: 293, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 293, iters: 3104, time: 0.092, data: 0.011) loss: 0.006 
(epoch: 293, iters: 3184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 293, iters: 3264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 293, iters: 3344, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 293, iters: 3424, time: 0.093, data: 0.000) loss: 0.016 
(epoch: 293, iters: 3504, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 293, iters: 3584, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 293, iters: 3664, time: 0.086, data: 0.011) loss: 0.000 
saving the model at the end of epoch 293, iters 1092304
End of epoch 293 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001806
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 293, TEST ACC: [82.094 %]

(epoch: 294, iters: 16, time: 0.111, data: 0.012) loss: 0.000 
saving the latest model (epoch 294, total_steps 1092320)
(epoch: 294, iters: 96, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 294, iters: 176, time: 0.092, data: 0.012) loss: 0.006 
(epoch: 294, iters: 256, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 294, iters: 336, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 294, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 294, iters: 496, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 294, iters: 576, time: 0.096, data: 0.040) loss: 0.003 
(epoch: 294, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 294, iters: 736, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 294, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 294, iters: 896, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 294, iters: 976, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 294, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 294, iters: 1136, time: 0.096, data: 0.050) loss: 0.001 
(epoch: 294, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 294, iters: 1296, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 294, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 294, iters: 1456, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 294, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 294, iters: 1616, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 294, iters: 1696, time: 0.095, data: 0.038) loss: 0.002 
(epoch: 294, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 294, iters: 1856, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 294, iters: 1936, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 294, iters: 2016, time: 0.094, data: 0.011) loss: 0.029 
(epoch: 294, iters: 2096, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 294, iters: 2176, time: 0.094, data: 0.000) loss: 0.053 
(epoch: 294, iters: 2256, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 294, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 294, iters: 2416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 294, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 294, iters: 2576, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 294, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 294, iters: 2736, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 294, iters: 2816, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 294, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 294, iters: 2976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 294, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 294, iters: 3136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 294, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 294, iters: 3296, time: 0.093, data: 0.000) loss: 0.013 
(epoch: 294, iters: 3376, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 294, iters: 3456, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 294, iters: 3536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 294, iters: 3616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 294, iters: 3696, time: 0.090, data: 0.012) loss: 0.000 
saving the model at the end of epoch 294, iters 1096032
End of epoch 294 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001805
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 294, TEST ACC: [96.813 %]

saving the latest model (epoch 295, total_steps 1096048)
(epoch: 295, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 295, iters: 128, time: 0.094, data: 0.058) loss: 0.000 
(epoch: 295, iters: 208, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 295, iters: 288, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 295, iters: 368, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 295, iters: 448, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 295, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 295, iters: 608, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 295, iters: 688, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 295, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 295, iters: 848, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 295, iters: 928, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 295, iters: 1008, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 295, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 295, iters: 1168, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 295, iters: 1248, time: 0.094, data: 0.041) loss: 0.486 
(epoch: 295, iters: 1328, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 295, iters: 1408, time: 0.092, data: 0.011) loss: 0.029 
(epoch: 295, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 295, iters: 1568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 295, iters: 1648, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 295, iters: 1728, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 295, iters: 1808, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 295, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 295, iters: 1968, time: 0.093, data: 0.012) loss: 0.008 
(epoch: 295, iters: 2048, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 295, iters: 2128, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 295, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 295, iters: 2288, time: 0.093, data: 0.000) loss: 0.263 
(epoch: 295, iters: 2368, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 295, iters: 2448, time: 0.095, data: 0.000) loss: 0.032 
(epoch: 295, iters: 2528, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 295, iters: 2608, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 295, iters: 2688, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 295, iters: 2768, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 295, iters: 2848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 295, iters: 2928, time: 0.097, data: 0.040) loss: 0.058 
(epoch: 295, iters: 3008, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 295, iters: 3088, time: 0.092, data: 0.011) loss: 0.311 
(epoch: 295, iters: 3168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 295, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 295, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 295, iters: 3408, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 295, iters: 3488, time: 0.095, data: 0.039) loss: 0.037 
(epoch: 295, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 295, iters: 3648, time: 0.087, data: 0.011) loss: 0.001 
(epoch: 295, iters: 3728, time: 0.055, data: 0.000) loss: 0.003 
saving the model at the end of epoch 295, iters 1099760
End of epoch 295 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001804
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 295, TEST ACC: [96.662 %]

saving the latest model (epoch 296, total_steps 1099776)
(epoch: 296, iters: 80, time: 0.094, data: 0.569) loss: 0.006 
(epoch: 296, iters: 160, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 296, iters: 240, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 296, iters: 320, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 296, iters: 400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 296, iters: 480, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 296, iters: 560, time: 0.094, data: 0.012) loss: 0.045 
(epoch: 296, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 296, iters: 720, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 296, iters: 800, time: 0.094, data: 0.040) loss: 0.029 
(epoch: 296, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 296, iters: 960, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 296, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 296, iters: 1120, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 296, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 296, iters: 1280, time: 0.093, data: 0.000) loss: 0.008 
(epoch: 296, iters: 1360, time: 0.095, data: 0.039) loss: 0.007 
(epoch: 296, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 296, iters: 1520, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 296, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 296, iters: 1680, time: 0.095, data: 0.011) loss: 0.004 
(epoch: 296, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 296, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 296, iters: 1920, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 296, iters: 2000, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 296, iters: 2080, time: 0.092, data: 0.013) loss: 0.014 
(epoch: 296, iters: 2160, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 296, iters: 2240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 296, iters: 2320, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 296, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 296, iters: 2480, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 296, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 296, iters: 2640, time: 0.092, data: 0.011) loss: 0.006 
(epoch: 296, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 296, iters: 2800, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 296, iters: 2880, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 296, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 296, iters: 3040, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 296, iters: 3120, time: 0.094, data: 0.000) loss: 0.017 
(epoch: 296, iters: 3200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 296, iters: 3280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 296, iters: 3360, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 296, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 296, iters: 3520, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 296, iters: 3600, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 296, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 296, iters 1103488
End of epoch 296 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001803
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 296, TEST ACC: [94.234 %]

saving the latest model (epoch 297, total_steps 1103504)
(epoch: 297, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 297, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 297, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 297, iters: 272, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 297, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 297, iters: 432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 297, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 297, iters: 592, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 297, iters: 672, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 297, iters: 752, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 297, iters: 832, time: 0.094, data: 0.048) loss: 0.003 
(epoch: 297, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 297, iters: 992, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 297, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 297, iters: 1152, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 297, iters: 1232, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 297, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 297, iters: 1392, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 297, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 297, iters: 1552, time: 0.093, data: 0.011) loss: 0.008 
(epoch: 297, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 297, iters: 1712, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 297, iters: 1792, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 297, iters: 1872, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 297, iters: 1952, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 297, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 297, iters: 2112, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 297, iters: 2192, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 297, iters: 2272, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 297, iters: 2352, time: 0.095, data: 0.000) loss: 0.124 
(epoch: 297, iters: 2432, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 297, iters: 2512, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 297, iters: 2592, time: 0.094, data: 0.000) loss: 0.053 
(epoch: 297, iters: 2672, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 297, iters: 2752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 297, iters: 2832, time: 0.093, data: 0.012) loss: 0.008 
(epoch: 297, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 297, iters: 2992, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 297, iters: 3072, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 297, iters: 3152, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 297, iters: 3232, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 297, iters: 3312, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 297, iters: 3392, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 297, iters: 3472, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 297, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 297, iters: 3632, time: 0.093, data: 0.039) loss: 0.002 
(epoch: 297, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 297, iters 1107216
End of epoch 297 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001802
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 297, TEST ACC: [95.599 %]

saving the latest model (epoch 298, total_steps 1107232)
(epoch: 298, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 298, iters: 144, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 298, iters: 224, time: 0.096, data: 0.000) loss: 0.093 
(epoch: 298, iters: 304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 298, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 298, iters: 464, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 298, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 298, iters: 624, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 298, iters: 704, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 298, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 298, iters: 864, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 298, iters: 944, time: 0.093, data: 0.000) loss: 0.132 
(epoch: 298, iters: 1024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 298, iters: 1104, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 298, iters: 1184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 298, iters: 1264, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 298, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 298, iters: 1424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 298, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 298, iters: 1584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 298, iters: 1664, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 298, iters: 1744, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 298, iters: 1824, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 298, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 298, iters: 1984, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 298, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 298, iters: 2144, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 298, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 298, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 298, iters: 2384, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 298, iters: 2464, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 298, iters: 2544, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 298, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 298, iters: 2704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 298, iters: 2784, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 298, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 298, iters: 2944, time: 0.093, data: 0.047) loss: 0.000 
(epoch: 298, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 298, iters: 3104, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 298, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 298, iters: 3264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 298, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 298, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 298, iters: 3504, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 298, iters: 3584, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 298, iters: 3664, time: 0.087, data: 0.012) loss: 0.001 
saving the model at the end of epoch 298, iters 1110944
End of epoch 298 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001801
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 298, TEST ACC: [95.448 %]

(epoch: 299, iters: 16, time: 0.109, data: 0.012) loss: 0.000 
saving the latest model (epoch 299, total_steps 1110960)
(epoch: 299, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 299, iters: 176, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 299, iters: 256, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 299, iters: 336, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 299, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 299, iters: 496, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 299, iters: 576, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 299, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 299, iters: 736, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 299, iters: 816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 299, iters: 896, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 299, iters: 976, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 299, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 299, iters: 1136, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 299, iters: 1216, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 299, iters: 1296, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 299, iters: 1376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 299, iters: 1456, time: 0.095, data: 0.012) loss: 0.026 
(epoch: 299, iters: 1536, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 299, iters: 1616, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 299, iters: 1696, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 299, iters: 1776, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 299, iters: 1856, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 299, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 299, iters: 2016, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 299, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 299, iters: 2176, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 299, iters: 2256, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 299, iters: 2336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 299, iters: 2416, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 299, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 299, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 299, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 299, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 299, iters: 2816, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 299, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 299, iters: 2976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 299, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 299, iters: 3136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 299, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 299, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 299, iters: 3376, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 299, iters: 3456, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 299, iters: 3536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 299, iters: 3616, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 299, iters: 3696, time: 0.090, data: 0.012) loss: 0.000 
saving the model at the end of epoch 299, iters 1114672
End of epoch 299 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001800
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 299, TEST ACC: [96.662 %]

saving the latest model (epoch 300, total_steps 1114688)
(epoch: 300, iters: 48, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 300, iters: 128, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 300, iters: 208, time: 0.092, data: 0.021) loss: 0.008 
(epoch: 300, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 300, iters: 368, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 300, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 300, iters: 528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 300, iters: 608, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 300, iters: 688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 300, iters: 768, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 300, iters: 848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 300, iters: 928, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 300, iters: 1008, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 300, iters: 1088, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 300, iters: 1168, time: 0.094, data: 0.038) loss: 0.001 
(epoch: 300, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 300, iters: 1328, time: 0.092, data: 0.012) loss: 0.007 
(epoch: 300, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 300, iters: 1488, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 300, iters: 1568, time: 0.094, data: 0.000) loss: 0.037 
(epoch: 300, iters: 1648, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 300, iters: 1728, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 300, iters: 1808, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 300, iters: 1888, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 300, iters: 1968, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 300, iters: 2048, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 300, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 300, iters: 2208, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 300, iters: 2288, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 300, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 300, iters: 2448, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 300, iters: 2528, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 300, iters: 2608, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 300, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 300, iters: 2768, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 300, iters: 2848, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 300, iters: 2928, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 300, iters: 3008, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 300, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 300, iters: 3168, time: 0.094, data: 0.020) loss: 0.003 
(epoch: 300, iters: 3248, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 300, iters: 3328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 300, iters: 3408, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 300, iters: 3488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 300, iters: 3568, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 300, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 300, iters: 3728, time: 0.058, data: 0.013) loss: 0.000 
saving the model at the end of epoch 300, iters 1118400
End of epoch 300 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001799
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 300, TEST ACC: [95.144 %]

saving the latest model (epoch 301, total_steps 1118416)
(epoch: 301, iters: 80, time: 0.095, data: 0.522) loss: 0.000 
(epoch: 301, iters: 160, time: 0.095, data: 0.000) loss: 0.131 
(epoch: 301, iters: 240, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 301, iters: 320, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 301, iters: 400, time: 0.093, data: 0.011) loss: 0.021 
(epoch: 301, iters: 480, time: 0.093, data: 0.000) loss: 0.008 
(epoch: 301, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 301, iters: 640, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 301, iters: 720, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 301, iters: 800, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 301, iters: 880, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 301, iters: 960, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 301, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 301, iters: 1120, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 301, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 301, iters: 1280, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 301, iters: 1360, time: 0.093, data: 0.040) loss: 0.003 
(epoch: 301, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 301, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 301, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 301, iters: 1680, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 301, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 301, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 301, iters: 1920, time: 0.094, data: 0.051) loss: 0.109 
(epoch: 301, iters: 2000, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 301, iters: 2080, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 301, iters: 2160, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 301, iters: 2240, time: 0.093, data: 0.011) loss: 0.685 
(epoch: 301, iters: 2320, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 301, iters: 2400, time: 0.093, data: 0.000) loss: 0.202 
(epoch: 301, iters: 2480, time: 0.093, data: 0.040) loss: 0.319 
(epoch: 301, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 301, iters: 2640, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 301, iters: 2720, time: 0.093, data: 0.000) loss: 0.132 
(epoch: 301, iters: 2800, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 301, iters: 2880, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 301, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 301, iters: 3040, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 301, iters: 3120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 301, iters: 3200, time: 0.094, data: 0.012) loss: 0.117 
(epoch: 301, iters: 3280, time: 0.095, data: 0.000) loss: 0.065 
(epoch: 301, iters: 3360, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 301, iters: 3440, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 301, iters: 3520, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 301, iters: 3600, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 301, iters: 3680, time: 0.089, data: 0.000) loss: 0.002 
saving the model at the end of epoch 301, iters 1122128
End of epoch 301 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001798
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 301, TEST ACC: [90.895 %]

saving the latest model (epoch 302, total_steps 1122144)
(epoch: 302, iters: 32, time: 0.091, data: 0.005) loss: 0.000 
(epoch: 302, iters: 112, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 302, iters: 192, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 302, iters: 272, time: 0.093, data: 0.000) loss: 0.015 
(epoch: 302, iters: 352, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 302, iters: 432, time: 0.098, data: 0.000) loss: 0.003 
(epoch: 302, iters: 512, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 302, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 302, iters: 672, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 302, iters: 752, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 302, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 302, iters: 912, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 302, iters: 992, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 302, iters: 1072, time: 0.092, data: 0.021) loss: 0.178 
(epoch: 302, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 302, iters: 1232, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 302, iters: 1312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 302, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 302, iters: 1472, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 302, iters: 1552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 302, iters: 1632, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 302, iters: 1712, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 302, iters: 1792, time: 0.093, data: 0.012) loss: 0.022 
(epoch: 302, iters: 1872, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 302, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 302, iters: 2032, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 302, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 302, iters: 2192, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 302, iters: 2272, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 302, iters: 2352, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 302, iters: 2432, time: 0.094, data: 0.000) loss: 0.312 
(epoch: 302, iters: 2512, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 302, iters: 2592, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 302, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 302, iters: 2752, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 302, iters: 2832, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 302, iters: 2912, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 302, iters: 2992, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 302, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 302, iters: 3152, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 302, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 302, iters: 3312, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 302, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 302, iters: 3472, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 302, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 302, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 302, iters: 3712, time: 0.088, data: 0.046) loss: 0.000 
saving the model at the end of epoch 302, iters 1125856
End of epoch 302 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001797
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 302, TEST ACC: [94.992 %]

saving the latest model (epoch 303, total_steps 1125872)
(epoch: 303, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 303, iters: 144, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 303, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 303, iters: 304, time: 0.093, data: 0.011) loss: 0.076 
(epoch: 303, iters: 384, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 303, iters: 464, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 303, iters: 544, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 303, iters: 624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 303, iters: 704, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 303, iters: 784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 303, iters: 864, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 303, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 303, iters: 1024, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 303, iters: 1104, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 303, iters: 1184, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 303, iters: 1264, time: 0.096, data: 0.039) loss: 0.036 
(epoch: 303, iters: 1344, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 303, iters: 1424, time: 0.092, data: 0.023) loss: 0.000 
(epoch: 303, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 303, iters: 1584, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 303, iters: 1664, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 303, iters: 1744, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 303, iters: 1824, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 303, iters: 1904, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 303, iters: 1984, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 303, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 303, iters: 2144, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 303, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 303, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 303, iters: 2384, time: 0.094, data: 0.038) loss: 0.001 
(epoch: 303, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 303, iters: 2544, time: 0.092, data: 0.012) loss: 0.014 
(epoch: 303, iters: 2624, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 303, iters: 2704, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 303, iters: 2784, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 303, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 303, iters: 2944, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 303, iters: 3024, time: 0.095, data: 0.000) loss: 0.047 
(epoch: 303, iters: 3104, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 303, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 303, iters: 3264, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 303, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 303, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 303, iters: 3504, time: 0.095, data: 0.040) loss: 0.002 
(epoch: 303, iters: 3584, time: 0.095, data: 0.000) loss: 0.025 
(epoch: 303, iters: 3664, time: 0.086, data: 0.011) loss: 0.000 
saving the model at the end of epoch 303, iters 1129584
End of epoch 303 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001796
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 303, TEST ACC: [96.206 %]

(epoch: 304, iters: 16, time: 0.110, data: 0.021) loss: 0.000 
saving the latest model (epoch 304, total_steps 1129600)
(epoch: 304, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 304, iters: 176, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 304, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 304, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 304, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 304, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 304, iters: 576, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 304, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 304, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 304, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 304, iters: 896, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 304, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 304, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 304, iters: 1136, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 304, iters: 1216, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 304, iters: 1296, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 304, iters: 1376, time: 0.094, data: 0.000) loss: 0.094 
(epoch: 304, iters: 1456, time: 0.093, data: 0.011) loss: 0.005 
(epoch: 304, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 304, iters: 1616, time: 0.094, data: 0.000) loss: 0.124 
(epoch: 304, iters: 1696, time: 0.094, data: 0.039) loss: 0.002 
(epoch: 304, iters: 1776, time: 0.095, data: 0.000) loss: 0.625 
(epoch: 304, iters: 1856, time: 0.094, data: 0.011) loss: 0.013 
(epoch: 304, iters: 1936, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 304, iters: 2016, time: 0.095, data: 0.012) loss: 0.008 
(epoch: 304, iters: 2096, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 304, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 304, iters: 2256, time: 0.095, data: 0.041) loss: 0.152 
(epoch: 304, iters: 2336, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 304, iters: 2416, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 304, iters: 2496, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 304, iters: 2576, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 304, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 304, iters: 2736, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 304, iters: 2816, time: 0.097, data: 0.044) loss: 0.000 
(epoch: 304, iters: 2896, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 304, iters: 2976, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 304, iters: 3056, time: 0.095, data: 0.000) loss: 0.034 
(epoch: 304, iters: 3136, time: 0.095, data: 0.011) loss: 0.016 
(epoch: 304, iters: 3216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 304, iters: 3296, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 304, iters: 3376, time: 0.096, data: 0.050) loss: 0.001 
(epoch: 304, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 304, iters: 3536, time: 0.092, data: 0.012) loss: 0.066 
(epoch: 304, iters: 3616, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 304, iters: 3696, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 304, iters 1133312
End of epoch 304 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001795
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 304, TEST ACC: [95.296 %]

saving the latest model (epoch 305, total_steps 1133328)
(epoch: 305, iters: 48, time: 0.094, data: 0.000) loss: 0.130 
(epoch: 305, iters: 128, time: 0.096, data: 0.057) loss: 0.007 
(epoch: 305, iters: 208, time: 0.096, data: 0.000) loss: 0.232 
(epoch: 305, iters: 288, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 305, iters: 368, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 305, iters: 448, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 305, iters: 528, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 305, iters: 608, time: 0.093, data: 0.000) loss: 0.465 
(epoch: 305, iters: 688, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 305, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 305, iters: 848, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 305, iters: 928, time: 0.093, data: 0.000) loss: 0.055 
(epoch: 305, iters: 1008, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 305, iters: 1088, time: 0.095, data: 0.000) loss: 0.094 
(epoch: 305, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 305, iters: 1248, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 305, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 305, iters: 1408, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 305, iters: 1488, time: 0.093, data: 0.000) loss: 0.028 
(epoch: 305, iters: 1568, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 305, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 305, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 305, iters: 1808, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 305, iters: 1888, time: 0.095, data: 0.000) loss: 0.069 
(epoch: 305, iters: 1968, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 305, iters: 2048, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 305, iters: 2128, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 305, iters: 2208, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 305, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 305, iters: 2368, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 305, iters: 2448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 305, iters: 2528, time: 0.092, data: 0.012) loss: 0.005 
(epoch: 305, iters: 2608, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 305, iters: 2688, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 305, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 305, iters: 2848, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 305, iters: 2928, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 305, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 305, iters: 3088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 305, iters: 3168, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 305, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 305, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 305, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 305, iters: 3488, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 305, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 305, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 305, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 305, iters 1137040
End of epoch 305 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001794
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 305, TEST ACC: [93.02 %]

saving the latest model (epoch 306, total_steps 1137056)
(epoch: 306, iters: 80, time: 0.095, data: 0.506) loss: 0.000 
(epoch: 306, iters: 160, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 306, iters: 240, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 306, iters: 320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 306, iters: 400, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 306, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 306, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 306, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 306, iters: 720, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 306, iters: 800, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 306, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 306, iters: 960, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 306, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 306, iters: 1120, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 306, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 306, iters: 1280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 306, iters: 1360, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 306, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 306, iters: 1520, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 306, iters: 1600, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 306, iters: 1680, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 306, iters: 1760, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 306, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 306, iters: 1920, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 306, iters: 2000, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 306, iters: 2080, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 306, iters: 2160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 306, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 306, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 306, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 306, iters: 2480, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 306, iters: 2560, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 306, iters: 2640, time: 0.092, data: 0.021) loss: 0.067 
(epoch: 306, iters: 2720, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 306, iters: 2800, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 306, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 306, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 306, iters: 3040, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 306, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 306, iters: 3200, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 306, iters: 3280, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 306, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 306, iters: 3440, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 306, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 306, iters: 3600, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 306, iters: 3680, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 306, iters 1140768
End of epoch 306 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001793
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 306, TEST ACC: [95.144 %]

saving the latest model (epoch 307, total_steps 1140784)
(epoch: 307, iters: 32, time: 0.092, data: 0.005) loss: 0.000 
(epoch: 307, iters: 112, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 307, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 307, iters: 272, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 307, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 307, iters: 432, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 307, iters: 512, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 307, iters: 592, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 307, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 307, iters: 752, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 307, iters: 832, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 307, iters: 912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 307, iters: 992, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 307, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 307, iters: 1152, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 307, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 307, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 307, iters: 1392, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 307, iters: 1472, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 307, iters: 1552, time: 0.093, data: 0.013) loss: 0.009 
(epoch: 307, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 307, iters: 1712, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 307, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 307, iters: 1872, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 307, iters: 1952, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 307, iters: 2032, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 307, iters: 2112, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 307, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 307, iters: 2272, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 307, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 307, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 307, iters: 2512, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 307, iters: 2592, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 307, iters: 2672, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 307, iters: 2752, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 307, iters: 2832, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 307, iters: 2912, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 307, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 307, iters: 3072, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 307, iters: 3152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 307, iters: 3232, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 307, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 307, iters: 3392, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 307, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 307, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 307, iters: 3632, time: 0.091, data: 0.041) loss: 0.000 
(epoch: 307, iters: 3712, time: 0.088, data: 0.000) loss: 0.507 
saving the model at the end of epoch 307, iters 1144496
End of epoch 307 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001792
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 307, TEST ACC: [95.296 %]

saving the latest model (epoch 308, total_steps 1144512)
(epoch: 308, iters: 64, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 308, iters: 144, time: 0.097, data: 0.036) loss: 0.000 
(epoch: 308, iters: 224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 308, iters: 304, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 308, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 308, iters: 464, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 308, iters: 544, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 308, iters: 624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 308, iters: 704, time: 0.095, data: 0.040) loss: 0.005 
(epoch: 308, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 308, iters: 864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 308, iters: 944, time: 0.096, data: 0.000) loss: 0.593 
(epoch: 308, iters: 1024, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 308, iters: 1104, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 308, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 308, iters: 1264, time: 0.094, data: 0.041) loss: 0.004 
(epoch: 308, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 308, iters: 1424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 308, iters: 1504, time: 0.094, data: 0.000) loss: 0.107 
(epoch: 308, iters: 1584, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 308, iters: 1664, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 308, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 308, iters: 1824, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 308, iters: 1904, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 308, iters: 1984, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 308, iters: 2064, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 308, iters: 2144, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 308, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 308, iters: 2304, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 308, iters: 2384, time: 0.093, data: 0.039) loss: 0.002 
(epoch: 308, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 308, iters: 2544, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 308, iters: 2624, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 308, iters: 2704, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 308, iters: 2784, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 308, iters: 2864, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 308, iters: 2944, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 308, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 308, iters: 3104, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 308, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 308, iters: 3264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 308, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 308, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 308, iters: 3504, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 308, iters: 3584, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 308, iters: 3664, time: 0.090, data: 0.012) loss: 0.000 
saving the model at the end of epoch 308, iters 1148224
End of epoch 308 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001791
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 308, TEST ACC: [93.475 %]

(epoch: 309, iters: 16, time: 0.109, data: 0.012) loss: 0.004 
saving the latest model (epoch 309, total_steps 1148240)
(epoch: 309, iters: 96, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 309, iters: 176, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 309, iters: 256, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 309, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 309, iters: 416, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 309, iters: 496, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 309, iters: 576, time: 0.096, data: 0.048) loss: 0.003 
(epoch: 309, iters: 656, time: 0.094, data: 0.000) loss: 0.185 
(epoch: 309, iters: 736, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 309, iters: 816, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 309, iters: 896, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 309, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 309, iters: 1056, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 309, iters: 1136, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 309, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 309, iters: 1296, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 309, iters: 1376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 309, iters: 1456, time: 0.093, data: 0.012) loss: 0.010 
(epoch: 309, iters: 1536, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 309, iters: 1616, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 309, iters: 1696, time: 0.093, data: 0.039) loss: 0.016 
(epoch: 309, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 309, iters: 1856, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 309, iters: 1936, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 309, iters: 2016, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 309, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 309, iters: 2176, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 309, iters: 2256, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 309, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 309, iters: 2416, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 309, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 309, iters: 2576, time: 0.095, data: 0.011) loss: 0.041 
(epoch: 309, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 309, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 309, iters: 2816, time: 0.094, data: 0.040) loss: 0.107 
(epoch: 309, iters: 2896, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 309, iters: 2976, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 309, iters: 3056, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 309, iters: 3136, time: 0.093, data: 0.012) loss: 0.013 
(epoch: 309, iters: 3216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 309, iters: 3296, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 309, iters: 3376, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 309, iters: 3456, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 309, iters: 3536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 309, iters: 3616, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 309, iters: 3696, time: 0.087, data: 0.011) loss: 0.003 
saving the model at the end of epoch 309, iters 1151952
End of epoch 309 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001790
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 309, TEST ACC: [71.32 %]

saving the latest model (epoch 310, total_steps 1151968)
(epoch: 310, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 310, iters: 128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 310, iters: 208, time: 0.093, data: 0.041) loss: 1.349 
(epoch: 310, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 310, iters: 368, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 310, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 310, iters: 528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 310, iters: 608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 310, iters: 688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 310, iters: 768, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 310, iters: 848, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 310, iters: 928, time: 0.092, data: 0.011) loss: 0.009 
(epoch: 310, iters: 1008, time: 0.094, data: 0.000) loss: 0.026 
(epoch: 310, iters: 1088, time: 0.092, data: 0.019) loss: 0.000 
(epoch: 310, iters: 1168, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 310, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 310, iters: 1328, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 310, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 310, iters: 1488, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 310, iters: 1568, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 310, iters: 1648, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 310, iters: 1728, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 310, iters: 1808, time: 0.095, data: 0.000) loss: 0.114 
(epoch: 310, iters: 1888, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 310, iters: 1968, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 310, iters: 2048, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 310, iters: 2128, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 310, iters: 2208, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 310, iters: 2288, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 310, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 310, iters: 2448, time: 0.094, data: 0.041) loss: 0.012 
(epoch: 310, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 310, iters: 2608, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 310, iters: 2688, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 310, iters: 2768, time: 0.092, data: 0.013) loss: 0.022 
(epoch: 310, iters: 2848, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 310, iters: 2928, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 310, iters: 3008, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 310, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 310, iters: 3168, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 310, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 310, iters: 3328, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 310, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 310, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 310, iters: 3568, time: 0.094, data: 0.040) loss: 0.015 
(epoch: 310, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 310, iters: 3728, time: 0.056, data: 0.021) loss: 0.005 
saving the model at the end of epoch 310, iters 1155680
End of epoch 310 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001789
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 310, TEST ACC: [91.654 %]

saving the latest model (epoch 311, total_steps 1155696)
(epoch: 311, iters: 80, time: 0.091, data: 0.503) loss: 0.001 
(epoch: 311, iters: 160, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 311, iters: 240, time: 0.093, data: 0.019) loss: 0.000 
(epoch: 311, iters: 320, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 311, iters: 400, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 311, iters: 480, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 311, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 311, iters: 640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 311, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 311, iters: 800, time: 0.093, data: 0.011) loss: 0.097 
(epoch: 311, iters: 880, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 311, iters: 960, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 311, iters: 1040, time: 0.094, data: 0.038) loss: 0.001 
(epoch: 311, iters: 1120, time: 0.095, data: 0.000) loss: 0.072 
(epoch: 311, iters: 1200, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 311, iters: 1280, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 311, iters: 1360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 311, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 311, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 311, iters: 1600, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 311, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 311, iters: 1760, time: 0.093, data: 0.013) loss: 0.006 
(epoch: 311, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 311, iters: 1920, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 311, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 311, iters: 2080, time: 0.092, data: 0.000) loss: 0.024 
(epoch: 311, iters: 2160, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 311, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 311, iters: 2320, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 311, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 311, iters: 2480, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 311, iters: 2560, time: 0.097, data: 0.000) loss: 0.095 
(epoch: 311, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 311, iters: 2720, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 311, iters: 2800, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 311, iters: 2880, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 311, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 311, iters: 3040, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 311, iters: 3120, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 311, iters: 3200, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 311, iters: 3280, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 311, iters: 3360, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 311, iters: 3440, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 311, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 311, iters: 3600, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 311, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 311, iters 1159408
End of epoch 311 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001788
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 311, TEST ACC: [94.689 %]

saving the latest model (epoch 312, total_steps 1159424)
(epoch: 312, iters: 32, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 312, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 312, iters: 192, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 312, iters: 272, time: 0.096, data: 0.041) loss: 0.001 
(epoch: 312, iters: 352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 312, iters: 432, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 312, iters: 512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 312, iters: 592, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 312, iters: 672, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 312, iters: 752, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 312, iters: 832, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 312, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 312, iters: 992, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 312, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 312, iters: 1152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 312, iters: 1232, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 312, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 312, iters: 1392, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 312, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 312, iters: 1552, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 312, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 312, iters: 1712, time: 0.094, data: 0.011) loss: 0.015 
(epoch: 312, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 312, iters: 1872, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 312, iters: 1952, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 312, iters: 2032, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 312, iters: 2112, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 312, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 312, iters: 2272, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 312, iters: 2352, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 312, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 312, iters: 2512, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 312, iters: 2592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 312, iters: 2672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 312, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 312, iters: 2832, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 312, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 312, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 312, iters: 3072, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 312, iters: 3152, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 312, iters: 3232, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 312, iters: 3312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 312, iters: 3392, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 312, iters: 3472, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 312, iters: 3552, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 312, iters: 3632, time: 0.091, data: 0.039) loss: 0.000 
(epoch: 312, iters: 3712, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 312, iters 1163136
End of epoch 312 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001787
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 312, TEST ACC: [95.144 %]

saving the latest model (epoch 313, total_steps 1163152)
(epoch: 313, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 313, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 313, iters: 224, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 313, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 313, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 313, iters: 464, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 313, iters: 544, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 313, iters: 624, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 313, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 313, iters: 784, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 313, iters: 864, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 313, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 313, iters: 1024, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 313, iters: 1104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 313, iters: 1184, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 313, iters: 1264, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 313, iters: 1344, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 313, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 313, iters: 1504, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 313, iters: 1584, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 313, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 313, iters: 1744, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 313, iters: 1824, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 313, iters: 1904, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 313, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 313, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 313, iters: 2144, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 313, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 313, iters: 2304, time: 0.092, data: 0.012) loss: 0.016 
(epoch: 313, iters: 2384, time: 0.094, data: 0.000) loss: 0.549 
(epoch: 313, iters: 2464, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 313, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 313, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 313, iters: 2704, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 313, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 313, iters: 2864, time: 0.093, data: 0.021) loss: 0.004 
(epoch: 313, iters: 2944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 313, iters: 3024, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 313, iters: 3104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 313, iters: 3184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 313, iters: 3264, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 313, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 313, iters: 3424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 313, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 313, iters: 3584, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 313, iters: 3664, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 313, iters 1166864
End of epoch 313 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001786
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 313, TEST ACC: [92.868 %]

(epoch: 314, iters: 16, time: 0.110, data: 0.000) loss: 0.002 
saving the latest model (epoch 314, total_steps 1166880)
(epoch: 314, iters: 96, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 314, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 314, iters: 256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 314, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 314, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 314, iters: 496, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 314, iters: 576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 314, iters: 656, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 314, iters: 736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 314, iters: 816, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 314, iters: 896, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 314, iters: 976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 314, iters: 1056, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 314, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 314, iters: 1216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 314, iters: 1296, time: 0.093, data: 0.000) loss: 0.017 
(epoch: 314, iters: 1376, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 314, iters: 1456, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 314, iters: 1536, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 314, iters: 1616, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 314, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 314, iters: 1776, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 314, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 314, iters: 1936, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 314, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 314, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 314, iters: 2176, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 314, iters: 2256, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 314, iters: 2336, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 314, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 314, iters: 2496, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 314, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 314, iters: 2656, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 314, iters: 2736, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 314, iters: 2816, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 314, iters: 2896, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 314, iters: 2976, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 314, iters: 3056, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 314, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 314, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 314, iters: 3296, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 314, iters: 3376, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 314, iters: 3456, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 314, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 314, iters: 3616, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 314, iters: 3696, time: 0.089, data: 0.000) loss: 0.001 
saving the model at the end of epoch 314, iters 1170592
End of epoch 314 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001785
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 314, TEST ACC: [95.144 %]

saving the latest model (epoch 315, total_steps 1170608)
(epoch: 315, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 315, iters: 128, time: 0.096, data: 0.027) loss: 0.005 
(epoch: 315, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 315, iters: 288, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 315, iters: 368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 315, iters: 448, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 315, iters: 528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 315, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 315, iters: 688, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 315, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 315, iters: 848, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 315, iters: 928, time: 0.093, data: 0.000) loss: 0.047 
(epoch: 315, iters: 1008, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 315, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 315, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 315, iters: 1248, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 315, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 315, iters: 1408, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 315, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 315, iters: 1568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 315, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 315, iters: 1728, time: 0.093, data: 0.000) loss: 0.014 
(epoch: 315, iters: 1808, time: 0.096, data: 0.040) loss: 0.013 
(epoch: 315, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 315, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 315, iters: 2048, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 315, iters: 2128, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 315, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 315, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 315, iters: 2368, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 315, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 315, iters: 2528, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 315, iters: 2608, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 315, iters: 2688, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 315, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 315, iters: 2848, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 315, iters: 2928, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 315, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 315, iters: 3088, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 315, iters: 3168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 315, iters: 3248, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 315, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 315, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 315, iters: 3488, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 315, iters: 3568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 315, iters: 3648, time: 0.088, data: 0.012) loss: 0.001 
(epoch: 315, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 315, iters 1174320
End of epoch 315 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001784
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 315, TEST ACC: [96.662 %]

saving the latest model (epoch 316, total_steps 1174336)
(epoch: 316, iters: 80, time: 0.094, data: 0.531) loss: 0.000 
(epoch: 316, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 316, iters: 240, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 316, iters: 320, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 316, iters: 400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 316, iters: 480, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 316, iters: 560, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 316, iters: 640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 316, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 316, iters: 800, time: 0.095, data: 0.013) loss: 0.007 
(epoch: 316, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 316, iters: 960, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 316, iters: 1040, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 316, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 316, iters: 1200, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 316, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 316, iters: 1360, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 316, iters: 1440, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 316, iters: 1520, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 316, iters: 1600, time: 0.095, data: 0.041) loss: 0.004 
(epoch: 316, iters: 1680, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 316, iters: 1760, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 316, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 316, iters: 1920, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 316, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 316, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 316, iters: 2160, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 316, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 316, iters: 2320, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 316, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 316, iters: 2480, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 316, iters: 2560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 316, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 316, iters: 2720, time: 0.094, data: 0.049) loss: 0.001 
(epoch: 316, iters: 2800, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 316, iters: 2880, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 316, iters: 2960, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 316, iters: 3040, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 316, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 316, iters: 3200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 316, iters: 3280, time: 0.094, data: 0.038) loss: 0.001 
(epoch: 316, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 316, iters: 3440, time: 0.091, data: 0.011) loss: 0.001 
(epoch: 316, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 316, iters: 3600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 316, iters: 3680, time: 0.087, data: 0.000) loss: 0.001 
saving the model at the end of epoch 316, iters 1178048
End of epoch 316 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001783
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 316, TEST ACC: [96.358 %]

saving the latest model (epoch 317, total_steps 1178064)
(epoch: 317, iters: 32, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 317, iters: 112, time: 0.094, data: 0.026) loss: 0.027 
(epoch: 317, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 317, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 317, iters: 352, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 317, iters: 432, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 317, iters: 512, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 317, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 317, iters: 672, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 317, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 317, iters: 832, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 317, iters: 912, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 317, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 317, iters: 1072, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 317, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 317, iters: 1232, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 317, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 317, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 317, iters: 1472, time: 0.096, data: 0.048) loss: 0.387 
(epoch: 317, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 317, iters: 1632, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 317, iters: 1712, time: 0.093, data: 0.000) loss: 0.051 
(epoch: 317, iters: 1792, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 317, iters: 1872, time: 0.094, data: 0.000) loss: 0.131 
(epoch: 317, iters: 1952, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 317, iters: 2032, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 317, iters: 2112, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 317, iters: 2192, time: 0.092, data: 0.021) loss: 0.001 
(epoch: 317, iters: 2272, time: 0.094, data: 0.000) loss: 0.062 
(epoch: 317, iters: 2352, time: 0.095, data: 0.012) loss: 0.004 
(epoch: 317, iters: 2432, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 317, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 317, iters: 2592, time: 0.093, data: 0.040) loss: 0.010 
(epoch: 317, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 317, iters: 2752, time: 0.092, data: 0.011) loss: 0.018 
(epoch: 317, iters: 2832, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 317, iters: 2912, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 317, iters: 2992, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 317, iters: 3072, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 317, iters: 3152, time: 0.095, data: 0.039) loss: 0.002 
(epoch: 317, iters: 3232, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 317, iters: 3312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 317, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 317, iters: 3472, time: 0.094, data: 0.012) loss: 0.026 
(epoch: 317, iters: 3552, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 317, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 317, iters: 3712, time: 0.088, data: 0.037) loss: 0.009 
saving the model at the end of epoch 317, iters 1181776
End of epoch 317 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001782
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 317, TEST ACC: [96.055 %]

saving the latest model (epoch 318, total_steps 1181792)
(epoch: 318, iters: 64, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 318, iters: 144, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 318, iters: 224, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 318, iters: 304, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 318, iters: 384, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 318, iters: 464, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 318, iters: 544, time: 0.094, data: 0.041) loss: 0.020 
(epoch: 318, iters: 624, time: 0.094, data: 0.000) loss: 0.049 
(epoch: 318, iters: 704, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 318, iters: 784, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 318, iters: 864, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 318, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 318, iters: 1024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 318, iters: 1104, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 318, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 318, iters: 1264, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 318, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 318, iters: 1424, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 318, iters: 1504, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 318, iters: 1584, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 318, iters: 1664, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 318, iters: 1744, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 318, iters: 1824, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 318, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 318, iters: 1984, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 318, iters: 2064, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 318, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 318, iters: 2224, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 318, iters: 2304, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 318, iters: 2384, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 318, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 318, iters: 2544, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 318, iters: 2624, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 318, iters: 2704, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 318, iters: 2784, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 318, iters: 2864, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 318, iters: 2944, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 318, iters: 3024, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 318, iters: 3104, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 318, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 318, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 318, iters: 3344, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 318, iters: 3424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 318, iters: 3504, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 318, iters: 3584, time: 0.094, data: 0.000) loss: 0.132 
(epoch: 318, iters: 3664, time: 0.087, data: 0.012) loss: 0.514 
saving the model at the end of epoch 318, iters 1185504
End of epoch 318 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001781
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 318, TEST ACC: [93.627 %]

(epoch: 319, iters: 16, time: 0.109, data: 0.000) loss: 0.001 
saving the latest model (epoch 319, total_steps 1185520)
(epoch: 319, iters: 96, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 319, iters: 176, time: 0.094, data: 0.000) loss: 0.466 
(epoch: 319, iters: 256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 319, iters: 336, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 319, iters: 416, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 319, iters: 496, time: 0.094, data: 0.050) loss: 0.309 
(epoch: 319, iters: 576, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 319, iters: 656, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 319, iters: 736, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 319, iters: 816, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 319, iters: 896, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 319, iters: 976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 319, iters: 1056, time: 0.094, data: 0.038) loss: 0.001 
(epoch: 319, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 319, iters: 1216, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 319, iters: 1296, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 319, iters: 1376, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 319, iters: 1456, time: 0.095, data: 0.000) loss: 0.024 
(epoch: 319, iters: 1536, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 319, iters: 1616, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 319, iters: 1696, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 319, iters: 1776, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 319, iters: 1856, time: 0.093, data: 0.000) loss: 0.070 
(epoch: 319, iters: 1936, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 319, iters: 2016, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 319, iters: 2096, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 319, iters: 2176, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 319, iters: 2256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 319, iters: 2336, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 319, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 319, iters: 2496, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 319, iters: 2576, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 319, iters: 2656, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 319, iters: 2736, time: 0.096, data: 0.041) loss: 0.003 
(epoch: 319, iters: 2816, time: 0.096, data: 0.000) loss: 0.072 
(epoch: 319, iters: 2896, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 319, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 319, iters: 3056, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 319, iters: 3136, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 319, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 319, iters: 3296, time: 0.096, data: 0.041) loss: 0.007 
(epoch: 319, iters: 3376, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 319, iters: 3456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 319, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 319, iters: 3616, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 319, iters: 3696, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 319, iters 1189232
End of epoch 319 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001780
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 319, TEST ACC: [96.055 %]

saving the latest model (epoch 320, total_steps 1189248)
(epoch: 320, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 320, iters: 128, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 320, iters: 208, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 320, iters: 288, time: 0.093, data: 0.000) loss: 0.026 
(epoch: 320, iters: 368, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 320, iters: 448, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 320, iters: 528, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 320, iters: 608, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 320, iters: 688, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 320, iters: 768, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 320, iters: 848, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 320, iters: 928, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 320, iters: 1008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 320, iters: 1088, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 320, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 320, iters: 1248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 320, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 320, iters: 1408, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 320, iters: 1488, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 320, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 320, iters: 1648, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 320, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 320, iters: 1808, time: 0.093, data: 0.012) loss: 0.007 
(epoch: 320, iters: 1888, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 320, iters: 1968, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 320, iters: 2048, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 320, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 320, iters: 2208, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 320, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 320, iters: 2368, time: 0.094, data: 0.013) loss: 0.006 
(epoch: 320, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 320, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 320, iters: 2608, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 320, iters: 2688, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 320, iters: 2768, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 320, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 320, iters: 2928, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 320, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 320, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 320, iters: 3168, time: 0.094, data: 0.041) loss: 0.008 
(epoch: 320, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 320, iters: 3328, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 320, iters: 3408, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 320, iters: 3488, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 320, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 320, iters: 3648, time: 0.086, data: 0.000) loss: 0.000 
(epoch: 320, iters: 3728, time: 0.057, data: 0.015) loss: 0.000 
saving the model at the end of epoch 320, iters 1192960
End of epoch 320 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001779
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 320, TEST ACC: [95.599 %]

saving the latest model (epoch 321, total_steps 1192976)
(epoch: 321, iters: 80, time: 0.095, data: 0.497) loss: 0.000 
(epoch: 321, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 321, iters: 240, time: 0.094, data: 0.039) loss: 0.002 
(epoch: 321, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 321, iters: 400, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 321, iters: 480, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 321, iters: 560, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 321, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 321, iters: 720, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 321, iters: 800, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 321, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 321, iters: 960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 321, iters: 1040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 321, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 321, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 321, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 321, iters: 1360, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 321, iters: 1440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 321, iters: 1520, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 321, iters: 1600, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 321, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 321, iters: 1760, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 321, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 321, iters: 1920, time: 0.094, data: 0.051) loss: 0.070 
(epoch: 321, iters: 2000, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 321, iters: 2080, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 321, iters: 2160, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 321, iters: 2240, time: 0.095, data: 0.020) loss: 0.001 
(epoch: 321, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 321, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 321, iters: 2480, time: 0.094, data: 0.042) loss: 0.001 
(epoch: 321, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 321, iters: 2640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 321, iters: 2720, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 321, iters: 2800, time: 0.094, data: 0.012) loss: 0.008 
(epoch: 321, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 321, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 321, iters: 3040, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 321, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 321, iters: 3200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 321, iters: 3280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 321, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 321, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 321, iters: 3520, time: 0.093, data: 0.000) loss: 0.014 
(epoch: 321, iters: 3600, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 321, iters: 3680, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 321, iters 1196688
End of epoch 321 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001778
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 321, TEST ACC: [74.052 %]

saving the latest model (epoch 322, total_steps 1196704)
(epoch: 322, iters: 32, time: 0.092, data: 0.005) loss: 0.000 
(epoch: 322, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 322, iters: 192, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 322, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 322, iters: 352, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 322, iters: 432, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 322, iters: 512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 322, iters: 592, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 322, iters: 672, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 322, iters: 752, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 322, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 322, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 322, iters: 992, time: 0.094, data: 0.039) loss: 0.004 
(epoch: 322, iters: 1072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 322, iters: 1152, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 322, iters: 1232, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 322, iters: 1312, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 322, iters: 1392, time: 0.096, data: 0.000) loss: 0.283 
(epoch: 322, iters: 1472, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 322, iters: 1552, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 322, iters: 1632, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 322, iters: 1712, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 322, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 322, iters: 1872, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 322, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 322, iters: 2032, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 322, iters: 2112, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 322, iters: 2192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 322, iters: 2272, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 322, iters: 2352, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 322, iters: 2432, time: 0.093, data: 0.012) loss: 0.036 
(epoch: 322, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 322, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 322, iters: 2672, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 322, iters: 2752, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 322, iters: 2832, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 322, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 322, iters: 2992, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 322, iters: 3072, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 322, iters: 3152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 322, iters: 3232, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 322, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 322, iters: 3392, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 322, iters: 3472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 322, iters: 3552, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 322, iters: 3632, time: 0.091, data: 0.000) loss: 0.004 
(epoch: 322, iters: 3712, time: 0.088, data: 0.000) loss: 0.099 
saving the model at the end of epoch 322, iters 1200416
End of epoch 322 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001777
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 322, TEST ACC: [92.109 %]

saving the latest model (epoch 323, total_steps 1200432)
(epoch: 323, iters: 64, time: 0.095, data: 0.003) loss: 0.010 
(epoch: 323, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 323, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 323, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 323, iters: 384, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 323, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 323, iters: 544, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 323, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 323, iters: 704, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 323, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 323, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 323, iters: 944, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 323, iters: 1024, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 323, iters: 1104, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 323, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 323, iters: 1264, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 323, iters: 1344, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 323, iters: 1424, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 323, iters: 1504, time: 0.096, data: 0.039) loss: 0.010 
(epoch: 323, iters: 1584, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 323, iters: 1664, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 323, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 323, iters: 1824, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 323, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 323, iters: 1984, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 323, iters: 2064, time: 0.094, data: 0.041) loss: 0.027 
(epoch: 323, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 323, iters: 2224, time: 0.094, data: 0.013) loss: 0.003 
(epoch: 323, iters: 2304, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 323, iters: 2384, time: 0.094, data: 0.012) loss: 0.011 
(epoch: 323, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 323, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 323, iters: 2624, time: 0.095, data: 0.049) loss: 0.001 
(epoch: 323, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 323, iters: 2784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 323, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 323, iters: 2944, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 323, iters: 3024, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 323, iters: 3104, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 323, iters: 3184, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 323, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 323, iters: 3344, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 323, iters: 3424, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 323, iters: 3504, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 323, iters: 3584, time: 0.097, data: 0.000) loss: 0.066 
(epoch: 323, iters: 3664, time: 0.089, data: 0.000) loss: 0.006 
saving the model at the end of epoch 323, iters 1204144
End of epoch 323 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001776
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 323, TEST ACC: [95.296 %]

(epoch: 324, iters: 16, time: 0.114, data: 0.012) loss: 0.002 
saving the latest model (epoch 324, total_steps 1204160)
(epoch: 324, iters: 96, time: 0.094, data: 0.012) loss: 0.011 
(epoch: 324, iters: 176, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 324, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 324, iters: 336, time: 0.092, data: 0.012) loss: 0.026 
(epoch: 324, iters: 416, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 324, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 324, iters: 576, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 324, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 324, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 324, iters: 816, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 324, iters: 896, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 324, iters: 976, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 324, iters: 1056, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 324, iters: 1136, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 324, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 324, iters: 1296, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 324, iters: 1376, time: 0.095, data: 0.000) loss: 0.120 
(epoch: 324, iters: 1456, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 324, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 324, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 324, iters: 1696, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 324, iters: 1776, time: 0.094, data: 0.000) loss: 0.629 
(epoch: 324, iters: 1856, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 324, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 324, iters: 2016, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 324, iters: 2096, time: 0.095, data: 0.000) loss: 0.252 
(epoch: 324, iters: 2176, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 324, iters: 2256, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 324, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 324, iters: 2416, time: 0.093, data: 0.011) loss: 0.244 
(epoch: 324, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 324, iters: 2576, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 324, iters: 2656, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 324, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 324, iters: 2816, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 324, iters: 2896, time: 0.094, data: 0.000) loss: 0.375 
(epoch: 324, iters: 2976, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 324, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 324, iters: 3136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 324, iters: 3216, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 324, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 324, iters: 3376, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 324, iters: 3456, time: 0.094, data: 0.000) loss: 0.054 
(epoch: 324, iters: 3536, time: 0.093, data: 0.012) loss: 0.010 
(epoch: 324, iters: 3616, time: 0.095, data: 0.000) loss: 0.117 
(epoch: 324, iters: 3696, time: 0.090, data: 0.012) loss: 0.000 
saving the model at the end of epoch 324, iters 1207872
End of epoch 324 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001775
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 324, TEST ACC: [91.654 %]

saving the latest model (epoch 325, total_steps 1207888)
(epoch: 325, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 325, iters: 128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 325, iters: 208, time: 0.095, data: 0.049) loss: 0.002 
(epoch: 325, iters: 288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 325, iters: 368, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 325, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 325, iters: 528, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 325, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 325, iters: 688, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 325, iters: 768, time: 0.096, data: 0.039) loss: 0.005 
(epoch: 325, iters: 848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 325, iters: 928, time: 0.094, data: 0.011) loss: 0.096 
(epoch: 325, iters: 1008, time: 0.096, data: 0.000) loss: 0.183 
(epoch: 325, iters: 1088, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 325, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 325, iters: 1248, time: 0.095, data: 0.000) loss: 0.200 
(epoch: 325, iters: 1328, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 325, iters: 1408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 325, iters: 1488, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 325, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 325, iters: 1648, time: 0.095, data: 0.012) loss: 0.020 
(epoch: 325, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 325, iters: 1808, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 325, iters: 1888, time: 0.094, data: 0.038) loss: 0.003 
(epoch: 325, iters: 1968, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 325, iters: 2048, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 325, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 325, iters: 2208, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 325, iters: 2288, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 325, iters: 2368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 325, iters: 2448, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 325, iters: 2528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 325, iters: 2608, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 325, iters: 2688, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 325, iters: 2768, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 325, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 325, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 325, iters: 3008, time: 0.094, data: 0.041) loss: 0.010 
(epoch: 325, iters: 3088, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 325, iters: 3168, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 325, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 325, iters: 3328, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 325, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 325, iters: 3488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 325, iters: 3568, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 325, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 325, iters: 3728, time: 0.055, data: 0.012) loss: 0.001 
saving the model at the end of epoch 325, iters 1211600
End of epoch 325 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001774
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 325, TEST ACC: [95.296 %]

saving the latest model (epoch 326, total_steps 1211616)
(epoch: 326, iters: 80, time: 0.092, data: 0.504) loss: 0.000 
(epoch: 326, iters: 160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 326, iters: 240, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 326, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 326, iters: 400, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 326, iters: 480, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 326, iters: 560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 326, iters: 640, time: 0.095, data: 0.022) loss: 0.000 
(epoch: 326, iters: 720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 326, iters: 800, time: 0.094, data: 0.013) loss: 0.008 
(epoch: 326, iters: 880, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 326, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 326, iters: 1040, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 326, iters: 1120, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 326, iters: 1200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 326, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 326, iters: 1360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 326, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 326, iters: 1520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 326, iters: 1600, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 326, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 326, iters: 1760, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 326, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 326, iters: 1920, time: 0.096, data: 0.012) loss: 0.003 
(epoch: 326, iters: 2000, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 326, iters: 2080, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 326, iters: 2160, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 326, iters: 2240, time: 0.097, data: 0.000) loss: 0.012 
(epoch: 326, iters: 2320, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 326, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 326, iters: 2480, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 326, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 326, iters: 2640, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 326, iters: 2720, time: 0.096, data: 0.040) loss: 0.006 
(epoch: 326, iters: 2800, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 326, iters: 2880, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 326, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 326, iters: 3040, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 326, iters: 3120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 326, iters: 3200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 326, iters: 3280, time: 0.093, data: 0.041) loss: 0.001 
(epoch: 326, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 326, iters: 3440, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 326, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 326, iters: 3600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 326, iters: 3680, time: 0.087, data: 0.000) loss: 0.002 
saving the model at the end of epoch 326, iters 1215328
End of epoch 326 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001773
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 326, TEST ACC: [96.51 %]

saving the latest model (epoch 327, total_steps 1215344)
(epoch: 327, iters: 32, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 327, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 327, iters: 192, time: 0.092, data: 0.011) loss: 0.004 
(epoch: 327, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 327, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 327, iters: 432, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 327, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 327, iters: 592, time: 0.091, data: 0.021) loss: 0.003 
(epoch: 327, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 327, iters: 752, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 327, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 327, iters: 912, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 327, iters: 992, time: 0.094, data: 0.039) loss: 0.126 
(epoch: 327, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 327, iters: 1152, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 327, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 327, iters: 1312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 327, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 327, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 327, iters: 1552, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 327, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 327, iters: 1712, time: 0.093, data: 0.013) loss: 0.004 
(epoch: 327, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 327, iters: 1872, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 327, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 327, iters: 2032, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 327, iters: 2112, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 327, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 327, iters: 2272, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 327, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 327, iters: 2432, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 327, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 327, iters: 2592, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 327, iters: 2672, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 327, iters: 2752, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 327, iters: 2832, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 327, iters: 2912, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 327, iters: 2992, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 327, iters: 3072, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 327, iters: 3152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 327, iters: 3232, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 327, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 327, iters: 3392, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 327, iters: 3472, time: 0.095, data: 0.000) loss: 0.025 
(epoch: 327, iters: 3552, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 327, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 327, iters: 3712, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 327, iters 1219056
End of epoch 327 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001772
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 327, TEST ACC: [97.117 %]

saving the latest model (epoch 328, total_steps 1219072)
(epoch: 328, iters: 64, time: 0.094, data: 0.002) loss: 0.000 
(epoch: 328, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 328, iters: 224, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 328, iters: 304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 328, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 328, iters: 464, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 328, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 328, iters: 624, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 328, iters: 704, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 328, iters: 784, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 328, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 328, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 328, iters: 1024, time: 0.094, data: 0.048) loss: 0.001 
(epoch: 328, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 328, iters: 1184, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 328, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 328, iters: 1344, time: 0.094, data: 0.011) loss: 0.007 
(epoch: 328, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 328, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 328, iters: 1584, time: 0.094, data: 0.040) loss: 0.038 
(epoch: 328, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 328, iters: 1744, time: 0.092, data: 0.011) loss: 0.004 
(epoch: 328, iters: 1824, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 328, iters: 1904, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 328, iters: 1984, time: 0.095, data: 0.000) loss: 0.028 
(epoch: 328, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 328, iters: 2144, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 328, iters: 2224, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 328, iters: 2304, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 328, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 328, iters: 2464, time: 0.093, data: 0.012) loss: 0.014 
(epoch: 328, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 328, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 328, iters: 2704, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 328, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 328, iters: 2864, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 328, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 328, iters: 3024, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 328, iters: 3104, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 328, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 328, iters: 3264, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 328, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 328, iters: 3424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 328, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 328, iters: 3584, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 328, iters: 3664, time: 0.089, data: 0.000) loss: 0.001 
saving the model at the end of epoch 328, iters 1222784
End of epoch 328 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001771
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 328, TEST ACC: [95.751 %]

(epoch: 329, iters: 16, time: 0.110, data: 0.000) loss: 0.000 
saving the latest model (epoch 329, total_steps 1222800)
(epoch: 329, iters: 96, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 329, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 329, iters: 256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 329, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 329, iters: 416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 329, iters: 496, time: 0.093, data: 0.039) loss: 0.008 
(epoch: 329, iters: 576, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 329, iters: 656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 329, iters: 736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 329, iters: 816, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 329, iters: 896, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 329, iters: 976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 329, iters: 1056, time: 0.094, data: 0.050) loss: 0.010 
(epoch: 329, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 329, iters: 1216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 329, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 329, iters: 1376, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 329, iters: 1456, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 329, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 329, iters: 1616, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 329, iters: 1696, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 329, iters: 1776, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 329, iters: 1856, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 329, iters: 1936, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 329, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 329, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 329, iters: 2176, time: 0.096, data: 0.040) loss: 0.260 
(epoch: 329, iters: 2256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 329, iters: 2336, time: 0.091, data: 0.013) loss: 0.139 
(epoch: 329, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 329, iters: 2496, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 329, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 329, iters: 2656, time: 0.093, data: 0.000) loss: 0.028 
(epoch: 329, iters: 2736, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 329, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 329, iters: 2896, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 329, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 329, iters: 3056, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 329, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 329, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 329, iters: 3296, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 329, iters: 3376, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 329, iters: 3456, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 329, iters: 3536, time: 0.093, data: 0.000) loss: 0.208 
(epoch: 329, iters: 3616, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 329, iters: 3696, time: 0.088, data: 0.000) loss: 0.005 
saving the model at the end of epoch 329, iters 1226512
End of epoch 329 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001770
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 329, TEST ACC: [94.992 %]

saving the latest model (epoch 330, total_steps 1226528)
(epoch: 330, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 330, iters: 128, time: 0.095, data: 0.057) loss: 0.022 
(epoch: 330, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 330, iters: 288, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 330, iters: 368, time: 0.095, data: 0.000) loss: 0.321 
(epoch: 330, iters: 448, time: 0.093, data: 0.012) loss: 0.383 
(epoch: 330, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 330, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 330, iters: 688, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 330, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 330, iters: 848, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 330, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 330, iters: 1008, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 330, iters: 1088, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 330, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 330, iters: 1248, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 330, iters: 1328, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 330, iters: 1408, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 330, iters: 1488, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 330, iters: 1568, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 330, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 330, iters: 1728, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 330, iters: 1808, time: 0.098, data: 0.049) loss: 0.000 
(epoch: 330, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 330, iters: 1968, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 330, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 330, iters: 2128, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 330, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 330, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 330, iters: 2368, time: 0.094, data: 0.038) loss: 0.002 
(epoch: 330, iters: 2448, time: 0.095, data: 0.000) loss: 0.059 
(epoch: 330, iters: 2528, time: 0.092, data: 0.012) loss: 0.011 
(epoch: 330, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 330, iters: 2688, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 330, iters: 2768, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 330, iters: 2848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 330, iters: 2928, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 330, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 330, iters: 3088, time: 0.092, data: 0.021) loss: 0.354 
(epoch: 330, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 330, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 330, iters: 3328, time: 0.095, data: 0.000) loss: 0.018 
(epoch: 330, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 330, iters: 3488, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 330, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 330, iters: 3648, time: 0.086, data: 0.012) loss: 0.006 
(epoch: 330, iters: 3728, time: 0.056, data: 0.000) loss: 0.005 
saving the model at the end of epoch 330, iters 1230240
End of epoch 330 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001769
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 330, TEST ACC: [95.751 %]

saving the latest model (epoch 331, total_steps 1230256)
(epoch: 331, iters: 80, time: 0.097, data: 0.293) loss: 0.014 
(epoch: 331, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 331, iters: 240, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 331, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 331, iters: 400, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 331, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 331, iters: 560, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 331, iters: 640, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 331, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 331, iters: 800, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 331, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 331, iters: 960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 331, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 331, iters: 1120, time: 0.094, data: 0.012) loss: 0.009 
(epoch: 331, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 331, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 331, iters: 1360, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 331, iters: 1440, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 331, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 331, iters: 1600, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 331, iters: 1680, time: 0.092, data: 0.011) loss: 0.070 
(epoch: 331, iters: 1760, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 331, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 331, iters: 1920, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 331, iters: 2000, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 331, iters: 2080, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 331, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 331, iters: 2240, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 331, iters: 2320, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 331, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 331, iters: 2480, time: 0.095, data: 0.051) loss: 0.002 
(epoch: 331, iters: 2560, time: 0.095, data: 0.000) loss: 0.050 
(epoch: 331, iters: 2640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 331, iters: 2720, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 331, iters: 2800, time: 0.094, data: 0.011) loss: 0.005 
(epoch: 331, iters: 2880, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 331, iters: 2960, time: 0.093, data: 0.000) loss: 0.116 
(epoch: 331, iters: 3040, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 331, iters: 3120, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 331, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 331, iters: 3280, time: 0.096, data: 0.000) loss: 0.058 
(epoch: 331, iters: 3360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 331, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 331, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 331, iters: 3600, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 331, iters: 3680, time: 0.090, data: 0.000) loss: 0.045 
saving the model at the end of epoch 331, iters 1233968
End of epoch 331 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001768
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 331, TEST ACC: [96.055 %]

saving the latest model (epoch 332, total_steps 1233984)
(epoch: 332, iters: 32, time: 0.094, data: 0.005) loss: 0.000 
(epoch: 332, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 332, iters: 192, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 332, iters: 272, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 332, iters: 352, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 332, iters: 432, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 332, iters: 512, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 332, iters: 592, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 332, iters: 672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 332, iters: 752, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 332, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 332, iters: 912, time: 0.093, data: 0.039) loss: 0.019 
(epoch: 332, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 332, iters: 1072, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 332, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 332, iters: 1232, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 332, iters: 1312, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 332, iters: 1392, time: 0.093, data: 0.000) loss: 0.019 
(epoch: 332, iters: 1472, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 332, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 332, iters: 1632, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 332, iters: 1712, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 332, iters: 1792, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 332, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 332, iters: 1952, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 332, iters: 2032, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 332, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 332, iters: 2192, time: 0.091, data: 0.012) loss: 0.094 
(epoch: 332, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 332, iters: 2352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 332, iters: 2432, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 332, iters: 2512, time: 0.093, data: 0.000) loss: 0.143 
(epoch: 332, iters: 2592, time: 0.094, data: 0.039) loss: 0.013 
(epoch: 332, iters: 2672, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 332, iters: 2752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 332, iters: 2832, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 332, iters: 2912, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 332, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 332, iters: 3072, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 332, iters: 3152, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 332, iters: 3232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 332, iters: 3312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 332, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 332, iters: 3472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 332, iters: 3552, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 332, iters: 3632, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 332, iters: 3712, time: 0.087, data: 0.035) loss: 0.000 
saving the model at the end of epoch 332, iters 1237696
End of epoch 332 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001767
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 332, TEST ACC: [94.082 %]

saving the latest model (epoch 333, total_steps 1237712)
(epoch: 333, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 333, iters: 144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 333, iters: 224, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 333, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 333, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 333, iters: 464, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 333, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 333, iters: 624, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 333, iters: 704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 333, iters: 784, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 333, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 333, iters: 944, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 333, iters: 1024, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 333, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 333, iters: 1184, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 333, iters: 1264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 333, iters: 1344, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 333, iters: 1424, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 333, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 333, iters: 1584, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 333, iters: 1664, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 333, iters: 1744, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 333, iters: 1824, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 333, iters: 1904, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 333, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 333, iters: 2064, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 333, iters: 2144, time: 0.094, data: 0.049) loss: 0.003 
(epoch: 333, iters: 2224, time: 0.095, data: 0.000) loss: 0.033 
(epoch: 333, iters: 2304, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 333, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 333, iters: 2464, time: 0.093, data: 0.011) loss: 0.016 
(epoch: 333, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 333, iters: 2624, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 333, iters: 2704, time: 0.094, data: 0.039) loss: 0.002 
(epoch: 333, iters: 2784, time: 0.095, data: 0.000) loss: 0.022 
(epoch: 333, iters: 2864, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 333, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 333, iters: 3024, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 333, iters: 3104, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 333, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 333, iters: 3264, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 333, iters: 3344, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 333, iters: 3424, time: 0.094, data: 0.011) loss: 0.056 
(epoch: 333, iters: 3504, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 333, iters: 3584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 333, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 333, iters 1241424
End of epoch 333 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001766
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 333, TEST ACC: [93.475 %]

(epoch: 334, iters: 16, time: 0.106, data: 0.000) loss: 0.000 
saving the latest model (epoch 334, total_steps 1241440)
(epoch: 334, iters: 96, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 334, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 334, iters: 256, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 334, iters: 336, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 334, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 334, iters: 496, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 334, iters: 576, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 334, iters: 656, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 334, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 334, iters: 816, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 334, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 334, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 334, iters: 1056, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 334, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 334, iters: 1216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 334, iters: 1296, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 334, iters: 1376, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 334, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 334, iters: 1536, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 334, iters: 1616, time: 0.095, data: 0.048) loss: 0.002 
(epoch: 334, iters: 1696, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 334, iters: 1776, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 334, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 334, iters: 1936, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 334, iters: 2016, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 334, iters: 2096, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 334, iters: 2176, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 334, iters: 2256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 334, iters: 2336, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 334, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 334, iters: 2496, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 334, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 334, iters: 2656, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 334, iters: 2736, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 334, iters: 2816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 334, iters: 2896, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 334, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 334, iters: 3056, time: 0.092, data: 0.012) loss: 0.032 
(epoch: 334, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 334, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 334, iters: 3296, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 334, iters: 3376, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 334, iters: 3456, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 334, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 334, iters: 3616, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 334, iters: 3696, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 334, iters 1245152
End of epoch 334 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001765
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 334, TEST ACC: [95.144 %]

saving the latest model (epoch 335, total_steps 1245168)
(epoch: 335, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 335, iters: 128, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 335, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 335, iters: 288, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 335, iters: 368, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 335, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 335, iters: 528, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 335, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 335, iters: 688, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 335, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 335, iters: 848, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 335, iters: 928, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 335, iters: 1008, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 335, iters: 1088, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 335, iters: 1168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 335, iters: 1248, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 335, iters: 1328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 335, iters: 1408, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 335, iters: 1488, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 335, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 335, iters: 1648, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 335, iters: 1728, time: 0.093, data: 0.000) loss: 0.020 
(epoch: 335, iters: 1808, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 335, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 335, iters: 1968, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 335, iters: 2048, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 335, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 335, iters: 2208, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 335, iters: 2288, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 335, iters: 2368, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 335, iters: 2448, time: 0.095, data: 0.000) loss: 0.034 
(epoch: 335, iters: 2528, time: 0.093, data: 0.000) loss: 0.038 
(epoch: 335, iters: 2608, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 335, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 335, iters: 2768, time: 0.092, data: 0.011) loss: 0.008 
(epoch: 335, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 335, iters: 2928, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 335, iters: 3008, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 335, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 335, iters: 3168, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 335, iters: 3248, time: 0.094, data: 0.000) loss: 0.113 
(epoch: 335, iters: 3328, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 335, iters: 3408, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 335, iters: 3488, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 335, iters: 3568, time: 0.097, data: 0.000) loss: 0.025 
(epoch: 335, iters: 3648, time: 0.087, data: 0.000) loss: 0.000 
(epoch: 335, iters: 3728, time: 0.056, data: 0.015) loss: 0.000 
saving the model at the end of epoch 335, iters 1248880
End of epoch 335 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001764
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 335, TEST ACC: [92.868 %]

saving the latest model (epoch 336, total_steps 1248896)
(epoch: 336, iters: 80, time: 0.094, data: 0.468) loss: 0.000 
(epoch: 336, iters: 160, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 336, iters: 240, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 336, iters: 320, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 336, iters: 400, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 336, iters: 480, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 336, iters: 560, time: 0.095, data: 0.012) loss: 0.014 
(epoch: 336, iters: 640, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 336, iters: 720, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 336, iters: 800, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 336, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 336, iters: 960, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 336, iters: 1040, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 336, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 336, iters: 1200, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 336, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 336, iters: 1360, time: 0.094, data: 0.048) loss: 0.001 
(epoch: 336, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 336, iters: 1520, time: 0.092, data: 0.011) loss: 0.011 
(epoch: 336, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 336, iters: 1680, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 336, iters: 1760, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 336, iters: 1840, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 336, iters: 1920, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 336, iters: 2000, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 336, iters: 2080, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 336, iters: 2160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 336, iters: 2240, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 336, iters: 2320, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 336, iters: 2400, time: 0.093, data: 0.000) loss: 0.283 
(epoch: 336, iters: 2480, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 336, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 336, iters: 2640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 336, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 336, iters: 2800, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 336, iters: 2880, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 336, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 336, iters: 3040, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 336, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 336, iters: 3200, time: 0.092, data: 0.011) loss: 0.539 
(epoch: 336, iters: 3280, time: 0.093, data: 0.000) loss: 0.084 
(epoch: 336, iters: 3360, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 336, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 336, iters: 3520, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 336, iters: 3600, time: 0.095, data: 0.040) loss: 0.215 
(epoch: 336, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 336, iters 1252608
End of epoch 336 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001763
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 336, TEST ACC: [94.385 %]

saving the latest model (epoch 337, total_steps 1252624)
(epoch: 337, iters: 32, time: 0.093, data: 0.004) loss: 0.001 
(epoch: 337, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 337, iters: 192, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 337, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 337, iters: 352, time: 0.093, data: 0.039) loss: 0.084 
(epoch: 337, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 337, iters: 512, time: 0.093, data: 0.011) loss: 0.082 
(epoch: 337, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 337, iters: 672, time: 0.095, data: 0.011) loss: 0.069 
(epoch: 337, iters: 752, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 337, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 337, iters: 912, time: 0.095, data: 0.049) loss: 0.001 
(epoch: 337, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 337, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 337, iters: 1152, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 337, iters: 1232, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 337, iters: 1312, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 337, iters: 1392, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 337, iters: 1472, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 337, iters: 1552, time: 0.094, data: 0.000) loss: 0.024 
(epoch: 337, iters: 1632, time: 0.092, data: 0.020) loss: 0.001 
(epoch: 337, iters: 1712, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 337, iters: 1792, time: 0.093, data: 0.011) loss: 0.023 
(epoch: 337, iters: 1872, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 337, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 337, iters: 2032, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 337, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 337, iters: 2192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 337, iters: 2272, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 337, iters: 2352, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 337, iters: 2432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 337, iters: 2512, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 337, iters: 2592, time: 0.097, data: 0.049) loss: 0.000 
(epoch: 337, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 337, iters: 2752, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 337, iters: 2832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 337, iters: 2912, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 337, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 337, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 337, iters: 3152, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 337, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 337, iters: 3312, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 337, iters: 3392, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 337, iters: 3472, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 337, iters: 3552, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 337, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 337, iters: 3712, time: 0.089, data: 0.037) loss: 0.000 
saving the model at the end of epoch 337, iters 1256336
End of epoch 337 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001762
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 337, TEST ACC: [95.296 %]

saving the latest model (epoch 338, total_steps 1256352)
(epoch: 338, iters: 64, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 338, iters: 144, time: 0.096, data: 0.000) loss: 0.016 
(epoch: 338, iters: 224, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 338, iters: 304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 338, iters: 384, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 338, iters: 464, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 338, iters: 544, time: 0.094, data: 0.000) loss: 0.055 
(epoch: 338, iters: 624, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 338, iters: 704, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 338, iters: 784, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 338, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 338, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 338, iters: 1024, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 338, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 338, iters: 1184, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 338, iters: 1264, time: 0.096, data: 0.000) loss: 0.026 
(epoch: 338, iters: 1344, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 338, iters: 1424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 338, iters: 1504, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 338, iters: 1584, time: 0.094, data: 0.039) loss: 0.005 
(epoch: 338, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 338, iters: 1744, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 338, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 338, iters: 1904, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 338, iters: 1984, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 338, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 338, iters: 2144, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 338, iters: 2224, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 338, iters: 2304, time: 0.092, data: 0.012) loss: 0.010 
(epoch: 338, iters: 2384, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 338, iters: 2464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 338, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 338, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 338, iters: 2704, time: 0.097, data: 0.049) loss: 0.000 
(epoch: 338, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 338, iters: 2864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 338, iters: 2944, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 338, iters: 3024, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 338, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 338, iters: 3184, time: 0.092, data: 0.000) loss: 0.003 
(epoch: 338, iters: 3264, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 338, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 338, iters: 3424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 338, iters: 3504, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 338, iters: 3584, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 338, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 338, iters 1260064
End of epoch 338 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001761
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 338, TEST ACC: [95.599 %]

(epoch: 339, iters: 16, time: 0.114, data: 0.000) loss: 0.000 
saving the latest model (epoch 339, total_steps 1260080)
(epoch: 339, iters: 96, time: 0.095, data: 0.045) loss: 0.000 
(epoch: 339, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 339, iters: 256, time: 0.092, data: 0.012) loss: 0.023 
(epoch: 339, iters: 336, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 339, iters: 416, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 339, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 339, iters: 576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 339, iters: 656, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 339, iters: 736, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 339, iters: 816, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 339, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 339, iters: 976, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 339, iters: 1056, time: 0.097, data: 0.000) loss: 0.081 
(epoch: 339, iters: 1136, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 339, iters: 1216, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 339, iters: 1296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 339, iters: 1376, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 339, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 339, iters: 1536, time: 0.093, data: 0.012) loss: 0.021 
(epoch: 339, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 339, iters: 1696, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 339, iters: 1776, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 339, iters: 1856, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 339, iters: 1936, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 339, iters: 2016, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 339, iters: 2096, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 339, iters: 2176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 339, iters: 2256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 339, iters: 2336, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 339, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 339, iters: 2496, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 339, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 339, iters: 2656, time: 0.095, data: 0.020) loss: 0.001 
(epoch: 339, iters: 2736, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 339, iters: 2816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 339, iters: 2896, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 339, iters: 2976, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 339, iters: 3056, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 339, iters: 3136, time: 0.094, data: 0.000) loss: 0.024 
(epoch: 339, iters: 3216, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 339, iters: 3296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 339, iters: 3376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 339, iters: 3456, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 339, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 339, iters: 3616, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 339, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 339, iters 1263792
End of epoch 339 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001760
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 339, TEST ACC: [94.537 %]

saving the latest model (epoch 340, total_steps 1263808)
(epoch: 340, iters: 48, time: 0.094, data: 0.004) loss: 0.000 
(epoch: 340, iters: 128, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 340, iters: 208, time: 0.094, data: 0.000) loss: 0.147 
(epoch: 340, iters: 288, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 340, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 340, iters: 448, time: 0.095, data: 0.011) loss: 0.021 
(epoch: 340, iters: 528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 340, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 340, iters: 688, time: 0.097, data: 0.049) loss: 0.000 
(epoch: 340, iters: 768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 340, iters: 848, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 340, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 340, iters: 1008, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 340, iters: 1088, time: 0.096, data: 0.000) loss: 0.092 
(epoch: 340, iters: 1168, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 340, iters: 1248, time: 0.094, data: 0.038) loss: 0.001 
(epoch: 340, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 340, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 340, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 340, iters: 1568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 340, iters: 1648, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 340, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 340, iters: 1808, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 340, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 340, iters: 1968, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 340, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 340, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 340, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 340, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 340, iters: 2368, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 340, iters: 2448, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 340, iters: 2528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 340, iters: 2608, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 340, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 340, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 340, iters: 2848, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 340, iters: 2928, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 340, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 340, iters: 3088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 340, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 340, iters: 3248, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 340, iters: 3328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 340, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 340, iters: 3488, time: 0.097, data: 0.039) loss: 0.000 
(epoch: 340, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 340, iters: 3648, time: 0.088, data: 0.012) loss: 0.001 
(epoch: 340, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 340, iters 1267520
End of epoch 340 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001759
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 340, TEST ACC: [89.074 %]

saving the latest model (epoch 341, total_steps 1267536)
(epoch: 341, iters: 80, time: 0.097, data: 0.531) loss: 0.000 
(epoch: 341, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 341, iters: 240, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 341, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 341, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 341, iters: 480, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 341, iters: 560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 341, iters: 640, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 341, iters: 720, time: 0.092, data: 0.000) loss: 0.030 
(epoch: 341, iters: 800, time: 0.097, data: 0.039) loss: 0.000 
(epoch: 341, iters: 880, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 341, iters: 960, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 341, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 341, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 341, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 341, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 341, iters: 1360, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 341, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 341, iters: 1520, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 341, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 341, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 341, iters: 1760, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 341, iters: 1840, time: 0.093, data: 0.000) loss: 0.023 
(epoch: 341, iters: 1920, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 341, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 341, iters: 2080, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 341, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 341, iters: 2240, time: 0.093, data: 0.012) loss: 0.024 
(epoch: 341, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 341, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 341, iters: 2480, time: 0.095, data: 0.048) loss: 0.003 
(epoch: 341, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 341, iters: 2640, time: 0.094, data: 0.011) loss: 0.035 
(epoch: 341, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 341, iters: 2800, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 341, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 341, iters: 2960, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 341, iters: 3040, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 341, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 341, iters: 3200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 341, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 341, iters: 3360, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 341, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 341, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 341, iters: 3600, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 341, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 341, iters 1271248
End of epoch 341 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001758
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 341, TEST ACC: [94.841 %]

saving the latest model (epoch 342, total_steps 1271264)
(epoch: 342, iters: 32, time: 0.093, data: 0.005) loss: 0.000 
(epoch: 342, iters: 112, time: 0.095, data: 0.011) loss: 0.300 
(epoch: 342, iters: 192, time: 0.092, data: 0.011) loss: 0.016 
(epoch: 342, iters: 272, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 342, iters: 352, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 342, iters: 432, time: 0.097, data: 0.000) loss: 0.235 
(epoch: 342, iters: 512, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 342, iters: 592, time: 0.095, data: 0.039) loss: 0.027 
(epoch: 342, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 342, iters: 752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 342, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 342, iters: 912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 342, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 342, iters: 1072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 342, iters: 1152, time: 0.093, data: 0.048) loss: 0.004 
(epoch: 342, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 342, iters: 1312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 342, iters: 1392, time: 0.094, data: 0.000) loss: 0.075 
(epoch: 342, iters: 1472, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 342, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 342, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 342, iters: 1712, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 342, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 342, iters: 1872, time: 0.091, data: 0.012) loss: 0.016 
(epoch: 342, iters: 1952, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 342, iters: 2032, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 342, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 342, iters: 2192, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 342, iters: 2272, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 342, iters: 2352, time: 0.094, data: 0.000) loss: 0.048 
(epoch: 342, iters: 2432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 342, iters: 2512, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 342, iters: 2592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 342, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 342, iters: 2752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 342, iters: 2832, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 342, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 342, iters: 2992, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 342, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 342, iters: 3152, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 342, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 342, iters: 3312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 342, iters: 3392, time: 0.096, data: 0.040) loss: 0.002 
(epoch: 342, iters: 3472, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 342, iters: 3552, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 342, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 342, iters: 3712, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 342, iters 1274976
End of epoch 342 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001757
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 342, TEST ACC: [97.117 %]

saving the latest model (epoch 343, total_steps 1274992)
(epoch: 343, iters: 64, time: 0.092, data: 0.003) loss: 0.003 
(epoch: 343, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 343, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 343, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 343, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 343, iters: 464, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 343, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 343, iters: 624, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 343, iters: 704, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 343, iters: 784, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 343, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 343, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 343, iters: 1024, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 343, iters: 1104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 343, iters: 1184, time: 0.092, data: 0.012) loss: 0.530 
(epoch: 343, iters: 1264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 343, iters: 1344, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 343, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 343, iters: 1504, time: 0.093, data: 0.000) loss: 0.092 
(epoch: 343, iters: 1584, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 343, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 343, iters: 1744, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 343, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 343, iters: 1904, time: 0.093, data: 0.013) loss: 0.002 
(epoch: 343, iters: 1984, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 343, iters: 2064, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 343, iters: 2144, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 343, iters: 2224, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 343, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 343, iters: 2384, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 343, iters: 2464, time: 0.093, data: 0.012) loss: 0.015 
(epoch: 343, iters: 2544, time: 0.093, data: 0.000) loss: 0.013 
(epoch: 343, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 343, iters: 2704, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 343, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 343, iters: 2864, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 343, iters: 2944, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 343, iters: 3024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 343, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 343, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 343, iters: 3264, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 343, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 343, iters: 3424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 343, iters: 3504, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 343, iters: 3584, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 343, iters: 3664, time: 0.089, data: 0.000) loss: 0.001 
saving the model at the end of epoch 343, iters 1278704
End of epoch 343 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001756
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 343, TEST ACC: [95.296 %]

(epoch: 344, iters: 16, time: 0.108, data: 0.000) loss: 0.000 
saving the latest model (epoch 344, total_steps 1278720)
(epoch: 344, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 344, iters: 176, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 344, iters: 256, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 344, iters: 336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 344, iters: 416, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 344, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 344, iters: 576, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 344, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 344, iters: 736, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 344, iters: 816, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 344, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 344, iters: 976, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 344, iters: 1056, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 344, iters: 1136, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 344, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 344, iters: 1296, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 344, iters: 1376, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 344, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 344, iters: 1536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 344, iters: 1616, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 344, iters: 1696, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 344, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 344, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 344, iters: 1936, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 344, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 344, iters: 2096, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 344, iters: 2176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 344, iters: 2256, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 344, iters: 2336, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 344, iters: 2416, time: 0.095, data: 0.000) loss: 0.036 
(epoch: 344, iters: 2496, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 344, iters: 2576, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 344, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 344, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 344, iters: 2816, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 344, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 344, iters: 2976, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 344, iters: 3056, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 344, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 344, iters: 3216, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 344, iters: 3296, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 344, iters: 3376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 344, iters: 3456, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 344, iters: 3536, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 344, iters: 3616, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 344, iters: 3696, time: 0.088, data: 0.000) loss: 0.168 
saving the model at the end of epoch 344, iters 1282432
End of epoch 344 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001755
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 344, TEST ACC: [95.448 %]

saving the latest model (epoch 345, total_steps 1282448)
(epoch: 345, iters: 48, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 345, iters: 128, time: 0.093, data: 0.057) loss: 0.000 
(epoch: 345, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 345, iters: 288, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 345, iters: 368, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 345, iters: 448, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 345, iters: 528, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 345, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 345, iters: 688, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 345, iters: 768, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 345, iters: 848, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 345, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 345, iters: 1008, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 345, iters: 1088, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 345, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 345, iters: 1248, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 345, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 345, iters: 1408, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 345, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 345, iters: 1568, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 345, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 345, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 345, iters: 1808, time: 0.096, data: 0.048) loss: 0.000 
(epoch: 345, iters: 1888, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 345, iters: 1968, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 345, iters: 2048, time: 0.093, data: 0.000) loss: 0.012 
(epoch: 345, iters: 2128, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 345, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 345, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 345, iters: 2368, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 345, iters: 2448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 345, iters: 2528, time: 0.092, data: 0.012) loss: 0.073 
(epoch: 345, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 345, iters: 2688, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 345, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 345, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 345, iters: 2928, time: 0.094, data: 0.049) loss: 0.011 
(epoch: 345, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 345, iters: 3088, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 345, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 345, iters: 3248, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 345, iters: 3328, time: 0.094, data: 0.000) loss: 0.030 
(epoch: 345, iters: 3408, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 345, iters: 3488, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 345, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 345, iters: 3648, time: 0.086, data: 0.011) loss: 0.000 
(epoch: 345, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 345, iters 1286160
End of epoch 345 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001754
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 345, TEST ACC: [96.206 %]

saving the latest model (epoch 346, total_steps 1286176)
(epoch: 346, iters: 80, time: 0.095, data: 0.515) loss: 0.000 
(epoch: 346, iters: 160, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 346, iters: 240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 346, iters: 320, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 346, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 346, iters: 480, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 346, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 346, iters: 640, time: 0.093, data: 0.000) loss: 0.010 
(epoch: 346, iters: 720, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 346, iters: 800, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 346, iters: 880, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 346, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 346, iters: 1040, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 346, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 346, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 346, iters: 1280, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 346, iters: 1360, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 346, iters: 1440, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 346, iters: 1520, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 346, iters: 1600, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 346, iters: 1680, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 346, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 346, iters: 1840, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 346, iters: 1920, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 346, iters: 2000, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 346, iters: 2080, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 346, iters: 2160, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 346, iters: 2240, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 346, iters: 2320, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 346, iters: 2400, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 346, iters: 2480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 346, iters: 2560, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 346, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 346, iters: 2720, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 346, iters: 2800, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 346, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 346, iters: 2960, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 346, iters: 3040, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 346, iters: 3120, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 346, iters: 3200, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 346, iters: 3280, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 346, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 346, iters: 3440, time: 0.094, data: 0.000) loss: 0.118 
(epoch: 346, iters: 3520, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 346, iters: 3600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 346, iters: 3680, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 346, iters 1289888
End of epoch 346 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001753
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 346, TEST ACC: [85.584 %]

saving the latest model (epoch 347, total_steps 1289904)
(epoch: 347, iters: 32, time: 0.093, data: 0.007) loss: 0.000 
(epoch: 347, iters: 112, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 347, iters: 192, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 347, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 347, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 347, iters: 432, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 347, iters: 512, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 347, iters: 592, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 347, iters: 672, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 347, iters: 752, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 347, iters: 832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 347, iters: 912, time: 0.093, data: 0.000) loss: 0.045 
(epoch: 347, iters: 992, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 347, iters: 1072, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 347, iters: 1152, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 347, iters: 1232, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 347, iters: 1312, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 347, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 347, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 347, iters: 1552, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 347, iters: 1632, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 347, iters: 1712, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 347, iters: 1792, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 347, iters: 1872, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 347, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 347, iters: 2032, time: 0.092, data: 0.000) loss: 0.028 
(epoch: 347, iters: 2112, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 347, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 347, iters: 2272, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 347, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 347, iters: 2432, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 347, iters: 2512, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 347, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 347, iters: 2672, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 347, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 347, iters: 2832, time: 0.091, data: 0.011) loss: 0.036 
(epoch: 347, iters: 2912, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 347, iters: 2992, time: 0.094, data: 0.011) loss: 0.022 
(epoch: 347, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 347, iters: 3152, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 347, iters: 3232, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 347, iters: 3312, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 347, iters: 3392, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 347, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 347, iters: 3552, time: 0.092, data: 0.011) loss: 0.126 
(epoch: 347, iters: 3632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 347, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 347, iters 1293616
End of epoch 347 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001752
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 347, TEST ACC: [91.502 %]

saving the latest model (epoch 348, total_steps 1293632)
(epoch: 348, iters: 64, time: 0.094, data: 0.002) loss: 0.002 
(epoch: 348, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 348, iters: 224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 348, iters: 304, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 348, iters: 384, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 348, iters: 464, time: 0.097, data: 0.050) loss: 0.037 
(epoch: 348, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 348, iters: 624, time: 0.092, data: 0.011) loss: 0.004 
(epoch: 348, iters: 704, time: 0.094, data: 0.000) loss: 0.349 
(epoch: 348, iters: 784, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 348, iters: 864, time: 0.095, data: 0.000) loss: 0.048 
(epoch: 348, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 348, iters: 1024, time: 0.098, data: 0.040) loss: 0.001 
(epoch: 348, iters: 1104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 348, iters: 1184, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 348, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 348, iters: 1344, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 348, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 348, iters: 1504, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 348, iters: 1584, time: 0.096, data: 0.039) loss: 0.022 
(epoch: 348, iters: 1664, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 348, iters: 1744, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 348, iters: 1824, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 348, iters: 1904, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 348, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 348, iters: 2064, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 348, iters: 2144, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 348, iters: 2224, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 348, iters: 2304, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 348, iters: 2384, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 348, iters: 2464, time: 0.093, data: 0.011) loss: 0.005 
(epoch: 348, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 348, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 348, iters: 2704, time: 0.095, data: 0.050) loss: 0.005 
(epoch: 348, iters: 2784, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 348, iters: 2864, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 348, iters: 2944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 348, iters: 3024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 348, iters: 3104, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 348, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 348, iters: 3264, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 348, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 348, iters: 3424, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 348, iters: 3504, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 348, iters: 3584, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 348, iters: 3664, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 348, iters 1297344
End of epoch 348 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001751
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 348, TEST ACC: [92.716 %]

(epoch: 349, iters: 16, time: 0.111, data: 0.000) loss: 0.000 
saving the latest model (epoch 349, total_steps 1297360)
(epoch: 349, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 349, iters: 176, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 349, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 349, iters: 336, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 349, iters: 416, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 349, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 349, iters: 576, time: 0.095, data: 0.039) loss: 0.005 
(epoch: 349, iters: 656, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 349, iters: 736, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 349, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 349, iters: 896, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 349, iters: 976, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 349, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 349, iters: 1136, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 349, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 349, iters: 1296, time: 0.092, data: 0.011) loss: 0.003 
(epoch: 349, iters: 1376, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 349, iters: 1456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 349, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 349, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 349, iters: 1696, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 349, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 349, iters: 1856, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 349, iters: 1936, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 349, iters: 2016, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 349, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 349, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 349, iters: 2256, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 349, iters: 2336, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 349, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 349, iters: 2496, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 349, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 349, iters: 2656, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 349, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 349, iters: 2816, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 349, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 349, iters: 2976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 349, iters: 3056, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 349, iters: 3136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 349, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 349, iters: 3296, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 349, iters: 3376, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 349, iters: 3456, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 349, iters: 3536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 349, iters: 3616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 349, iters: 3696, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 349, iters 1301072
End of epoch 349 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001750
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 349, TEST ACC: [94.234 %]

saving the latest model (epoch 350, total_steps 1301088)
(epoch: 350, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 350, iters: 128, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 350, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 350, iters: 288, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 350, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 350, iters: 448, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 350, iters: 528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 350, iters: 608, time: 0.093, data: 0.000) loss: 0.062 
(epoch: 350, iters: 688, time: 0.094, data: 0.039) loss: 0.082 
(epoch: 350, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 350, iters: 848, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 350, iters: 928, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 350, iters: 1008, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 350, iters: 1088, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 350, iters: 1168, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 350, iters: 1248, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 350, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 350, iters: 1408, time: 0.092, data: 0.011) loss: 0.013 
(epoch: 350, iters: 1488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 350, iters: 1568, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 350, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 350, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 350, iters: 1808, time: 0.094, data: 0.039) loss: 0.002 
(epoch: 350, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 350, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 350, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 350, iters: 2128, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 350, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 350, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 350, iters: 2368, time: 0.094, data: 0.048) loss: 0.004 
(epoch: 350, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 350, iters: 2528, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 350, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 350, iters: 2688, time: 0.093, data: 0.012) loss: 0.165 
(epoch: 350, iters: 2768, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 350, iters: 2848, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 350, iters: 2928, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 350, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 350, iters: 3088, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 350, iters: 3168, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 350, iters: 3248, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 350, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 350, iters: 3408, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 350, iters: 3488, time: 0.095, data: 0.041) loss: 0.283 
(epoch: 350, iters: 3568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 350, iters: 3648, time: 0.086, data: 0.011) loss: 0.000 
(epoch: 350, iters: 3728, time: 0.058, data: 0.000) loss: 0.000 
saving the model at the end of epoch 350, iters 1304800
End of epoch 350 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001749
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 350, TEST ACC: [87.405 %]

saving the latest model (epoch 351, total_steps 1304816)
(epoch: 351, iters: 80, time: 0.096, data: 0.509) loss: 0.002 
(epoch: 351, iters: 160, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 351, iters: 240, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 351, iters: 320, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 351, iters: 400, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 351, iters: 480, time: 0.095, data: 0.011) loss: 0.009 
(epoch: 351, iters: 560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 351, iters: 640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 351, iters: 720, time: 0.094, data: 0.039) loss: 0.015 
(epoch: 351, iters: 800, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 351, iters: 880, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 351, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 351, iters: 1040, time: 0.094, data: 0.011) loss: 0.041 
(epoch: 351, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 351, iters: 1200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 351, iters: 1280, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 351, iters: 1360, time: 0.094, data: 0.000) loss: 0.107 
(epoch: 351, iters: 1440, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 351, iters: 1520, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 351, iters: 1600, time: 0.093, data: 0.011) loss: 0.005 
(epoch: 351, iters: 1680, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 351, iters: 1760, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 351, iters: 1840, time: 0.096, data: 0.041) loss: 0.117 
(epoch: 351, iters: 1920, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 351, iters: 2000, time: 0.092, data: 0.022) loss: 0.001 
(epoch: 351, iters: 2080, time: 0.093, data: 0.000) loss: 0.008 
(epoch: 351, iters: 2160, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 351, iters: 2240, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 351, iters: 2320, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 351, iters: 2400, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 351, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 351, iters: 2560, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 351, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 351, iters: 2720, time: 0.095, data: 0.011) loss: 0.220 
(epoch: 351, iters: 2800, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 351, iters: 2880, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 351, iters: 2960, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 351, iters: 3040, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 351, iters: 3120, time: 0.093, data: 0.021) loss: 0.020 
(epoch: 351, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 351, iters: 3280, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 351, iters: 3360, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 351, iters: 3440, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 351, iters: 3520, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 351, iters: 3600, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 351, iters: 3680, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 351, iters 1308528
End of epoch 351 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001748
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 351, TEST ACC: [96.662 %]

saving the latest model (epoch 352, total_steps 1308544)
(epoch: 352, iters: 32, time: 0.093, data: 0.006) loss: 0.000 
(epoch: 352, iters: 112, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 352, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 352, iters: 272, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 352, iters: 352, time: 0.093, data: 0.052) loss: 0.000 
(epoch: 352, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 352, iters: 512, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 352, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 352, iters: 672, time: 0.093, data: 0.011) loss: 0.020 
(epoch: 352, iters: 752, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 352, iters: 832, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 352, iters: 912, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 352, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 352, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 352, iters: 1152, time: 0.093, data: 0.000) loss: 0.023 
(epoch: 352, iters: 1232, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 352, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 352, iters: 1392, time: 0.094, data: 0.000) loss: 0.045 
(epoch: 352, iters: 1472, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 352, iters: 1552, time: 0.095, data: 0.000) loss: 0.079 
(epoch: 352, iters: 1632, time: 0.095, data: 0.012) loss: 0.016 
(epoch: 352, iters: 1712, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 352, iters: 1792, time: 0.093, data: 0.012) loss: 0.046 
(epoch: 352, iters: 1872, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 352, iters: 1952, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 352, iters: 2032, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 352, iters: 2112, time: 0.095, data: 0.000) loss: 0.126 
(epoch: 352, iters: 2192, time: 0.092, data: 0.012) loss: 0.007 
(epoch: 352, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 352, iters: 2352, time: 0.096, data: 0.012) loss: 0.022 
(epoch: 352, iters: 2432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 352, iters: 2512, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 352, iters: 2592, time: 0.095, data: 0.038) loss: 0.002 
(epoch: 352, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 352, iters: 2752, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 352, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 352, iters: 2912, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 352, iters: 2992, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 352, iters: 3072, time: 0.092, data: 0.000) loss: 0.111 
(epoch: 352, iters: 3152, time: 0.094, data: 0.039) loss: 0.005 
(epoch: 352, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 352, iters: 3312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 352, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 352, iters: 3472, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 352, iters: 3552, time: 0.095, data: 0.000) loss: 0.050 
(epoch: 352, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 352, iters: 3712, time: 0.087, data: 0.036) loss: 0.000 
saving the model at the end of epoch 352, iters 1312256
End of epoch 352 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001747
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 352, TEST ACC: [94.537 %]

saving the latest model (epoch 353, total_steps 1312272)
(epoch: 353, iters: 64, time: 0.093, data: 0.000) loss: 0.016 
(epoch: 353, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 353, iters: 224, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 353, iters: 304, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 353, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 353, iters: 464, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 353, iters: 544, time: 0.095, data: 0.000) loss: 0.124 
(epoch: 353, iters: 624, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 353, iters: 704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 353, iters: 784, time: 0.094, data: 0.019) loss: 0.001 
(epoch: 353, iters: 864, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 353, iters: 944, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 353, iters: 1024, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 353, iters: 1104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 353, iters: 1184, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 353, iters: 1264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 353, iters: 1344, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 353, iters: 1424, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 353, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 353, iters: 1584, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 353, iters: 1664, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 353, iters: 1744, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 353, iters: 1824, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 353, iters: 1904, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 353, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 353, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 353, iters: 2144, time: 0.095, data: 0.039) loss: 0.017 
(epoch: 353, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 353, iters: 2304, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 353, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 353, iters: 2464, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 353, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 353, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 353, iters: 2704, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 353, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 353, iters: 2864, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 353, iters: 2944, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 353, iters: 3024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 353, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 353, iters: 3184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 353, iters: 3264, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 353, iters: 3344, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 353, iters: 3424, time: 0.092, data: 0.022) loss: 0.068 
(epoch: 353, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 353, iters: 3584, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 353, iters: 3664, time: 0.088, data: 0.000) loss: 0.002 
saving the model at the end of epoch 353, iters 1315984
End of epoch 353 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001746
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 353, TEST ACC: [94.234 %]

(epoch: 354, iters: 16, time: 0.107, data: 0.000) loss: 0.000 
saving the latest model (epoch 354, total_steps 1316000)
(epoch: 354, iters: 96, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 354, iters: 176, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 354, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 354, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 354, iters: 416, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 354, iters: 496, time: 0.093, data: 0.000) loss: 0.057 
(epoch: 354, iters: 576, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 354, iters: 656, time: 0.095, data: 0.000) loss: 0.146 
(epoch: 354, iters: 736, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 354, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 354, iters: 896, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 354, iters: 976, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 354, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 354, iters: 1136, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 354, iters: 1216, time: 0.096, data: 0.000) loss: 0.028 
(epoch: 354, iters: 1296, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 354, iters: 1376, time: 0.095, data: 0.000) loss: 0.023 
(epoch: 354, iters: 1456, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 354, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 354, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 354, iters: 1696, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 354, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 354, iters: 1856, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 354, iters: 1936, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 354, iters: 2016, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 354, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 354, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 354, iters: 2256, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 354, iters: 2336, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 354, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 354, iters: 2496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 354, iters: 2576, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 354, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 354, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 354, iters: 2816, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 354, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 354, iters: 2976, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 354, iters: 3056, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 354, iters: 3136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 354, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 354, iters: 3296, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 354, iters: 3376, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 354, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 354, iters: 3536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 354, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 354, iters: 3696, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 354, iters 1319712
End of epoch 354 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001745
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 354, TEST ACC: [96.055 %]

saving the latest model (epoch 355, total_steps 1319728)
(epoch: 355, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 355, iters: 128, time: 0.096, data: 0.058) loss: 0.010 
(epoch: 355, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 355, iters: 288, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 355, iters: 368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 355, iters: 448, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 355, iters: 528, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 355, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 355, iters: 688, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 355, iters: 768, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 355, iters: 848, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 355, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 355, iters: 1008, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 355, iters: 1088, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 355, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 355, iters: 1248, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 355, iters: 1328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 355, iters: 1408, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 355, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 355, iters: 1568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 355, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 355, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 355, iters: 1808, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 355, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 355, iters: 1968, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 355, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 355, iters: 2128, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 355, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 355, iters: 2288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 355, iters: 2368, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 355, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 355, iters: 2528, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 355, iters: 2608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 355, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 355, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 355, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 355, iters: 2928, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 355, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 355, iters: 3088, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 355, iters: 3168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 355, iters: 3248, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 355, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 355, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 355, iters: 3488, time: 0.094, data: 0.039) loss: 0.015 
(epoch: 355, iters: 3568, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 355, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 355, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 355, iters 1323440
End of epoch 355 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001744
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 355, TEST ACC: [95.903 %]

saving the latest model (epoch 356, total_steps 1323456)
(epoch: 356, iters: 80, time: 0.093, data: 0.463) loss: 0.000 
(epoch: 356, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 356, iters: 240, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 356, iters: 320, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 356, iters: 400, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 356, iters: 480, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 356, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 356, iters: 640, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 356, iters: 720, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 356, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 356, iters: 880, time: 0.095, data: 0.040) loss: 0.084 
(epoch: 356, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 356, iters: 1040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 356, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 356, iters: 1200, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 356, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 356, iters: 1360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 356, iters: 1440, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 356, iters: 1520, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 356, iters: 1600, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 356, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 356, iters: 1760, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 356, iters: 1840, time: 0.098, data: 0.000) loss: 0.162 
(epoch: 356, iters: 1920, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 356, iters: 2000, time: 0.096, data: 0.041) loss: 0.001 
(epoch: 356, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 356, iters: 2160, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 356, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 356, iters: 2320, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 356, iters: 2400, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 356, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 356, iters: 2560, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 356, iters: 2640, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 356, iters: 2720, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 356, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 356, iters: 2880, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 356, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 356, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 356, iters: 3120, time: 0.095, data: 0.039) loss: 0.450 
(epoch: 356, iters: 3200, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 356, iters: 3280, time: 0.095, data: 0.011) loss: 0.004 
(epoch: 356, iters: 3360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 356, iters: 3440, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 356, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 356, iters: 3600, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 356, iters: 3680, time: 0.087, data: 0.039) loss: 0.001 
saving the model at the end of epoch 356, iters 1327168
End of epoch 356 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001743
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 356, TEST ACC: [95.296 %]

saving the latest model (epoch 357, total_steps 1327184)
(epoch: 357, iters: 32, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 357, iters: 112, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 357, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 357, iters: 272, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 357, iters: 352, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 357, iters: 432, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 357, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 357, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 357, iters: 672, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 357, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 357, iters: 832, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 357, iters: 912, time: 0.096, data: 0.051) loss: 0.003 
(epoch: 357, iters: 992, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 357, iters: 1072, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 357, iters: 1152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 357, iters: 1232, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 357, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 357, iters: 1392, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 357, iters: 1472, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 357, iters: 1552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 357, iters: 1632, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 357, iters: 1712, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 357, iters: 1792, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 357, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 357, iters: 1952, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 357, iters: 2032, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 357, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 357, iters: 2192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 357, iters: 2272, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 357, iters: 2352, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 357, iters: 2432, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 357, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 357, iters: 2592, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 357, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 357, iters: 2752, time: 0.091, data: 0.011) loss: 0.001 
(epoch: 357, iters: 2832, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 357, iters: 2912, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 357, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 357, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 357, iters: 3152, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 357, iters: 3232, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 357, iters: 3312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 357, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 357, iters: 3472, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 357, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 357, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 357, iters: 3712, time: 0.088, data: 0.035) loss: 0.001 
saving the model at the end of epoch 357, iters 1330896
End of epoch 357 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001742
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 357, TEST ACC: [94.992 %]

saving the latest model (epoch 358, total_steps 1330912)
(epoch: 358, iters: 64, time: 0.094, data: 0.000) loss: 0.380 
(epoch: 358, iters: 144, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 358, iters: 224, time: 0.094, data: 0.013) loss: 0.002 
(epoch: 358, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 358, iters: 384, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 358, iters: 464, time: 0.093, data: 0.040) loss: 0.002 
(epoch: 358, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 358, iters: 624, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 358, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 358, iters: 784, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 358, iters: 864, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 358, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 358, iters: 1024, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 358, iters: 1104, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 358, iters: 1184, time: 0.091, data: 0.011) loss: 0.001 
(epoch: 358, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 358, iters: 1344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 358, iters: 1424, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 358, iters: 1504, time: 0.095, data: 0.000) loss: 0.118 
(epoch: 358, iters: 1584, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 358, iters: 1664, time: 0.094, data: 0.000) loss: 0.116 
(epoch: 358, iters: 1744, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 358, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 358, iters: 1904, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 358, iters: 1984, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 358, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 358, iters: 2144, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 358, iters: 2224, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 358, iters: 2304, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 358, iters: 2384, time: 0.095, data: 0.000) loss: 0.027 
(epoch: 358, iters: 2464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 358, iters: 2544, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 358, iters: 2624, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 358, iters: 2704, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 358, iters: 2784, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 358, iters: 2864, time: 0.093, data: 0.012) loss: 0.031 
(epoch: 358, iters: 2944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 358, iters: 3024, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 358, iters: 3104, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 358, iters: 3184, time: 0.092, data: 0.000) loss: 0.016 
(epoch: 358, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 358, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 358, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 358, iters: 3504, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 358, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 358, iters: 3664, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 358, iters 1334624
End of epoch 358 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001741
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 358, TEST ACC: [92.716 %]

(epoch: 359, iters: 16, time: 0.113, data: 0.014) loss: 0.000 
saving the latest model (epoch 359, total_steps 1334640)
(epoch: 359, iters: 96, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 359, iters: 176, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 359, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 359, iters: 336, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 359, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 359, iters: 496, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 359, iters: 576, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 359, iters: 656, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 359, iters: 736, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 359, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 359, iters: 896, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 359, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 359, iters: 1056, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 359, iters: 1136, time: 0.094, data: 0.048) loss: 0.002 
(epoch: 359, iters: 1216, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 359, iters: 1296, time: 0.092, data: 0.012) loss: 0.008 
(epoch: 359, iters: 1376, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 359, iters: 1456, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 359, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 359, iters: 1616, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 359, iters: 1696, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 359, iters: 1776, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 359, iters: 1856, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 359, iters: 1936, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 359, iters: 2016, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 359, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 359, iters: 2176, time: 0.095, data: 0.000) loss: 0.198 
(epoch: 359, iters: 2256, time: 0.094, data: 0.040) loss: 0.595 
(epoch: 359, iters: 2336, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 359, iters: 2416, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 359, iters: 2496, time: 0.094, data: 0.000) loss: 0.020 
(epoch: 359, iters: 2576, time: 0.094, data: 0.012) loss: 0.016 
(epoch: 359, iters: 2656, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 359, iters: 2736, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 359, iters: 2816, time: 0.094, data: 0.039) loss: 0.005 
(epoch: 359, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 359, iters: 2976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 359, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 359, iters: 3136, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 359, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 359, iters: 3296, time: 0.092, data: 0.000) loss: 0.006 
(epoch: 359, iters: 3376, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 359, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 359, iters: 3536, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 359, iters: 3616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 359, iters: 3696, time: 0.089, data: 0.026) loss: 0.011 
saving the model at the end of epoch 359, iters 1338352
End of epoch 359 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001740
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 359, TEST ACC: [96.206 %]

saving the latest model (epoch 360, total_steps 1338368)
(epoch: 360, iters: 48, time: 0.095, data: 0.004) loss: 0.000 
(epoch: 360, iters: 128, time: 0.093, data: 0.026) loss: 0.012 
(epoch: 360, iters: 208, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 360, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 360, iters: 368, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 360, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 360, iters: 528, time: 0.092, data: 0.000) loss: 0.007 
(epoch: 360, iters: 608, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 360, iters: 688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 360, iters: 768, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 360, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 360, iters: 928, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 360, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 360, iters: 1088, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 360, iters: 1168, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 360, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 360, iters: 1328, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 360, iters: 1408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 360, iters: 1488, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 360, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 360, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 360, iters: 1728, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 360, iters: 1808, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 360, iters: 1888, time: 0.092, data: 0.012) loss: 0.028 
(epoch: 360, iters: 1968, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 360, iters: 2048, time: 0.093, data: 0.012) loss: 0.029 
(epoch: 360, iters: 2128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 360, iters: 2208, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 360, iters: 2288, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 360, iters: 2368, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 360, iters: 2448, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 360, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 360, iters: 2608, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 360, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 360, iters: 2768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 360, iters: 2848, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 360, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 360, iters: 3008, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 360, iters: 3088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 360, iters: 3168, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 360, iters: 3248, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 360, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 360, iters: 3408, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 360, iters: 3488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 360, iters: 3568, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 360, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 360, iters: 3728, time: 0.057, data: 0.011) loss: 0.000 
saving the model at the end of epoch 360, iters 1342080
End of epoch 360 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001739
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 360, TEST ACC: [94.537 %]

saving the latest model (epoch 361, total_steps 1342096)
(epoch: 361, iters: 80, time: 0.094, data: 0.477) loss: 0.000 
(epoch: 361, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 361, iters: 240, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 361, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 361, iters: 400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 361, iters: 480, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 361, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 361, iters: 640, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 361, iters: 720, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 361, iters: 800, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 361, iters: 880, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 361, iters: 960, time: 0.092, data: 0.000) loss: 0.050 
(epoch: 361, iters: 1040, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 361, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 361, iters: 1200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 361, iters: 1280, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 361, iters: 1360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 361, iters: 1440, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 361, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 361, iters: 1600, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 361, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 361, iters: 1760, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 361, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 361, iters: 1920, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 361, iters: 2000, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 361, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 361, iters: 2160, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 361, iters: 2240, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 361, iters: 2320, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 361, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 361, iters: 2480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 361, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 361, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 361, iters: 2720, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 361, iters: 2800, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 361, iters: 2880, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 361, iters: 2960, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 361, iters: 3040, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 361, iters: 3120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 361, iters: 3200, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 361, iters: 3280, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 361, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 361, iters: 3440, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 361, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 361, iters: 3600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 361, iters: 3680, time: 0.086, data: 0.000) loss: 0.000 
saving the model at the end of epoch 361, iters 1345808
End of epoch 361 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001738
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 361, TEST ACC: [95.903 %]

saving the latest model (epoch 362, total_steps 1345824)
(epoch: 362, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 362, iters: 112, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 362, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 362, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 362, iters: 352, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 362, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 362, iters: 512, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 362, iters: 592, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 362, iters: 672, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 362, iters: 752, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 362, iters: 832, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 362, iters: 912, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 362, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 362, iters: 1072, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 362, iters: 1152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 362, iters: 1232, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 362, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 362, iters: 1392, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 362, iters: 1472, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 362, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 362, iters: 1632, time: 0.091, data: 0.011) loss: 0.002 
(epoch: 362, iters: 1712, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 362, iters: 1792, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 362, iters: 1872, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 362, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 362, iters: 2032, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 362, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 362, iters: 2192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 362, iters: 2272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 362, iters: 2352, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 362, iters: 2432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 362, iters: 2512, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 362, iters: 2592, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 362, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 362, iters: 2752, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 362, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 362, iters: 2912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 362, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 362, iters: 3072, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 362, iters: 3152, time: 0.094, data: 0.048) loss: 0.007 
(epoch: 362, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 362, iters: 3312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 362, iters: 3392, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 362, iters: 3472, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 362, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 362, iters: 3632, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 362, iters: 3712, time: 0.087, data: 0.036) loss: 0.000 
saving the model at the end of epoch 362, iters 1349536
End of epoch 362 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001737
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 362, TEST ACC: [93.627 %]

saving the latest model (epoch 363, total_steps 1349552)
(epoch: 363, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 363, iters: 144, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 363, iters: 224, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 363, iters: 304, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 363, iters: 384, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 363, iters: 464, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 363, iters: 544, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 363, iters: 624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 363, iters: 704, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 363, iters: 784, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 363, iters: 864, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 363, iters: 944, time: 0.094, data: 0.000) loss: 0.029 
(epoch: 363, iters: 1024, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 363, iters: 1104, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 363, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 363, iters: 1264, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 363, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 363, iters: 1424, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 363, iters: 1504, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 363, iters: 1584, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 363, iters: 1664, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 363, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 363, iters: 1824, time: 0.092, data: 0.012) loss: 0.017 
(epoch: 363, iters: 1904, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 363, iters: 1984, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 363, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 363, iters: 2144, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 363, iters: 2224, time: 0.094, data: 0.040) loss: 0.004 
(epoch: 363, iters: 2304, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 363, iters: 2384, time: 0.092, data: 0.012) loss: 0.005 
(epoch: 363, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 363, iters: 2544, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 363, iters: 2624, time: 0.095, data: 0.000) loss: 0.220 
(epoch: 363, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 363, iters: 2784, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 363, iters: 2864, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 363, iters: 2944, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 363, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 363, iters: 3104, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 363, iters: 3184, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 363, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 363, iters: 3344, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 363, iters: 3424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 363, iters: 3504, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 363, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 363, iters: 3664, time: 0.088, data: 0.011) loss: 0.147 
saving the model at the end of epoch 363, iters 1353264
End of epoch 363 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001736
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 363, TEST ACC: [96.358 %]

(epoch: 364, iters: 16, time: 0.110, data: 0.000) loss: 0.000 
saving the latest model (epoch 364, total_steps 1353280)
(epoch: 364, iters: 96, time: 0.094, data: 0.043) loss: 0.001 
(epoch: 364, iters: 176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 364, iters: 256, time: 0.092, data: 0.022) loss: 0.382 
(epoch: 364, iters: 336, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 364, iters: 416, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 364, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 364, iters: 576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 364, iters: 656, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 364, iters: 736, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 364, iters: 816, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 364, iters: 896, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 364, iters: 976, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 364, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 364, iters: 1136, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 364, iters: 1216, time: 0.094, data: 0.049) loss: 0.001 
(epoch: 364, iters: 1296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 364, iters: 1376, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 364, iters: 1456, time: 0.095, data: 0.000) loss: 0.018 
(epoch: 364, iters: 1536, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 364, iters: 1616, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 364, iters: 1696, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 364, iters: 1776, time: 0.096, data: 0.039) loss: 0.003 
(epoch: 364, iters: 1856, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 364, iters: 1936, time: 0.094, data: 0.011) loss: 0.085 
(epoch: 364, iters: 2016, time: 0.094, data: 0.000) loss: 0.017 
(epoch: 364, iters: 2096, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 364, iters: 2176, time: 0.093, data: 0.000) loss: 0.010 
(epoch: 364, iters: 2256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 364, iters: 2336, time: 0.094, data: 0.039) loss: 0.011 
(epoch: 364, iters: 2416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 364, iters: 2496, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 364, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 364, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 364, iters: 2736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 364, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 364, iters: 2896, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 364, iters: 2976, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 364, iters: 3056, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 364, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 364, iters: 3216, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 364, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 364, iters: 3376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 364, iters: 3456, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 364, iters: 3536, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 364, iters: 3616, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 364, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 364, iters 1356992
End of epoch 364 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001735
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 364, TEST ACC: [97.572 %]

saving the latest model (epoch 365, total_steps 1357008)
(epoch: 365, iters: 48, time: 0.093, data: 0.005) loss: 0.000 
(epoch: 365, iters: 128, time: 0.093, data: 0.055) loss: 0.000 
(epoch: 365, iters: 208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 365, iters: 288, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 365, iters: 368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 365, iters: 448, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 365, iters: 528, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 365, iters: 608, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 365, iters: 688, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 365, iters: 768, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 365, iters: 848, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 365, iters: 928, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 365, iters: 1008, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 365, iters: 1088, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 365, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 365, iters: 1248, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 365, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 365, iters: 1408, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 365, iters: 1488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 365, iters: 1568, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 365, iters: 1648, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 365, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 365, iters: 1808, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 365, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 365, iters: 1968, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 365, iters: 2048, time: 0.093, data: 0.000) loss: 0.010 
(epoch: 365, iters: 2128, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 365, iters: 2208, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 365, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 365, iters: 2368, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 365, iters: 2448, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 365, iters: 2528, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 365, iters: 2608, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 365, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 365, iters: 2768, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 365, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 365, iters: 2928, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 365, iters: 3008, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 365, iters: 3088, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 365, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 365, iters: 3248, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 365, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 365, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 365, iters: 3488, time: 0.097, data: 0.048) loss: 0.000 
(epoch: 365, iters: 3568, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 365, iters: 3648, time: 0.086, data: 0.012) loss: 0.016 
(epoch: 365, iters: 3728, time: 0.057, data: 0.000) loss: 0.001 
saving the model at the end of epoch 365, iters 1360720
End of epoch 365 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001734
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 365, TEST ACC: [95.448 %]

saving the latest model (epoch 366, total_steps 1360736)
(epoch: 366, iters: 80, time: 0.095, data: 0.472) loss: 0.000 
(epoch: 366, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 366, iters: 240, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 366, iters: 320, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 366, iters: 400, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 366, iters: 480, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 366, iters: 560, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 366, iters: 640, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 366, iters: 720, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 366, iters: 800, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 366, iters: 880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 366, iters: 960, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 366, iters: 1040, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 366, iters: 1120, time: 0.095, data: 0.013) loss: 0.002 
(epoch: 366, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 366, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 366, iters: 1360, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 366, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 366, iters: 1520, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 366, iters: 1600, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 366, iters: 1680, time: 0.095, data: 0.012) loss: 0.004 
(epoch: 366, iters: 1760, time: 0.097, data: 0.000) loss: 0.034 
(epoch: 366, iters: 1840, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 366, iters: 1920, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 366, iters: 2000, time: 0.094, data: 0.000) loss: 0.055 
(epoch: 366, iters: 2080, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 366, iters: 2160, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 366, iters: 2240, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 366, iters: 2320, time: 0.094, data: 0.000) loss: 0.149 
(epoch: 366, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 366, iters: 2480, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 366, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 366, iters: 2640, time: 0.092, data: 0.011) loss: 0.295 
(epoch: 366, iters: 2720, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 366, iters: 2800, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 366, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 366, iters: 2960, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 366, iters: 3040, time: 0.095, data: 0.039) loss: 0.002 
(epoch: 366, iters: 3120, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 366, iters: 3200, time: 0.092, data: 0.012) loss: 0.005 
(epoch: 366, iters: 3280, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 366, iters: 3360, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 366, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 366, iters: 3520, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 366, iters: 3600, time: 0.095, data: 0.039) loss: 0.005 
(epoch: 366, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 366, iters 1364448
End of epoch 366 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001733
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 366, TEST ACC: [92.261 %]

saving the latest model (epoch 367, total_steps 1364464)
(epoch: 367, iters: 32, time: 0.091, data: 0.004) loss: 0.000 
(epoch: 367, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 367, iters: 192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 367, iters: 272, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 367, iters: 352, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 367, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 367, iters: 512, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 367, iters: 592, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 367, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 367, iters: 752, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 367, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 367, iters: 912, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 367, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 367, iters: 1072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 367, iters: 1152, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 367, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 367, iters: 1312, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 367, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 367, iters: 1472, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 367, iters: 1552, time: 0.095, data: 0.000) loss: 0.075 
(epoch: 367, iters: 1632, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 367, iters: 1712, time: 0.093, data: 0.048) loss: 0.003 
(epoch: 367, iters: 1792, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 367, iters: 1872, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 367, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 367, iters: 2032, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 367, iters: 2112, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 367, iters: 2192, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 367, iters: 2272, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 367, iters: 2352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 367, iters: 2432, time: 0.092, data: 0.011) loss: 0.034 
(epoch: 367, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 367, iters: 2592, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 367, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 367, iters: 2752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 367, iters: 2832, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 367, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 367, iters: 2992, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 367, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 367, iters: 3152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 367, iters: 3232, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 367, iters: 3312, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 367, iters: 3392, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 367, iters: 3472, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 367, iters: 3552, time: 0.092, data: 0.012) loss: 0.017 
(epoch: 367, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 367, iters: 3712, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 367, iters 1368176
End of epoch 367 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001732
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 367, TEST ACC: [94.841 %]

saving the latest model (epoch 368, total_steps 1368192)
(epoch: 368, iters: 64, time: 0.094, data: 0.003) loss: 0.001 
(epoch: 368, iters: 144, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 368, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 368, iters: 304, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 368, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 368, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 368, iters: 544, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 368, iters: 624, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 368, iters: 704, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 368, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 368, iters: 864, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 368, iters: 944, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 368, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 368, iters: 1104, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 368, iters: 1184, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 368, iters: 1264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 368, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 368, iters: 1424, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 368, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 368, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 368, iters: 1664, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 368, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 368, iters: 1824, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 368, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 368, iters: 1984, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 368, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 368, iters: 2144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 368, iters: 2224, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 368, iters: 2304, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 368, iters: 2384, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 368, iters: 2464, time: 0.094, data: 0.000) loss: 0.031 
(epoch: 368, iters: 2544, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 368, iters: 2624, time: 0.094, data: 0.000) loss: 0.056 
(epoch: 368, iters: 2704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 368, iters: 2784, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 368, iters: 2864, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 368, iters: 2944, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 368, iters: 3024, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 368, iters: 3104, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 368, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 368, iters: 3264, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 368, iters: 3344, time: 0.093, data: 0.039) loss: 0.044 
(epoch: 368, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 368, iters: 3504, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 368, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 368, iters: 3664, time: 0.087, data: 0.011) loss: 0.001 
saving the model at the end of epoch 368, iters 1371904
End of epoch 368 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001731
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 368, TEST ACC: [97.42 %]

(epoch: 369, iters: 16, time: 0.111, data: 0.000) loss: 0.000 
saving the latest model (epoch 369, total_steps 1371920)
(epoch: 369, iters: 96, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 369, iters: 176, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 369, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 369, iters: 336, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 369, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 369, iters: 496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 369, iters: 576, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 369, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 369, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 369, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 369, iters: 896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 369, iters: 976, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 369, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 369, iters: 1136, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 369, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 369, iters: 1296, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 369, iters: 1376, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 369, iters: 1456, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 369, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 369, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 369, iters: 1696, time: 0.096, data: 0.039) loss: 0.003 
(epoch: 369, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 369, iters: 1856, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 369, iters: 1936, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 369, iters: 2016, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 369, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 369, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 369, iters: 2256, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 369, iters: 2336, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 369, iters: 2416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 369, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 369, iters: 2576, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 369, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 369, iters: 2736, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 369, iters: 2816, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 369, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 369, iters: 2976, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 369, iters: 3056, time: 0.093, data: 0.000) loss: 0.351 
(epoch: 369, iters: 3136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 369, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 369, iters: 3296, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 369, iters: 3376, time: 0.095, data: 0.039) loss: 0.012 
(epoch: 369, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 369, iters: 3536, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 369, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 369, iters: 3696, time: 0.088, data: 0.011) loss: 0.001 
saving the model at the end of epoch 369, iters 1375632
End of epoch 369 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001730
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 369, TEST ACC: [95.448 %]

saving the latest model (epoch 370, total_steps 1375648)
(epoch: 370, iters: 48, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 370, iters: 128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 370, iters: 208, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 370, iters: 288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 370, iters: 368, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 370, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 370, iters: 528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 370, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 370, iters: 688, time: 0.093, data: 0.000) loss: 0.051 
(epoch: 370, iters: 768, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 370, iters: 848, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 370, iters: 928, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 370, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 370, iters: 1088, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 370, iters: 1168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 370, iters: 1248, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 370, iters: 1328, time: 0.095, data: 0.043) loss: 0.000 
(epoch: 370, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 370, iters: 1488, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 370, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 370, iters: 1648, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 370, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 370, iters: 1808, time: 0.092, data: 0.000) loss: 0.003 
(epoch: 370, iters: 1888, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 370, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 370, iters: 2048, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 370, iters: 2128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 370, iters: 2208, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 370, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 370, iters: 2368, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 370, iters: 2448, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 370, iters: 2528, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 370, iters: 2608, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 370, iters: 2688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 370, iters: 2768, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 370, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 370, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 370, iters: 3008, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 370, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 370, iters: 3168, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 370, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 370, iters: 3328, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 370, iters: 3408, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 370, iters: 3488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 370, iters: 3568, time: 0.096, data: 0.050) loss: 0.020 
(epoch: 370, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 370, iters: 3728, time: 0.056, data: 0.012) loss: 0.003 
saving the model at the end of epoch 370, iters 1379360
End of epoch 370 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001729
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 370, TEST ACC: [77.997 %]

saving the latest model (epoch 371, total_steps 1379376)
(epoch: 371, iters: 80, time: 0.095, data: 0.520) loss: 0.000 
(epoch: 371, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 371, iters: 240, time: 0.094, data: 0.039) loss: 0.008 
(epoch: 371, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 371, iters: 400, time: 0.092, data: 0.011) loss: 0.005 
(epoch: 371, iters: 480, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 371, iters: 560, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 371, iters: 640, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 371, iters: 720, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 371, iters: 800, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 371, iters: 880, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 371, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 371, iters: 1040, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 371, iters: 1120, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 371, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 371, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 371, iters: 1360, time: 0.094, data: 0.039) loss: 0.017 
(epoch: 371, iters: 1440, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 371, iters: 1520, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 371, iters: 1600, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 371, iters: 1680, time: 0.093, data: 0.011) loss: 0.008 
(epoch: 371, iters: 1760, time: 0.094, data: 0.000) loss: 0.042 
(epoch: 371, iters: 1840, time: 0.096, data: 0.000) loss: 0.186 
(epoch: 371, iters: 1920, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 371, iters: 2000, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 371, iters: 2080, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 371, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 371, iters: 2240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 371, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 371, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 371, iters: 2480, time: 0.094, data: 0.039) loss: 0.007 
(epoch: 371, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 371, iters: 2640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 371, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 371, iters: 2800, time: 0.093, data: 0.012) loss: 0.354 
(epoch: 371, iters: 2880, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 371, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 371, iters: 3040, time: 0.095, data: 0.048) loss: 0.001 
(epoch: 371, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 371, iters: 3200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 371, iters: 3280, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 371, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 371, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 371, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 371, iters: 3600, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 371, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 371, iters 1383088
End of epoch 371 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001728
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 371, TEST ACC: [95.296 %]

saving the latest model (epoch 372, total_steps 1383104)
(epoch: 372, iters: 32, time: 0.095, data: 0.004) loss: 0.000 
(epoch: 372, iters: 112, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 372, iters: 192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 372, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 372, iters: 352, time: 0.095, data: 0.040) loss: 0.004 
(epoch: 372, iters: 432, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 372, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 372, iters: 592, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 372, iters: 672, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 372, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 372, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 372, iters: 912, time: 0.095, data: 0.050) loss: 0.060 
(epoch: 372, iters: 992, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 372, iters: 1072, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 372, iters: 1152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 372, iters: 1232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 372, iters: 1312, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 372, iters: 1392, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 372, iters: 1472, time: 0.096, data: 0.052) loss: 0.000 
(epoch: 372, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 372, iters: 1632, time: 0.094, data: 0.011) loss: 0.015 
(epoch: 372, iters: 1712, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 372, iters: 1792, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 372, iters: 1872, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 372, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 372, iters: 2032, time: 0.096, data: 0.041) loss: 0.203 
(epoch: 372, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 372, iters: 2192, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 372, iters: 2272, time: 0.096, data: 0.000) loss: 0.101 
(epoch: 372, iters: 2352, time: 0.093, data: 0.012) loss: 0.039 
(epoch: 372, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 372, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 372, iters: 2592, time: 0.095, data: 0.041) loss: 0.069 
(epoch: 372, iters: 2672, time: 0.094, data: 0.000) loss: 0.045 
(epoch: 372, iters: 2752, time: 0.093, data: 0.012) loss: 0.010 
(epoch: 372, iters: 2832, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 372, iters: 2912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 372, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 372, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 372, iters: 3152, time: 0.097, data: 0.050) loss: 0.002 
(epoch: 372, iters: 3232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 372, iters: 3312, time: 0.092, data: 0.012) loss: 0.026 
(epoch: 372, iters: 3392, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 372, iters: 3472, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 372, iters: 3552, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 372, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 372, iters: 3712, time: 0.088, data: 0.035) loss: 0.000 
saving the model at the end of epoch 372, iters 1386816
End of epoch 372 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001727
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 372, TEST ACC: [94.992 %]

saving the latest model (epoch 373, total_steps 1386832)
(epoch: 373, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 373, iters: 144, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 373, iters: 224, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 373, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 373, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 373, iters: 464, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 373, iters: 544, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 373, iters: 624, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 373, iters: 704, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 373, iters: 784, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 373, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 373, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 373, iters: 1024, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 373, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 373, iters: 1184, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 373, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 373, iters: 1344, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 373, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 373, iters: 1504, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 373, iters: 1584, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 373, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 373, iters: 1744, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 373, iters: 1824, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 373, iters: 1904, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 373, iters: 1984, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 373, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 373, iters: 2144, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 373, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 373, iters: 2304, time: 0.093, data: 0.022) loss: 0.000 
(epoch: 373, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 373, iters: 2464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 373, iters: 2544, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 373, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 373, iters: 2704, time: 0.094, data: 0.039) loss: 0.004 
(epoch: 373, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 373, iters: 2864, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 373, iters: 2944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 373, iters: 3024, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 373, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 373, iters: 3184, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 373, iters: 3264, time: 0.096, data: 0.052) loss: 0.003 
(epoch: 373, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 373, iters: 3424, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 373, iters: 3504, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 373, iters: 3584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 373, iters: 3664, time: 0.088, data: 0.000) loss: 0.003 
saving the model at the end of epoch 373, iters 1390544
End of epoch 373 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001726
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 373, TEST ACC: [96.358 %]

(epoch: 374, iters: 16, time: 0.110, data: 0.000) loss: 0.001 
saving the latest model (epoch 374, total_steps 1390560)
(epoch: 374, iters: 96, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 374, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 374, iters: 256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 374, iters: 336, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 374, iters: 416, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 374, iters: 496, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 374, iters: 576, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 374, iters: 656, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 374, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 374, iters: 816, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 374, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 374, iters: 976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 374, iters: 1056, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 374, iters: 1136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 374, iters: 1216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 374, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 374, iters: 1376, time: 0.096, data: 0.023) loss: 0.000 
(epoch: 374, iters: 1456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 374, iters: 1536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 374, iters: 1616, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 374, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 374, iters: 1776, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 374, iters: 1856, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 374, iters: 1936, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 374, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 374, iters: 2096, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 374, iters: 2176, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 374, iters: 2256, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 374, iters: 2336, time: 0.094, data: 0.012) loss: 0.013 
(epoch: 374, iters: 2416, time: 0.094, data: 0.000) loss: 0.039 
(epoch: 374, iters: 2496, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 374, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 374, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 374, iters: 2736, time: 0.094, data: 0.040) loss: 0.083 
(epoch: 374, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 374, iters: 2896, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 374, iters: 2976, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 374, iters: 3056, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 374, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 374, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 374, iters: 3296, time: 0.097, data: 0.053) loss: 0.000 
(epoch: 374, iters: 3376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 374, iters: 3456, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 374, iters: 3536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 374, iters: 3616, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 374, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 374, iters 1394272
End of epoch 374 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001725
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 374, TEST ACC: [93.475 %]

saving the latest model (epoch 375, total_steps 1394288)
(epoch: 375, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 375, iters: 128, time: 0.094, data: 0.028) loss: 0.056 
(epoch: 375, iters: 208, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 375, iters: 288, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 375, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 375, iters: 448, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 375, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 375, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 375, iters: 688, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 375, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 375, iters: 848, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 375, iters: 928, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 375, iters: 1008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 375, iters: 1088, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 375, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 375, iters: 1248, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 375, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 375, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 375, iters: 1488, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 375, iters: 1568, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 375, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 375, iters: 1728, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 375, iters: 1808, time: 0.097, data: 0.051) loss: 0.000 
(epoch: 375, iters: 1888, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 375, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 375, iters: 2048, time: 0.093, data: 0.000) loss: 0.095 
(epoch: 375, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 375, iters: 2208, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 375, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 375, iters: 2368, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 375, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 375, iters: 2528, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 375, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 375, iters: 2688, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 375, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 375, iters: 2848, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 375, iters: 2928, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 375, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 375, iters: 3088, time: 0.091, data: 0.011) loss: 0.001 
(epoch: 375, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 375, iters: 3248, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 375, iters: 3328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 375, iters: 3408, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 375, iters: 3488, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 375, iters: 3568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 375, iters: 3648, time: 0.086, data: 0.013) loss: 0.001 
(epoch: 375, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 375, iters 1398000
End of epoch 375 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001724
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 375, TEST ACC: [94.537 %]

saving the latest model (epoch 376, total_steps 1398016)
(epoch: 376, iters: 80, time: 0.092, data: 0.523) loss: 0.000 
(epoch: 376, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 376, iters: 240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 376, iters: 320, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 376, iters: 400, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 376, iters: 480, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 376, iters: 560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 376, iters: 640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 376, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 376, iters: 800, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 376, iters: 880, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 376, iters: 960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 376, iters: 1040, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 376, iters: 1120, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 376, iters: 1200, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 376, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 376, iters: 1360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 376, iters: 1440, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 376, iters: 1520, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 376, iters: 1600, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 376, iters: 1680, time: 0.094, data: 0.000) loss: 0.023 
(epoch: 376, iters: 1760, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 376, iters: 1840, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 376, iters: 1920, time: 0.093, data: 0.012) loss: 0.011 
(epoch: 376, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 376, iters: 2080, time: 0.094, data: 0.000) loss: 0.074 
(epoch: 376, iters: 2160, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 376, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 376, iters: 2320, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 376, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 376, iters: 2480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 376, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 376, iters: 2640, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 376, iters: 2720, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 376, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 376, iters: 2880, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 376, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 376, iters: 3040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 376, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 376, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 376, iters: 3280, time: 0.095, data: 0.052) loss: 0.000 
(epoch: 376, iters: 3360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 376, iters: 3440, time: 0.092, data: 0.012) loss: 0.006 
(epoch: 376, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 376, iters: 3600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 376, iters: 3680, time: 0.086, data: 0.000) loss: 0.000 
saving the model at the end of epoch 376, iters 1401728
End of epoch 376 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001723
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 376, TEST ACC: [95.448 %]

saving the latest model (epoch 377, total_steps 1401744)
(epoch: 377, iters: 32, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 377, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 377, iters: 192, time: 0.093, data: 0.000) loss: 0.017 
(epoch: 377, iters: 272, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 377, iters: 352, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 377, iters: 432, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 377, iters: 512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 377, iters: 592, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 377, iters: 672, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 377, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 377, iters: 832, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 377, iters: 912, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 377, iters: 992, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 377, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 377, iters: 1152, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 377, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 377, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 377, iters: 1392, time: 0.093, data: 0.040) loss: 0.006 
(epoch: 377, iters: 1472, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 377, iters: 1552, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 377, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 377, iters: 1712, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 377, iters: 1792, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 377, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 377, iters: 1952, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 377, iters: 2032, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 377, iters: 2112, time: 0.094, data: 0.012) loss: 0.023 
(epoch: 377, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 377, iters: 2272, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 377, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 377, iters: 2432, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 377, iters: 2512, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 377, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 377, iters: 2672, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 377, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 377, iters: 2832, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 377, iters: 2912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 377, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 377, iters: 3072, time: 0.096, data: 0.052) loss: 0.000 
(epoch: 377, iters: 3152, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 377, iters: 3232, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 377, iters: 3312, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 377, iters: 3392, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 377, iters: 3472, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 377, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 377, iters: 3632, time: 0.092, data: 0.052) loss: 0.002 
(epoch: 377, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 377, iters 1405456
End of epoch 377 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001722
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 377, TEST ACC: [95.751 %]

saving the latest model (epoch 378, total_steps 1405472)
(epoch: 378, iters: 64, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 378, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 378, iters: 224, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 378, iters: 304, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 378, iters: 384, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 378, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 378, iters: 544, time: 0.093, data: 0.011) loss: 0.017 
(epoch: 378, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 378, iters: 704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 378, iters: 784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 378, iters: 864, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 378, iters: 944, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 378, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 378, iters: 1104, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 378, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 378, iters: 1264, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 378, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 378, iters: 1424, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 378, iters: 1504, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 378, iters: 1584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 378, iters: 1664, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 378, iters: 1744, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 378, iters: 1824, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 378, iters: 1904, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 378, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 378, iters: 2064, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 378, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 378, iters: 2224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 378, iters: 2304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 378, iters: 2384, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 378, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 378, iters: 2544, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 378, iters: 2624, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 378, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 378, iters: 2784, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 378, iters: 2864, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 378, iters: 2944, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 378, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 378, iters: 3104, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 378, iters: 3184, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 378, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 378, iters: 3344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 378, iters: 3424, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 378, iters: 3504, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 378, iters: 3584, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 378, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 378, iters 1409184
End of epoch 378 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001721
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 378, TEST ACC: [90.137 %]

(epoch: 379, iters: 16, time: 0.113, data: 0.013) loss: 0.000 
saving the latest model (epoch 379, total_steps 1409200)
(epoch: 379, iters: 96, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 379, iters: 176, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 379, iters: 256, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 379, iters: 336, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 379, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 379, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 379, iters: 576, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 379, iters: 656, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 379, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 379, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 379, iters: 896, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 379, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 379, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 379, iters: 1136, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 379, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 379, iters: 1296, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 379, iters: 1376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 379, iters: 1456, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 379, iters: 1536, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 379, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 379, iters: 1696, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 379, iters: 1776, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 379, iters: 1856, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 379, iters: 1936, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 379, iters: 2016, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 379, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 379, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 379, iters: 2256, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 379, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 379, iters: 2416, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 379, iters: 2496, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 379, iters: 2576, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 379, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 379, iters: 2736, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 379, iters: 2816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 379, iters: 2896, time: 0.094, data: 0.000) loss: 0.144 
(epoch: 379, iters: 2976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 379, iters: 3056, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 379, iters: 3136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 379, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 379, iters: 3296, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 379, iters: 3376, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 379, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 379, iters: 3536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 379, iters: 3616, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 379, iters: 3696, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 379, iters 1412912
End of epoch 379 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001720
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 379, TEST ACC: [95.296 %]

saving the latest model (epoch 380, total_steps 1412928)
(epoch: 380, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 380, iters: 128, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 380, iters: 208, time: 0.098, data: 0.000) loss: 0.020 
(epoch: 380, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 380, iters: 368, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 380, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 380, iters: 528, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 380, iters: 608, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 380, iters: 688, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 380, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 380, iters: 848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 380, iters: 928, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 380, iters: 1008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 380, iters: 1088, time: 0.096, data: 0.012) loss: 0.012 
(epoch: 380, iters: 1168, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 380, iters: 1248, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 380, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 380, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 380, iters: 1488, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 380, iters: 1568, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 380, iters: 1648, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 380, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 380, iters: 1808, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 380, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 380, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 380, iters: 2048, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 380, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 380, iters: 2208, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 380, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 380, iters: 2368, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 380, iters: 2448, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 380, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 380, iters: 2608, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 380, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 380, iters: 2768, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 380, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 380, iters: 2928, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 380, iters: 3008, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 380, iters: 3088, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 380, iters: 3168, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 380, iters: 3248, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 380, iters: 3328, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 380, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 380, iters: 3488, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 380, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 380, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 380, iters: 3728, time: 0.055, data: 0.014) loss: 0.000 
saving the model at the end of epoch 380, iters 1416640
End of epoch 380 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001719
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 380, TEST ACC: [94.841 %]

saving the latest model (epoch 381, total_steps 1416656)
(epoch: 381, iters: 80, time: 0.095, data: 0.450) loss: 0.000 
(epoch: 381, iters: 160, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 381, iters: 240, time: 0.093, data: 0.051) loss: 0.020 
(epoch: 381, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 381, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 381, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 381, iters: 560, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 381, iters: 640, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 381, iters: 720, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 381, iters: 800, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 381, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 381, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 381, iters: 1040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 381, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 381, iters: 1200, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 381, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 381, iters: 1360, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 381, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 381, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 381, iters: 1600, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 381, iters: 1680, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 381, iters: 1760, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 381, iters: 1840, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 381, iters: 1920, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 381, iters: 2000, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 381, iters: 2080, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 381, iters: 2160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 381, iters: 2240, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 381, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 381, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 381, iters: 2480, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 381, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 381, iters: 2640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 381, iters: 2720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 381, iters: 2800, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 381, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 381, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 381, iters: 3040, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 381, iters: 3120, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 381, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 381, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 381, iters: 3360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 381, iters: 3440, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 381, iters: 3520, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 381, iters: 3600, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 381, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 381, iters 1420368
End of epoch 381 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001718
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 381, TEST ACC: [94.689 %]

saving the latest model (epoch 382, total_steps 1420384)
(epoch: 382, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 382, iters: 112, time: 0.093, data: 0.027) loss: 0.001 
(epoch: 382, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 382, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 382, iters: 352, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 382, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 382, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 382, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 382, iters: 672, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 382, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 382, iters: 832, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 382, iters: 912, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 382, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 382, iters: 1072, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 382, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 382, iters: 1232, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 382, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 382, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 382, iters: 1472, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 382, iters: 1552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 382, iters: 1632, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 382, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 382, iters: 1792, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 382, iters: 1872, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 382, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 382, iters: 2032, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 382, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 382, iters: 2192, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 382, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 382, iters: 2352, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 382, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 382, iters: 2512, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 382, iters: 2592, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 382, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 382, iters: 2752, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 382, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 382, iters: 2912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 382, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 382, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 382, iters: 3152, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 382, iters: 3232, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 382, iters: 3312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 382, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 382, iters: 3472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 382, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 382, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 382, iters: 3712, time: 0.087, data: 0.036) loss: 0.000 
saving the model at the end of epoch 382, iters 1424096
End of epoch 382 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001717
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 382, TEST ACC: [95.751 %]

saving the latest model (epoch 383, total_steps 1424112)
(epoch: 383, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 383, iters: 144, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 383, iters: 224, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 383, iters: 304, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 383, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 383, iters: 464, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 383, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 383, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 383, iters: 704, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 383, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 383, iters: 864, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 383, iters: 944, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 383, iters: 1024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 383, iters: 1104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 383, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 383, iters: 1264, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 383, iters: 1344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 383, iters: 1424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 383, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 383, iters: 1584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 383, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 383, iters: 1744, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 383, iters: 1824, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 383, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 383, iters: 1984, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 383, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 383, iters: 2144, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 383, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 383, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 383, iters: 2384, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 383, iters: 2464, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 383, iters: 2544, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 383, iters: 2624, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 383, iters: 2704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 383, iters: 2784, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 383, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 383, iters: 2944, time: 0.094, data: 0.040) loss: 0.007 
(epoch: 383, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 383, iters: 3104, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 383, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 383, iters: 3264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 383, iters: 3344, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 383, iters: 3424, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 383, iters: 3504, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 383, iters: 3584, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 383, iters: 3664, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 383, iters 1427824
End of epoch 383 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001716
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 383, TEST ACC: [89.833 %]

(epoch: 384, iters: 16, time: 0.109, data: 0.013) loss: 0.000 
saving the latest model (epoch 384, total_steps 1427840)
(epoch: 384, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 384, iters: 176, time: 0.093, data: 0.000) loss: 0.014 
(epoch: 384, iters: 256, time: 0.096, data: 0.041) loss: 0.016 
(epoch: 384, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 384, iters: 416, time: 0.092, data: 0.012) loss: 0.005 
(epoch: 384, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 384, iters: 576, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 384, iters: 656, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 384, iters: 736, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 384, iters: 816, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 384, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 384, iters: 976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 384, iters: 1056, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 384, iters: 1136, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 384, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 384, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 384, iters: 1376, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 384, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 384, iters: 1536, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 384, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 384, iters: 1696, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 384, iters: 1776, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 384, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 384, iters: 1936, time: 0.094, data: 0.041) loss: 0.110 
(epoch: 384, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 384, iters: 2096, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 384, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 384, iters: 2256, time: 0.093, data: 0.012) loss: 0.008 
(epoch: 384, iters: 2336, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 384, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 384, iters: 2496, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 384, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 384, iters: 2656, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 384, iters: 2736, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 384, iters: 2816, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 384, iters: 2896, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 384, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 384, iters: 3056, time: 0.094, data: 0.040) loss: 0.165 
(epoch: 384, iters: 3136, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 384, iters: 3216, time: 0.092, data: 0.012) loss: 0.009 
(epoch: 384, iters: 3296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 384, iters: 3376, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 384, iters: 3456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 384, iters: 3536, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 384, iters: 3616, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 384, iters: 3696, time: 0.089, data: 0.000) loss: 0.095 
saving the model at the end of epoch 384, iters 1431552
End of epoch 384 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001715
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 384, TEST ACC: [93.93 %]

saving the latest model (epoch 385, total_steps 1431568)
(epoch: 385, iters: 48, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 385, iters: 128, time: 0.094, data: 0.043) loss: 0.000 
(epoch: 385, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 385, iters: 288, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 385, iters: 368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 385, iters: 448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 385, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 385, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 385, iters: 688, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 385, iters: 768, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 385, iters: 848, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 385, iters: 928, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 385, iters: 1008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 385, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 385, iters: 1168, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 385, iters: 1248, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 385, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 385, iters: 1408, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 385, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 385, iters: 1568, time: 0.096, data: 0.012) loss: 0.018 
(epoch: 385, iters: 1648, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 385, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 385, iters: 1808, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 385, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 385, iters: 1968, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 385, iters: 2048, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 385, iters: 2128, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 385, iters: 2208, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 385, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 385, iters: 2368, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 385, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 385, iters: 2528, time: 0.093, data: 0.012) loss: 0.008 
(epoch: 385, iters: 2608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 385, iters: 2688, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 385, iters: 2768, time: 0.096, data: 0.000) loss: 0.293 
(epoch: 385, iters: 2848, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 385, iters: 2928, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 385, iters: 3008, time: 0.094, data: 0.000) loss: 0.027 
(epoch: 385, iters: 3088, time: 0.093, data: 0.011) loss: 0.009 
(epoch: 385, iters: 3168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 385, iters: 3248, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 385, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 385, iters: 3408, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 385, iters: 3488, time: 0.094, data: 0.041) loss: 0.019 
(epoch: 385, iters: 3568, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 385, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 385, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 385, iters 1435280
End of epoch 385 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001714
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 385, TEST ACC: [94.537 %]

saving the latest model (epoch 386, total_steps 1435296)
(epoch: 386, iters: 80, time: 0.095, data: 0.443) loss: 0.000 
(epoch: 386, iters: 160, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 386, iters: 240, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 386, iters: 320, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 386, iters: 400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 386, iters: 480, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 386, iters: 560, time: 0.096, data: 0.012) loss: 0.004 
(epoch: 386, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 386, iters: 720, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 386, iters: 800, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 386, iters: 880, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 386, iters: 960, time: 0.094, data: 0.012) loss: 0.049 
(epoch: 386, iters: 1040, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 386, iters: 1120, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 386, iters: 1200, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 386, iters: 1280, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 386, iters: 1360, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 386, iters: 1440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 386, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 386, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 386, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 386, iters: 1760, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 386, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 386, iters: 1920, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 386, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 386, iters: 2080, time: 0.093, data: 0.022) loss: 0.000 
(epoch: 386, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 386, iters: 2240, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 386, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 386, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 386, iters: 2480, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 386, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 386, iters: 2640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 386, iters: 2720, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 386, iters: 2800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 386, iters: 2880, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 386, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 386, iters: 3040, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 386, iters: 3120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 386, iters: 3200, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 386, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 386, iters: 3360, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 386, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 386, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 386, iters: 3600, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 386, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 386, iters 1439008
End of epoch 386 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001713
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 386, TEST ACC: [93.627 %]

saving the latest model (epoch 387, total_steps 1439024)
(epoch: 387, iters: 32, time: 0.093, data: 0.004) loss: 0.000 
(epoch: 387, iters: 112, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 387, iters: 192, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 387, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 387, iters: 352, time: 0.098, data: 0.051) loss: 0.001 
(epoch: 387, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 387, iters: 512, time: 0.094, data: 0.012) loss: 0.083 
(epoch: 387, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 387, iters: 672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 387, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 387, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 387, iters: 912, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 387, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 387, iters: 1072, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 387, iters: 1152, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 387, iters: 1232, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 387, iters: 1312, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 387, iters: 1392, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 387, iters: 1472, time: 0.096, data: 0.040) loss: 0.216 
(epoch: 387, iters: 1552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 387, iters: 1632, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 387, iters: 1712, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 387, iters: 1792, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 387, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 387, iters: 1952, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 387, iters: 2032, time: 0.094, data: 0.040) loss: 0.025 
(epoch: 387, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 387, iters: 2192, time: 0.092, data: 0.012) loss: 0.009 
(epoch: 387, iters: 2272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 387, iters: 2352, time: 0.094, data: 0.012) loss: 0.005 
(epoch: 387, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 387, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 387, iters: 2592, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 387, iters: 2672, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 387, iters: 2752, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 387, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 387, iters: 2912, time: 0.093, data: 0.012) loss: 0.167 
(epoch: 387, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 387, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 387, iters: 3152, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 387, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 387, iters: 3312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 387, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 387, iters: 3472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 387, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 387, iters: 3632, time: 0.091, data: 0.000) loss: 0.001 
(epoch: 387, iters: 3712, time: 0.088, data: 0.046) loss: 0.000 
saving the model at the end of epoch 387, iters 1442736
End of epoch 387 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001712
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 387, TEST ACC: [95.448 %]

saving the latest model (epoch 388, total_steps 1442752)
(epoch: 388, iters: 64, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 388, iters: 144, time: 0.093, data: 0.000) loss: 0.008 
(epoch: 388, iters: 224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 388, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 388, iters: 384, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 388, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 388, iters: 544, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 388, iters: 624, time: 0.095, data: 0.000) loss: 0.031 
(epoch: 388, iters: 704, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 388, iters: 784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 388, iters: 864, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 388, iters: 944, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 388, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 388, iters: 1104, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 388, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 388, iters: 1264, time: 0.093, data: 0.012) loss: 0.018 
(epoch: 388, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 388, iters: 1424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 388, iters: 1504, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 388, iters: 1584, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 388, iters: 1664, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 388, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 388, iters: 1824, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 388, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 388, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 388, iters: 2064, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 388, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 388, iters: 2224, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 388, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 388, iters: 2384, time: 0.093, data: 0.012) loss: 0.063 
(epoch: 388, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 388, iters: 2544, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 388, iters: 2624, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 388, iters: 2704, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 388, iters: 2784, time: 0.092, data: 0.022) loss: 0.002 
(epoch: 388, iters: 2864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 388, iters: 2944, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 388, iters: 3024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 388, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 388, iters: 3184, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 388, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 388, iters: 3344, time: 0.092, data: 0.021) loss: 0.004 
(epoch: 388, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 388, iters: 3504, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 388, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 388, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 388, iters 1446464
End of epoch 388 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001711
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 388, TEST ACC: [94.841 %]

(epoch: 389, iters: 16, time: 0.108, data: 0.012) loss: 0.000 
saving the latest model (epoch 389, total_steps 1446480)
(epoch: 389, iters: 96, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 389, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 389, iters: 256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 389, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 389, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 389, iters: 496, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 389, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 389, iters: 656, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 389, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 389, iters: 816, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 389, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 389, iters: 976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 389, iters: 1056, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 389, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 389, iters: 1216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 389, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 389, iters: 1376, time: 0.094, data: 0.020) loss: 0.001 
(epoch: 389, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 389, iters: 1536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 389, iters: 1616, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 389, iters: 1696, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 389, iters: 1776, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 389, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 389, iters: 1936, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 389, iters: 2016, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 389, iters: 2096, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 389, iters: 2176, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 389, iters: 2256, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 389, iters: 2336, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 389, iters: 2416, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 389, iters: 2496, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 389, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 389, iters: 2656, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 389, iters: 2736, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 389, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 389, iters: 2896, time: 0.093, data: 0.012) loss: 0.026 
(epoch: 389, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 389, iters: 3056, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 389, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 389, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 389, iters: 3296, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 389, iters: 3376, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 389, iters: 3456, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 389, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 389, iters: 3616, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 389, iters: 3696, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 389, iters 1450192
End of epoch 389 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001710
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 389, TEST ACC: [94.385 %]

saving the latest model (epoch 390, total_steps 1450208)
(epoch: 390, iters: 48, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 390, iters: 128, time: 0.098, data: 0.043) loss: 0.000 
(epoch: 390, iters: 208, time: 0.096, data: 0.000) loss: 0.056 
(epoch: 390, iters: 288, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 390, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 390, iters: 448, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 390, iters: 528, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 390, iters: 608, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 390, iters: 688, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 390, iters: 768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 390, iters: 848, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 390, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 390, iters: 1008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 390, iters: 1088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 390, iters: 1168, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 390, iters: 1248, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 390, iters: 1328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 390, iters: 1408, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 390, iters: 1488, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 390, iters: 1568, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 390, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 390, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 390, iters: 1808, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 390, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 390, iters: 1968, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 390, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 390, iters: 2128, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 390, iters: 2208, time: 0.094, data: 0.000) loss: 0.034 
(epoch: 390, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 390, iters: 2368, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 390, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 390, iters: 2528, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 390, iters: 2608, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 390, iters: 2688, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 390, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 390, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 390, iters: 2928, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 390, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 390, iters: 3088, time: 0.091, data: 0.021) loss: 0.000 
(epoch: 390, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 390, iters: 3248, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 390, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 390, iters: 3408, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 390, iters: 3488, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 390, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 390, iters: 3648, time: 0.087, data: 0.012) loss: 0.000 
(epoch: 390, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 390, iters 1453920
End of epoch 390 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001709
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 390, TEST ACC: [94.234 %]

saving the latest model (epoch 391, total_steps 1453936)
(epoch: 391, iters: 80, time: 0.096, data: 0.545) loss: 0.000 
(epoch: 391, iters: 160, time: 0.094, data: 0.031) loss: 0.000 
(epoch: 391, iters: 240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 391, iters: 320, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 391, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 391, iters: 480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 391, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 391, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 391, iters: 720, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 391, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 391, iters: 880, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 391, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 391, iters: 1040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 391, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 391, iters: 1200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 391, iters: 1280, time: 0.094, data: 0.052) loss: 0.000 
(epoch: 391, iters: 1360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 391, iters: 1440, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 391, iters: 1520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 391, iters: 1600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 391, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 391, iters: 1760, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 391, iters: 1840, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 391, iters: 1920, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 391, iters: 2000, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 391, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 391, iters: 2160, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 391, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 391, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 391, iters: 2400, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 391, iters: 2480, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 391, iters: 2560, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 391, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 391, iters: 2720, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 391, iters: 2800, time: 0.095, data: 0.000) loss: 0.190 
(epoch: 391, iters: 2880, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 391, iters: 2960, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 391, iters: 3040, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 391, iters: 3120, time: 0.094, data: 0.022) loss: 0.002 
(epoch: 391, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 391, iters: 3280, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 391, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 391, iters: 3440, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 391, iters: 3520, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 391, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 391, iters: 3680, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 391, iters 1457648
End of epoch 391 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001708
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 391, TEST ACC: [91.047 %]

saving the latest model (epoch 392, total_steps 1457664)
(epoch: 392, iters: 32, time: 0.092, data: 0.016) loss: 0.006 
(epoch: 392, iters: 112, time: 0.093, data: 0.027) loss: 0.002 
(epoch: 392, iters: 192, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 392, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 392, iters: 352, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 392, iters: 432, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 392, iters: 512, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 392, iters: 592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 392, iters: 672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 392, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 392, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 392, iters: 912, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 392, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 392, iters: 1072, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 392, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 392, iters: 1232, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 392, iters: 1312, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 392, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 392, iters: 1472, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 392, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 392, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 392, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 392, iters: 1792, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 392, iters: 1872, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 392, iters: 1952, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 392, iters: 2032, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 392, iters: 2112, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 392, iters: 2192, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 392, iters: 2272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 392, iters: 2352, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 392, iters: 2432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 392, iters: 2512, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 392, iters: 2592, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 392, iters: 2672, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 392, iters: 2752, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 392, iters: 2832, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 392, iters: 2912, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 392, iters: 2992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 392, iters: 3072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 392, iters: 3152, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 392, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 392, iters: 3312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 392, iters: 3392, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 392, iters: 3472, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 392, iters: 3552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 392, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 392, iters: 3712, time: 0.088, data: 0.036) loss: 0.000 
saving the model at the end of epoch 392, iters 1461376
End of epoch 392 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001707
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 392, TEST ACC: [93.475 %]

saving the latest model (epoch 393, total_steps 1461392)
(epoch: 393, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 393, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 393, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 393, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 393, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 393, iters: 464, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 393, iters: 544, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 393, iters: 624, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 393, iters: 704, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 393, iters: 784, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 393, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 393, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 393, iters: 1024, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 393, iters: 1104, time: 0.094, data: 0.000) loss: 0.146 
(epoch: 393, iters: 1184, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 393, iters: 1264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 393, iters: 1344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 393, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 393, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 393, iters: 1584, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 393, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 393, iters: 1744, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 393, iters: 1824, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 393, iters: 1904, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 393, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 393, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 393, iters: 2144, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 393, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 393, iters: 2304, time: 0.092, data: 0.011) loss: 0.026 
(epoch: 393, iters: 2384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 393, iters: 2464, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 393, iters: 2544, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 393, iters: 2624, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 393, iters: 2704, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 393, iters: 2784, time: 0.096, data: 0.000) loss: 0.026 
(epoch: 393, iters: 2864, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 393, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 393, iters: 3024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 393, iters: 3104, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 393, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 393, iters: 3264, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 393, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 393, iters: 3424, time: 0.092, data: 0.012) loss: 0.016 
(epoch: 393, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 393, iters: 3584, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 393, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 393, iters 1465104
End of epoch 393 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001706
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 393, TEST ACC: [94.841 %]

(epoch: 394, iters: 16, time: 0.107, data: 0.000) loss: 0.000 
saving the latest model (epoch 394, total_steps 1465120)
(epoch: 394, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 394, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 394, iters: 256, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 394, iters: 336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 394, iters: 416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 394, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 394, iters: 576, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 394, iters: 656, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 394, iters: 736, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 394, iters: 816, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 394, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 394, iters: 976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 394, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 394, iters: 1136, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 394, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 394, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 394, iters: 1376, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 394, iters: 1456, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 394, iters: 1536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 394, iters: 1616, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 394, iters: 1696, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 394, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 394, iters: 1856, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 394, iters: 1936, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 394, iters: 2016, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 394, iters: 2096, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 394, iters: 2176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 394, iters: 2256, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 394, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 394, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 394, iters: 2496, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 394, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 394, iters: 2656, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 394, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 394, iters: 2816, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 394, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 394, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 394, iters: 3056, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 394, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 394, iters: 3216, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 394, iters: 3296, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 394, iters: 3376, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 394, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 394, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 394, iters: 3616, time: 0.094, data: 0.040) loss: 0.056 
(epoch: 394, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 394, iters 1468832
End of epoch 394 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001705
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 394, TEST ACC: [94.689 %]

saving the latest model (epoch 395, total_steps 1468848)
(epoch: 395, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 395, iters: 128, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 395, iters: 208, time: 0.094, data: 0.000) loss: 0.055 
(epoch: 395, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 395, iters: 368, time: 0.093, data: 0.000) loss: 0.054 
(epoch: 395, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 395, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 395, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 395, iters: 688, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 395, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 395, iters: 848, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 395, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 395, iters: 1008, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 395, iters: 1088, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 395, iters: 1168, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 395, iters: 1248, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 395, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 395, iters: 1408, time: 0.095, data: 0.011) loss: 0.004 
(epoch: 395, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 395, iters: 1568, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 395, iters: 1648, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 395, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 395, iters: 1808, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 395, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 395, iters: 1968, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 395, iters: 2048, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 395, iters: 2128, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 395, iters: 2208, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 395, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 395, iters: 2368, time: 0.094, data: 0.041) loss: 0.002 
(epoch: 395, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 395, iters: 2528, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 395, iters: 2608, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 395, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 395, iters: 2768, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 395, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 395, iters: 2928, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 395, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 395, iters: 3088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 395, iters: 3168, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 395, iters: 3248, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 395, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 395, iters: 3408, time: 0.093, data: 0.000) loss: 0.020 
(epoch: 395, iters: 3488, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 395, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 395, iters: 3648, time: 0.086, data: 0.011) loss: 0.000 
(epoch: 395, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 395, iters 1472560
End of epoch 395 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001704
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 395, TEST ACC: [89.226 %]

saving the latest model (epoch 396, total_steps 1472576)
(epoch: 396, iters: 80, time: 0.095, data: 0.434) loss: 0.000 
(epoch: 396, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 396, iters: 240, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 396, iters: 320, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 396, iters: 400, time: 0.092, data: 0.013) loss: 0.002 
(epoch: 396, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 396, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 396, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 396, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 396, iters: 800, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 396, iters: 880, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 396, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 396, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 396, iters: 1120, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 396, iters: 1200, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 396, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 396, iters: 1360, time: 0.094, data: 0.040) loss: 0.004 
(epoch: 396, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 396, iters: 1520, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 396, iters: 1600, time: 0.093, data: 0.000) loss: 0.015 
(epoch: 396, iters: 1680, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 396, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 396, iters: 1840, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 396, iters: 1920, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 396, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 396, iters: 2080, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 396, iters: 2160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 396, iters: 2240, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 396, iters: 2320, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 396, iters: 2400, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 396, iters: 2480, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 396, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 396, iters: 2640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 396, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 396, iters: 2800, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 396, iters: 2880, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 396, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 396, iters: 3040, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 396, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 396, iters: 3200, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 396, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 396, iters: 3360, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 396, iters: 3440, time: 0.094, data: 0.000) loss: 0.027 
(epoch: 396, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 396, iters: 3600, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 396, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 396, iters 1476288
End of epoch 396 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001703
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 396, TEST ACC: [95.751 %]

saving the latest model (epoch 397, total_steps 1476304)
(epoch: 397, iters: 32, time: 0.093, data: 0.005) loss: 0.000 
(epoch: 397, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 397, iters: 192, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 397, iters: 272, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 397, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 397, iters: 432, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 397, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 397, iters: 592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 397, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 397, iters: 752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 397, iters: 832, time: 0.095, data: 0.051) loss: 0.003 
(epoch: 397, iters: 912, time: 0.094, data: 0.000) loss: 0.038 
(epoch: 397, iters: 992, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 397, iters: 1072, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 397, iters: 1152, time: 0.096, data: 0.012) loss: 0.002 
(epoch: 397, iters: 1232, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 397, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 397, iters: 1392, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 397, iters: 1472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 397, iters: 1552, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 397, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 397, iters: 1712, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 397, iters: 1792, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 397, iters: 1872, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 397, iters: 1952, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 397, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 397, iters: 2112, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 397, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 397, iters: 2272, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 397, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 397, iters: 2432, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 397, iters: 2512, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 397, iters: 2592, time: 0.094, data: 0.000) loss: 0.037 
(epoch: 397, iters: 2672, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 397, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 397, iters: 2832, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 397, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 397, iters: 2992, time: 0.093, data: 0.000) loss: 0.022 
(epoch: 397, iters: 3072, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 397, iters: 3152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 397, iters: 3232, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 397, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 397, iters: 3392, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 397, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 397, iters: 3552, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 397, iters: 3632, time: 0.092, data: 0.039) loss: 0.000 
(epoch: 397, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 397, iters 1480016
End of epoch 397 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001702
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 397, TEST ACC: [96.055 %]

saving the latest model (epoch 398, total_steps 1480032)
(epoch: 398, iters: 64, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 398, iters: 144, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 398, iters: 224, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 398, iters: 304, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 398, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 398, iters: 464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 398, iters: 544, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 398, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 398, iters: 704, time: 0.093, data: 0.021) loss: 0.012 
(epoch: 398, iters: 784, time: 0.096, data: 0.000) loss: 0.031 
(epoch: 398, iters: 864, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 398, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 398, iters: 1024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 398, iters: 1104, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 398, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 398, iters: 1264, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 398, iters: 1344, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 398, iters: 1424, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 398, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 398, iters: 1584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 398, iters: 1664, time: 0.093, data: 0.047) loss: 0.001 
(epoch: 398, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 398, iters: 1824, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 398, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 398, iters: 1984, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 398, iters: 2064, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 398, iters: 2144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 398, iters: 2224, time: 0.095, data: 0.051) loss: 0.001 
(epoch: 398, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 398, iters: 2384, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 398, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 398, iters: 2544, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 398, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 398, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 398, iters: 2784, time: 0.095, data: 0.052) loss: 0.000 
(epoch: 398, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 398, iters: 2944, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 398, iters: 3024, time: 0.095, data: 0.000) loss: 0.018 
(epoch: 398, iters: 3104, time: 0.096, data: 0.021) loss: 0.000 
(epoch: 398, iters: 3184, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 398, iters: 3264, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 398, iters: 3344, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 398, iters: 3424, time: 0.094, data: 0.000) loss: 0.022 
(epoch: 398, iters: 3504, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 398, iters: 3584, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 398, iters: 3664, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 398, iters 1483744
End of epoch 398 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001701
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 398, TEST ACC: [96.662 %]

(epoch: 399, iters: 16, time: 0.111, data: 0.000) loss: 0.000 
saving the latest model (epoch 399, total_steps 1483760)
(epoch: 399, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 399, iters: 176, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 399, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 399, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 399, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 399, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 399, iters: 576, time: 0.094, data: 0.053) loss: 0.000 
(epoch: 399, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 399, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 399, iters: 816, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 399, iters: 896, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 399, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 399, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 399, iters: 1136, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 399, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 399, iters: 1296, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 399, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 399, iters: 1456, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 399, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 399, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 399, iters: 1696, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 399, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 399, iters: 1856, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 399, iters: 1936, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 399, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 399, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 399, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 399, iters: 2256, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 399, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 399, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 399, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 399, iters: 2576, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 399, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 399, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 399, iters: 2816, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 399, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 399, iters: 2976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 399, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 399, iters: 3136, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 399, iters: 3216, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 399, iters: 3296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 399, iters: 3376, time: 0.095, data: 0.041) loss: 0.004 
(epoch: 399, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 399, iters: 3536, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 399, iters: 3616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 399, iters: 3696, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 399, iters 1487472
End of epoch 399 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001700
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 399, TEST ACC: [96.51 %]

saving the latest model (epoch 400, total_steps 1487488)
(epoch: 400, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 400, iters: 128, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 400, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 400, iters: 288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 400, iters: 368, time: 0.093, data: 0.041) loss: 0.001 
(epoch: 400, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 400, iters: 528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 400, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 400, iters: 688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 400, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 400, iters: 848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 400, iters: 928, time: 0.097, data: 0.049) loss: 0.000 
(epoch: 400, iters: 1008, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 400, iters: 1088, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 400, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 400, iters: 1248, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 400, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 400, iters: 1408, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 400, iters: 1488, time: 0.095, data: 0.050) loss: 0.001 
(epoch: 400, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 400, iters: 1648, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 400, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 400, iters: 1808, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 400, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 400, iters: 1968, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 400, iters: 2048, time: 0.095, data: 0.052) loss: 0.012 
(epoch: 400, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 400, iters: 2208, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 400, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 400, iters: 2368, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 400, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 400, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 400, iters: 2608, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 400, iters: 2688, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 400, iters: 2768, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 400, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 400, iters: 2928, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 400, iters: 3008, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 400, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 400, iters: 3168, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 400, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 400, iters: 3328, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 400, iters: 3408, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 400, iters: 3488, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 400, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 400, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 400, iters: 3728, time: 0.056, data: 0.015) loss: 0.000 
saving the model at the end of epoch 400, iters 1491200
End of epoch 400 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001699
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 400, TEST ACC: [94.689 %]

saving the latest model (epoch 401, total_steps 1491216)
(epoch: 401, iters: 80, time: 0.095, data: 0.457) loss: 0.000 
(epoch: 401, iters: 160, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 401, iters: 240, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 401, iters: 320, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 401, iters: 400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 401, iters: 480, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 401, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 401, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 401, iters: 720, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 401, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 401, iters: 880, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 401, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 401, iters: 1040, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 401, iters: 1120, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 401, iters: 1200, time: 0.094, data: 0.000) loss: 0.121 
(epoch: 401, iters: 1280, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 401, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 401, iters: 1440, time: 0.092, data: 0.012) loss: 0.010 
(epoch: 401, iters: 1520, time: 0.094, data: 0.000) loss: 0.058 
(epoch: 401, iters: 1600, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 401, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 401, iters: 1760, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 401, iters: 1840, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 401, iters: 1920, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 401, iters: 2000, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 401, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 401, iters: 2160, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 401, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 401, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 401, iters: 2400, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 401, iters: 2480, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 401, iters: 2560, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 401, iters: 2640, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 401, iters: 2720, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 401, iters: 2800, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 401, iters: 2880, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 401, iters: 2960, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 401, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 401, iters: 3120, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 401, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 401, iters: 3280, time: 0.096, data: 0.012) loss: 0.003 
(epoch: 401, iters: 3360, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 401, iters: 3440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 401, iters: 3520, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 401, iters: 3600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 401, iters: 3680, time: 0.087, data: 0.011) loss: 0.002 
saving the model at the end of epoch 401, iters 1494928
End of epoch 401 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001698
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 401, TEST ACC: [94.385 %]

saving the latest model (epoch 402, total_steps 1494944)
(epoch: 402, iters: 32, time: 0.092, data: 0.007) loss: 0.003 
(epoch: 402, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 402, iters: 192, time: 0.094, data: 0.020) loss: 0.094 
(epoch: 402, iters: 272, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 402, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 402, iters: 432, time: 0.097, data: 0.042) loss: 0.012 
(epoch: 402, iters: 512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 402, iters: 592, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 402, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 402, iters: 752, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 402, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 402, iters: 912, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 402, iters: 992, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 402, iters: 1072, time: 0.097, data: 0.000) loss: 0.049 
(epoch: 402, iters: 1152, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 402, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 402, iters: 1312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 402, iters: 1392, time: 0.097, data: 0.000) loss: 0.008 
(epoch: 402, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 402, iters: 1552, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 402, iters: 1632, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 402, iters: 1712, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 402, iters: 1792, time: 0.098, data: 0.000) loss: 0.005 
(epoch: 402, iters: 1872, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 402, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 402, iters: 2032, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 402, iters: 2112, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 402, iters: 2192, time: 0.097, data: 0.000) loss: 0.070 
(epoch: 402, iters: 2272, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 402, iters: 2352, time: 0.097, data: 0.000) loss: 0.018 
(epoch: 402, iters: 2432, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 402, iters: 2512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 402, iters: 2592, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 402, iters: 2672, time: 0.094, data: 0.042) loss: 0.001 
(epoch: 402, iters: 2752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 402, iters: 2832, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 402, iters: 2912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 402, iters: 2992, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 402, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 402, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 402, iters: 3232, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 402, iters: 3312, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 402, iters: 3392, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 402, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 402, iters: 3552, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 402, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 402, iters: 3712, time: 0.088, data: 0.000) loss: 0.005 
saving the model at the end of epoch 402, iters 1498656
End of epoch 402 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001697
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 402, TEST ACC: [93.475 %]

saving the latest model (epoch 403, total_steps 1498672)
(epoch: 403, iters: 64, time: 0.093, data: 0.003) loss: 0.000 
(epoch: 403, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 403, iters: 224, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 403, iters: 304, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 403, iters: 384, time: 0.094, data: 0.050) loss: 0.001 
(epoch: 403, iters: 464, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 403, iters: 544, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 403, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 403, iters: 704, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 403, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 403, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 403, iters: 944, time: 0.094, data: 0.039) loss: 0.169 
(epoch: 403, iters: 1024, time: 0.096, data: 0.000) loss: 0.017 
(epoch: 403, iters: 1104, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 403, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 403, iters: 1264, time: 0.093, data: 0.012) loss: 0.010 
(epoch: 403, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 403, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 403, iters: 1504, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 403, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 403, iters: 1664, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 403, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 403, iters: 1824, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 403, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 403, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 403, iters: 2064, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 403, iters: 2144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 403, iters: 2224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 403, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 403, iters: 2384, time: 0.092, data: 0.013) loss: 0.002 
(epoch: 403, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 403, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 403, iters: 2624, time: 0.096, data: 0.040) loss: 0.005 
(epoch: 403, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 403, iters: 2784, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 403, iters: 2864, time: 0.097, data: 0.000) loss: 0.477 
(epoch: 403, iters: 2944, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 403, iters: 3024, time: 0.094, data: 0.000) loss: 0.032 
(epoch: 403, iters: 3104, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 403, iters: 3184, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 403, iters: 3264, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 403, iters: 3344, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 403, iters: 3424, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 403, iters: 3504, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 403, iters: 3584, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 403, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 403, iters 1502384
End of epoch 403 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001696
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 403, TEST ACC: [95.144 %]

(epoch: 404, iters: 16, time: 0.110, data: 0.012) loss: 0.000 
saving the latest model (epoch 404, total_steps 1502400)
(epoch: 404, iters: 96, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 404, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 404, iters: 256, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 404, iters: 336, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 404, iters: 416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 404, iters: 496, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 404, iters: 576, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 404, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 404, iters: 736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 404, iters: 816, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 404, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 404, iters: 976, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 404, iters: 1056, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 404, iters: 1136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 404, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 404, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 404, iters: 1376, time: 0.094, data: 0.041) loss: 0.034 
(epoch: 404, iters: 1456, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 404, iters: 1536, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 404, iters: 1616, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 404, iters: 1696, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 404, iters: 1776, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 404, iters: 1856, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 404, iters: 1936, time: 0.098, data: 0.051) loss: 0.017 
(epoch: 404, iters: 2016, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 404, iters: 2096, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 404, iters: 2176, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 404, iters: 2256, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 404, iters: 2336, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 404, iters: 2416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 404, iters: 2496, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 404, iters: 2576, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 404, iters: 2656, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 404, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 404, iters: 2816, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 404, iters: 2896, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 404, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 404, iters: 3056, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 404, iters: 3136, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 404, iters: 3216, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 404, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 404, iters: 3376, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 404, iters: 3456, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 404, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 404, iters: 3616, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 404, iters: 3696, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 404, iters 1506112
End of epoch 404 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001695
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 404, TEST ACC: [95.599 %]

saving the latest model (epoch 405, total_steps 1506128)
(epoch: 405, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 405, iters: 128, time: 0.096, data: 0.056) loss: 0.000 
(epoch: 405, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 405, iters: 288, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 405, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 405, iters: 448, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 405, iters: 528, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 405, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 405, iters: 688, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 405, iters: 768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 405, iters: 848, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 405, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 405, iters: 1008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 405, iters: 1088, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 405, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 405, iters: 1248, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 405, iters: 1328, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 405, iters: 1408, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 405, iters: 1488, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 405, iters: 1568, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 405, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 405, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 405, iters: 1808, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 405, iters: 1888, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 405, iters: 1968, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 405, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 405, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 405, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 405, iters: 2288, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 405, iters: 2368, time: 0.094, data: 0.040) loss: 0.020 
(epoch: 405, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 405, iters: 2528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 405, iters: 2608, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 405, iters: 2688, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 405, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 405, iters: 2848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 405, iters: 2928, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 405, iters: 3008, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 405, iters: 3088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 405, iters: 3168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 405, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 405, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 405, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 405, iters: 3488, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 405, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 405, iters: 3648, time: 0.087, data: 0.012) loss: 0.000 
(epoch: 405, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 405, iters 1509840
End of epoch 405 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001694
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 405, TEST ACC: [96.358 %]

saving the latest model (epoch 406, total_steps 1509856)
(epoch: 406, iters: 80, time: 0.093, data: 0.529) loss: 0.000 
(epoch: 406, iters: 160, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 406, iters: 240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 406, iters: 320, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 406, iters: 400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 406, iters: 480, time: 0.094, data: 0.039) loss: 0.004 
(epoch: 406, iters: 560, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 406, iters: 640, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 406, iters: 720, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 406, iters: 800, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 406, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 406, iters: 960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 406, iters: 1040, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 406, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 406, iters: 1200, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 406, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 406, iters: 1360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 406, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 406, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 406, iters: 1600, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 406, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 406, iters: 1760, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 406, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 406, iters: 1920, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 406, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 406, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 406, iters: 2160, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 406, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 406, iters: 2320, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 406, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 406, iters: 2480, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 406, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 406, iters: 2640, time: 0.092, data: 0.000) loss: 0.003 
(epoch: 406, iters: 2720, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 406, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 406, iters: 2880, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 406, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 406, iters: 3040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 406, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 406, iters: 3200, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 406, iters: 3280, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 406, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 406, iters: 3440, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 406, iters: 3520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 406, iters: 3600, time: 0.094, data: 0.021) loss: 0.033 
(epoch: 406, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 406, iters 1513568
End of epoch 406 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001693
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 406, TEST ACC: [77.542 %]

saving the latest model (epoch 407, total_steps 1513584)
(epoch: 407, iters: 32, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 407, iters: 112, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 407, iters: 192, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 407, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 407, iters: 352, time: 0.094, data: 0.040) loss: 0.024 
(epoch: 407, iters: 432, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 407, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 407, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 407, iters: 672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 407, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 407, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 407, iters: 912, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 407, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 407, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 407, iters: 1152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 407, iters: 1232, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 407, iters: 1312, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 407, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 407, iters: 1472, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 407, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 407, iters: 1632, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 407, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 407, iters: 1792, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 407, iters: 1872, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 407, iters: 1952, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 407, iters: 2032, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 407, iters: 2112, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 407, iters: 2192, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 407, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 407, iters: 2352, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 407, iters: 2432, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 407, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 407, iters: 2592, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 407, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 407, iters: 2752, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 407, iters: 2832, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 407, iters: 2912, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 407, iters: 2992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 407, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 407, iters: 3152, time: 0.097, data: 0.049) loss: 0.000 
(epoch: 407, iters: 3232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 407, iters: 3312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 407, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 407, iters: 3472, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 407, iters: 3552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 407, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 407, iters: 3712, time: 0.088, data: 0.035) loss: 0.000 
saving the model at the end of epoch 407, iters 1517296
End of epoch 407 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001692
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 407, TEST ACC: [95.296 %]

saving the latest model (epoch 408, total_steps 1517312)
(epoch: 408, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 408, iters: 144, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 408, iters: 224, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 408, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 408, iters: 384, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 408, iters: 464, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 408, iters: 544, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 408, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 408, iters: 704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 408, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 408, iters: 864, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 408, iters: 944, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 408, iters: 1024, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 408, iters: 1104, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 408, iters: 1184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 408, iters: 1264, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 408, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 408, iters: 1424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 408, iters: 1504, time: 0.096, data: 0.039) loss: 0.021 
(epoch: 408, iters: 1584, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 408, iters: 1664, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 408, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 408, iters: 1824, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 408, iters: 1904, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 408, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 408, iters: 2064, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 408, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 408, iters: 2224, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 408, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 408, iters: 2384, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 408, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 408, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 408, iters: 2624, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 408, iters: 2704, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 408, iters: 2784, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 408, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 408, iters: 2944, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 408, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 408, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 408, iters: 3184, time: 0.093, data: 0.049) loss: 0.018 
(epoch: 408, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 408, iters: 3344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 408, iters: 3424, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 408, iters: 3504, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 408, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 408, iters: 3664, time: 0.088, data: 0.000) loss: 0.002 
saving the model at the end of epoch 408, iters 1521024
End of epoch 408 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001691
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 408, TEST ACC: [96.206 %]

(epoch: 409, iters: 16, time: 0.112, data: 0.012) loss: 0.001 
saving the latest model (epoch 409, total_steps 1521040)
(epoch: 409, iters: 96, time: 0.095, data: 0.059) loss: 0.009 
(epoch: 409, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 409, iters: 256, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 409, iters: 336, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 409, iters: 416, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 409, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 409, iters: 576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 409, iters: 656, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 409, iters: 736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 409, iters: 816, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 409, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 409, iters: 976, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 409, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 409, iters: 1136, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 409, iters: 1216, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 409, iters: 1296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 409, iters: 1376, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 409, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 409, iters: 1536, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 409, iters: 1616, time: 0.094, data: 0.000) loss: 0.017 
(epoch: 409, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 409, iters: 1776, time: 0.094, data: 0.040) loss: 0.004 
(epoch: 409, iters: 1856, time: 0.095, data: 0.000) loss: 0.114 
(epoch: 409, iters: 1936, time: 0.092, data: 0.012) loss: 0.159 
(epoch: 409, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 409, iters: 2096, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 409, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 409, iters: 2256, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 409, iters: 2336, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 409, iters: 2416, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 409, iters: 2496, time: 0.092, data: 0.012) loss: 0.010 
(epoch: 409, iters: 2576, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 409, iters: 2656, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 409, iters: 2736, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 409, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 409, iters: 2896, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 409, iters: 2976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 409, iters: 3056, time: 0.091, data: 0.013) loss: 0.002 
(epoch: 409, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 409, iters: 3216, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 409, iters: 3296, time: 0.095, data: 0.000) loss: 0.028 
(epoch: 409, iters: 3376, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 409, iters: 3456, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 409, iters: 3536, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 409, iters: 3616, time: 0.091, data: 0.012) loss: 0.002 
(epoch: 409, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 409, iters 1524752
End of epoch 409 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001690
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 409, TEST ACC: [94.385 %]

saving the latest model (epoch 410, total_steps 1524768)
(epoch: 410, iters: 48, time: 0.093, data: 0.004) loss: 0.016 
(epoch: 410, iters: 128, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 410, iters: 208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 410, iters: 288, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 410, iters: 368, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 410, iters: 448, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 410, iters: 528, time: 0.097, data: 0.000) loss: 0.295 
(epoch: 410, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 410, iters: 688, time: 0.094, data: 0.040) loss: 0.012 
(epoch: 410, iters: 768, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 410, iters: 848, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 410, iters: 928, time: 0.097, data: 0.000) loss: 0.017 
(epoch: 410, iters: 1008, time: 0.093, data: 0.012) loss: 0.011 
(epoch: 410, iters: 1088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 410, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 410, iters: 1248, time: 0.096, data: 0.050) loss: 0.007 
(epoch: 410, iters: 1328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 410, iters: 1408, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 410, iters: 1488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 410, iters: 1568, time: 0.094, data: 0.012) loss: 0.094 
(epoch: 410, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 410, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 410, iters: 1808, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 410, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 410, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 410, iters: 2048, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 410, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 410, iters: 2208, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 410, iters: 2288, time: 0.094, data: 0.000) loss: 0.180 
(epoch: 410, iters: 2368, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 410, iters: 2448, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 410, iters: 2528, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 410, iters: 2608, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 410, iters: 2688, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 410, iters: 2768, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 410, iters: 2848, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 410, iters: 2928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 410, iters: 3008, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 410, iters: 3088, time: 0.093, data: 0.012) loss: 0.147 
(epoch: 410, iters: 3168, time: 0.092, data: 0.035) loss: 0.297 
(epoch: 410, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 410, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 410, iters: 3408, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 410, iters: 3488, time: 0.094, data: 0.024) loss: 0.004 
(epoch: 410, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 410, iters: 3648, time: 0.089, data: 0.000) loss: 0.097 
(epoch: 410, iters: 3728, time: 0.058, data: 0.011) loss: 0.010 
saving the model at the end of epoch 410, iters 1528480
End of epoch 410 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001689
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 410, TEST ACC: [95.903 %]

saving the latest model (epoch 411, total_steps 1528496)
(epoch: 411, iters: 80, time: 0.093, data: 0.498) loss: 0.000 
(epoch: 411, iters: 160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 411, iters: 240, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 411, iters: 320, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 411, iters: 400, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 411, iters: 480, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 411, iters: 560, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 411, iters: 640, time: 0.094, data: 0.011) loss: 0.016 
(epoch: 411, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 411, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 411, iters: 880, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 411, iters: 960, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 411, iters: 1040, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 411, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 411, iters: 1200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 411, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 411, iters: 1360, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 411, iters: 1440, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 411, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 411, iters: 1600, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 411, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 411, iters: 1760, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 411, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 411, iters: 1920, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 411, iters: 2000, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 411, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 411, iters: 2160, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 411, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 411, iters: 2320, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 411, iters: 2400, time: 0.097, data: 0.000) loss: 0.034 
(epoch: 411, iters: 2480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 411, iters: 2560, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 411, iters: 2640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 411, iters: 2720, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 411, iters: 2800, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 411, iters: 2880, time: 0.096, data: 0.011) loss: 0.022 
(epoch: 411, iters: 2960, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 411, iters: 3040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 411, iters: 3120, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 411, iters: 3200, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 411, iters: 3280, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 411, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 411, iters: 3440, time: 0.094, data: 0.021) loss: 0.001 
(epoch: 411, iters: 3520, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 411, iters: 3600, time: 0.093, data: 0.000) loss: 0.020 
(epoch: 411, iters: 3680, time: 0.089, data: 0.038) loss: 0.108 
saving the model at the end of epoch 411, iters 1532208
End of epoch 411 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001688
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 411, TEST ACC: [74.659 %]

saving the latest model (epoch 412, total_steps 1532224)
(epoch: 412, iters: 32, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 412, iters: 112, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 412, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 412, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 412, iters: 352, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 412, iters: 432, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 412, iters: 512, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 412, iters: 592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 412, iters: 672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 412, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 412, iters: 832, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 412, iters: 912, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 412, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 412, iters: 1072, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 412, iters: 1152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 412, iters: 1232, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 412, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 412, iters: 1392, time: 0.093, data: 0.000) loss: 0.010 
(epoch: 412, iters: 1472, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 412, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 412, iters: 1632, time: 0.092, data: 0.021) loss: 0.001 
(epoch: 412, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 412, iters: 1792, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 412, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 412, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 412, iters: 2032, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 412, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 412, iters: 2192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 412, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 412, iters: 2352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 412, iters: 2432, time: 0.094, data: 0.000) loss: 0.025 
(epoch: 412, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 412, iters: 2592, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 412, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 412, iters: 2752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 412, iters: 2832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 412, iters: 2912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 412, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 412, iters: 3072, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 412, iters: 3152, time: 0.096, data: 0.040) loss: 0.003 
(epoch: 412, iters: 3232, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 412, iters: 3312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 412, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 412, iters: 3472, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 412, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 412, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 412, iters: 3712, time: 0.088, data: 0.036) loss: 0.001 
saving the model at the end of epoch 412, iters 1535936
End of epoch 412 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001687
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 412, TEST ACC: [95.599 %]

saving the latest model (epoch 413, total_steps 1535952)
(epoch: 413, iters: 64, time: 0.093, data: 0.000) loss: 0.224 
(epoch: 413, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 413, iters: 224, time: 0.094, data: 0.019) loss: 0.000 
(epoch: 413, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 413, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 413, iters: 464, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 413, iters: 544, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 413, iters: 624, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 413, iters: 704, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 413, iters: 784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 413, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 413, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 413, iters: 1024, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 413, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 413, iters: 1184, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 413, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 413, iters: 1344, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 413, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 413, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 413, iters: 1584, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 413, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 413, iters: 1744, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 413, iters: 1824, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 413, iters: 1904, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 413, iters: 1984, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 413, iters: 2064, time: 0.093, data: 0.000) loss: 0.010 
(epoch: 413, iters: 2144, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 413, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 413, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 413, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 413, iters: 2464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 413, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 413, iters: 2624, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 413, iters: 2704, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 413, iters: 2784, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 413, iters: 2864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 413, iters: 2944, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 413, iters: 3024, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 413, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 413, iters: 3184, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 413, iters: 3264, time: 0.094, data: 0.040) loss: 0.011 
(epoch: 413, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 413, iters: 3424, time: 0.091, data: 0.011) loss: 0.005 
(epoch: 413, iters: 3504, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 413, iters: 3584, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 413, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 413, iters 1539664
End of epoch 413 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001686
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 413, TEST ACC: [96.51 %]

(epoch: 414, iters: 16, time: 0.108, data: 0.000) loss: 0.000 
saving the latest model (epoch 414, total_steps 1539680)
(epoch: 414, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 414, iters: 176, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 414, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 414, iters: 336, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 414, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 414, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 414, iters: 576, time: 0.094, data: 0.040) loss: 0.016 
(epoch: 414, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 414, iters: 736, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 414, iters: 816, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 414, iters: 896, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 414, iters: 976, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 414, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 414, iters: 1136, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 414, iters: 1216, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 414, iters: 1296, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 414, iters: 1376, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 414, iters: 1456, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 414, iters: 1536, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 414, iters: 1616, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 414, iters: 1696, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 414, iters: 1776, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 414, iters: 1856, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 414, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 414, iters: 2016, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 414, iters: 2096, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 414, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 414, iters: 2256, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 414, iters: 2336, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 414, iters: 2416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 414, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 414, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 414, iters: 2656, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 414, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 414, iters: 2816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 414, iters: 2896, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 414, iters: 2976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 414, iters: 3056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 414, iters: 3136, time: 0.093, data: 0.012) loss: 0.007 
(epoch: 414, iters: 3216, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 414, iters: 3296, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 414, iters: 3376, time: 0.094, data: 0.043) loss: 0.000 
(epoch: 414, iters: 3456, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 414, iters: 3536, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 414, iters: 3616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 414, iters: 3696, time: 0.088, data: 0.012) loss: 0.001 
saving the model at the end of epoch 414, iters 1543392
End of epoch 414 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001685
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 414, TEST ACC: [95.903 %]

saving the latest model (epoch 415, total_steps 1543408)
(epoch: 415, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 415, iters: 128, time: 0.095, data: 0.042) loss: 0.011 
(epoch: 415, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 415, iters: 288, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 415, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 415, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 415, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 415, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 415, iters: 688, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 415, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 415, iters: 848, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 415, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 415, iters: 1008, time: 0.094, data: 0.012) loss: 0.009 
(epoch: 415, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 415, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 415, iters: 1248, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 415, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 415, iters: 1408, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 415, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 415, iters: 1568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 415, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 415, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 415, iters: 1808, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 415, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 415, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 415, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 415, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 415, iters: 2208, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 415, iters: 2288, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 415, iters: 2368, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 415, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 415, iters: 2528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 415, iters: 2608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 415, iters: 2688, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 415, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 415, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 415, iters: 2928, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 415, iters: 3008, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 415, iters: 3088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 415, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 415, iters: 3248, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 415, iters: 3328, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 415, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 415, iters: 3488, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 415, iters: 3568, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 415, iters: 3648, time: 0.086, data: 0.011) loss: 0.000 
(epoch: 415, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 415, iters 1547120
End of epoch 415 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001684
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 415, TEST ACC: [94.689 %]

saving the latest model (epoch 416, total_steps 1547136)
(epoch: 416, iters: 80, time: 0.095, data: 0.505) loss: 0.000 
(epoch: 416, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 416, iters: 240, time: 0.096, data: 0.039) loss: 0.040 
(epoch: 416, iters: 320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 416, iters: 400, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 416, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 416, iters: 560, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 416, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 416, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 416, iters: 800, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 416, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 416, iters: 960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 416, iters: 1040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 416, iters: 1120, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 416, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 416, iters: 1280, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 416, iters: 1360, time: 0.095, data: 0.048) loss: 0.239 
(epoch: 416, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 416, iters: 1520, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 416, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 416, iters: 1680, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 416, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 416, iters: 1840, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 416, iters: 1920, time: 0.095, data: 0.051) loss: 0.001 
(epoch: 416, iters: 2000, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 416, iters: 2080, time: 0.092, data: 0.012) loss: 0.028 
(epoch: 416, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 416, iters: 2240, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 416, iters: 2320, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 416, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 416, iters: 2480, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 416, iters: 2560, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 416, iters: 2640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 416, iters: 2720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 416, iters: 2800, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 416, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 416, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 416, iters: 3040, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 416, iters: 3120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 416, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 416, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 416, iters: 3360, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 416, iters: 3440, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 416, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 416, iters: 3600, time: 0.094, data: 0.040) loss: 0.010 
(epoch: 416, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 416, iters 1550848
End of epoch 416 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001683
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 416, TEST ACC: [90.592 %]

saving the latest model (epoch 417, total_steps 1550864)
(epoch: 417, iters: 32, time: 0.092, data: 0.003) loss: 0.005 
(epoch: 417, iters: 112, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 417, iters: 192, time: 0.094, data: 0.000) loss: 0.191 
(epoch: 417, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 417, iters: 352, time: 0.093, data: 0.040) loss: 0.002 
(epoch: 417, iters: 432, time: 0.094, data: 0.000) loss: 0.069 
(epoch: 417, iters: 512, time: 0.092, data: 0.012) loss: 0.008 
(epoch: 417, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 417, iters: 672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 417, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 417, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 417, iters: 912, time: 0.094, data: 0.039) loss: 0.007 
(epoch: 417, iters: 992, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 417, iters: 1072, time: 0.094, data: 0.012) loss: 0.006 
(epoch: 417, iters: 1152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 417, iters: 1232, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 417, iters: 1312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 417, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 417, iters: 1472, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 417, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 417, iters: 1632, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 417, iters: 1712, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 417, iters: 1792, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 417, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 417, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 417, iters: 2032, time: 0.094, data: 0.039) loss: 0.002 
(epoch: 417, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 417, iters: 2192, time: 0.091, data: 0.011) loss: 0.099 
(epoch: 417, iters: 2272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 417, iters: 2352, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 417, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 417, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 417, iters: 2592, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 417, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 417, iters: 2752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 417, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 417, iters: 2912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 417, iters: 2992, time: 0.094, data: 0.000) loss: 0.225 
(epoch: 417, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 417, iters: 3152, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 417, iters: 3232, time: 0.094, data: 0.000) loss: 0.039 
(epoch: 417, iters: 3312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 417, iters: 3392, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 417, iters: 3472, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 417, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 417, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 417, iters: 3712, time: 0.087, data: 0.036) loss: 0.000 
saving the model at the end of epoch 417, iters 1554576
End of epoch 417 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001682
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 417, TEST ACC: [91.958 %]

saving the latest model (epoch 418, total_steps 1554592)
(epoch: 418, iters: 64, time: 0.091, data: 0.000) loss: 0.005 
(epoch: 418, iters: 144, time: 0.092, data: 0.000) loss: 0.004 
(epoch: 418, iters: 224, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 418, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 418, iters: 384, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 418, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 418, iters: 544, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 418, iters: 624, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 418, iters: 704, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 418, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 418, iters: 864, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 418, iters: 944, time: 0.093, data: 0.047) loss: 0.075 
(epoch: 418, iters: 1024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 418, iters: 1104, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 418, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 418, iters: 1264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 418, iters: 1344, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 418, iters: 1424, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 418, iters: 1504, time: 0.093, data: 0.048) loss: 0.002 
(epoch: 418, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 418, iters: 1664, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 418, iters: 1744, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 418, iters: 1824, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 418, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 418, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 418, iters: 2064, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 418, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 418, iters: 2224, time: 0.093, data: 0.011) loss: 0.012 
(epoch: 418, iters: 2304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 418, iters: 2384, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 418, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 418, iters: 2544, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 418, iters: 2624, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 418, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 418, iters: 2784, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 418, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 418, iters: 2944, time: 0.093, data: 0.012) loss: 0.029 
(epoch: 418, iters: 3024, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 418, iters: 3104, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 418, iters: 3184, time: 0.094, data: 0.052) loss: 0.000 
(epoch: 418, iters: 3264, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 418, iters: 3344, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 418, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 418, iters: 3504, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 418, iters: 3584, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 418, iters: 3664, time: 0.086, data: 0.000) loss: 0.000 
saving the model at the end of epoch 418, iters 1558304
End of epoch 418 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001681
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 418, TEST ACC: [96.51 %]

(epoch: 419, iters: 16, time: 0.108, data: 0.011) loss: 0.000 
saving the latest model (epoch 419, total_steps 1558320)
(epoch: 419, iters: 96, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 419, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 419, iters: 256, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 419, iters: 336, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 419, iters: 416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 419, iters: 496, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 419, iters: 576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 419, iters: 656, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 419, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 419, iters: 816, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 419, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 419, iters: 976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 419, iters: 1056, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 419, iters: 1136, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 419, iters: 1216, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 419, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 419, iters: 1376, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 419, iters: 1456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 419, iters: 1536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 419, iters: 1616, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 419, iters: 1696, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 419, iters: 1776, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 419, iters: 1856, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 419, iters: 1936, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 419, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 419, iters: 2096, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 419, iters: 2176, time: 0.094, data: 0.038) loss: 0.073 
(epoch: 419, iters: 2256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 419, iters: 2336, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 419, iters: 2416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 419, iters: 2496, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 419, iters: 2576, time: 0.097, data: 0.000) loss: 0.011 
(epoch: 419, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 419, iters: 2736, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 419, iters: 2816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 419, iters: 2896, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 419, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 419, iters: 3056, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 419, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 419, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 419, iters: 3296, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 419, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 419, iters: 3456, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 419, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 419, iters: 3616, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 419, iters: 3696, time: 0.087, data: 0.000) loss: 0.010 
saving the model at the end of epoch 419, iters 1562032
End of epoch 419 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001680
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 419, TEST ACC: [95.599 %]

saving the latest model (epoch 420, total_steps 1562048)
(epoch: 420, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 420, iters: 128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 420, iters: 208, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 420, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 420, iters: 368, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 420, iters: 448, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 420, iters: 528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 420, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 420, iters: 688, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 420, iters: 768, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 420, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 420, iters: 928, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 420, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 420, iters: 1088, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 420, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 420, iters: 1248, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 420, iters: 1328, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 420, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 420, iters: 1488, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 420, iters: 1568, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 420, iters: 1648, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 420, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 420, iters: 1808, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 420, iters: 1888, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 420, iters: 1968, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 420, iters: 2048, time: 0.091, data: 0.011) loss: 0.020 
(epoch: 420, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 420, iters: 2208, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 420, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 420, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 420, iters: 2448, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 420, iters: 2528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 420, iters: 2608, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 420, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 420, iters: 2768, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 420, iters: 2848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 420, iters: 2928, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 420, iters: 3008, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 420, iters: 3088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 420, iters: 3168, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 420, iters: 3248, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 420, iters: 3328, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 420, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 420, iters: 3488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 420, iters: 3568, time: 0.094, data: 0.039) loss: 0.073 
(epoch: 420, iters: 3648, time: 0.088, data: 0.000) loss: 0.008 
(epoch: 420, iters: 3728, time: 0.058, data: 0.011) loss: 0.001 
saving the model at the end of epoch 420, iters 1565760
End of epoch 420 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001679
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 420, TEST ACC: [94.082 %]

saving the latest model (epoch 421, total_steps 1565776)
(epoch: 421, iters: 80, time: 0.095, data: 0.448) loss: 0.000 
(epoch: 421, iters: 160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 421, iters: 240, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 421, iters: 320, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 421, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 421, iters: 480, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 421, iters: 560, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 421, iters: 640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 421, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 421, iters: 800, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 421, iters: 880, time: 0.093, data: 0.038) loss: 0.001 
(epoch: 421, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 421, iters: 1040, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 421, iters: 1120, time: 0.093, data: 0.000) loss: 0.239 
(epoch: 421, iters: 1200, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 421, iters: 1280, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 421, iters: 1360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 421, iters: 1440, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 421, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 421, iters: 1600, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 421, iters: 1680, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 421, iters: 1760, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 421, iters: 1840, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 421, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 421, iters: 2000, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 421, iters: 2080, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 421, iters: 2160, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 421, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 421, iters: 2320, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 421, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 421, iters: 2480, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 421, iters: 2560, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 421, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 421, iters: 2720, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 421, iters: 2800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 421, iters: 2880, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 421, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 421, iters: 3040, time: 0.092, data: 0.000) loss: 0.006 
(epoch: 421, iters: 3120, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 421, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 421, iters: 3280, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 421, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 421, iters: 3440, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 421, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 421, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 421, iters: 3680, time: 0.090, data: 0.040) loss: 0.000 
saving the model at the end of epoch 421, iters 1569488
End of epoch 421 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001678
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 421, TEST ACC: [94.841 %]

saving the latest model (epoch 422, total_steps 1569504)
(epoch: 422, iters: 32, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 422, iters: 112, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 422, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 422, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 422, iters: 352, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 422, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 422, iters: 512, time: 0.093, data: 0.012) loss: 0.029 
(epoch: 422, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 422, iters: 672, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 422, iters: 752, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 422, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 422, iters: 912, time: 0.097, data: 0.047) loss: 0.000 
(epoch: 422, iters: 992, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 422, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 422, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 422, iters: 1232, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 422, iters: 1312, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 422, iters: 1392, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 422, iters: 1472, time: 0.095, data: 0.048) loss: 0.088 
(epoch: 422, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 422, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 422, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 422, iters: 1792, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 422, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 422, iters: 1952, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 422, iters: 2032, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 422, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 422, iters: 2192, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 422, iters: 2272, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 422, iters: 2352, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 422, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 422, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 422, iters: 2592, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 422, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 422, iters: 2752, time: 0.092, data: 0.013) loss: 0.002 
(epoch: 422, iters: 2832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 422, iters: 2912, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 422, iters: 2992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 422, iters: 3072, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 422, iters: 3152, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 422, iters: 3232, time: 0.096, data: 0.000) loss: 0.186 
(epoch: 422, iters: 3312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 422, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 422, iters: 3472, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 422, iters: 3552, time: 0.094, data: 0.000) loss: 0.143 
(epoch: 422, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 422, iters: 3712, time: 0.088, data: 0.036) loss: 0.000 
saving the model at the end of epoch 422, iters 1573216
End of epoch 422 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001677
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 422, TEST ACC: [94.234 %]

saving the latest model (epoch 423, total_steps 1573232)
(epoch: 423, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 423, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 423, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 423, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 423, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 423, iters: 464, time: 0.095, data: 0.039) loss: 0.019 
(epoch: 423, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 423, iters: 624, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 423, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 423, iters: 784, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 423, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 423, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 423, iters: 1024, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 423, iters: 1104, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 423, iters: 1184, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 423, iters: 1264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 423, iters: 1344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 423, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 423, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 423, iters: 1584, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 423, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 423, iters: 1744, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 423, iters: 1824, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 423, iters: 1904, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 423, iters: 1984, time: 0.095, data: 0.000) loss: 0.344 
(epoch: 423, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 423, iters: 2144, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 423, iters: 2224, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 423, iters: 2304, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 423, iters: 2384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 423, iters: 2464, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 423, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 423, iters: 2624, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 423, iters: 2704, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 423, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 423, iters: 2864, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 423, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 423, iters: 3024, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 423, iters: 3104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 423, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 423, iters: 3264, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 423, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 423, iters: 3424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 423, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 423, iters: 3584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 423, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 423, iters 1576944
End of epoch 423 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001676
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 423, TEST ACC: [93.93 %]

(epoch: 424, iters: 16, time: 0.112, data: 0.000) loss: 0.001 
saving the latest model (epoch 424, total_steps 1576960)
(epoch: 424, iters: 96, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 424, iters: 176, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 424, iters: 256, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 424, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 424, iters: 416, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 424, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 424, iters: 576, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 424, iters: 656, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 424, iters: 736, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 424, iters: 816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 424, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 424, iters: 976, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 424, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 424, iters: 1136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 424, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 424, iters: 1296, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 424, iters: 1376, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 424, iters: 1456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 424, iters: 1536, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 424, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 424, iters: 1696, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 424, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 424, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 424, iters: 1936, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 424, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 424, iters: 2096, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 424, iters: 2176, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 424, iters: 2256, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 424, iters: 2336, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 424, iters: 2416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 424, iters: 2496, time: 0.094, data: 0.047) loss: 0.001 
(epoch: 424, iters: 2576, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 424, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 424, iters: 2736, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 424, iters: 2816, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 424, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 424, iters: 2976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 424, iters: 3056, time: 0.098, data: 0.051) loss: 0.000 
(epoch: 424, iters: 3136, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 424, iters: 3216, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 424, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 424, iters: 3376, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 424, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 424, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 424, iters: 3616, time: 0.096, data: 0.039) loss: 0.001 
(epoch: 424, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 424, iters 1580672
End of epoch 424 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001675
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 424, TEST ACC: [96.662 %]

saving the latest model (epoch 425, total_steps 1580688)
(epoch: 425, iters: 48, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 425, iters: 128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 425, iters: 208, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 425, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 425, iters: 368, time: 0.092, data: 0.012) loss: 0.007 
(epoch: 425, iters: 448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 425, iters: 528, time: 0.093, data: 0.011) loss: 0.025 
(epoch: 425, iters: 608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 425, iters: 688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 425, iters: 768, time: 0.094, data: 0.039) loss: 0.005 
(epoch: 425, iters: 848, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 425, iters: 928, time: 0.091, data: 0.012) loss: 0.003 
(epoch: 425, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 425, iters: 1088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 425, iters: 1168, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 425, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 425, iters: 1328, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 425, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 425, iters: 1488, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 425, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 425, iters: 1648, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 425, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 425, iters: 1808, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 425, iters: 1888, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 425, iters: 1968, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 425, iters: 2048, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 425, iters: 2128, time: 0.095, data: 0.000) loss: 0.159 
(epoch: 425, iters: 2208, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 425, iters: 2288, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 425, iters: 2368, time: 0.092, data: 0.000) loss: 0.085 
(epoch: 425, iters: 2448, time: 0.097, data: 0.048) loss: 0.000 
(epoch: 425, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 425, iters: 2608, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 425, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 425, iters: 2768, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 425, iters: 2848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 425, iters: 2928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 425, iters: 3008, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 425, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 425, iters: 3168, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 425, iters: 3248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 425, iters: 3328, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 425, iters: 3408, time: 0.094, data: 0.000) loss: 0.056 
(epoch: 425, iters: 3488, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 425, iters: 3568, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 425, iters: 3648, time: 0.088, data: 0.000) loss: 0.120 
(epoch: 425, iters: 3728, time: 0.056, data: 0.011) loss: 0.000 
saving the model at the end of epoch 425, iters 1584400
End of epoch 425 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001674
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 425, TEST ACC: [95.144 %]

saving the latest model (epoch 426, total_steps 1584416)
(epoch: 426, iters: 80, time: 0.094, data: 0.470) loss: 0.000 
(epoch: 426, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 426, iters: 240, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 426, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 426, iters: 400, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 426, iters: 480, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 426, iters: 560, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 426, iters: 640, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 426, iters: 720, time: 0.093, data: 0.000) loss: 0.024 
(epoch: 426, iters: 800, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 426, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 426, iters: 960, time: 0.092, data: 0.013) loss: 0.003 
(epoch: 426, iters: 1040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 426, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 426, iters: 1200, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 426, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 426, iters: 1360, time: 0.093, data: 0.041) loss: 0.002 
(epoch: 426, iters: 1440, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 426, iters: 1520, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 426, iters: 1600, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 426, iters: 1680, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 426, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 426, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 426, iters: 1920, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 426, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 426, iters: 2080, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 426, iters: 2160, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 426, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 426, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 426, iters: 2400, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 426, iters: 2480, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 426, iters: 2560, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 426, iters: 2640, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 426, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 426, iters: 2800, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 426, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 426, iters: 2960, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 426, iters: 3040, time: 0.093, data: 0.047) loss: 0.000 
(epoch: 426, iters: 3120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 426, iters: 3200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 426, iters: 3280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 426, iters: 3360, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 426, iters: 3440, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 426, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 426, iters: 3600, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 426, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 426, iters 1588128
End of epoch 426 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001673
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 426, TEST ACC: [94.234 %]

saving the latest model (epoch 427, total_steps 1588144)
(epoch: 427, iters: 32, time: 0.093, data: 0.005) loss: 0.000 
(epoch: 427, iters: 112, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 427, iters: 192, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 427, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 427, iters: 352, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 427, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 427, iters: 512, time: 0.094, data: 0.000) loss: 0.040 
(epoch: 427, iters: 592, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 427, iters: 672, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 427, iters: 752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 427, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 427, iters: 912, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 427, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 427, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 427, iters: 1152, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 427, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 427, iters: 1312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 427, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 427, iters: 1472, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 427, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 427, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 427, iters: 1712, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 427, iters: 1792, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 427, iters: 1872, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 427, iters: 1952, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 427, iters: 2032, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 427, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 427, iters: 2192, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 427, iters: 2272, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 427, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 427, iters: 2432, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 427, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 427, iters: 2592, time: 0.092, data: 0.011) loss: 0.014 
(epoch: 427, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 427, iters: 2752, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 427, iters: 2832, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 427, iters: 2912, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 427, iters: 2992, time: 0.092, data: 0.012) loss: 0.018 
(epoch: 427, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 427, iters: 3152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 427, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 427, iters: 3312, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 427, iters: 3392, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 427, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 427, iters: 3552, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 427, iters: 3632, time: 0.091, data: 0.000) loss: 0.002 
(epoch: 427, iters: 3712, time: 0.088, data: 0.013) loss: 0.001 
saving the model at the end of epoch 427, iters 1591856
End of epoch 427 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001672
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 427, TEST ACC: [93.778 %]

saving the latest model (epoch 428, total_steps 1591872)
(epoch: 428, iters: 64, time: 0.093, data: 0.003) loss: 0.000 
(epoch: 428, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 428, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 428, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 428, iters: 384, time: 0.093, data: 0.000) loss: 0.008 
(epoch: 428, iters: 464, time: 0.096, data: 0.048) loss: 0.000 
(epoch: 428, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 428, iters: 624, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 428, iters: 704, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 428, iters: 784, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 428, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 428, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 428, iters: 1024, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 428, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 428, iters: 1184, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 428, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 428, iters: 1344, time: 0.095, data: 0.020) loss: 0.000 
(epoch: 428, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 428, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 428, iters: 1584, time: 0.097, data: 0.050) loss: 0.000 
(epoch: 428, iters: 1664, time: 0.096, data: 0.000) loss: 0.031 
(epoch: 428, iters: 1744, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 428, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 428, iters: 1904, time: 0.095, data: 0.012) loss: 0.121 
(epoch: 428, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 428, iters: 2064, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 428, iters: 2144, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 428, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 428, iters: 2304, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 428, iters: 2384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 428, iters: 2464, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 428, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 428, iters: 2624, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 428, iters: 2704, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 428, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 428, iters: 2864, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 428, iters: 2944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 428, iters: 3024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 428, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 428, iters: 3184, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 428, iters: 3264, time: 0.094, data: 0.038) loss: 0.001 
(epoch: 428, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 428, iters: 3424, time: 0.091, data: 0.011) loss: 0.333 
(epoch: 428, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 428, iters: 3584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 428, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 428, iters 1595584
End of epoch 428 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001671
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 428, TEST ACC: [95.296 %]

(epoch: 429, iters: 16, time: 0.112, data: 0.000) loss: 0.000 
saving the latest model (epoch 429, total_steps 1595600)
(epoch: 429, iters: 96, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 429, iters: 176, time: 0.094, data: 0.012) loss: 0.007 
(epoch: 429, iters: 256, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 429, iters: 336, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 429, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 429, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 429, iters: 576, time: 0.095, data: 0.052) loss: 0.000 
(epoch: 429, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 429, iters: 736, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 429, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 429, iters: 896, time: 0.095, data: 0.020) loss: 0.000 
(epoch: 429, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 429, iters: 1056, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 429, iters: 1136, time: 0.096, data: 0.040) loss: 0.002 
(epoch: 429, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 429, iters: 1296, time: 0.094, data: 0.012) loss: 0.010 
(epoch: 429, iters: 1376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 429, iters: 1456, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 429, iters: 1536, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 429, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 429, iters: 1696, time: 0.095, data: 0.040) loss: 0.005 
(epoch: 429, iters: 1776, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 429, iters: 1856, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 429, iters: 1936, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 429, iters: 2016, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 429, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 429, iters: 2176, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 429, iters: 2256, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 429, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 429, iters: 2416, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 429, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 429, iters: 2576, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 429, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 429, iters: 2736, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 429, iters: 2816, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 429, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 429, iters: 2976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 429, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 429, iters: 3136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 429, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 429, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 429, iters: 3376, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 429, iters: 3456, time: 0.093, data: 0.034) loss: 0.000 
(epoch: 429, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 429, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 429, iters: 3696, time: 0.088, data: 0.011) loss: 0.067 
saving the model at the end of epoch 429, iters 1599312
End of epoch 429 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001670
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 429, TEST ACC: [92.261 %]

saving the latest model (epoch 430, total_steps 1599328)
(epoch: 430, iters: 48, time: 0.094, data: 0.004) loss: 0.000 
(epoch: 430, iters: 128, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 430, iters: 208, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 430, iters: 288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 430, iters: 368, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 430, iters: 448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 430, iters: 528, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 430, iters: 608, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 430, iters: 688, time: 0.094, data: 0.000) loss: 0.248 
(epoch: 430, iters: 768, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 430, iters: 848, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 430, iters: 928, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 430, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 430, iters: 1088, time: 0.092, data: 0.000) loss: 0.003 
(epoch: 430, iters: 1168, time: 0.095, data: 0.038) loss: 0.006 
(epoch: 430, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 430, iters: 1328, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 430, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 430, iters: 1488, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 430, iters: 1568, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 430, iters: 1648, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 430, iters: 1728, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 430, iters: 1808, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 430, iters: 1888, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 430, iters: 1968, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 430, iters: 2048, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 430, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 430, iters: 2208, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 430, iters: 2288, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 430, iters: 2368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 430, iters: 2448, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 430, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 430, iters: 2608, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 430, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 430, iters: 2768, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 430, iters: 2848, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 430, iters: 2928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 430, iters: 3008, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 430, iters: 3088, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 430, iters: 3168, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 430, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 430, iters: 3328, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 430, iters: 3408, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 430, iters: 3488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 430, iters: 3568, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 430, iters: 3648, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 430, iters: 3728, time: 0.056, data: 0.020) loss: 0.000 
saving the model at the end of epoch 430, iters 1603040
End of epoch 430 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001669
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 430, TEST ACC: [95.903 %]

saving the latest model (epoch 431, total_steps 1603056)
(epoch: 431, iters: 80, time: 0.095, data: 0.483) loss: 0.000 
(epoch: 431, iters: 160, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 431, iters: 240, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 431, iters: 320, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 431, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 431, iters: 480, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 431, iters: 560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 431, iters: 640, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 431, iters: 720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 431, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 431, iters: 880, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 431, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 431, iters: 1040, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 431, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 431, iters: 1200, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 431, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 431, iters: 1360, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 431, iters: 1440, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 431, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 431, iters: 1600, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 431, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 431, iters: 1760, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 431, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 431, iters: 1920, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 431, iters: 2000, time: 0.094, data: 0.050) loss: 0.001 
(epoch: 431, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 431, iters: 2160, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 431, iters: 2240, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 431, iters: 2320, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 431, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 431, iters: 2480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 431, iters: 2560, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 431, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 431, iters: 2720, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 431, iters: 2800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 431, iters: 2880, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 431, iters: 2960, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 431, iters: 3040, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 431, iters: 3120, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 431, iters: 3200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 431, iters: 3280, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 431, iters: 3360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 431, iters: 3440, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 431, iters: 3520, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 431, iters: 3600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 431, iters: 3680, time: 0.090, data: 0.040) loss: 0.000 
saving the model at the end of epoch 431, iters 1606768
End of epoch 431 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001668
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 431, TEST ACC: [87.709 %]

saving the latest model (epoch 432, total_steps 1606784)
(epoch: 432, iters: 32, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 432, iters: 112, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 432, iters: 192, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 432, iters: 272, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 432, iters: 352, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 432, iters: 432, time: 0.094, data: 0.000) loss: 0.146 
(epoch: 432, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 432, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 432, iters: 672, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 432, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 432, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 432, iters: 912, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 432, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 432, iters: 1072, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 432, iters: 1152, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 432, iters: 1232, time: 0.096, data: 0.012) loss: 0.055 
(epoch: 432, iters: 1312, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 432, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 432, iters: 1472, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 432, iters: 1552, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 432, iters: 1632, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 432, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 432, iters: 1792, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 432, iters: 1872, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 432, iters: 1952, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 432, iters: 2032, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 432, iters: 2112, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 432, iters: 2192, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 432, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 432, iters: 2352, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 432, iters: 2432, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 432, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 432, iters: 2592, time: 0.097, data: 0.041) loss: 0.020 
(epoch: 432, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 432, iters: 2752, time: 0.092, data: 0.011) loss: 0.009 
(epoch: 432, iters: 2832, time: 0.093, data: 0.000) loss: 0.112 
(epoch: 432, iters: 2912, time: 0.094, data: 0.011) loss: 0.007 
(epoch: 432, iters: 2992, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 432, iters: 3072, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 432, iters: 3152, time: 0.096, data: 0.052) loss: 0.062 
(epoch: 432, iters: 3232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 432, iters: 3312, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 432, iters: 3392, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 432, iters: 3472, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 432, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 432, iters: 3632, time: 0.091, data: 0.000) loss: 0.001 
(epoch: 432, iters: 3712, time: 0.089, data: 0.045) loss: 0.000 
saving the model at the end of epoch 432, iters 1610496
End of epoch 432 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001667
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 432, TEST ACC: [95.903 %]

saving the latest model (epoch 433, total_steps 1610512)
(epoch: 433, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 433, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 433, iters: 224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 433, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 433, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 433, iters: 464, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 433, iters: 544, time: 0.095, data: 0.000) loss: 0.048 
(epoch: 433, iters: 624, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 433, iters: 704, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 433, iters: 784, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 433, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 433, iters: 944, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 433, iters: 1024, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 433, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 433, iters: 1184, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 433, iters: 1264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 433, iters: 1344, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 433, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 433, iters: 1504, time: 0.093, data: 0.000) loss: 0.018 
(epoch: 433, iters: 1584, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 433, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 433, iters: 1744, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 433, iters: 1824, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 433, iters: 1904, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 433, iters: 1984, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 433, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 433, iters: 2144, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 433, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 433, iters: 2304, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 433, iters: 2384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 433, iters: 2464, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 433, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 433, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 433, iters: 2704, time: 0.094, data: 0.050) loss: 0.001 
(epoch: 433, iters: 2784, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 433, iters: 2864, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 433, iters: 2944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 433, iters: 3024, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 433, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 433, iters: 3184, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 433, iters: 3264, time: 0.095, data: 0.050) loss: 0.004 
(epoch: 433, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 433, iters: 3424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 433, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 433, iters: 3584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 433, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 433, iters 1614224
End of epoch 433 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001666
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 433, TEST ACC: [93.323 %]

(epoch: 434, iters: 16, time: 0.109, data: 0.000) loss: 0.001 
saving the latest model (epoch 434, total_steps 1614240)
(epoch: 434, iters: 96, time: 0.092, data: 0.000) loss: 0.105 
(epoch: 434, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 434, iters: 256, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 434, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 434, iters: 416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 434, iters: 496, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 434, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 434, iters: 656, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 434, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 434, iters: 816, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 434, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 434, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 434, iters: 1056, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 434, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 434, iters: 1216, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 434, iters: 1296, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 434, iters: 1376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 434, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 434, iters: 1536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 434, iters: 1616, time: 0.093, data: 0.040) loss: 0.053 
(epoch: 434, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 434, iters: 1776, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 434, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 434, iters: 1936, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 434, iters: 2016, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 434, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 434, iters: 2176, time: 0.093, data: 0.041) loss: 0.008 
(epoch: 434, iters: 2256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 434, iters: 2336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 434, iters: 2416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 434, iters: 2496, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 434, iters: 2576, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 434, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 434, iters: 2736, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 434, iters: 2816, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 434, iters: 2896, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 434, iters: 2976, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 434, iters: 3056, time: 0.095, data: 0.012) loss: 0.005 
(epoch: 434, iters: 3136, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 434, iters: 3216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 434, iters: 3296, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 434, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 434, iters: 3456, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 434, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 434, iters: 3616, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 434, iters: 3696, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 434, iters 1617952
End of epoch 434 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001665
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 434, TEST ACC: [94.841 %]

saving the latest model (epoch 435, total_steps 1617968)
(epoch: 435, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 435, iters: 128, time: 0.096, data: 0.028) loss: 0.000 
(epoch: 435, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 435, iters: 288, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 435, iters: 368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 435, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 435, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 435, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 435, iters: 688, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 435, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 435, iters: 848, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 435, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 435, iters: 1008, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 435, iters: 1088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 435, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 435, iters: 1248, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 435, iters: 1328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 435, iters: 1408, time: 0.091, data: 0.012) loss: 0.003 
(epoch: 435, iters: 1488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 435, iters: 1568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 435, iters: 1648, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 435, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 435, iters: 1808, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 435, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 435, iters: 1968, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 435, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 435, iters: 2128, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 435, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 435, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 435, iters: 2368, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 435, iters: 2448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 435, iters: 2528, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 435, iters: 2608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 435, iters: 2688, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 435, iters: 2768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 435, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 435, iters: 2928, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 435, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 435, iters: 3088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 435, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 435, iters: 3248, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 435, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 435, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 435, iters: 3488, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 435, iters: 3568, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 435, iters: 3648, time: 0.085, data: 0.011) loss: 0.000 
(epoch: 435, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 435, iters 1621680
End of epoch 435 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001664
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 435, TEST ACC: [95.751 %]

saving the latest model (epoch 436, total_steps 1621696)
(epoch: 436, iters: 80, time: 0.094, data: 0.477) loss: 0.000 
(epoch: 436, iters: 160, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 436, iters: 240, time: 0.095, data: 0.052) loss: 0.000 
(epoch: 436, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 436, iters: 400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 436, iters: 480, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 436, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 436, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 436, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 436, iters: 800, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 436, iters: 880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 436, iters: 960, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 436, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 436, iters: 1120, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 436, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 436, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 436, iters: 1360, time: 0.095, data: 0.050) loss: 0.001 
(epoch: 436, iters: 1440, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 436, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 436, iters: 1600, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 436, iters: 1680, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 436, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 436, iters: 1840, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 436, iters: 1920, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 436, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 436, iters: 2080, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 436, iters: 2160, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 436, iters: 2240, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 436, iters: 2320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 436, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 436, iters: 2480, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 436, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 436, iters: 2640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 436, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 436, iters: 2800, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 436, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 436, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 436, iters: 3040, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 436, iters: 3120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 436, iters: 3200, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 436, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 436, iters: 3360, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 436, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 436, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 436, iters: 3600, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 436, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 436, iters 1625408
End of epoch 436 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001663
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 436, TEST ACC: [95.599 %]

saving the latest model (epoch 437, total_steps 1625424)
(epoch: 437, iters: 32, time: 0.093, data: 0.004) loss: 0.006 
(epoch: 437, iters: 112, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 437, iters: 192, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 437, iters: 272, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 437, iters: 352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 437, iters: 432, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 437, iters: 512, time: 0.095, data: 0.000) loss: 0.069 
(epoch: 437, iters: 592, time: 0.094, data: 0.040) loss: 0.128 
(epoch: 437, iters: 672, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 437, iters: 752, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 437, iters: 832, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 437, iters: 912, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 437, iters: 992, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 437, iters: 1072, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 437, iters: 1152, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 437, iters: 1232, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 437, iters: 1312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 437, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 437, iters: 1472, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 437, iters: 1552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 437, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 437, iters: 1712, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 437, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 437, iters: 1872, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 437, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 437, iters: 2032, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 437, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 437, iters: 2192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 437, iters: 2272, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 437, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 437, iters: 2432, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 437, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 437, iters: 2592, time: 0.092, data: 0.011) loss: 0.005 
(epoch: 437, iters: 2672, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 437, iters: 2752, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 437, iters: 2832, time: 0.093, data: 0.051) loss: 0.000 
(epoch: 437, iters: 2912, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 437, iters: 2992, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 437, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 437, iters: 3152, time: 0.093, data: 0.011) loss: 0.027 
(epoch: 437, iters: 3232, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 437, iters: 3312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 437, iters: 3392, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 437, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 437, iters: 3552, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 437, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 437, iters: 3712, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 437, iters 1629136
End of epoch 437 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001662
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 437, TEST ACC: [93.475 %]

saving the latest model (epoch 438, total_steps 1629152)
(epoch: 438, iters: 64, time: 0.094, data: 0.003) loss: 0.000 
(epoch: 438, iters: 144, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 438, iters: 224, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 438, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 438, iters: 384, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 438, iters: 464, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 438, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 438, iters: 624, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 438, iters: 704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 438, iters: 784, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 438, iters: 864, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 438, iters: 944, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 438, iters: 1024, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 438, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 438, iters: 1184, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 438, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 438, iters: 1344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 438, iters: 1424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 438, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 438, iters: 1584, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 438, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 438, iters: 1744, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 438, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 438, iters: 1904, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 438, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 438, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 438, iters: 2144, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 438, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 438, iters: 2304, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 438, iters: 2384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 438, iters: 2464, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 438, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 438, iters: 2624, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 438, iters: 2704, time: 0.094, data: 0.041) loss: 0.009 
(epoch: 438, iters: 2784, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 438, iters: 2864, time: 0.092, data: 0.012) loss: 0.008 
(epoch: 438, iters: 2944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 438, iters: 3024, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 438, iters: 3104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 438, iters: 3184, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 438, iters: 3264, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 438, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 438, iters: 3424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 438, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 438, iters: 3584, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 438, iters: 3664, time: 0.087, data: 0.000) loss: 0.001 
saving the model at the end of epoch 438, iters 1632864
End of epoch 438 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001661
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 438, TEST ACC: [96.51 %]

(epoch: 439, iters: 16, time: 0.111, data: 0.000) loss: 0.000 
saving the latest model (epoch 439, total_steps 1632880)
(epoch: 439, iters: 96, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 439, iters: 176, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 439, iters: 256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 439, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 439, iters: 416, time: 0.093, data: 0.000) loss: 0.155 
(epoch: 439, iters: 496, time: 0.092, data: 0.000) loss: 0.146 
(epoch: 439, iters: 576, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 439, iters: 656, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 439, iters: 736, time: 0.092, data: 0.011) loss: 0.109 
(epoch: 439, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 439, iters: 896, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 439, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 439, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 439, iters: 1136, time: 0.093, data: 0.039) loss: 0.002 
(epoch: 439, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 439, iters: 1296, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 439, iters: 1376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 439, iters: 1456, time: 0.093, data: 0.011) loss: 0.241 
(epoch: 439, iters: 1536, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 439, iters: 1616, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 439, iters: 1696, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 439, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 439, iters: 1856, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 439, iters: 1936, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 439, iters: 2016, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 439, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 439, iters: 2176, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 439, iters: 2256, time: 0.094, data: 0.039) loss: 0.015 
(epoch: 439, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 439, iters: 2416, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 439, iters: 2496, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 439, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 439, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 439, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 439, iters: 2816, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 439, iters: 2896, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 439, iters: 2976, time: 0.092, data: 0.012) loss: 0.006 
(epoch: 439, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 439, iters: 3136, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 439, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 439, iters: 3296, time: 0.092, data: 0.000) loss: 0.069 
(epoch: 439, iters: 3376, time: 0.094, data: 0.041) loss: 0.007 
(epoch: 439, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 439, iters: 3536, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 439, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 439, iters: 3696, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 439, iters 1636592
End of epoch 439 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001660
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 439, TEST ACC: [94.537 %]

saving the latest model (epoch 440, total_steps 1636608)
(epoch: 440, iters: 48, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 440, iters: 128, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 440, iters: 208, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 440, iters: 288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 440, iters: 368, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 440, iters: 448, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 440, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 440, iters: 608, time: 0.096, data: 0.041) loss: 0.034 
(epoch: 440, iters: 688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 440, iters: 768, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 440, iters: 848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 440, iters: 928, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 440, iters: 1008, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 440, iters: 1088, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 440, iters: 1168, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 440, iters: 1248, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 440, iters: 1328, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 440, iters: 1408, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 440, iters: 1488, time: 0.093, data: 0.011) loss: 0.005 
(epoch: 440, iters: 1568, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 440, iters: 1648, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 440, iters: 1728, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 440, iters: 1808, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 440, iters: 1888, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 440, iters: 1968, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 440, iters: 2048, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 440, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 440, iters: 2208, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 440, iters: 2288, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 440, iters: 2368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 440, iters: 2448, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 440, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 440, iters: 2608, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 440, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 440, iters: 2768, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 440, iters: 2848, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 440, iters: 2928, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 440, iters: 3008, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 440, iters: 3088, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 440, iters: 3168, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 440, iters: 3248, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 440, iters: 3328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 440, iters: 3408, time: 0.093, data: 0.041) loss: 0.001 
(epoch: 440, iters: 3488, time: 0.094, data: 0.000) loss: 0.047 
(epoch: 440, iters: 3568, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 440, iters: 3648, time: 0.086, data: 0.000) loss: 0.001 
(epoch: 440, iters: 3728, time: 0.056, data: 0.012) loss: 0.000 
saving the model at the end of epoch 440, iters 1640320
End of epoch 440 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001659
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 440, TEST ACC: [94.689 %]

saving the latest model (epoch 441, total_steps 1640336)
(epoch: 441, iters: 80, time: 0.095, data: 0.528) loss: 0.000 
(epoch: 441, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 441, iters: 240, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 441, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 441, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 441, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 441, iters: 560, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 441, iters: 640, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 441, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 441, iters: 800, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 441, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 441, iters: 960, time: 0.093, data: 0.011) loss: 0.134 
(epoch: 441, iters: 1040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 441, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 441, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 441, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 441, iters: 1360, time: 0.097, data: 0.039) loss: 0.000 
(epoch: 441, iters: 1440, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 441, iters: 1520, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 441, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 441, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 441, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 441, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 441, iters: 1920, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 441, iters: 2000, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 441, iters: 2080, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 441, iters: 2160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 441, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 441, iters: 2320, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 441, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 441, iters: 2480, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 441, iters: 2560, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 441, iters: 2640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 441, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 441, iters: 2800, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 441, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 441, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 441, iters: 3040, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 441, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 441, iters: 3200, time: 0.092, data: 0.021) loss: 0.001 
(epoch: 441, iters: 3280, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 441, iters: 3360, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 441, iters: 3440, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 441, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 441, iters: 3600, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 441, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 441, iters 1644048
End of epoch 441 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001658
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 441, TEST ACC: [95.599 %]

saving the latest model (epoch 442, total_steps 1644064)
(epoch: 442, iters: 32, time: 0.095, data: 0.014) loss: 0.000 
(epoch: 442, iters: 112, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 442, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 442, iters: 272, time: 0.094, data: 0.044) loss: 0.001 
(epoch: 442, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 442, iters: 432, time: 0.093, data: 0.011) loss: 0.007 
(epoch: 442, iters: 512, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 442, iters: 592, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 442, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 442, iters: 752, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 442, iters: 832, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 442, iters: 912, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 442, iters: 992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 442, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 442, iters: 1152, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 442, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 442, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 442, iters: 1392, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 442, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 442, iters: 1552, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 442, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 442, iters: 1712, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 442, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 442, iters: 1872, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 442, iters: 1952, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 442, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 442, iters: 2112, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 442, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 442, iters: 2272, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 442, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 442, iters: 2432, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 442, iters: 2512, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 442, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 442, iters: 2672, time: 0.091, data: 0.021) loss: 0.001 
(epoch: 442, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 442, iters: 2832, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 442, iters: 2912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 442, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 442, iters: 3072, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 442, iters: 3152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 442, iters: 3232, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 442, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 442, iters: 3392, time: 0.093, data: 0.012) loss: 0.014 
(epoch: 442, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 442, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 442, iters: 3632, time: 0.091, data: 0.041) loss: 0.000 
(epoch: 442, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 442, iters 1647776
End of epoch 442 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001657
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 442, TEST ACC: [97.117 %]

saving the latest model (epoch 443, total_steps 1647792)
(epoch: 443, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 443, iters: 144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 443, iters: 224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 443, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 443, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 443, iters: 464, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 443, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 443, iters: 624, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 443, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 443, iters: 784, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 443, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 443, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 443, iters: 1024, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 443, iters: 1104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 443, iters: 1184, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 443, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 443, iters: 1344, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 443, iters: 1424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 443, iters: 1504, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 443, iters: 1584, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 443, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 443, iters: 1744, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 443, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 443, iters: 1904, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 443, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 443, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 443, iters: 2144, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 443, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 443, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 443, iters: 2384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 443, iters: 2464, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 443, iters: 2544, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 443, iters: 2624, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 443, iters: 2704, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 443, iters: 2784, time: 0.094, data: 0.000) loss: 0.050 
(epoch: 443, iters: 2864, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 443, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 443, iters: 3024, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 443, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 443, iters: 3184, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 443, iters: 3264, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 443, iters: 3344, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 443, iters: 3424, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 443, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 443, iters: 3584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 443, iters: 3664, time: 0.089, data: 0.000) loss: 0.014 
saving the model at the end of epoch 443, iters 1651504
End of epoch 443 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001656
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 443, TEST ACC: [92.868 %]

(epoch: 444, iters: 16, time: 0.112, data: 0.000) loss: 0.000 
saving the latest model (epoch 444, total_steps 1651520)
(epoch: 444, iters: 96, time: 0.093, data: 0.044) loss: 0.000 
(epoch: 444, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 444, iters: 256, time: 0.091, data: 0.011) loss: 0.002 
(epoch: 444, iters: 336, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 444, iters: 416, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 444, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 444, iters: 576, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 444, iters: 656, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 444, iters: 736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 444, iters: 816, time: 0.092, data: 0.011) loss: 0.036 
(epoch: 444, iters: 896, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 444, iters: 976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 444, iters: 1056, time: 0.093, data: 0.000) loss: 0.028 
(epoch: 444, iters: 1136, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 444, iters: 1216, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 444, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 444, iters: 1376, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 444, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 444, iters: 1536, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 444, iters: 1616, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 444, iters: 1696, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 444, iters: 1776, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 444, iters: 1856, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 444, iters: 1936, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 444, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 444, iters: 2096, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 444, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 444, iters: 2256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 444, iters: 2336, time: 0.097, data: 0.051) loss: 0.000 
(epoch: 444, iters: 2416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 444, iters: 2496, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 444, iters: 2576, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 444, iters: 2656, time: 0.094, data: 0.012) loss: 0.036 
(epoch: 444, iters: 2736, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 444, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 444, iters: 2896, time: 0.094, data: 0.051) loss: 0.002 
(epoch: 444, iters: 2976, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 444, iters: 3056, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 444, iters: 3136, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 444, iters: 3216, time: 0.094, data: 0.011) loss: 0.011 
(epoch: 444, iters: 3296, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 444, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 444, iters: 3456, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 444, iters: 3536, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 444, iters: 3616, time: 0.091, data: 0.012) loss: 0.003 
(epoch: 444, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 444, iters 1655232
End of epoch 444 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001655
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 444, TEST ACC: [94.234 %]

saving the latest model (epoch 445, total_steps 1655248)
(epoch: 445, iters: 48, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 445, iters: 128, time: 0.096, data: 0.044) loss: 0.001 
(epoch: 445, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 445, iters: 288, time: 0.091, data: 0.012) loss: 0.008 
(epoch: 445, iters: 368, time: 0.094, data: 0.000) loss: 0.046 
(epoch: 445, iters: 448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 445, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 445, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 445, iters: 688, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 445, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 445, iters: 848, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 445, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 445, iters: 1008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 445, iters: 1088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 445, iters: 1168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 445, iters: 1248, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 445, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 445, iters: 1408, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 445, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 445, iters: 1568, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 445, iters: 1648, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 445, iters: 1728, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 445, iters: 1808, time: 0.093, data: 0.040) loss: 0.002 
(epoch: 445, iters: 1888, time: 0.095, data: 0.000) loss: 0.021 
(epoch: 445, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 445, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 445, iters: 2128, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 445, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 445, iters: 2288, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 445, iters: 2368, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 445, iters: 2448, time: 0.095, data: 0.000) loss: 0.056 
(epoch: 445, iters: 2528, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 445, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 445, iters: 2688, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 445, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 445, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 445, iters: 2928, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 445, iters: 3008, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 445, iters: 3088, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 445, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 445, iters: 3248, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 445, iters: 3328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 445, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 445, iters: 3488, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 445, iters: 3568, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 445, iters: 3648, time: 0.085, data: 0.011) loss: 0.000 
(epoch: 445, iters: 3728, time: 0.056, data: 0.000) loss: 0.001 
saving the model at the end of epoch 445, iters 1658960
End of epoch 445 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001654
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 445, TEST ACC: [96.055 %]

saving the latest model (epoch 446, total_steps 1658976)
(epoch: 446, iters: 80, time: 0.092, data: 0.533) loss: 0.014 
(epoch: 446, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 446, iters: 240, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 446, iters: 320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 446, iters: 400, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 446, iters: 480, time: 0.093, data: 0.041) loss: 0.002 
(epoch: 446, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 446, iters: 640, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 446, iters: 720, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 446, iters: 800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 446, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 446, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 446, iters: 1040, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 446, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 446, iters: 1200, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 446, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 446, iters: 1360, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 446, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 446, iters: 1520, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 446, iters: 1600, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 446, iters: 1680, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 446, iters: 1760, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 446, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 446, iters: 1920, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 446, iters: 2000, time: 0.093, data: 0.000) loss: 0.085 
(epoch: 446, iters: 2080, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 446, iters: 2160, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 446, iters: 2240, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 446, iters: 2320, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 446, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 446, iters: 2480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 446, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 446, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 446, iters: 2720, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 446, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 446, iters: 2880, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 446, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 446, iters: 3040, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 446, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 446, iters: 3200, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 446, iters: 3280, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 446, iters: 3360, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 446, iters: 3440, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 446, iters: 3520, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 446, iters: 3600, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 446, iters: 3680, time: 0.086, data: 0.000) loss: 0.000 
saving the model at the end of epoch 446, iters 1662688
End of epoch 446 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001653
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 446, TEST ACC: [94.992 %]

saving the latest model (epoch 447, total_steps 1662704)
(epoch: 447, iters: 32, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 447, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 447, iters: 192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 447, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 447, iters: 352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 447, iters: 432, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 447, iters: 512, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 447, iters: 592, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 447, iters: 672, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 447, iters: 752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 447, iters: 832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 447, iters: 912, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 447, iters: 992, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 447, iters: 1072, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 447, iters: 1152, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 447, iters: 1232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 447, iters: 1312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 447, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 447, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 447, iters: 1552, time: 0.093, data: 0.041) loss: 0.014 
(epoch: 447, iters: 1632, time: 0.094, data: 0.000) loss: 0.215 
(epoch: 447, iters: 1712, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 447, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 447, iters: 1872, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 447, iters: 1952, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 447, iters: 2032, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 447, iters: 2112, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 447, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 447, iters: 2272, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 447, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 447, iters: 2432, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 447, iters: 2512, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 447, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 447, iters: 2672, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 447, iters: 2752, time: 0.091, data: 0.027) loss: 0.000 
(epoch: 447, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 447, iters: 2912, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 447, iters: 2992, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 447, iters: 3072, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 447, iters: 3152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 447, iters: 3232, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 447, iters: 3312, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 447, iters: 3392, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 447, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 447, iters: 3552, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 447, iters: 3632, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 447, iters: 3712, time: 0.087, data: 0.022) loss: 0.000 
saving the model at the end of epoch 447, iters 1666416
End of epoch 447 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001652
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 447, TEST ACC: [96.662 %]

saving the latest model (epoch 448, total_steps 1666432)
(epoch: 448, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 448, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 448, iters: 224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 448, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 448, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 448, iters: 464, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 448, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 448, iters: 624, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 448, iters: 704, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 448, iters: 784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 448, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 448, iters: 944, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 448, iters: 1024, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 448, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 448, iters: 1184, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 448, iters: 1264, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 448, iters: 1344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 448, iters: 1424, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 448, iters: 1504, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 448, iters: 1584, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 448, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 448, iters: 1744, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 448, iters: 1824, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 448, iters: 1904, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 448, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 448, iters: 2064, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 448, iters: 2144, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 448, iters: 2224, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 448, iters: 2304, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 448, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 448, iters: 2464, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 448, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 448, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 448, iters: 2704, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 448, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 448, iters: 2864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 448, iters: 2944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 448, iters: 3024, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 448, iters: 3104, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 448, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 448, iters: 3264, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 448, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 448, iters: 3424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 448, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 448, iters: 3584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 448, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 448, iters 1670144
End of epoch 448 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001651
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 448, TEST ACC: [94.992 %]

(epoch: 449, iters: 16, time: 0.108, data: 0.000) loss: 0.000 
saving the latest model (epoch 449, total_steps 1670160)
(epoch: 449, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 449, iters: 176, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 449, iters: 256, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 449, iters: 336, time: 0.094, data: 0.012) loss: 0.016 
(epoch: 449, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 449, iters: 496, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 449, iters: 576, time: 0.093, data: 0.039) loss: 0.011 
(epoch: 449, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 449, iters: 736, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 449, iters: 816, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 449, iters: 896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 449, iters: 976, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 449, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 449, iters: 1136, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 449, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 449, iters: 1296, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 449, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 449, iters: 1456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 449, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 449, iters: 1616, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 449, iters: 1696, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 449, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 449, iters: 1856, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 449, iters: 1936, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 449, iters: 2016, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 449, iters: 2096, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 449, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 449, iters: 2256, time: 0.094, data: 0.040) loss: 0.006 
(epoch: 449, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 449, iters: 2416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 449, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 449, iters: 2576, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 449, iters: 2656, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 449, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 449, iters: 2816, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 449, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 449, iters: 2976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 449, iters: 3056, time: 0.094, data: 0.000) loss: 0.323 
(epoch: 449, iters: 3136, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 449, iters: 3216, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 449, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 449, iters: 3376, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 449, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 449, iters: 3536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 449, iters: 3616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 449, iters: 3696, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 449, iters 1673872
End of epoch 449 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001650
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 449, TEST ACC: [91.654 %]

saving the latest model (epoch 450, total_steps 1673888)
(epoch: 450, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 450, iters: 128, time: 0.093, data: 0.042) loss: 0.508 
(epoch: 450, iters: 208, time: 0.093, data: 0.000) loss: 0.038 
(epoch: 450, iters: 288, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 450, iters: 368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 450, iters: 448, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 450, iters: 528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 450, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 450, iters: 688, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 450, iters: 768, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 450, iters: 848, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 450, iters: 928, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 450, iters: 1008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 450, iters: 1088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 450, iters: 1168, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 450, iters: 1248, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 450, iters: 1328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 450, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 450, iters: 1488, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 450, iters: 1568, time: 0.091, data: 0.025) loss: 0.000 
(epoch: 450, iters: 1648, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 450, iters: 1728, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 450, iters: 1808, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 450, iters: 1888, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 450, iters: 1968, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 450, iters: 2048, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 450, iters: 2128, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 450, iters: 2208, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 450, iters: 2288, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 450, iters: 2368, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 450, iters: 2448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 450, iters: 2528, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 450, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 450, iters: 2688, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 450, iters: 2768, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 450, iters: 2848, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 450, iters: 2928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 450, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 450, iters: 3088, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 450, iters: 3168, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 450, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 450, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 450, iters: 3408, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 450, iters: 3488, time: 0.094, data: 0.027) loss: 0.003 
(epoch: 450, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 450, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 450, iters: 3728, time: 0.057, data: 0.012) loss: 0.000 
saving the model at the end of epoch 450, iters 1677600
End of epoch 450 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001649
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 450, TEST ACC: [95.903 %]

saving the latest model (epoch 451, total_steps 1677616)
(epoch: 451, iters: 80, time: 0.094, data: 0.466) loss: 0.001 
(epoch: 451, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 451, iters: 240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 451, iters: 320, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 451, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 451, iters: 480, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 451, iters: 560, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 451, iters: 640, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 451, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 451, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 451, iters: 880, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 451, iters: 960, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 451, iters: 1040, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 451, iters: 1120, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 451, iters: 1200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 451, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 451, iters: 1360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 451, iters: 1440, time: 0.096, data: 0.043) loss: 0.022 
(epoch: 451, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 451, iters: 1600, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 451, iters: 1680, time: 0.094, data: 0.030) loss: 0.019 
(epoch: 451, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 451, iters: 1840, time: 0.093, data: 0.000) loss: 0.030 
(epoch: 451, iters: 1920, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 451, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 451, iters: 2080, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 451, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 451, iters: 2240, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 451, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 451, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 451, iters: 2480, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 451, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 451, iters: 2640, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 451, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 451, iters: 2800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 451, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 451, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 451, iters: 3040, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 451, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 451, iters: 3200, time: 0.095, data: 0.012) loss: 0.010 
(epoch: 451, iters: 3280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 451, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 451, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 451, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 451, iters: 3600, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 451, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 451, iters 1681328
End of epoch 451 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001648
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 451, TEST ACC: [96.813 %]

saving the latest model (epoch 452, total_steps 1681344)
(epoch: 452, iters: 32, time: 0.091, data: 0.005) loss: 0.000 
(epoch: 452, iters: 112, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 452, iters: 192, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 452, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 452, iters: 352, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 452, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 452, iters: 512, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 452, iters: 592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 452, iters: 672, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 452, iters: 752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 452, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 452, iters: 912, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 452, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 452, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 452, iters: 1152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 452, iters: 1232, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 452, iters: 1312, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 452, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 452, iters: 1472, time: 0.093, data: 0.040) loss: 0.005 
(epoch: 452, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 452, iters: 1632, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 452, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 452, iters: 1792, time: 0.095, data: 0.012) loss: 0.173 
(epoch: 452, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 452, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 452, iters: 2032, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 452, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 452, iters: 2192, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 452, iters: 2272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 452, iters: 2352, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 452, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 452, iters: 2512, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 452, iters: 2592, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 452, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 452, iters: 2752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 452, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 452, iters: 2912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 452, iters: 2992, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 452, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 452, iters: 3152, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 452, iters: 3232, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 452, iters: 3312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 452, iters: 3392, time: 0.094, data: 0.000) loss: 0.433 
(epoch: 452, iters: 3472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 452, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 452, iters: 3632, time: 0.091, data: 0.000) loss: 0.036 
(epoch: 452, iters: 3712, time: 0.087, data: 0.036) loss: 0.000 
saving the model at the end of epoch 452, iters 1685056
End of epoch 452 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001647
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 452, TEST ACC: [93.171 %]

saving the latest model (epoch 453, total_steps 1685072)
(epoch: 453, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 453, iters: 144, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 453, iters: 224, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 453, iters: 304, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 453, iters: 384, time: 0.097, data: 0.000) loss: 0.008 
(epoch: 453, iters: 464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 453, iters: 544, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 453, iters: 624, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 453, iters: 704, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 453, iters: 784, time: 0.094, data: 0.000) loss: 0.110 
(epoch: 453, iters: 864, time: 0.095, data: 0.012) loss: 0.049 
(epoch: 453, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 453, iters: 1024, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 453, iters: 1104, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 453, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 453, iters: 1264, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 453, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 453, iters: 1424, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 453, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 453, iters: 1584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 453, iters: 1664, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 453, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 453, iters: 1824, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 453, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 453, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 453, iters: 2064, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 453, iters: 2144, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 453, iters: 2224, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 453, iters: 2304, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 453, iters: 2384, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 453, iters: 2464, time: 0.092, data: 0.037) loss: 0.195 
(epoch: 453, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 453, iters: 2624, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 453, iters: 2704, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 453, iters: 2784, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 453, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 453, iters: 2944, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 453, iters: 3024, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 453, iters: 3104, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 453, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 453, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 453, iters: 3344, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 453, iters: 3424, time: 0.093, data: 0.024) loss: 0.001 
(epoch: 453, iters: 3504, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 453, iters: 3584, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 453, iters: 3664, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 453, iters 1688784
End of epoch 453 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001646
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 453, TEST ACC: [84.674 %]

(epoch: 454, iters: 16, time: 0.107, data: 0.013) loss: 0.000 
saving the latest model (epoch 454, total_steps 1688800)
(epoch: 454, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 454, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 454, iters: 256, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 454, iters: 336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 454, iters: 416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 454, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 454, iters: 576, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 454, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 454, iters: 736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 454, iters: 816, time: 0.096, data: 0.052) loss: 0.000 
(epoch: 454, iters: 896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 454, iters: 976, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 454, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 454, iters: 1136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 454, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 454, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 454, iters: 1376, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 454, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 454, iters: 1536, time: 0.091, data: 0.021) loss: 0.000 
(epoch: 454, iters: 1616, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 454, iters: 1696, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 454, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 454, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 454, iters: 1936, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 454, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 454, iters: 2096, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 454, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 454, iters: 2256, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 454, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 454, iters: 2416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 454, iters: 2496, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 454, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 454, iters: 2656, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 454, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 454, iters: 2816, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 454, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 454, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 454, iters: 3056, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 454, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 454, iters: 3216, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 454, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 454, iters: 3376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 454, iters: 3456, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 454, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 454, iters: 3616, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 454, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 454, iters 1692512
End of epoch 454 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001645
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 454, TEST ACC: [94.385 %]

saving the latest model (epoch 455, total_steps 1692528)
(epoch: 455, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 455, iters: 128, time: 0.094, data: 0.000) loss: 0.223 
(epoch: 455, iters: 208, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 455, iters: 288, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 455, iters: 368, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 455, iters: 448, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 455, iters: 528, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 455, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 455, iters: 688, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 455, iters: 768, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 455, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 455, iters: 928, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 455, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 455, iters: 1088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 455, iters: 1168, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 455, iters: 1248, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 455, iters: 1328, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 455, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 455, iters: 1488, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 455, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 455, iters: 1648, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 455, iters: 1728, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 455, iters: 1808, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 455, iters: 1888, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 455, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 455, iters: 2048, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 455, iters: 2128, time: 0.093, data: 0.000) loss: 0.016 
(epoch: 455, iters: 2208, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 455, iters: 2288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 455, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 455, iters: 2448, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 455, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 455, iters: 2608, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 455, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 455, iters: 2768, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 455, iters: 2848, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 455, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 455, iters: 3008, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 455, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 455, iters: 3168, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 455, iters: 3248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 455, iters: 3328, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 455, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 455, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 455, iters: 3568, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 455, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 455, iters: 3728, time: 0.056, data: 0.011) loss: 0.000 
saving the model at the end of epoch 455, iters 1696240
End of epoch 455 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001644
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 455, TEST ACC: [94.537 %]

saving the latest model (epoch 456, total_steps 1696256)
(epoch: 456, iters: 80, time: 0.096, data: 0.455) loss: 0.000 
(epoch: 456, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 456, iters: 240, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 456, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 456, iters: 400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 456, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 456, iters: 560, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 456, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 456, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 456, iters: 800, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 456, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 456, iters: 960, time: 0.092, data: 0.012) loss: 0.011 
(epoch: 456, iters: 1040, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 456, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 456, iters: 1200, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 456, iters: 1280, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 456, iters: 1360, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 456, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 456, iters: 1520, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 456, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 456, iters: 1680, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 456, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 456, iters: 1840, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 456, iters: 1920, time: 0.093, data: 0.047) loss: 0.000 
(epoch: 456, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 456, iters: 2080, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 456, iters: 2160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 456, iters: 2240, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 456, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 456, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 456, iters: 2480, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 456, iters: 2560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 456, iters: 2640, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 456, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 456, iters: 2800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 456, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 456, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 456, iters: 3040, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 456, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 456, iters: 3200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 456, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 456, iters: 3360, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 456, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 456, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 456, iters: 3600, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 456, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 456, iters 1699968
End of epoch 456 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001643
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 456, TEST ACC: [94.385 %]

saving the latest model (epoch 457, total_steps 1699984)
(epoch: 457, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 457, iters: 112, time: 0.093, data: 0.027) loss: 0.504 
(epoch: 457, iters: 192, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 457, iters: 272, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 457, iters: 352, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 457, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 457, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 457, iters: 592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 457, iters: 672, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 457, iters: 752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 457, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 457, iters: 912, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 457, iters: 992, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 457, iters: 1072, time: 0.092, data: 0.012) loss: 0.043 
(epoch: 457, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 457, iters: 1232, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 457, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 457, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 457, iters: 1472, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 457, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 457, iters: 1632, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 457, iters: 1712, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 457, iters: 1792, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 457, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 457, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 457, iters: 2032, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 457, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 457, iters: 2192, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 457, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 457, iters: 2352, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 457, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 457, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 457, iters: 2592, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 457, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 457, iters: 2752, time: 0.091, data: 0.011) loss: 0.011 
(epoch: 457, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 457, iters: 2912, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 457, iters: 2992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 457, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 457, iters: 3152, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 457, iters: 3232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 457, iters: 3312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 457, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 457, iters: 3472, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 457, iters: 3552, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 457, iters: 3632, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 457, iters: 3712, time: 0.090, data: 0.037) loss: 0.004 
saving the model at the end of epoch 457, iters 1703696
End of epoch 457 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001642
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 457, TEST ACC: [94.537 %]

saving the latest model (epoch 458, total_steps 1703712)
(epoch: 458, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 458, iters: 144, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 458, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 458, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 458, iters: 384, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 458, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 458, iters: 544, time: 0.091, data: 0.021) loss: 0.000 
(epoch: 458, iters: 624, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 458, iters: 704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 458, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 458, iters: 864, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 458, iters: 944, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 458, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 458, iters: 1104, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 458, iters: 1184, time: 0.098, data: 0.000) loss: 0.019 
(epoch: 458, iters: 1264, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 458, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 458, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 458, iters: 1504, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 458, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 458, iters: 1664, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 458, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 458, iters: 1824, time: 0.095, data: 0.011) loss: 0.073 
(epoch: 458, iters: 1904, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 458, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 458, iters: 2064, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 458, iters: 2144, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 458, iters: 2224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 458, iters: 2304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 458, iters: 2384, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 458, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 458, iters: 2544, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 458, iters: 2624, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 458, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 458, iters: 2784, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 458, iters: 2864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 458, iters: 2944, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 458, iters: 3024, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 458, iters: 3104, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 458, iters: 3184, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 458, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 458, iters: 3344, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 458, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 458, iters: 3504, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 458, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 458, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 458, iters 1707424
End of epoch 458 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001641
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 458, TEST ACC: [95.599 %]

(epoch: 459, iters: 16, time: 0.110, data: 0.012) loss: 0.000 
saving the latest model (epoch 459, total_steps 1707440)
(epoch: 459, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 459, iters: 176, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 459, iters: 256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 459, iters: 336, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 459, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 459, iters: 496, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 459, iters: 576, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 459, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 459, iters: 736, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 459, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 459, iters: 896, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 459, iters: 976, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 459, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 459, iters: 1136, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 459, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 459, iters: 1296, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 459, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 459, iters: 1456, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 459, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 459, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 459, iters: 1696, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 459, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 459, iters: 1856, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 459, iters: 1936, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 459, iters: 2016, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 459, iters: 2096, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 459, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 459, iters: 2256, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 459, iters: 2336, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 459, iters: 2416, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 459, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 459, iters: 2576, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 459, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 459, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 459, iters: 2816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 459, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 459, iters: 2976, time: 0.093, data: 0.012) loss: 0.029 
(epoch: 459, iters: 3056, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 459, iters: 3136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 459, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 459, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 459, iters: 3376, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 459, iters: 3456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 459, iters: 3536, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 459, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 459, iters: 3696, time: 0.087, data: 0.021) loss: 0.000 
saving the model at the end of epoch 459, iters 1711152
End of epoch 459 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001640
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 459, TEST ACC: [94.385 %]

saving the latest model (epoch 460, total_steps 1711168)
(epoch: 460, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 460, iters: 128, time: 0.096, data: 0.057) loss: 0.000 
(epoch: 460, iters: 208, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 460, iters: 288, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 460, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 460, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 460, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 460, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 460, iters: 688, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 460, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 460, iters: 848, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 460, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 460, iters: 1008, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 460, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 460, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 460, iters: 1248, time: 0.093, data: 0.039) loss: 0.014 
(epoch: 460, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 460, iters: 1408, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 460, iters: 1488, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 460, iters: 1568, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 460, iters: 1648, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 460, iters: 1728, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 460, iters: 1808, time: 0.093, data: 0.040) loss: 0.006 
(epoch: 460, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 460, iters: 1968, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 460, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 460, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 460, iters: 2208, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 460, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 460, iters: 2368, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 460, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 460, iters: 2528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 460, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 460, iters: 2688, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 460, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 460, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 460, iters: 2928, time: 0.095, data: 0.049) loss: 0.249 
(epoch: 460, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 460, iters: 3088, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 460, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 460, iters: 3248, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 460, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 460, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 460, iters: 3488, time: 0.094, data: 0.039) loss: 0.010 
(epoch: 460, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 460, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 460, iters: 3728, time: 0.056, data: 0.000) loss: 0.001 
saving the model at the end of epoch 460, iters 1714880
End of epoch 460 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001639
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 460, TEST ACC: [93.323 %]

saving the latest model (epoch 461, total_steps 1714896)
(epoch: 461, iters: 80, time: 0.094, data: 0.569) loss: 0.000 
(epoch: 461, iters: 160, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 461, iters: 240, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 461, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 461, iters: 400, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 461, iters: 480, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 461, iters: 560, time: 0.092, data: 0.012) loss: 0.028 
(epoch: 461, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 461, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 461, iters: 800, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 461, iters: 880, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 461, iters: 960, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 461, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 461, iters: 1120, time: 0.093, data: 0.012) loss: 0.014 
(epoch: 461, iters: 1200, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 461, iters: 1280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 461, iters: 1360, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 461, iters: 1440, time: 0.094, data: 0.000) loss: 0.050 
(epoch: 461, iters: 1520, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 461, iters: 1600, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 461, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 461, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 461, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 461, iters: 1920, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 461, iters: 2000, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 461, iters: 2080, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 461, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 461, iters: 2240, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 461, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 461, iters: 2400, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 461, iters: 2480, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 461, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 461, iters: 2640, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 461, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 461, iters: 2800, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 461, iters: 2880, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 461, iters: 2960, time: 0.093, data: 0.000) loss: 0.011 
(epoch: 461, iters: 3040, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 461, iters: 3120, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 461, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 461, iters: 3280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 461, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 461, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 461, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 461, iters: 3600, time: 0.094, data: 0.053) loss: 0.000 
(epoch: 461, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 461, iters 1718608
End of epoch 461 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001638
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 461, TEST ACC: [94.537 %]

saving the latest model (epoch 462, total_steps 1718624)
(epoch: 462, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 462, iters: 112, time: 0.092, data: 0.041) loss: 0.000 
(epoch: 462, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 462, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 462, iters: 352, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 462, iters: 432, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 462, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 462, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 462, iters: 672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 462, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 462, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 462, iters: 912, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 462, iters: 992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 462, iters: 1072, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 462, iters: 1152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 462, iters: 1232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 462, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 462, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 462, iters: 1472, time: 0.093, data: 0.043) loss: 0.000 
(epoch: 462, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 462, iters: 1632, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 462, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 462, iters: 1792, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 462, iters: 1872, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 462, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 462, iters: 2032, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 462, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 462, iters: 2192, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 462, iters: 2272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 462, iters: 2352, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 462, iters: 2432, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 462, iters: 2512, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 462, iters: 2592, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 462, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 462, iters: 2752, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 462, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 462, iters: 2912, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 462, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 462, iters: 3072, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 462, iters: 3152, time: 0.094, data: 0.038) loss: 0.001 
(epoch: 462, iters: 3232, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 462, iters: 3312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 462, iters: 3392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 462, iters: 3472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 462, iters: 3552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 462, iters: 3632, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 462, iters: 3712, time: 0.087, data: 0.035) loss: 0.000 
saving the model at the end of epoch 462, iters 1722336
End of epoch 462 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001637
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 462, TEST ACC: [95.751 %]

saving the latest model (epoch 463, total_steps 1722352)
(epoch: 463, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 463, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 463, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 463, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 463, iters: 384, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 463, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 463, iters: 544, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 463, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 463, iters: 704, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 463, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 463, iters: 864, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 463, iters: 944, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 463, iters: 1024, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 463, iters: 1104, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 463, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 463, iters: 1264, time: 0.093, data: 0.012) loss: 0.007 
(epoch: 463, iters: 1344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 463, iters: 1424, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 463, iters: 1504, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 463, iters: 1584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 463, iters: 1664, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 463, iters: 1744, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 463, iters: 1824, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 463, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 463, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 463, iters: 2064, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 463, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 463, iters: 2224, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 463, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 463, iters: 2384, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 463, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 463, iters: 2544, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 463, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 463, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 463, iters: 2784, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 463, iters: 2864, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 463, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 463, iters: 3024, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 463, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 463, iters: 3184, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 463, iters: 3264, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 463, iters: 3344, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 463, iters: 3424, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 463, iters: 3504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 463, iters: 3584, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 463, iters: 3664, time: 0.088, data: 0.000) loss: 0.187 
saving the model at the end of epoch 463, iters 1726064
End of epoch 463 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001636
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 463, TEST ACC: [91.958 %]

(epoch: 464, iters: 16, time: 0.109, data: 0.009) loss: 0.000 
saving the latest model (epoch 464, total_steps 1726080)
(epoch: 464, iters: 96, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 464, iters: 176, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 464, iters: 256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 464, iters: 336, time: 0.093, data: 0.020) loss: 0.009 
(epoch: 464, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 464, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 464, iters: 576, time: 0.093, data: 0.035) loss: 0.000 
(epoch: 464, iters: 656, time: 0.092, data: 0.000) loss: 0.004 
(epoch: 464, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 464, iters: 816, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 464, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 464, iters: 976, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 464, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 464, iters: 1136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 464, iters: 1216, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 464, iters: 1296, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 464, iters: 1376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 464, iters: 1456, time: 0.094, data: 0.000) loss: 0.051 
(epoch: 464, iters: 1536, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 464, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 464, iters: 1696, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 464, iters: 1776, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 464, iters: 1856, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 464, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 464, iters: 2016, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 464, iters: 2096, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 464, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 464, iters: 2256, time: 0.094, data: 0.000) loss: 0.042 
(epoch: 464, iters: 2336, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 464, iters: 2416, time: 0.093, data: 0.034) loss: 0.000 
(epoch: 464, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 464, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 464, iters: 2656, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 464, iters: 2736, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 464, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 464, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 464, iters: 2976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 464, iters: 3056, time: 0.092, data: 0.026) loss: 0.058 
(epoch: 464, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 464, iters: 3216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 464, iters: 3296, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 464, iters: 3376, time: 0.095, data: 0.028) loss: 0.000 
(epoch: 464, iters: 3456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 464, iters: 3536, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 464, iters: 3616, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 464, iters: 3696, time: 0.087, data: 0.026) loss: 0.000 
saving the model at the end of epoch 464, iters 1729792
End of epoch 464 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001635
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 464, TEST ACC: [94.689 %]

saving the latest model (epoch 465, total_steps 1729808)
(epoch: 465, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 465, iters: 128, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 465, iters: 208, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 465, iters: 288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 465, iters: 368, time: 0.094, data: 0.047) loss: 0.000 
(epoch: 465, iters: 448, time: 0.095, data: 0.000) loss: 0.211 
(epoch: 465, iters: 528, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 465, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 465, iters: 688, time: 0.093, data: 0.011) loss: 0.027 
(epoch: 465, iters: 768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 465, iters: 848, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 465, iters: 928, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 465, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 465, iters: 1088, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 465, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 465, iters: 1248, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 465, iters: 1328, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 465, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 465, iters: 1488, time: 0.096, data: 0.041) loss: 0.072 
(epoch: 465, iters: 1568, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 465, iters: 1648, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 465, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 465, iters: 1808, time: 0.096, data: 0.011) loss: 0.051 
(epoch: 465, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 465, iters: 1968, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 465, iters: 2048, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 465, iters: 2128, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 465, iters: 2208, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 465, iters: 2288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 465, iters: 2368, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 465, iters: 2448, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 465, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 465, iters: 2608, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 465, iters: 2688, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 465, iters: 2768, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 465, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 465, iters: 2928, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 465, iters: 3008, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 465, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 465, iters: 3168, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 465, iters: 3248, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 465, iters: 3328, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 465, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 465, iters: 3488, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 465, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 465, iters: 3648, time: 0.087, data: 0.000) loss: 0.000 
(epoch: 465, iters: 3728, time: 0.056, data: 0.015) loss: 0.001 
saving the model at the end of epoch 465, iters 1733520
End of epoch 465 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001634
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 465, TEST ACC: [94.841 %]

saving the latest model (epoch 466, total_steps 1733536)
(epoch: 466, iters: 80, time: 0.095, data: 0.485) loss: 0.000 
(epoch: 466, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 466, iters: 240, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 466, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 466, iters: 400, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 466, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 466, iters: 560, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 466, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 466, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 466, iters: 800, time: 0.094, data: 0.051) loss: 0.001 
(epoch: 466, iters: 880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 466, iters: 960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 466, iters: 1040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 466, iters: 1120, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 466, iters: 1200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 466, iters: 1280, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 466, iters: 1360, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 466, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 466, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 466, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 466, iters: 1680, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 466, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 466, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 466, iters: 1920, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 466, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 466, iters: 2080, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 466, iters: 2160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 466, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 466, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 466, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 466, iters: 2480, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 466, iters: 2560, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 466, iters: 2640, time: 0.093, data: 0.011) loss: 0.052 
(epoch: 466, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 466, iters: 2800, time: 0.093, data: 0.012) loss: 0.090 
(epoch: 466, iters: 2880, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 466, iters: 2960, time: 0.094, data: 0.000) loss: 0.051 
(epoch: 466, iters: 3040, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 466, iters: 3120, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 466, iters: 3200, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 466, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 466, iters: 3360, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 466, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 466, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 466, iters: 3600, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 466, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 466, iters 1737248
End of epoch 466 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001633
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 466, TEST ACC: [95.751 %]

saving the latest model (epoch 467, total_steps 1737264)
(epoch: 467, iters: 32, time: 0.093, data: 0.004) loss: 0.000 
(epoch: 467, iters: 112, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 467, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 467, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 467, iters: 352, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 467, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 467, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 467, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 467, iters: 672, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 467, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 467, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 467, iters: 912, time: 0.095, data: 0.022) loss: 0.032 
(epoch: 467, iters: 992, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 467, iters: 1072, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 467, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 467, iters: 1232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 467, iters: 1312, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 467, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 467, iters: 1472, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 467, iters: 1552, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 467, iters: 1632, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 467, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 467, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 467, iters: 1872, time: 0.095, data: 0.012) loss: 0.015 
(epoch: 467, iters: 1952, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 467, iters: 2032, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 467, iters: 2112, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 467, iters: 2192, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 467, iters: 2272, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 467, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 467, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 467, iters: 2512, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 467, iters: 2592, time: 0.093, data: 0.026) loss: 0.006 
(epoch: 467, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 467, iters: 2752, time: 0.096, data: 0.000) loss: 0.032 
(epoch: 467, iters: 2832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 467, iters: 2912, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 467, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 467, iters: 3072, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 467, iters: 3152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 467, iters: 3232, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 467, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 467, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 467, iters: 3472, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 467, iters: 3552, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 467, iters: 3632, time: 0.090, data: 0.013) loss: 0.006 
(epoch: 467, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 467, iters 1740976
End of epoch 467 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001632
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 467, TEST ACC: [96.662 %]

saving the latest model (epoch 468, total_steps 1740992)
(epoch: 468, iters: 64, time: 0.092, data: 0.003) loss: 0.000 
(epoch: 468, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 468, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 468, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 468, iters: 384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 468, iters: 464, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 468, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 468, iters: 624, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 468, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 468, iters: 784, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 468, iters: 864, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 468, iters: 944, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 468, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 468, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 468, iters: 1184, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 468, iters: 1264, time: 0.091, data: 0.025) loss: 0.000 
(epoch: 468, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 468, iters: 1424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 468, iters: 1504, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 468, iters: 1584, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 468, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 468, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 468, iters: 1824, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 468, iters: 1904, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 468, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 468, iters: 2064, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 468, iters: 2144, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 468, iters: 2224, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 468, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 468, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 468, iters: 2464, time: 0.093, data: 0.012) loss: 0.008 
(epoch: 468, iters: 2544, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 468, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 468, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 468, iters: 2784, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 468, iters: 2864, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 468, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 468, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 468, iters: 3104, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 468, iters: 3184, time: 0.092, data: 0.025) loss: 0.129 
(epoch: 468, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 468, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 468, iters: 3424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 468, iters: 3504, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 468, iters: 3584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 468, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 468, iters 1744704
End of epoch 468 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001631
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 468, TEST ACC: [96.51 %]

(epoch: 469, iters: 16, time: 0.109, data: 0.009) loss: 0.000 
saving the latest model (epoch 469, total_steps 1744720)
(epoch: 469, iters: 96, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 469, iters: 176, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 469, iters: 256, time: 0.094, data: 0.048) loss: 0.016 
(epoch: 469, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 469, iters: 416, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 469, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 469, iters: 576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 469, iters: 656, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 469, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 469, iters: 816, time: 0.094, data: 0.044) loss: 0.000 
(epoch: 469, iters: 896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 469, iters: 976, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 469, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 469, iters: 1136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 469, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 469, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 469, iters: 1376, time: 0.093, data: 0.040) loss: 0.003 
(epoch: 469, iters: 1456, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 469, iters: 1536, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 469, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 469, iters: 1696, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 469, iters: 1776, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 469, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 469, iters: 1936, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 469, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 469, iters: 2096, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 469, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 469, iters: 2256, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 469, iters: 2336, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 469, iters: 2416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 469, iters: 2496, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 469, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 469, iters: 2656, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 469, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 469, iters: 2816, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 469, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 469, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 469, iters: 3056, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 469, iters: 3136, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 469, iters: 3216, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 469, iters: 3296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 469, iters: 3376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 469, iters: 3456, time: 0.095, data: 0.000) loss: 0.038 
(epoch: 469, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 469, iters: 3616, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 469, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 469, iters 1748432
End of epoch 469 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001630
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 469, TEST ACC: [95.144 %]

saving the latest model (epoch 470, total_steps 1748448)
(epoch: 470, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 470, iters: 128, time: 0.097, data: 0.027) loss: 0.002 
(epoch: 470, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 470, iters: 288, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 470, iters: 368, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 470, iters: 448, time: 0.093, data: 0.000) loss: 0.040 
(epoch: 470, iters: 528, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 470, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 470, iters: 688, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 470, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 470, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 470, iters: 928, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 470, iters: 1008, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 470, iters: 1088, time: 0.091, data: 0.012) loss: 0.044 
(epoch: 470, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 470, iters: 1248, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 470, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 470, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 470, iters: 1488, time: 0.093, data: 0.039) loss: 0.002 
(epoch: 470, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 470, iters: 1648, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 470, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 470, iters: 1808, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 470, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 470, iters: 1968, time: 0.092, data: 0.000) loss: 0.126 
(epoch: 470, iters: 2048, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 470, iters: 2128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 470, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 470, iters: 2288, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 470, iters: 2368, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 470, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 470, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 470, iters: 2608, time: 0.093, data: 0.012) loss: 0.029 
(epoch: 470, iters: 2688, time: 0.093, data: 0.025) loss: 0.002 
(epoch: 470, iters: 2768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 470, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 470, iters: 2928, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 470, iters: 3008, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 470, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 470, iters: 3168, time: 0.094, data: 0.000) loss: 0.117 
(epoch: 470, iters: 3248, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 470, iters: 3328, time: 0.092, data: 0.035) loss: 0.000 
(epoch: 470, iters: 3408, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 470, iters: 3488, time: 0.094, data: 0.000) loss: 0.088 
(epoch: 470, iters: 3568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 470, iters: 3648, time: 0.088, data: 0.026) loss: 0.000 
(epoch: 470, iters: 3728, time: 0.056, data: 0.030) loss: 0.010 
saving the model at the end of epoch 470, iters 1752160
End of epoch 470 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001629
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 470, TEST ACC: [85.736 %]

saving the latest model (epoch 471, total_steps 1752176)
(epoch: 471, iters: 80, time: 0.093, data: 0.500) loss: 0.000 
(epoch: 471, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 471, iters: 240, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 471, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 471, iters: 400, time: 0.091, data: 0.012) loss: 0.003 
(epoch: 471, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 471, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 471, iters: 640, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 471, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 471, iters: 800, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 471, iters: 880, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 471, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 471, iters: 1040, time: 0.094, data: 0.000) loss: 0.151 
(epoch: 471, iters: 1120, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 471, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 471, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 471, iters: 1360, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 471, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 471, iters: 1520, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 471, iters: 1600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 471, iters: 1680, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 471, iters: 1760, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 471, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 471, iters: 1920, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 471, iters: 2000, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 471, iters: 2080, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 471, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 471, iters: 2240, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 471, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 471, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 471, iters: 2480, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 471, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 471, iters: 2640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 471, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 471, iters: 2800, time: 0.094, data: 0.020) loss: 0.001 
(epoch: 471, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 471, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 471, iters: 3040, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 471, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 471, iters: 3200, time: 0.092, data: 0.011) loss: 0.214 
(epoch: 471, iters: 3280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 471, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 471, iters: 3440, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 471, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 471, iters: 3600, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 471, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 471, iters 1755888
End of epoch 471 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001628
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 471, TEST ACC: [96.358 %]

saving the latest model (epoch 472, total_steps 1755904)
(epoch: 472, iters: 32, time: 0.093, data: 0.004) loss: 0.000 
(epoch: 472, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 472, iters: 192, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 472, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 472, iters: 352, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 472, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 472, iters: 512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 472, iters: 592, time: 0.095, data: 0.040) loss: 0.065 
(epoch: 472, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 472, iters: 752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 472, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 472, iters: 912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 472, iters: 992, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 472, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 472, iters: 1152, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 472, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 472, iters: 1312, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 472, iters: 1392, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 472, iters: 1472, time: 0.096, data: 0.026) loss: 0.002 
(epoch: 472, iters: 1552, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 472, iters: 1632, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 472, iters: 1712, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 472, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 472, iters: 1872, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 472, iters: 1952, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 472, iters: 2032, time: 0.097, data: 0.000) loss: 0.017 
(epoch: 472, iters: 2112, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 472, iters: 2192, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 472, iters: 2272, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 472, iters: 2352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 472, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 472, iters: 2512, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 472, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 472, iters: 2672, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 472, iters: 2752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 472, iters: 2832, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 472, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 472, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 472, iters: 3072, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 472, iters: 3152, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 472, iters: 3232, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 472, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 472, iters: 3392, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 472, iters: 3472, time: 0.094, data: 0.000) loss: 0.073 
(epoch: 472, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 472, iters: 3632, time: 0.091, data: 0.040) loss: 0.007 
(epoch: 472, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 472, iters 1759616
End of epoch 472 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001627
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 472, TEST ACC: [91.958 %]

saving the latest model (epoch 473, total_steps 1759632)
(epoch: 473, iters: 64, time: 0.091, data: 0.000) loss: 0.002 
(epoch: 473, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 473, iters: 224, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 473, iters: 304, time: 0.094, data: 0.000) loss: 0.032 
(epoch: 473, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 473, iters: 464, time: 0.093, data: 0.039) loss: 0.004 
(epoch: 473, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 473, iters: 624, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 473, iters: 704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 473, iters: 784, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 473, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 473, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 473, iters: 1024, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 473, iters: 1104, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 473, iters: 1184, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 473, iters: 1264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 473, iters: 1344, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 473, iters: 1424, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 473, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 473, iters: 1584, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 473, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 473, iters: 1744, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 473, iters: 1824, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 473, iters: 1904, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 473, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 473, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 473, iters: 2144, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 473, iters: 2224, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 473, iters: 2304, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 473, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 473, iters: 2464, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 473, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 473, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 473, iters: 2704, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 473, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 473, iters: 2864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 473, iters: 2944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 473, iters: 3024, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 473, iters: 3104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 473, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 473, iters: 3264, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 473, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 473, iters: 3424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 473, iters: 3504, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 473, iters: 3584, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 473, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 473, iters 1763344
End of epoch 473 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001626
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 473, TEST ACC: [95.903 %]

(epoch: 474, iters: 16, time: 0.112, data: 0.000) loss: 0.000 
saving the latest model (epoch 474, total_steps 1763360)
(epoch: 474, iters: 96, time: 0.094, data: 0.011) loss: 0.011 
(epoch: 474, iters: 176, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 474, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 474, iters: 336, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 474, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 474, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 474, iters: 576, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 474, iters: 656, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 474, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 474, iters: 816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 474, iters: 896, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 474, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 474, iters: 1056, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 474, iters: 1136, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 474, iters: 1216, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 474, iters: 1296, time: 0.091, data: 0.020) loss: 0.000 
(epoch: 474, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 474, iters: 1456, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 474, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 474, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 474, iters: 1696, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 474, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 474, iters: 1856, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 474, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 474, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 474, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 474, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 474, iters: 2256, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 474, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 474, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 474, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 474, iters: 2576, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 474, iters: 2656, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 474, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 474, iters: 2816, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 474, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 474, iters: 2976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 474, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 474, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 474, iters: 3216, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 474, iters: 3296, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 474, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 474, iters: 3456, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 474, iters: 3536, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 474, iters: 3616, time: 0.092, data: 0.035) loss: 0.000 
(epoch: 474, iters: 3696, time: 0.088, data: 0.000) loss: 0.002 
saving the model at the end of epoch 474, iters 1767072
End of epoch 474 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001625
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 474, TEST ACC: [96.813 %]

saving the latest model (epoch 475, total_steps 1767088)
(epoch: 475, iters: 48, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 475, iters: 128, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 475, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 475, iters: 288, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 475, iters: 368, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 475, iters: 448, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 475, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 475, iters: 608, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 475, iters: 688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 475, iters: 768, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 475, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 475, iters: 928, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 475, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 475, iters: 1088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 475, iters: 1168, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 475, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 475, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 475, iters: 1408, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 475, iters: 1488, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 475, iters: 1568, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 475, iters: 1648, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 475, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 475, iters: 1808, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 475, iters: 1888, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 475, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 475, iters: 2048, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 475, iters: 2128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 475, iters: 2208, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 475, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 475, iters: 2368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 475, iters: 2448, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 475, iters: 2528, time: 0.094, data: 0.000) loss: 0.031 
(epoch: 475, iters: 2608, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 475, iters: 2688, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 475, iters: 2768, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 475, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 475, iters: 2928, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 475, iters: 3008, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 475, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 475, iters: 3168, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 475, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 475, iters: 3328, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 475, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 475, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 475, iters: 3568, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 475, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 475, iters: 3728, time: 0.055, data: 0.012) loss: 0.000 
saving the model at the end of epoch 475, iters 1770800
End of epoch 475 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001624
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 475, TEST ACC: [96.813 %]

saving the latest model (epoch 476, total_steps 1770816)
(epoch: 476, iters: 80, time: 0.094, data: 0.507) loss: 0.001 
(epoch: 476, iters: 160, time: 0.094, data: 0.031) loss: 0.000 
(epoch: 476, iters: 240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 476, iters: 320, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 476, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 476, iters: 480, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 476, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 476, iters: 640, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 476, iters: 720, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 476, iters: 800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 476, iters: 880, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 476, iters: 960, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 476, iters: 1040, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 476, iters: 1120, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 476, iters: 1200, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 476, iters: 1280, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 476, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 476, iters: 1440, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 476, iters: 1520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 476, iters: 1600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 476, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 476, iters: 1760, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 476, iters: 1840, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 476, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 476, iters: 2000, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 476, iters: 2080, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 476, iters: 2160, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 476, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 476, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 476, iters: 2400, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 476, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 476, iters: 2560, time: 0.092, data: 0.012) loss: 0.042 
(epoch: 476, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 476, iters: 2720, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 476, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 476, iters: 2880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 476, iters: 2960, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 476, iters: 3040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 476, iters: 3120, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 476, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 476, iters: 3280, time: 0.092, data: 0.013) loss: 0.002 
(epoch: 476, iters: 3360, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 476, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 476, iters: 3520, time: 0.095, data: 0.052) loss: 0.000 
(epoch: 476, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 476, iters: 3680, time: 0.087, data: 0.012) loss: 0.008 
saving the model at the end of epoch 476, iters 1774528
End of epoch 476 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001623
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 476, TEST ACC: [93.323 %]

saving the latest model (epoch 477, total_steps 1774544)
(epoch: 477, iters: 32, time: 0.092, data: 0.006) loss: 0.000 
(epoch: 477, iters: 112, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 477, iters: 192, time: 0.092, data: 0.012) loss: 0.008 
(epoch: 477, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 477, iters: 352, time: 0.093, data: 0.011) loss: 0.007 
(epoch: 477, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 477, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 477, iters: 592, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 477, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 477, iters: 752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 477, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 477, iters: 912, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 477, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 477, iters: 1072, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 477, iters: 1152, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 477, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 477, iters: 1312, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 477, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 477, iters: 1472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 477, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 477, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 477, iters: 1712, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 477, iters: 1792, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 477, iters: 1872, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 477, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 477, iters: 2032, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 477, iters: 2112, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 477, iters: 2192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 477, iters: 2272, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 477, iters: 2352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 477, iters: 2432, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 477, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 477, iters: 2592, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 477, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 477, iters: 2752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 477, iters: 2832, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 477, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 477, iters: 2992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 477, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 477, iters: 3152, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 477, iters: 3232, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 477, iters: 3312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 477, iters: 3392, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 477, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 477, iters: 3552, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 477, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 477, iters: 3712, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 477, iters 1778256
End of epoch 477 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001622
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 477, TEST ACC: [95.296 %]

saving the latest model (epoch 478, total_steps 1778272)
(epoch: 478, iters: 64, time: 0.092, data: 0.003) loss: 0.000 
(epoch: 478, iters: 144, time: 0.092, data: 0.027) loss: 0.004 
(epoch: 478, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 478, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 478, iters: 384, time: 0.093, data: 0.012) loss: 0.142 
(epoch: 478, iters: 464, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 478, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 478, iters: 624, time: 0.094, data: 0.000) loss: 0.020 
(epoch: 478, iters: 704, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 478, iters: 784, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 478, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 478, iters: 944, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 478, iters: 1024, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 478, iters: 1104, time: 0.093, data: 0.024) loss: 0.000 
(epoch: 478, iters: 1184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 478, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 478, iters: 1344, time: 0.094, data: 0.012) loss: 0.016 
(epoch: 478, iters: 1424, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 478, iters: 1504, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 478, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 478, iters: 1664, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 478, iters: 1744, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 478, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 478, iters: 1904, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 478, iters: 1984, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 478, iters: 2064, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 478, iters: 2144, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 478, iters: 2224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 478, iters: 2304, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 478, iters: 2384, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 478, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 478, iters: 2544, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 478, iters: 2624, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 478, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 478, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 478, iters: 2864, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 478, iters: 2944, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 478, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 478, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 478, iters: 3184, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 478, iters: 3264, time: 0.094, data: 0.025) loss: 0.253 
(epoch: 478, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 478, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 478, iters: 3504, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 478, iters: 3584, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 478, iters: 3664, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 478, iters 1781984
End of epoch 478 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001621
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 478, TEST ACC: [94.537 %]

(epoch: 479, iters: 16, time: 0.108, data: 0.000) loss: 0.537 
saving the latest model (epoch 479, total_steps 1782000)
(epoch: 479, iters: 96, time: 0.094, data: 0.000) loss: 0.375 
(epoch: 479, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 479, iters: 256, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 479, iters: 336, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 479, iters: 416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 479, iters: 496, time: 0.093, data: 0.000) loss: 0.102 
(epoch: 479, iters: 576, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 479, iters: 656, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 479, iters: 736, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 479, iters: 816, time: 0.094, data: 0.040) loss: 0.004 
(epoch: 479, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 479, iters: 976, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 479, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 479, iters: 1136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 479, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 479, iters: 1296, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 479, iters: 1376, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 479, iters: 1456, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 479, iters: 1536, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 479, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 479, iters: 1696, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 479, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 479, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 479, iters: 1936, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 479, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 479, iters: 2096, time: 0.092, data: 0.012) loss: 0.019 
(epoch: 479, iters: 2176, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 479, iters: 2256, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 479, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 479, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 479, iters: 2496, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 479, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 479, iters: 2656, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 479, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 479, iters: 2816, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 479, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 479, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 479, iters: 3056, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 479, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 479, iters: 3216, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 479, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 479, iters: 3376, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 479, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 479, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 479, iters: 3616, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 479, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 479, iters 1785712
End of epoch 479 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001620
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 479, TEST ACC: [94.992 %]

saving the latest model (epoch 480, total_steps 1785728)
(epoch: 480, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 480, iters: 128, time: 0.095, data: 0.028) loss: 0.000 
(epoch: 480, iters: 208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 480, iters: 288, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 480, iters: 368, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 480, iters: 448, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 480, iters: 528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 480, iters: 608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 480, iters: 688, time: 0.096, data: 0.041) loss: 0.257 
(epoch: 480, iters: 768, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 480, iters: 848, time: 0.094, data: 0.011) loss: 0.011 
(epoch: 480, iters: 928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 480, iters: 1008, time: 0.095, data: 0.011) loss: 0.035 
(epoch: 480, iters: 1088, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 480, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 480, iters: 1248, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 480, iters: 1328, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 480, iters: 1408, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 480, iters: 1488, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 480, iters: 1568, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 480, iters: 1648, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 480, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 480, iters: 1808, time: 0.096, data: 0.050) loss: 0.002 
(epoch: 480, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 480, iters: 1968, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 480, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 480, iters: 2128, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 480, iters: 2208, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 480, iters: 2288, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 480, iters: 2368, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 480, iters: 2448, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 480, iters: 2528, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 480, iters: 2608, time: 0.095, data: 0.000) loss: 0.095 
(epoch: 480, iters: 2688, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 480, iters: 2768, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 480, iters: 2848, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 480, iters: 2928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 480, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 480, iters: 3088, time: 0.095, data: 0.021) loss: 0.000 
(epoch: 480, iters: 3168, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 480, iters: 3248, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 480, iters: 3328, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 480, iters: 3408, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 480, iters: 3488, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 480, iters: 3568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 480, iters: 3648, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 480, iters: 3728, time: 0.057, data: 0.011) loss: 0.000 
saving the model at the end of epoch 480, iters 1789440
End of epoch 480 / 2100 	 Time Taken: 358 sec
learning rate = 0.0001619
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 480, TEST ACC: [95.751 %]

saving the latest model (epoch 481, total_steps 1789456)
(epoch: 481, iters: 80, time: 0.093, data: 0.450) loss: 0.000 
(epoch: 481, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 481, iters: 240, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 481, iters: 320, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 481, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 481, iters: 480, time: 0.092, data: 0.012) loss: 0.014 
(epoch: 481, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 481, iters: 640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 481, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 481, iters: 800, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 481, iters: 880, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 481, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 481, iters: 1040, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 481, iters: 1120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 481, iters: 1200, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 481, iters: 1280, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 481, iters: 1360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 481, iters: 1440, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 481, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 481, iters: 1600, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 481, iters: 1680, time: 0.094, data: 0.040) loss: 0.133 
(epoch: 481, iters: 1760, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 481, iters: 1840, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 481, iters: 1920, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 481, iters: 2000, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 481, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 481, iters: 2160, time: 0.093, data: 0.000) loss: 0.075 
(epoch: 481, iters: 2240, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 481, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 481, iters: 2400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 481, iters: 2480, time: 0.094, data: 0.000) loss: 0.187 
(epoch: 481, iters: 2560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 481, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 481, iters: 2720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 481, iters: 2800, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 481, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 481, iters: 2960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 481, iters: 3040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 481, iters: 3120, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 481, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 481, iters: 3280, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 481, iters: 3360, time: 0.095, data: 0.039) loss: 0.004 
(epoch: 481, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 481, iters: 3520, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 481, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 481, iters: 3680, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 481, iters 1793168
End of epoch 481 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001618
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 481, TEST ACC: [95.448 %]

saving the latest model (epoch 482, total_steps 1793184)
(epoch: 482, iters: 32, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 482, iters: 112, time: 0.095, data: 0.027) loss: 0.002 
(epoch: 482, iters: 192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 482, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 482, iters: 352, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 482, iters: 432, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 482, iters: 512, time: 0.091, data: 0.021) loss: 0.016 
(epoch: 482, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 482, iters: 672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 482, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 482, iters: 832, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 482, iters: 912, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 482, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 482, iters: 1072, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 482, iters: 1152, time: 0.094, data: 0.000) loss: 0.314 
(epoch: 482, iters: 1232, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 482, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 482, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 482, iters: 1472, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 482, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 482, iters: 1632, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 482, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 482, iters: 1792, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 482, iters: 1872, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 482, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 482, iters: 2032, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 482, iters: 2112, time: 0.095, data: 0.000) loss: 0.037 
(epoch: 482, iters: 2192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 482, iters: 2272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 482, iters: 2352, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 482, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 482, iters: 2512, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 482, iters: 2592, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 482, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 482, iters: 2752, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 482, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 482, iters: 2912, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 482, iters: 2992, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 482, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 482, iters: 3152, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 482, iters: 3232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 482, iters: 3312, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 482, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 482, iters: 3472, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 482, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 482, iters: 3632, time: 0.092, data: 0.000) loss: 0.015 
(epoch: 482, iters: 3712, time: 0.089, data: 0.035) loss: 0.000 
saving the model at the end of epoch 482, iters 1796896
End of epoch 482 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001617
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 482, TEST ACC: [96.055 %]

saving the latest model (epoch 483, total_steps 1796912)
(epoch: 483, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 483, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 483, iters: 224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 483, iters: 304, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 483, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 483, iters: 464, time: 0.096, data: 0.041) loss: 0.001 
(epoch: 483, iters: 544, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 483, iters: 624, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 483, iters: 704, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 483, iters: 784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 483, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 483, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 483, iters: 1024, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 483, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 483, iters: 1184, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 483, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 483, iters: 1344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 483, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 483, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 483, iters: 1584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 483, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 483, iters: 1744, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 483, iters: 1824, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 483, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 483, iters: 1984, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 483, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 483, iters: 2144, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 483, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 483, iters: 2304, time: 0.093, data: 0.000) loss: 0.024 
(epoch: 483, iters: 2384, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 483, iters: 2464, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 483, iters: 2544, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 483, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 483, iters: 2704, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 483, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 483, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 483, iters: 2944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 483, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 483, iters: 3104, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 483, iters: 3184, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 483, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 483, iters: 3344, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 483, iters: 3424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 483, iters: 3504, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 483, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 483, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 483, iters 1800624
End of epoch 483 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001616
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 483, TEST ACC: [95.751 %]

(epoch: 484, iters: 16, time: 0.109, data: 0.013) loss: 0.000 
saving the latest model (epoch 484, total_steps 1800640)
(epoch: 484, iters: 96, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 484, iters: 176, time: 0.093, data: 0.012) loss: 0.020 
(epoch: 484, iters: 256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 484, iters: 336, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 484, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 484, iters: 496, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 484, iters: 576, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 484, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 484, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 484, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 484, iters: 896, time: 0.094, data: 0.012) loss: 0.124 
(epoch: 484, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 484, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 484, iters: 1136, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 484, iters: 1216, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 484, iters: 1296, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 484, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 484, iters: 1456, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 484, iters: 1536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 484, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 484, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 484, iters: 1776, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 484, iters: 1856, time: 0.093, data: 0.024) loss: 0.001 
(epoch: 484, iters: 1936, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 484, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 484, iters: 2096, time: 0.093, data: 0.011) loss: 0.015 
(epoch: 484, iters: 2176, time: 0.093, data: 0.036) loss: 0.000 
(epoch: 484, iters: 2256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 484, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 484, iters: 2416, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 484, iters: 2496, time: 0.092, data: 0.036) loss: 0.002 
(epoch: 484, iters: 2576, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 484, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 484, iters: 2736, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 484, iters: 2816, time: 0.092, data: 0.026) loss: 0.001 
(epoch: 484, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 484, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 484, iters: 3056, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 484, iters: 3136, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 484, iters: 3216, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 484, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 484, iters: 3376, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 484, iters: 3456, time: 0.093, data: 0.025) loss: 0.001 
(epoch: 484, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 484, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 484, iters: 3696, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 484, iters 1804352
End of epoch 484 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001615
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 484, TEST ACC: [95.144 %]

saving the latest model (epoch 485, total_steps 1804368)
(epoch: 485, iters: 48, time: 0.095, data: 0.005) loss: 0.000 
(epoch: 485, iters: 128, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 485, iters: 208, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 485, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 485, iters: 368, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 485, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 485, iters: 528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 485, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 485, iters: 688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 485, iters: 768, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 485, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 485, iters: 928, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 485, iters: 1008, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 485, iters: 1088, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 485, iters: 1168, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 485, iters: 1248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 485, iters: 1328, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 485, iters: 1408, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 485, iters: 1488, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 485, iters: 1568, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 485, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 485, iters: 1728, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 485, iters: 1808, time: 0.093, data: 0.027) loss: 0.003 
(epoch: 485, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 485, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 485, iters: 2048, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 485, iters: 2128, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 485, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 485, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 485, iters: 2368, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 485, iters: 2448, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 485, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 485, iters: 2608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 485, iters: 2688, time: 0.093, data: 0.012) loss: 0.006 
(epoch: 485, iters: 2768, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 485, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 485, iters: 2928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 485, iters: 3008, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 485, iters: 3088, time: 0.092, data: 0.024) loss: 0.000 
(epoch: 485, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 485, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 485, iters: 3328, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 485, iters: 3408, time: 0.091, data: 0.034) loss: 0.000 
(epoch: 485, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 485, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 485, iters: 3648, time: 0.088, data: 0.012) loss: 0.000 
(epoch: 485, iters: 3728, time: 0.057, data: 0.028) loss: 0.000 
saving the model at the end of epoch 485, iters 1808080
End of epoch 485 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001614
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 485, TEST ACC: [95.751 %]

saving the latest model (epoch 486, total_steps 1808096)
(epoch: 486, iters: 80, time: 0.096, data: 0.527) loss: 0.026 
(epoch: 486, iters: 160, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 486, iters: 240, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 486, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 486, iters: 400, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 486, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 486, iters: 560, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 486, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 486, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 486, iters: 800, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 486, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 486, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 486, iters: 1040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 486, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 486, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 486, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 486, iters: 1360, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 486, iters: 1440, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 486, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 486, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 486, iters: 1680, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 486, iters: 1760, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 486, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 486, iters: 1920, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 486, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 486, iters: 2080, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 486, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 486, iters: 2240, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 486, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 486, iters: 2400, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 486, iters: 2480, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 486, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 486, iters: 2640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 486, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 486, iters: 2800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 486, iters: 2880, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 486, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 486, iters: 3040, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 486, iters: 3120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 486, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 486, iters: 3280, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 486, iters: 3360, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 486, iters: 3440, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 486, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 486, iters: 3600, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 486, iters: 3680, time: 0.088, data: 0.000) loss: 0.078 
saving the model at the end of epoch 486, iters 1811808
End of epoch 486 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001613
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 486, TEST ACC: [95.448 %]

saving the latest model (epoch 487, total_steps 1811824)
(epoch: 487, iters: 32, time: 0.094, data: 0.004) loss: 0.000 
(epoch: 487, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 487, iters: 192, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 487, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 487, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 487, iters: 432, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 487, iters: 512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 487, iters: 592, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 487, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 487, iters: 752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 487, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 487, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 487, iters: 992, time: 0.094, data: 0.039) loss: 0.017 
(epoch: 487, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 487, iters: 1152, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 487, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 487, iters: 1312, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 487, iters: 1392, time: 0.095, data: 0.000) loss: 0.055 
(epoch: 487, iters: 1472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 487, iters: 1552, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 487, iters: 1632, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 487, iters: 1712, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 487, iters: 1792, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 487, iters: 1872, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 487, iters: 1952, time: 0.094, data: 0.000) loss: 0.101 
(epoch: 487, iters: 2032, time: 0.093, data: 0.000) loss: 0.025 
(epoch: 487, iters: 2112, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 487, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 487, iters: 2272, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 487, iters: 2352, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 487, iters: 2432, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 487, iters: 2512, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 487, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 487, iters: 2672, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 487, iters: 2752, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 487, iters: 2832, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 487, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 487, iters: 2992, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 487, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 487, iters: 3152, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 487, iters: 3232, time: 0.094, data: 0.040) loss: 0.325 
(epoch: 487, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 487, iters: 3392, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 487, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 487, iters: 3552, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 487, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 487, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 487, iters 1815536
End of epoch 487 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001612
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 487, TEST ACC: [95.448 %]

saving the latest model (epoch 488, total_steps 1815552)
(epoch: 488, iters: 64, time: 0.092, data: 0.002) loss: 0.001 
(epoch: 488, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 488, iters: 224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 488, iters: 304, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 488, iters: 384, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 488, iters: 464, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 488, iters: 544, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 488, iters: 624, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 488, iters: 704, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 488, iters: 784, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 488, iters: 864, time: 0.094, data: 0.000) loss: 0.303 
(epoch: 488, iters: 944, time: 0.093, data: 0.000) loss: 0.137 
(epoch: 488, iters: 1024, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 488, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 488, iters: 1184, time: 0.093, data: 0.012) loss: 0.038 
(epoch: 488, iters: 1264, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 488, iters: 1344, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 488, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 488, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 488, iters: 1584, time: 0.095, data: 0.048) loss: 0.133 
(epoch: 488, iters: 1664, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 488, iters: 1744, time: 0.092, data: 0.011) loss: 0.004 
(epoch: 488, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 488, iters: 1904, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 488, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 488, iters: 2064, time: 0.093, data: 0.000) loss: 0.024 
(epoch: 488, iters: 2144, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 488, iters: 2224, time: 0.095, data: 0.000) loss: 0.065 
(epoch: 488, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 488, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 488, iters: 2464, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 488, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 488, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 488, iters: 2704, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 488, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 488, iters: 2864, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 488, iters: 2944, time: 0.092, data: 0.034) loss: 0.000 
(epoch: 488, iters: 3024, time: 0.094, data: 0.000) loss: 0.130 
(epoch: 488, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 488, iters: 3184, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 488, iters: 3264, time: 0.094, data: 0.036) loss: 0.000 
(epoch: 488, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 488, iters: 3424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 488, iters: 3504, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 488, iters: 3584, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 488, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 488, iters 1819264
End of epoch 488 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001611
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 488, TEST ACC: [93.93 %]

(epoch: 489, iters: 16, time: 0.108, data: 0.000) loss: 0.000 
saving the latest model (epoch 489, total_steps 1819280)
(epoch: 489, iters: 96, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 489, iters: 176, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 489, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 489, iters: 336, time: 0.093, data: 0.012) loss: 0.007 
(epoch: 489, iters: 416, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 489, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 489, iters: 576, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 489, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 489, iters: 736, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 489, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 489, iters: 896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 489, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 489, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 489, iters: 1136, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 489, iters: 1216, time: 0.095, data: 0.000) loss: 0.037 
(epoch: 489, iters: 1296, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 489, iters: 1376, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 489, iters: 1456, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 489, iters: 1536, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 489, iters: 1616, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 489, iters: 1696, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 489, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 489, iters: 1856, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 489, iters: 1936, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 489, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 489, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 489, iters: 2176, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 489, iters: 2256, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 489, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 489, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 489, iters: 2496, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 489, iters: 2576, time: 0.092, data: 0.025) loss: 0.001 
(epoch: 489, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 489, iters: 2736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 489, iters: 2816, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 489, iters: 2896, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 489, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 489, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 489, iters: 3136, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 489, iters: 3216, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 489, iters: 3296, time: 0.093, data: 0.000) loss: 0.008 
(epoch: 489, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 489, iters: 3456, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 489, iters: 3536, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 489, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 489, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 489, iters 1822992
End of epoch 489 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001610
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 489, TEST ACC: [95.599 %]

saving the latest model (epoch 490, total_steps 1823008)
(epoch: 490, iters: 48, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 490, iters: 128, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 490, iters: 208, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 490, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 490, iters: 368, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 490, iters: 448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 490, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 490, iters: 608, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 490, iters: 688, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 490, iters: 768, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 490, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 490, iters: 928, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 490, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 490, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 490, iters: 1168, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 490, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 490, iters: 1328, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 490, iters: 1408, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 490, iters: 1488, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 490, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 490, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 490, iters: 1728, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 490, iters: 1808, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 490, iters: 1888, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 490, iters: 1968, time: 0.094, data: 0.000) loss: 0.102 
(epoch: 490, iters: 2048, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 490, iters: 2128, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 490, iters: 2208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 490, iters: 2288, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 490, iters: 2368, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 490, iters: 2448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 490, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 490, iters: 2608, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 490, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 490, iters: 2768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 490, iters: 2848, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 490, iters: 2928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 490, iters: 3008, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 490, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 490, iters: 3168, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 490, iters: 3248, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 490, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 490, iters: 3408, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 490, iters: 3488, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 490, iters: 3568, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 490, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 490, iters: 3728, time: 0.055, data: 0.012) loss: 0.000 
saving the model at the end of epoch 490, iters 1826720
End of epoch 490 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001609
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 490, TEST ACC: [94.234 %]

saving the latest model (epoch 491, total_steps 1826736)
(epoch: 491, iters: 80, time: 0.095, data: 0.523) loss: 0.000 
(epoch: 491, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 491, iters: 240, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 491, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 491, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 491, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 491, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 491, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 491, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 491, iters: 800, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 491, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 491, iters: 960, time: 0.094, data: 0.011) loss: 0.004 
(epoch: 491, iters: 1040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 491, iters: 1120, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 491, iters: 1200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 491, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 491, iters: 1360, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 491, iters: 1440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 491, iters: 1520, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 491, iters: 1600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 491, iters: 1680, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 491, iters: 1760, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 491, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 491, iters: 1920, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 491, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 491, iters: 2080, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 491, iters: 2160, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 491, iters: 2240, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 491, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 491, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 491, iters: 2480, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 491, iters: 2560, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 491, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 491, iters: 2720, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 491, iters: 2800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 491, iters: 2880, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 491, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 491, iters: 3040, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 491, iters: 3120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 491, iters: 3200, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 491, iters: 3280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 491, iters: 3360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 491, iters: 3440, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 491, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 491, iters: 3600, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 491, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 491, iters 1830448
End of epoch 491 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001608
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 491, TEST ACC: [97.42 %]

saving the latest model (epoch 492, total_steps 1830464)
(epoch: 492, iters: 32, time: 0.092, data: 0.005) loss: 0.000 
(epoch: 492, iters: 112, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 492, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 492, iters: 272, time: 0.093, data: 0.000) loss: 0.032 
(epoch: 492, iters: 352, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 492, iters: 432, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 492, iters: 512, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 492, iters: 592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 492, iters: 672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 492, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 492, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 492, iters: 912, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 492, iters: 992, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 492, iters: 1072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 492, iters: 1152, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 492, iters: 1232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 492, iters: 1312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 492, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 492, iters: 1472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 492, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 492, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 492, iters: 1712, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 492, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 492, iters: 1872, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 492, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 492, iters: 2032, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 492, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 492, iters: 2192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 492, iters: 2272, time: 0.094, data: 0.049) loss: 0.023 
(epoch: 492, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 492, iters: 2432, time: 0.092, data: 0.011) loss: 0.004 
(epoch: 492, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 492, iters: 2592, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 492, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 492, iters: 2752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 492, iters: 2832, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 492, iters: 2912, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 492, iters: 2992, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 492, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 492, iters: 3152, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 492, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 492, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 492, iters: 3392, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 492, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 492, iters: 3552, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 492, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 492, iters: 3712, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 492, iters 1834176
End of epoch 492 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001607
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 492, TEST ACC: [93.627 %]

saving the latest model (epoch 493, total_steps 1834192)
(epoch: 493, iters: 64, time: 0.093, data: 0.003) loss: 0.000 
(epoch: 493, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 493, iters: 224, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 493, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 493, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 493, iters: 464, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 493, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 493, iters: 624, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 493, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 493, iters: 784, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 493, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 493, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 493, iters: 1024, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 493, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 493, iters: 1184, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 493, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 493, iters: 1344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 493, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 493, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 493, iters: 1584, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 493, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 493, iters: 1744, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 493, iters: 1824, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 493, iters: 1904, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 493, iters: 1984, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 493, iters: 2064, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 493, iters: 2144, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 493, iters: 2224, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 493, iters: 2304, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 493, iters: 2384, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 493, iters: 2464, time: 0.096, data: 0.012) loss: 0.007 
(epoch: 493, iters: 2544, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 493, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 493, iters: 2704, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 493, iters: 2784, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 493, iters: 2864, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 493, iters: 2944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 493, iters: 3024, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 493, iters: 3104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 493, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 493, iters: 3264, time: 0.096, data: 0.040) loss: 0.001 
(epoch: 493, iters: 3344, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 493, iters: 3424, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 493, iters: 3504, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 493, iters: 3584, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 493, iters: 3664, time: 0.091, data: 0.000) loss: 0.000 
saving the model at the end of epoch 493, iters 1837904
End of epoch 493 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001606
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 493, TEST ACC: [94.537 %]

(epoch: 494, iters: 16, time: 0.111, data: 0.000) loss: 0.000 
saving the latest model (epoch 494, total_steps 1837920)
(epoch: 494, iters: 96, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 494, iters: 176, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 494, iters: 256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 494, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 494, iters: 416, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 494, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 494, iters: 576, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 494, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 494, iters: 736, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 494, iters: 816, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 494, iters: 896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 494, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 494, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 494, iters: 1136, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 494, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 494, iters: 1296, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 494, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 494, iters: 1456, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 494, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 494, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 494, iters: 1696, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 494, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 494, iters: 1856, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 494, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 494, iters: 2016, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 494, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 494, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 494, iters: 2256, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 494, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 494, iters: 2416, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 494, iters: 2496, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 494, iters: 2576, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 494, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 494, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 494, iters: 2816, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 494, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 494, iters: 2976, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 494, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 494, iters: 3136, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 494, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 494, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 494, iters: 3376, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 494, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 494, iters: 3536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 494, iters: 3616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 494, iters: 3696, time: 0.090, data: 0.012) loss: 0.000 
saving the model at the end of epoch 494, iters 1841632
End of epoch 494 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001605
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 494, TEST ACC: [96.358 %]

saving the latest model (epoch 495, total_steps 1841648)
(epoch: 495, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 495, iters: 128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 495, iters: 208, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 495, iters: 288, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 495, iters: 368, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 495, iters: 448, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 495, iters: 528, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 495, iters: 608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 495, iters: 688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 495, iters: 768, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 495, iters: 848, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 495, iters: 928, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 495, iters: 1008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 495, iters: 1088, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 495, iters: 1168, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 495, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 495, iters: 1328, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 495, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 495, iters: 1488, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 495, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 495, iters: 1648, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 495, iters: 1728, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 495, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 495, iters: 1888, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 495, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 495, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 495, iters: 2128, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 495, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 495, iters: 2288, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 495, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 495, iters: 2448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 495, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 495, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 495, iters: 2688, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 495, iters: 2768, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 495, iters: 2848, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 495, iters: 2928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 495, iters: 3008, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 495, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 495, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 495, iters: 3248, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 495, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 495, iters: 3408, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 495, iters: 3488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 495, iters: 3568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 495, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 495, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 495, iters 1845360
End of epoch 495 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001604
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 495, TEST ACC: [95.903 %]

saving the latest model (epoch 496, total_steps 1845376)
(epoch: 496, iters: 80, time: 0.095, data: 0.515) loss: 0.006 
(epoch: 496, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 496, iters: 240, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 496, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 496, iters: 400, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 496, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 496, iters: 560, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 496, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 496, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 496, iters: 800, time: 0.095, data: 0.041) loss: 0.006 
(epoch: 496, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 496, iters: 960, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 496, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 496, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 496, iters: 1200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 496, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 496, iters: 1360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 496, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 496, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 496, iters: 1600, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 496, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 496, iters: 1760, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 496, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 496, iters: 1920, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 496, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 496, iters: 2080, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 496, iters: 2160, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 496, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 496, iters: 2320, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 496, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 496, iters: 2480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 496, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 496, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 496, iters: 2720, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 496, iters: 2800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 496, iters: 2880, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 496, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 496, iters: 3040, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 496, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 496, iters: 3200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 496, iters: 3280, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 496, iters: 3360, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 496, iters: 3440, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 496, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 496, iters: 3600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 496, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 496, iters 1849088
End of epoch 496 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001603
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 496, TEST ACC: [96.51 %]

saving the latest model (epoch 497, total_steps 1849104)
(epoch: 497, iters: 32, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 497, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 497, iters: 192, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 497, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 497, iters: 352, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 497, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 497, iters: 512, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 497, iters: 592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 497, iters: 672, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 497, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 497, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 497, iters: 912, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 497, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 497, iters: 1072, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 497, iters: 1152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 497, iters: 1232, time: 0.094, data: 0.011) loss: 0.079 
(epoch: 497, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 497, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 497, iters: 1472, time: 0.097, data: 0.040) loss: 0.007 
(epoch: 497, iters: 1552, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 497, iters: 1632, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 497, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 497, iters: 1792, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 497, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 497, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 497, iters: 2032, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 497, iters: 2112, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 497, iters: 2192, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 497, iters: 2272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 497, iters: 2352, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 497, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 497, iters: 2512, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 497, iters: 2592, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 497, iters: 2672, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 497, iters: 2752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 497, iters: 2832, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 497, iters: 2912, time: 0.093, data: 0.011) loss: 0.019 
(epoch: 497, iters: 2992, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 497, iters: 3072, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 497, iters: 3152, time: 0.093, data: 0.035) loss: 0.000 
(epoch: 497, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 497, iters: 3312, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 497, iters: 3392, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 497, iters: 3472, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 497, iters: 3552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 497, iters: 3632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 497, iters: 3712, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 497, iters 1852816
End of epoch 497 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001602
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 497, TEST ACC: [97.117 %]

saving the latest model (epoch 498, total_steps 1852832)
(epoch: 498, iters: 64, time: 0.092, data: 0.000) loss: 0.015 
(epoch: 498, iters: 144, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 498, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 498, iters: 304, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 498, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 498, iters: 464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 498, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 498, iters: 624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 498, iters: 704, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 498, iters: 784, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 498, iters: 864, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 498, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 498, iters: 1024, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 498, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 498, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 498, iters: 1264, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 498, iters: 1344, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 498, iters: 1424, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 498, iters: 1504, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 498, iters: 1584, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 498, iters: 1664, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 498, iters: 1744, time: 0.094, data: 0.000) loss: 0.329 
(epoch: 498, iters: 1824, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 498, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 498, iters: 1984, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 498, iters: 2064, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 498, iters: 2144, time: 0.095, data: 0.012) loss: 0.006 
(epoch: 498, iters: 2224, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 498, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 498, iters: 2384, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 498, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 498, iters: 2544, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 498, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 498, iters: 2704, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 498, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 498, iters: 2864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 498, iters: 2944, time: 0.092, data: 0.036) loss: 0.010 
(epoch: 498, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 498, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 498, iters: 3184, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 498, iters: 3264, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 498, iters: 3344, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 498, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 498, iters: 3504, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 498, iters: 3584, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 498, iters: 3664, time: 0.088, data: 0.039) loss: 0.000 
saving the model at the end of epoch 498, iters 1856544
End of epoch 498 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001601
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 498, TEST ACC: [93.627 %]

(epoch: 499, iters: 16, time: 0.108, data: 0.000) loss: 0.004 
saving the latest model (epoch 499, total_steps 1856560)
(epoch: 499, iters: 96, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 499, iters: 176, time: 0.095, data: 0.012) loss: 0.006 
(epoch: 499, iters: 256, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 499, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 499, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 499, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 499, iters: 576, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 499, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 499, iters: 736, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 499, iters: 816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 499, iters: 896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 499, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 499, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 499, iters: 1136, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 499, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 499, iters: 1296, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 499, iters: 1376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 499, iters: 1456, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 499, iters: 1536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 499, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 499, iters: 1696, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 499, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 499, iters: 1856, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 499, iters: 1936, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 499, iters: 2016, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 499, iters: 2096, time: 0.096, data: 0.000) loss: 0.022 
(epoch: 499, iters: 2176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 499, iters: 2256, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 499, iters: 2336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 499, iters: 2416, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 499, iters: 2496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 499, iters: 2576, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 499, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 499, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 499, iters: 2816, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 499, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 499, iters: 2976, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 499, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 499, iters: 3136, time: 0.093, data: 0.011) loss: 0.005 
(epoch: 499, iters: 3216, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 499, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 499, iters: 3376, time: 0.095, data: 0.039) loss: 0.018 
(epoch: 499, iters: 3456, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 499, iters: 3536, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 499, iters: 3616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 499, iters: 3696, time: 0.087, data: 0.012) loss: 0.007 
saving the model at the end of epoch 499, iters 1860272
End of epoch 499 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001600
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 499, TEST ACC: [93.475 %]

saving the latest model (epoch 500, total_steps 1860288)
(epoch: 500, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 500, iters: 128, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 500, iters: 208, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 500, iters: 288, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 500, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 500, iters: 448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 500, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 500, iters: 608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 500, iters: 688, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 500, iters: 768, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 500, iters: 848, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 500, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 500, iters: 1008, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 500, iters: 1088, time: 0.092, data: 0.000) loss: 0.111 
(epoch: 500, iters: 1168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 500, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 500, iters: 1328, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 500, iters: 1408, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 500, iters: 1488, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 500, iters: 1568, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 500, iters: 1648, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 500, iters: 1728, time: 0.092, data: 0.025) loss: 0.001 
(epoch: 500, iters: 1808, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 500, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 500, iters: 1968, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 500, iters: 2048, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 500, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 500, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 500, iters: 2288, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 500, iters: 2368, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 500, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 500, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 500, iters: 2608, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 500, iters: 2688, time: 0.092, data: 0.025) loss: 0.016 
(epoch: 500, iters: 2768, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 500, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 500, iters: 2928, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 500, iters: 3008, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 500, iters: 3088, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 500, iters: 3168, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 500, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 500, iters: 3328, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 500, iters: 3408, time: 0.094, data: 0.000) loss: 0.020 
(epoch: 500, iters: 3488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 500, iters: 3568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 500, iters: 3648, time: 0.088, data: 0.026) loss: 0.000 
(epoch: 500, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 500, iters 1864000
End of epoch 500 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001599
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 500, TEST ACC: [96.055 %]

saving the latest model (epoch 501, total_steps 1864016)
(epoch: 501, iters: 80, time: 0.096, data: 0.478) loss: 0.000 
(epoch: 501, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 501, iters: 240, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 501, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 501, iters: 400, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 501, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 501, iters: 560, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 501, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 501, iters: 720, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 501, iters: 800, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 501, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 501, iters: 960, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 501, iters: 1040, time: 0.095, data: 0.000) loss: 0.023 
(epoch: 501, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 501, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 501, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 501, iters: 1360, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 501, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 501, iters: 1520, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 501, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 501, iters: 1680, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 501, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 501, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 501, iters: 1920, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 501, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 501, iters: 2080, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 501, iters: 2160, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 501, iters: 2240, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 501, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 501, iters: 2400, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 501, iters: 2480, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 501, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 501, iters: 2640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 501, iters: 2720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 501, iters: 2800, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 501, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 501, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 501, iters: 3040, time: 0.093, data: 0.040) loss: 0.017 
(epoch: 501, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 501, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 501, iters: 3280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 501, iters: 3360, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 501, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 501, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 501, iters: 3600, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 501, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 501, iters 1867728
End of epoch 501 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001598
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 501, TEST ACC: [93.171 %]

saving the latest model (epoch 502, total_steps 1867744)
(epoch: 502, iters: 32, time: 0.091, data: 0.004) loss: 0.003 
(epoch: 502, iters: 112, time: 0.093, data: 0.028) loss: 0.000 
(epoch: 502, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 502, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 502, iters: 352, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 502, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 502, iters: 512, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 502, iters: 592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 502, iters: 672, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 502, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 502, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 502, iters: 912, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 502, iters: 992, time: 0.094, data: 0.000) loss: 0.040 
(epoch: 502, iters: 1072, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 502, iters: 1152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 502, iters: 1232, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 502, iters: 1312, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 502, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 502, iters: 1472, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 502, iters: 1552, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 502, iters: 1632, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 502, iters: 1712, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 502, iters: 1792, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 502, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 502, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 502, iters: 2032, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 502, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 502, iters: 2192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 502, iters: 2272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 502, iters: 2352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 502, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 502, iters: 2512, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 502, iters: 2592, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 502, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 502, iters: 2752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 502, iters: 2832, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 502, iters: 2912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 502, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 502, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 502, iters: 3152, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 502, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 502, iters: 3312, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 502, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 502, iters: 3472, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 502, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 502, iters: 3632, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 502, iters: 3712, time: 0.088, data: 0.045) loss: 0.000 
saving the model at the end of epoch 502, iters 1871456
End of epoch 502 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001597
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 502, TEST ACC: [95.751 %]

saving the latest model (epoch 503, total_steps 1871472)
(epoch: 503, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 503, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 503, iters: 224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 503, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 503, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 503, iters: 464, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 503, iters: 544, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 503, iters: 624, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 503, iters: 704, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 503, iters: 784, time: 0.092, data: 0.012) loss: 0.022 
(epoch: 503, iters: 864, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 503, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 503, iters: 1024, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 503, iters: 1104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 503, iters: 1184, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 503, iters: 1264, time: 0.094, data: 0.000) loss: 0.052 
(epoch: 503, iters: 1344, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 503, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 503, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 503, iters: 1584, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 503, iters: 1664, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 503, iters: 1744, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 503, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 503, iters: 1904, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 503, iters: 1984, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 503, iters: 2064, time: 0.093, data: 0.000) loss: 0.066 
(epoch: 503, iters: 2144, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 503, iters: 2224, time: 0.095, data: 0.000) loss: 0.018 
(epoch: 503, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 503, iters: 2384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 503, iters: 2464, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 503, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 503, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 503, iters: 2704, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 503, iters: 2784, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 503, iters: 2864, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 503, iters: 2944, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 503, iters: 3024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 503, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 503, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 503, iters: 3264, time: 0.095, data: 0.042) loss: 0.001 
(epoch: 503, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 503, iters: 3424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 503, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 503, iters: 3584, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 503, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 503, iters 1875184
End of epoch 503 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001596
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 503, TEST ACC: [95.903 %]

(epoch: 504, iters: 16, time: 0.112, data: 0.000) loss: 0.000 
saving the latest model (epoch 504, total_steps 1875200)
(epoch: 504, iters: 96, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 504, iters: 176, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 504, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 504, iters: 336, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 504, iters: 416, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 504, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 504, iters: 576, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 504, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 504, iters: 736, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 504, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 504, iters: 896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 504, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 504, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 504, iters: 1136, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 504, iters: 1216, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 504, iters: 1296, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 504, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 504, iters: 1456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 504, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 504, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 504, iters: 1696, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 504, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 504, iters: 1856, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 504, iters: 1936, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 504, iters: 2016, time: 0.095, data: 0.012) loss: 0.048 
(epoch: 504, iters: 2096, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 504, iters: 2176, time: 0.092, data: 0.000) loss: 0.006 
(epoch: 504, iters: 2256, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 504, iters: 2336, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 504, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 504, iters: 2496, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 504, iters: 2576, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 504, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 504, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 504, iters: 2816, time: 0.093, data: 0.049) loss: 0.001 
(epoch: 504, iters: 2896, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 504, iters: 2976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 504, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 504, iters: 3136, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 504, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 504, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 504, iters: 3376, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 504, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 504, iters: 3536, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 504, iters: 3616, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 504, iters: 3696, time: 0.090, data: 0.012) loss: 0.001 
saving the model at the end of epoch 504, iters 1878912
End of epoch 504 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001595
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 504, TEST ACC: [92.716 %]

saving the latest model (epoch 505, total_steps 1878928)
(epoch: 505, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 505, iters: 128, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 505, iters: 208, time: 0.094, data: 0.000) loss: 0.176 
(epoch: 505, iters: 288, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 505, iters: 368, time: 0.094, data: 0.024) loss: 0.000 
(epoch: 505, iters: 448, time: 0.092, data: 0.026) loss: 0.001 
(epoch: 505, iters: 528, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 505, iters: 608, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 505, iters: 688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 505, iters: 768, time: 0.093, data: 0.025) loss: 0.004 
(epoch: 505, iters: 848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 505, iters: 928, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 505, iters: 1008, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 505, iters: 1088, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 505, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 505, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 505, iters: 1328, time: 0.093, data: 0.012) loss: 0.218 
(epoch: 505, iters: 1408, time: 0.093, data: 0.024) loss: 0.000 
(epoch: 505, iters: 1488, time: 0.096, data: 0.000) loss: 0.052 
(epoch: 505, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 505, iters: 1648, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 505, iters: 1728, time: 0.092, data: 0.024) loss: 0.000 
(epoch: 505, iters: 1808, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 505, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 505, iters: 1968, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 505, iters: 2048, time: 0.092, data: 0.024) loss: 0.168 
(epoch: 505, iters: 2128, time: 0.095, data: 0.000) loss: 0.052 
(epoch: 505, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 505, iters: 2288, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 505, iters: 2368, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 505, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 505, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 505, iters: 2608, time: 0.093, data: 0.012) loss: 0.022 
(epoch: 505, iters: 2688, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 505, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 505, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 505, iters: 2928, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 505, iters: 3008, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 505, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 505, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 505, iters: 3248, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 505, iters: 3328, time: 0.094, data: 0.026) loss: 0.022 
(epoch: 505, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 505, iters: 3488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 505, iters: 3568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 505, iters: 3648, time: 0.087, data: 0.027) loss: 0.050 
(epoch: 505, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 505, iters 1882640
End of epoch 505 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001594
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 505, TEST ACC: [96.206 %]

saving the latest model (epoch 506, total_steps 1882656)
(epoch: 506, iters: 80, time: 0.095, data: 0.337) loss: 0.000 
(epoch: 506, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 506, iters: 240, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 506, iters: 320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 506, iters: 400, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 506, iters: 480, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 506, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 506, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 506, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 506, iters: 800, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 506, iters: 880, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 506, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 506, iters: 1040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 506, iters: 1120, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 506, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 506, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 506, iters: 1360, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 506, iters: 1440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 506, iters: 1520, time: 0.092, data: 0.013) loss: 0.009 
(epoch: 506, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 506, iters: 1680, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 506, iters: 1760, time: 0.093, data: 0.012) loss: 0.011 
(epoch: 506, iters: 1840, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 506, iters: 1920, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 506, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 506, iters: 2080, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 506, iters: 2160, time: 0.092, data: 0.025) loss: 0.001 
(epoch: 506, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 506, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 506, iters: 2400, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 506, iters: 2480, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 506, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 506, iters: 2640, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 506, iters: 2720, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 506, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 506, iters: 2880, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 506, iters: 2960, time: 0.094, data: 0.000) loss: 0.084 
(epoch: 506, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 506, iters: 3120, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 506, iters: 3200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 506, iters: 3280, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 506, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 506, iters: 3440, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 506, iters: 3520, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 506, iters: 3600, time: 0.095, data: 0.000) loss: 0.550 
(epoch: 506, iters: 3680, time: 0.088, data: 0.040) loss: 0.000 
saving the model at the end of epoch 506, iters 1886368
End of epoch 506 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001593
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 506, TEST ACC: [95.751 %]

saving the latest model (epoch 507, total_steps 1886384)
(epoch: 507, iters: 32, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 507, iters: 112, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 507, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 507, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 507, iters: 352, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 507, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 507, iters: 512, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 507, iters: 592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 507, iters: 672, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 507, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 507, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 507, iters: 912, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 507, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 507, iters: 1072, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 507, iters: 1152, time: 0.091, data: 0.035) loss: 0.001 
(epoch: 507, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 507, iters: 1312, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 507, iters: 1392, time: 0.094, data: 0.029) loss: 0.000 
(epoch: 507, iters: 1472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 507, iters: 1552, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 507, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 507, iters: 1712, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 507, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 507, iters: 1872, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 507, iters: 1952, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 507, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 507, iters: 2112, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 507, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 507, iters: 2272, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 507, iters: 2352, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 507, iters: 2432, time: 0.092, data: 0.000) loss: 0.005 
(epoch: 507, iters: 2512, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 507, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 507, iters: 2672, time: 0.091, data: 0.022) loss: 0.000 
(epoch: 507, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 507, iters: 2832, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 507, iters: 2912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 507, iters: 2992, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 507, iters: 3072, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 507, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 507, iters: 3232, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 507, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 507, iters: 3392, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 507, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 507, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 507, iters: 3632, time: 0.091, data: 0.041) loss: 0.001 
(epoch: 507, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 507, iters 1890096
End of epoch 507 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001592
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 507, TEST ACC: [90.137 %]

saving the latest model (epoch 508, total_steps 1890112)
(epoch: 508, iters: 64, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 508, iters: 144, time: 0.094, data: 0.000) loss: 0.097 
(epoch: 508, iters: 224, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 508, iters: 304, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 508, iters: 384, time: 0.095, data: 0.041) loss: 0.007 
(epoch: 508, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 508, iters: 544, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 508, iters: 624, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 508, iters: 704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 508, iters: 784, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 508, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 508, iters: 944, time: 0.096, data: 0.050) loss: 0.002 
(epoch: 508, iters: 1024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 508, iters: 1104, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 508, iters: 1184, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 508, iters: 1264, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 508, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 508, iters: 1424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 508, iters: 1504, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 508, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 508, iters: 1664, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 508, iters: 1744, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 508, iters: 1824, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 508, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 508, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 508, iters: 2064, time: 0.093, data: 0.040) loss: 0.015 
(epoch: 508, iters: 2144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 508, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 508, iters: 2304, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 508, iters: 2384, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 508, iters: 2464, time: 0.094, data: 0.000) loss: 0.038 
(epoch: 508, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 508, iters: 2624, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 508, iters: 2704, time: 0.093, data: 0.035) loss: 0.000 
(epoch: 508, iters: 2784, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 508, iters: 2864, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 508, iters: 2944, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 508, iters: 3024, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 508, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 508, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 508, iters: 3264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 508, iters: 3344, time: 0.093, data: 0.027) loss: 0.079 
(epoch: 508, iters: 3424, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 508, iters: 3504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 508, iters: 3584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 508, iters: 3664, time: 0.087, data: 0.027) loss: 0.000 
saving the model at the end of epoch 508, iters 1893824
End of epoch 508 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001591
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 508, TEST ACC: [96.662 %]

(epoch: 509, iters: 16, time: 0.109, data: 0.000) loss: 0.000 
saving the latest model (epoch 509, total_steps 1893840)
(epoch: 509, iters: 96, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 509, iters: 176, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 509, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 509, iters: 336, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 509, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 509, iters: 496, time: 0.093, data: 0.000) loss: 0.011 
(epoch: 509, iters: 576, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 509, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 509, iters: 736, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 509, iters: 816, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 509, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 509, iters: 976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 509, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 509, iters: 1136, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 509, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 509, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 509, iters: 1376, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 509, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 509, iters: 1536, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 509, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 509, iters: 1696, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 509, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 509, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 509, iters: 1936, time: 0.094, data: 0.040) loss: 0.021 
(epoch: 509, iters: 2016, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 509, iters: 2096, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 509, iters: 2176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 509, iters: 2256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 509, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 509, iters: 2416, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 509, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 509, iters: 2576, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 509, iters: 2656, time: 0.093, data: 0.027) loss: 0.002 
(epoch: 509, iters: 2736, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 509, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 509, iters: 2896, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 509, iters: 2976, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 509, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 509, iters: 3136, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 509, iters: 3216, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 509, iters: 3296, time: 0.092, data: 0.035) loss: 0.000 
(epoch: 509, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 509, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 509, iters: 3536, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 509, iters: 3616, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 509, iters: 3696, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 509, iters 1897552
End of epoch 509 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001590
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 509, TEST ACC: [94.992 %]

saving the latest model (epoch 510, total_steps 1897568)
(epoch: 510, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 510, iters: 128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 510, iters: 208, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 510, iters: 288, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 510, iters: 368, time: 0.094, data: 0.012) loss: 0.014 
(epoch: 510, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 510, iters: 528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 510, iters: 608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 510, iters: 688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 510, iters: 768, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 510, iters: 848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 510, iters: 928, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 510, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 510, iters: 1088, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 510, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 510, iters: 1248, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 510, iters: 1328, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 510, iters: 1408, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 510, iters: 1488, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 510, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 510, iters: 1648, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 510, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 510, iters: 1808, time: 0.093, data: 0.000) loss: 0.408 
(epoch: 510, iters: 1888, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 510, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 510, iters: 2048, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 510, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 510, iters: 2208, time: 0.095, data: 0.011) loss: 0.168 
(epoch: 510, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 510, iters: 2368, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 510, iters: 2448, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 510, iters: 2528, time: 0.096, data: 0.000) loss: 0.053 
(epoch: 510, iters: 2608, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 510, iters: 2688, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 510, iters: 2768, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 510, iters: 2848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 510, iters: 2928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 510, iters: 3008, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 510, iters: 3088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 510, iters: 3168, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 510, iters: 3248, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 510, iters: 3328, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 510, iters: 3408, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 510, iters: 3488, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 510, iters: 3568, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 510, iters: 3648, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 510, iters: 3728, time: 0.057, data: 0.012) loss: 0.000 
saving the model at the end of epoch 510, iters 1901280
End of epoch 510 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001589
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 510, TEST ACC: [96.206 %]

saving the latest model (epoch 511, total_steps 1901296)
(epoch: 511, iters: 80, time: 0.094, data: 0.511) loss: 0.003 
(epoch: 511, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 511, iters: 240, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 511, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 511, iters: 400, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 511, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 511, iters: 560, time: 0.095, data: 0.012) loss: 0.100 
(epoch: 511, iters: 640, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 511, iters: 720, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 511, iters: 800, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 511, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 511, iters: 960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 511, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 511, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 511, iters: 1200, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 511, iters: 1280, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 511, iters: 1360, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 511, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 511, iters: 1520, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 511, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 511, iters: 1680, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 511, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 511, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 511, iters: 1920, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 511, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 511, iters: 2080, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 511, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 511, iters: 2240, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 511, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 511, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 511, iters: 2480, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 511, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 511, iters: 2640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 511, iters: 2720, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 511, iters: 2800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 511, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 511, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 511, iters: 3040, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 511, iters: 3120, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 511, iters: 3200, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 511, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 511, iters: 3360, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 511, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 511, iters: 3520, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 511, iters: 3600, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 511, iters: 3680, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 511, iters 1905008
End of epoch 511 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001588
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 511, TEST ACC: [95.296 %]

saving the latest model (epoch 512, total_steps 1905024)
(epoch: 512, iters: 32, time: 0.091, data: 0.004) loss: 0.003 
(epoch: 512, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 512, iters: 192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 512, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 512, iters: 352, time: 0.093, data: 0.012) loss: 0.020 
(epoch: 512, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 512, iters: 512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 512, iters: 592, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 512, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 512, iters: 752, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 512, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 512, iters: 912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 512, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 512, iters: 1072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 512, iters: 1152, time: 0.093, data: 0.040) loss: 0.014 
(epoch: 512, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 512, iters: 1312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 512, iters: 1392, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 512, iters: 1472, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 512, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 512, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 512, iters: 1712, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 512, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 512, iters: 1872, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 512, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 512, iters: 2032, time: 0.093, data: 0.011) loss: 0.022 
(epoch: 512, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 512, iters: 2192, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 512, iters: 2272, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 512, iters: 2352, time: 0.094, data: 0.000) loss: 0.084 
(epoch: 512, iters: 2432, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 512, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 512, iters: 2592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 512, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 512, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 512, iters: 2832, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 512, iters: 2912, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 512, iters: 2992, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 512, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 512, iters: 3152, time: 0.094, data: 0.011) loss: 0.004 
(epoch: 512, iters: 3232, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 512, iters: 3312, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 512, iters: 3392, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 512, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 512, iters: 3552, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 512, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 512, iters: 3712, time: 0.087, data: 0.012) loss: 0.001 
saving the model at the end of epoch 512, iters 1908736
End of epoch 512 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001587
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 512, TEST ACC: [96.206 %]

saving the latest model (epoch 513, total_steps 1908752)
(epoch: 513, iters: 64, time: 0.092, data: 0.003) loss: 0.000 
(epoch: 513, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 513, iters: 224, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 513, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 513, iters: 384, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 513, iters: 464, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 513, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 513, iters: 624, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 513, iters: 704, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 513, iters: 784, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 513, iters: 864, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 513, iters: 944, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 513, iters: 1024, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 513, iters: 1104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 513, iters: 1184, time: 0.094, data: 0.012) loss: 0.007 
(epoch: 513, iters: 1264, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 513, iters: 1344, time: 0.095, data: 0.020) loss: 0.003 
(epoch: 513, iters: 1424, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 513, iters: 1504, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 513, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 513, iters: 1664, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 513, iters: 1744, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 513, iters: 1824, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 513, iters: 1904, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 513, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 513, iters: 2064, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 513, iters: 2144, time: 0.095, data: 0.027) loss: 0.002 
(epoch: 513, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 513, iters: 2304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 513, iters: 2384, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 513, iters: 2464, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 513, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 513, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 513, iters: 2704, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 513, iters: 2784, time: 0.093, data: 0.025) loss: 0.002 
(epoch: 513, iters: 2864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 513, iters: 2944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 513, iters: 3024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 513, iters: 3104, time: 0.091, data: 0.025) loss: 0.000 
(epoch: 513, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 513, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 513, iters: 3344, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 513, iters: 3424, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 513, iters: 3504, time: 0.094, data: 0.000) loss: 0.041 
(epoch: 513, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 513, iters: 3664, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 513, iters 1912464
End of epoch 513 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001586
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 513, TEST ACC: [95.599 %]

(epoch: 514, iters: 16, time: 0.109, data: 0.012) loss: 0.000 
saving the latest model (epoch 514, total_steps 1912480)
(epoch: 514, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 514, iters: 176, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 514, iters: 256, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 514, iters: 336, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 514, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 514, iters: 496, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 514, iters: 576, time: 0.096, data: 0.053) loss: 0.000 
(epoch: 514, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 514, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 514, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 514, iters: 896, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 514, iters: 976, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 514, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 514, iters: 1136, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 514, iters: 1216, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 514, iters: 1296, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 514, iters: 1376, time: 0.094, data: 0.029) loss: 0.000 
(epoch: 514, iters: 1456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 514, iters: 1536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 514, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 514, iters: 1696, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 514, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 514, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 514, iters: 1936, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 514, iters: 2016, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 514, iters: 2096, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 514, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 514, iters: 2256, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 514, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 514, iters: 2416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 514, iters: 2496, time: 0.093, data: 0.040) loss: 0.002 
(epoch: 514, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 514, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 514, iters: 2736, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 514, iters: 2816, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 514, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 514, iters: 2976, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 514, iters: 3056, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 514, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 514, iters: 3216, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 514, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 514, iters: 3376, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 514, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 514, iters: 3536, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 514, iters: 3616, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 514, iters: 3696, time: 0.088, data: 0.000) loss: 0.013 
saving the model at the end of epoch 514, iters 1916192
End of epoch 514 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001585
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 514, TEST ACC: [93.93 %]

saving the latest model (epoch 515, total_steps 1916208)
(epoch: 515, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 515, iters: 128, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 515, iters: 208, time: 0.091, data: 0.013) loss: 0.035 
(epoch: 515, iters: 288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 515, iters: 368, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 515, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 515, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 515, iters: 608, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 515, iters: 688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 515, iters: 768, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 515, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 515, iters: 928, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 515, iters: 1008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 515, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 515, iters: 1168, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 515, iters: 1248, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 515, iters: 1328, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 515, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 515, iters: 1488, time: 0.094, data: 0.022) loss: 0.000 
(epoch: 515, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 515, iters: 1648, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 515, iters: 1728, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 515, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 515, iters: 1888, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 515, iters: 1968, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 515, iters: 2048, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 515, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 515, iters: 2208, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 515, iters: 2288, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 515, iters: 2368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 515, iters: 2448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 515, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 515, iters: 2608, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 515, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 515, iters: 2768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 515, iters: 2848, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 515, iters: 2928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 515, iters: 3008, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 515, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 515, iters: 3168, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 515, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 515, iters: 3328, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 515, iters: 3408, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 515, iters: 3488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 515, iters: 3568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 515, iters: 3648, time: 0.091, data: 0.000) loss: 0.001 
(epoch: 515, iters: 3728, time: 0.056, data: 0.012) loss: 0.000 
saving the model at the end of epoch 515, iters 1919920
End of epoch 515 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001584
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 515, TEST ACC: [97.117 %]

saving the latest model (epoch 516, total_steps 1919936)
(epoch: 516, iters: 80, time: 0.095, data: 0.466) loss: 0.000 
(epoch: 516, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 516, iters: 240, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 516, iters: 320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 516, iters: 400, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 516, iters: 480, time: 0.097, data: 0.000) loss: 0.006 
(epoch: 516, iters: 560, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 516, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 516, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 516, iters: 800, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 516, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 516, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 516, iters: 1040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 516, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 516, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 516, iters: 1280, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 516, iters: 1360, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 516, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 516, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 516, iters: 1600, time: 0.095, data: 0.021) loss: 0.000 
(epoch: 516, iters: 1680, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 516, iters: 1760, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 516, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 516, iters: 1920, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 516, iters: 2000, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 516, iters: 2080, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 516, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 516, iters: 2240, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 516, iters: 2320, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 516, iters: 2400, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 516, iters: 2480, time: 0.094, data: 0.000) loss: 0.149 
(epoch: 516, iters: 2560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 516, iters: 2640, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 516, iters: 2720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 516, iters: 2800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 516, iters: 2880, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 516, iters: 2960, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 516, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 516, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 516, iters: 3200, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 516, iters: 3280, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 516, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 516, iters: 3440, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 516, iters: 3520, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 516, iters: 3600, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 516, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 516, iters 1923648
End of epoch 516 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001583
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 516, TEST ACC: [95.599 %]

saving the latest model (epoch 517, total_steps 1923664)
(epoch: 517, iters: 32, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 517, iters: 112, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 517, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 517, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 517, iters: 352, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 517, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 517, iters: 512, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 517, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 517, iters: 672, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 517, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 517, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 517, iters: 912, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 517, iters: 992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 517, iters: 1072, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 517, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 517, iters: 1232, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 517, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 517, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 517, iters: 1472, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 517, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 517, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 517, iters: 1712, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 517, iters: 1792, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 517, iters: 1872, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 517, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 517, iters: 2032, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 517, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 517, iters: 2192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 517, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 517, iters: 2352, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 517, iters: 2432, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 517, iters: 2512, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 517, iters: 2592, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 517, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 517, iters: 2752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 517, iters: 2832, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 517, iters: 2912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 517, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 517, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 517, iters: 3152, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 517, iters: 3232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 517, iters: 3312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 517, iters: 3392, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 517, iters: 3472, time: 0.092, data: 0.012) loss: 0.024 
(epoch: 517, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 517, iters: 3632, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 517, iters: 3712, time: 0.087, data: 0.037) loss: 0.001 
saving the model at the end of epoch 517, iters 1927376
End of epoch 517 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001582
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 517, TEST ACC: [95.599 %]

saving the latest model (epoch 518, total_steps 1927392)
(epoch: 518, iters: 64, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 518, iters: 144, time: 0.092, data: 0.012) loss: 0.031 
(epoch: 518, iters: 224, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 518, iters: 304, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 518, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 518, iters: 464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 518, iters: 544, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 518, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 518, iters: 704, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 518, iters: 784, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 518, iters: 864, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 518, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 518, iters: 1024, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 518, iters: 1104, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 518, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 518, iters: 1264, time: 0.091, data: 0.012) loss: 0.002 
(epoch: 518, iters: 1344, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 518, iters: 1424, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 518, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 518, iters: 1584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 518, iters: 1664, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 518, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 518, iters: 1824, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 518, iters: 1904, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 518, iters: 1984, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 518, iters: 2064, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 518, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 518, iters: 2224, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 518, iters: 2304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 518, iters: 2384, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 518, iters: 2464, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 518, iters: 2544, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 518, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 518, iters: 2704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 518, iters: 2784, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 518, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 518, iters: 2944, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 518, iters: 3024, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 518, iters: 3104, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 518, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 518, iters: 3264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 518, iters: 3344, time: 0.093, data: 0.039) loss: 0.005 
(epoch: 518, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 518, iters: 3504, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 518, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 518, iters: 3664, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 518, iters 1931104
End of epoch 518 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001581
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 518, TEST ACC: [95.144 %]

(epoch: 519, iters: 16, time: 0.110, data: 0.000) loss: 0.000 
saving the latest model (epoch 519, total_steps 1931120)
(epoch: 519, iters: 96, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 519, iters: 176, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 519, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 519, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 519, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 519, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 519, iters: 576, time: 0.091, data: 0.046) loss: 0.000 
(epoch: 519, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 519, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 519, iters: 816, time: 0.094, data: 0.029) loss: 0.000 
(epoch: 519, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 519, iters: 976, time: 0.092, data: 0.012) loss: 0.025 
(epoch: 519, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 519, iters: 1136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 519, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 519, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 519, iters: 1376, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 519, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 519, iters: 1536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 519, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 519, iters: 1696, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 519, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 519, iters: 1856, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 519, iters: 1936, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 519, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 519, iters: 2096, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 519, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 519, iters: 2256, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 519, iters: 2336, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 519, iters: 2416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 519, iters: 2496, time: 0.096, data: 0.042) loss: 0.226 
(epoch: 519, iters: 2576, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 519, iters: 2656, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 519, iters: 2736, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 519, iters: 2816, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 519, iters: 2896, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 519, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 519, iters: 3056, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 519, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 519, iters: 3216, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 519, iters: 3296, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 519, iters: 3376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 519, iters: 3456, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 519, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 519, iters: 3616, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 519, iters: 3696, time: 0.087, data: 0.036) loss: 0.000 
saving the model at the end of epoch 519, iters 1934832
End of epoch 519 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001580
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 519, TEST ACC: [93.171 %]

saving the latest model (epoch 520, total_steps 1934848)
(epoch: 520, iters: 48, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 520, iters: 128, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 520, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 520, iters: 288, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 520, iters: 368, time: 0.093, data: 0.041) loss: 0.109 
(epoch: 520, iters: 448, time: 0.094, data: 0.000) loss: 0.037 
(epoch: 520, iters: 528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 520, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 520, iters: 688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 520, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 520, iters: 848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 520, iters: 928, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 520, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 520, iters: 1088, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 520, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 520, iters: 1248, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 520, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 520, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 520, iters: 1488, time: 0.094, data: 0.039) loss: 0.026 
(epoch: 520, iters: 1568, time: 0.096, data: 0.000) loss: 0.028 
(epoch: 520, iters: 1648, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 520, iters: 1728, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 520, iters: 1808, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 520, iters: 1888, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 520, iters: 1968, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 520, iters: 2048, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 520, iters: 2128, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 520, iters: 2208, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 520, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 520, iters: 2368, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 520, iters: 2448, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 520, iters: 2528, time: 0.093, data: 0.000) loss: 0.011 
(epoch: 520, iters: 2608, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 520, iters: 2688, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 520, iters: 2768, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 520, iters: 2848, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 520, iters: 2928, time: 0.095, data: 0.012) loss: 0.021 
(epoch: 520, iters: 3008, time: 0.095, data: 0.000) loss: 0.166 
(epoch: 520, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 520, iters: 3168, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 520, iters: 3248, time: 0.094, data: 0.000) loss: 0.164 
(epoch: 520, iters: 3328, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 520, iters: 3408, time: 0.094, data: 0.000) loss: 0.049 
(epoch: 520, iters: 3488, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 520, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 520, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 520, iters: 3728, time: 0.057, data: 0.015) loss: 0.000 
saving the model at the end of epoch 520, iters 1938560
End of epoch 520 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001579
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 520, TEST ACC: [93.02 %]

saving the latest model (epoch 521, total_steps 1938576)
(epoch: 521, iters: 80, time: 0.091, data: 0.550) loss: 0.000 
(epoch: 521, iters: 160, time: 0.094, data: 0.026) loss: 0.015 
(epoch: 521, iters: 240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 521, iters: 320, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 521, iters: 400, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 521, iters: 480, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 521, iters: 560, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 521, iters: 640, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 521, iters: 720, time: 0.096, data: 0.049) loss: 0.001 
(epoch: 521, iters: 800, time: 0.095, data: 0.000) loss: 0.095 
(epoch: 521, iters: 880, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 521, iters: 960, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 521, iters: 1040, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 521, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 521, iters: 1200, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 521, iters: 1280, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 521, iters: 1360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 521, iters: 1440, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 521, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 521, iters: 1600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 521, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 521, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 521, iters: 1840, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 521, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 521, iters: 2000, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 521, iters: 2080, time: 0.094, data: 0.011) loss: 0.065 
(epoch: 521, iters: 2160, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 521, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 521, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 521, iters: 2400, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 521, iters: 2480, time: 0.093, data: 0.026) loss: 0.002 
(epoch: 521, iters: 2560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 521, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 521, iters: 2720, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 521, iters: 2800, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 521, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 521, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 521, iters: 3040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 521, iters: 3120, time: 0.092, data: 0.035) loss: 0.000 
(epoch: 521, iters: 3200, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 521, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 521, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 521, iters: 3440, time: 0.093, data: 0.037) loss: 0.000 
(epoch: 521, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 521, iters: 3600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 521, iters: 3680, time: 0.089, data: 0.012) loss: 0.000 
saving the model at the end of epoch 521, iters 1942288
End of epoch 521 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001578
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 521, TEST ACC: [94.082 %]

saving the latest model (epoch 522, total_steps 1942304)
(epoch: 522, iters: 32, time: 0.091, data: 0.007) loss: 0.000 
(epoch: 522, iters: 112, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 522, iters: 192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 522, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 522, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 522, iters: 432, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 522, iters: 512, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 522, iters: 592, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 522, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 522, iters: 752, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 522, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 522, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 522, iters: 992, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 522, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 522, iters: 1152, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 522, iters: 1232, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 522, iters: 1312, time: 0.096, data: 0.025) loss: 0.000 
(epoch: 522, iters: 1392, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 522, iters: 1472, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 522, iters: 1552, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 522, iters: 1632, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 522, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 522, iters: 1792, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 522, iters: 1872, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 522, iters: 1952, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 522, iters: 2032, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 522, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 522, iters: 2192, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 522, iters: 2272, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 522, iters: 2352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 522, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 522, iters: 2512, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 522, iters: 2592, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 522, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 522, iters: 2752, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 522, iters: 2832, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 522, iters: 2912, time: 0.091, data: 0.035) loss: 0.000 
(epoch: 522, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 522, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 522, iters: 3152, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 522, iters: 3232, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 522, iters: 3312, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 522, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 522, iters: 3472, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 522, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 522, iters: 3632, time: 0.091, data: 0.020) loss: 0.000 
(epoch: 522, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 522, iters 1946016
End of epoch 522 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001577
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 522, TEST ACC: [94.385 %]

saving the latest model (epoch 523, total_steps 1946032)
(epoch: 523, iters: 64, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 523, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 523, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 523, iters: 304, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 523, iters: 384, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 523, iters: 464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 523, iters: 544, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 523, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 523, iters: 704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 523, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 523, iters: 864, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 523, iters: 944, time: 0.095, data: 0.041) loss: 0.081 
(epoch: 523, iters: 1024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 523, iters: 1104, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 523, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 523, iters: 1264, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 523, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 523, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 523, iters: 1504, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 523, iters: 1584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 523, iters: 1664, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 523, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 523, iters: 1824, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 523, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 523, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 523, iters: 2064, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 523, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 523, iters: 2224, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 523, iters: 2304, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 523, iters: 2384, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 523, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 523, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 523, iters: 2624, time: 0.096, data: 0.042) loss: 0.015 
(epoch: 523, iters: 2704, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 523, iters: 2784, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 523, iters: 2864, time: 0.094, data: 0.000) loss: 0.126 
(epoch: 523, iters: 2944, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 523, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 523, iters: 3104, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 523, iters: 3184, time: 0.094, data: 0.039) loss: 0.027 
(epoch: 523, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 523, iters: 3344, time: 0.093, data: 0.012) loss: 0.016 
(epoch: 523, iters: 3424, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 523, iters: 3504, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 523, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 523, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 523, iters 1949744
End of epoch 523 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001576
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 523, TEST ACC: [95.144 %]

(epoch: 524, iters: 16, time: 0.108, data: 0.012) loss: 0.001 
saving the latest model (epoch 524, total_steps 1949760)
(epoch: 524, iters: 96, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 524, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 524, iters: 256, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 524, iters: 336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 524, iters: 416, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 524, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 524, iters: 576, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 524, iters: 656, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 524, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 524, iters: 816, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 524, iters: 896, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 524, iters: 976, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 524, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 524, iters: 1136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 524, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 524, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 524, iters: 1376, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 524, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 524, iters: 1536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 524, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 524, iters: 1696, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 524, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 524, iters: 1856, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 524, iters: 1936, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 524, iters: 2016, time: 0.097, data: 0.000) loss: 0.033 
(epoch: 524, iters: 2096, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 524, iters: 2176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 524, iters: 2256, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 524, iters: 2336, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 524, iters: 2416, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 524, iters: 2496, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 524, iters: 2576, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 524, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 524, iters: 2736, time: 0.096, data: 0.000) loss: 0.016 
(epoch: 524, iters: 2816, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 524, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 524, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 524, iters: 3056, time: 0.095, data: 0.044) loss: 0.000 
(epoch: 524, iters: 3136, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 524, iters: 3216, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 524, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 524, iters: 3376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 524, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 524, iters: 3536, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 524, iters: 3616, time: 0.093, data: 0.048) loss: 0.001 
(epoch: 524, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 524, iters 1953472
End of epoch 524 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001575
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 524, TEST ACC: [94.385 %]

saving the latest model (epoch 525, total_steps 1953488)
(epoch: 525, iters: 48, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 525, iters: 128, time: 0.097, data: 0.058) loss: 0.000 
(epoch: 525, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 525, iters: 288, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 525, iters: 368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 525, iters: 448, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 525, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 525, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 525, iters: 688, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 525, iters: 768, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 525, iters: 848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 525, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 525, iters: 1008, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 525, iters: 1088, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 525, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 525, iters: 1248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 525, iters: 1328, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 525, iters: 1408, time: 0.093, data: 0.024) loss: 0.000 
(epoch: 525, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 525, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 525, iters: 1648, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 525, iters: 1728, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 525, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 525, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 525, iters: 1968, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 525, iters: 2048, time: 0.092, data: 0.034) loss: 0.000 
(epoch: 525, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 525, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 525, iters: 2288, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 525, iters: 2368, time: 0.092, data: 0.025) loss: 0.001 
(epoch: 525, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 525, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 525, iters: 2608, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 525, iters: 2688, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 525, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 525, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 525, iters: 2928, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 525, iters: 3008, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 525, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 525, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 525, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 525, iters: 3328, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 525, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 525, iters: 3488, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 525, iters: 3568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 525, iters: 3648, time: 0.087, data: 0.027) loss: 0.000 
(epoch: 525, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 525, iters 1957200
End of epoch 525 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001574
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 525, TEST ACC: [96.813 %]

saving the latest model (epoch 526, total_steps 1957216)
(epoch: 526, iters: 80, time: 0.093, data: 0.492) loss: 0.000 
(epoch: 526, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 526, iters: 240, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 526, iters: 320, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 526, iters: 400, time: 0.093, data: 0.020) loss: 0.006 
(epoch: 526, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 526, iters: 560, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 526, iters: 640, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 526, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 526, iters: 800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 526, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 526, iters: 960, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 526, iters: 1040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 526, iters: 1120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 526, iters: 1200, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 526, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 526, iters: 1360, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 526, iters: 1440, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 526, iters: 1520, time: 0.096, data: 0.012) loss: 0.003 
(epoch: 526, iters: 1600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 526, iters: 1680, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 526, iters: 1760, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 526, iters: 1840, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 526, iters: 1920, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 526, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 526, iters: 2080, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 526, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 526, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 526, iters: 2320, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 526, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 526, iters: 2480, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 526, iters: 2560, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 526, iters: 2640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 526, iters: 2720, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 526, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 526, iters: 2880, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 526, iters: 2960, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 526, iters: 3040, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 526, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 526, iters: 3200, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 526, iters: 3280, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 526, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 526, iters: 3440, time: 0.097, data: 0.052) loss: 0.001 
(epoch: 526, iters: 3520, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 526, iters: 3600, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 526, iters: 3680, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 526, iters 1960928
End of epoch 526 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001573
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 526, TEST ACC: [94.841 %]

saving the latest model (epoch 527, total_steps 1960944)
(epoch: 527, iters: 32, time: 0.095, data: 0.004) loss: 0.000 
(epoch: 527, iters: 112, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 527, iters: 192, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 527, iters: 272, time: 0.095, data: 0.048) loss: 0.133 
(epoch: 527, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 527, iters: 432, time: 0.094, data: 0.012) loss: 0.057 
(epoch: 527, iters: 512, time: 0.094, data: 0.000) loss: 0.033 
(epoch: 527, iters: 592, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 527, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 527, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 527, iters: 832, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 527, iters: 912, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 527, iters: 992, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 527, iters: 1072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 527, iters: 1152, time: 0.095, data: 0.012) loss: 0.004 
(epoch: 527, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 527, iters: 1312, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 527, iters: 1392, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 527, iters: 1472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 527, iters: 1552, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 527, iters: 1632, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 527, iters: 1712, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 527, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 527, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 527, iters: 1952, time: 0.095, data: 0.040) loss: 0.023 
(epoch: 527, iters: 2032, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 527, iters: 2112, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 527, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 527, iters: 2272, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 527, iters: 2352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 527, iters: 2432, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 527, iters: 2512, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 527, iters: 2592, time: 0.094, data: 0.000) loss: 0.095 
(epoch: 527, iters: 2672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 527, iters: 2752, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 527, iters: 2832, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 527, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 527, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 527, iters: 3072, time: 0.093, data: 0.041) loss: 0.001 
(epoch: 527, iters: 3152, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 527, iters: 3232, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 527, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 527, iters: 3392, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 527, iters: 3472, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 527, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 527, iters: 3632, time: 0.091, data: 0.041) loss: 0.000 
(epoch: 527, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 527, iters 1964656
End of epoch 527 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001572
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 527, TEST ACC: [95.903 %]

saving the latest model (epoch 528, total_steps 1964672)
(epoch: 528, iters: 64, time: 0.092, data: 0.003) loss: 0.000 
(epoch: 528, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 528, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 528, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 528, iters: 384, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 528, iters: 464, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 528, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 528, iters: 624, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 528, iters: 704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 528, iters: 784, time: 0.093, data: 0.012) loss: 0.021 
(epoch: 528, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 528, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 528, iters: 1024, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 528, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 528, iters: 1184, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 528, iters: 1264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 528, iters: 1344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 528, iters: 1424, time: 0.093, data: 0.011) loss: 0.009 
(epoch: 528, iters: 1504, time: 0.092, data: 0.027) loss: 0.001 
(epoch: 528, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 528, iters: 1664, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 528, iters: 1744, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 528, iters: 1824, time: 0.094, data: 0.028) loss: 0.006 
(epoch: 528, iters: 1904, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 528, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 528, iters: 2064, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 528, iters: 2144, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 528, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 528, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 528, iters: 2384, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 528, iters: 2464, time: 0.091, data: 0.026) loss: 0.000 
(epoch: 528, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 528, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 528, iters: 2704, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 528, iters: 2784, time: 0.094, data: 0.026) loss: 0.090 
(epoch: 528, iters: 2864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 528, iters: 2944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 528, iters: 3024, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 528, iters: 3104, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 528, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 528, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 528, iters: 3344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 528, iters: 3424, time: 0.092, data: 0.026) loss: 0.001 
(epoch: 528, iters: 3504, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 528, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 528, iters: 3664, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 528, iters 1968384
End of epoch 528 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001571
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 528, TEST ACC: [93.93 %]

(epoch: 529, iters: 16, time: 0.108, data: 0.013) loss: 0.001 
saving the latest model (epoch 529, total_steps 1968400)
(epoch: 529, iters: 96, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 529, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 529, iters: 256, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 529, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 529, iters: 416, time: 0.093, data: 0.000) loss: 0.121 
(epoch: 529, iters: 496, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 529, iters: 576, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 529, iters: 656, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 529, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 529, iters: 816, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 529, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 529, iters: 976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 529, iters: 1056, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 529, iters: 1136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 529, iters: 1216, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 529, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 529, iters: 1376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 529, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 529, iters: 1536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 529, iters: 1616, time: 0.094, data: 0.023) loss: 0.000 
(epoch: 529, iters: 1696, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 529, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 529, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 529, iters: 1936, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 529, iters: 2016, time: 0.093, data: 0.025) loss: 0.001 
(epoch: 529, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 529, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 529, iters: 2256, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 529, iters: 2336, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 529, iters: 2416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 529, iters: 2496, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 529, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 529, iters: 2656, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 529, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 529, iters: 2816, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 529, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 529, iters: 2976, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 529, iters: 3056, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 529, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 529, iters: 3216, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 529, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 529, iters: 3376, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 529, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 529, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 529, iters: 3616, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 529, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 529, iters 1972112
End of epoch 529 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001570
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 529, TEST ACC: [90.44 %]

saving the latest model (epoch 530, total_steps 1972128)
(epoch: 530, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 530, iters: 128, time: 0.094, data: 0.043) loss: 0.034 
(epoch: 530, iters: 208, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 530, iters: 288, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 530, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 530, iters: 448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 530, iters: 528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 530, iters: 608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 530, iters: 688, time: 0.094, data: 0.041) loss: 0.010 
(epoch: 530, iters: 768, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 530, iters: 848, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 530, iters: 928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 530, iters: 1008, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 530, iters: 1088, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 530, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 530, iters: 1248, time: 0.095, data: 0.041) loss: 0.007 
(epoch: 530, iters: 1328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 530, iters: 1408, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 530, iters: 1488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 530, iters: 1568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 530, iters: 1648, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 530, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 530, iters: 1808, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 530, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 530, iters: 1968, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 530, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 530, iters: 2128, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 530, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 530, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 530, iters: 2368, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 530, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 530, iters: 2528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 530, iters: 2608, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 530, iters: 2688, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 530, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 530, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 530, iters: 2928, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 530, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 530, iters: 3088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 530, iters: 3168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 530, iters: 3248, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 530, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 530, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 530, iters: 3488, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 530, iters: 3568, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 530, iters: 3648, time: 0.087, data: 0.011) loss: 0.000 
(epoch: 530, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 530, iters 1975840
End of epoch 530 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001569
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 530, TEST ACC: [95.751 %]

saving the latest model (epoch 531, total_steps 1975856)
(epoch: 531, iters: 80, time: 0.095, data: 0.458) loss: 0.001 
(epoch: 531, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 531, iters: 240, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 531, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 531, iters: 400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 531, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 531, iters: 560, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 531, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 531, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 531, iters: 800, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 531, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 531, iters: 960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 531, iters: 1040, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 531, iters: 1120, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 531, iters: 1200, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 531, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 531, iters: 1360, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 531, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 531, iters: 1520, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 531, iters: 1600, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 531, iters: 1680, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 531, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 531, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 531, iters: 1920, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 531, iters: 2000, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 531, iters: 2080, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 531, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 531, iters: 2240, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 531, iters: 2320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 531, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 531, iters: 2480, time: 0.094, data: 0.049) loss: 0.001 
(epoch: 531, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 531, iters: 2640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 531, iters: 2720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 531, iters: 2800, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 531, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 531, iters: 2960, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 531, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 531, iters: 3120, time: 0.096, data: 0.000) loss: 0.087 
(epoch: 531, iters: 3200, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 531, iters: 3280, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 531, iters: 3360, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 531, iters: 3440, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 531, iters: 3520, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 531, iters: 3600, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 531, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 531, iters 1979568
End of epoch 531 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001568
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 531, TEST ACC: [90.44 %]

saving the latest model (epoch 532, total_steps 1979584)
(epoch: 532, iters: 32, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 532, iters: 112, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 532, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 532, iters: 272, time: 0.096, data: 0.050) loss: 0.082 
(epoch: 532, iters: 352, time: 0.096, data: 0.000) loss: 0.018 
(epoch: 532, iters: 432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 532, iters: 512, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 532, iters: 592, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 532, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 532, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 532, iters: 832, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 532, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 532, iters: 992, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 532, iters: 1072, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 532, iters: 1152, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 532, iters: 1232, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 532, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 532, iters: 1392, time: 0.095, data: 0.047) loss: 0.001 
(epoch: 532, iters: 1472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 532, iters: 1552, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 532, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 532, iters: 1712, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 532, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 532, iters: 1872, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 532, iters: 1952, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 532, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 532, iters: 2112, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 532, iters: 2192, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 532, iters: 2272, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 532, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 532, iters: 2432, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 532, iters: 2512, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 532, iters: 2592, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 532, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 532, iters: 2752, time: 0.095, data: 0.013) loss: 0.003 
(epoch: 532, iters: 2832, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 532, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 532, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 532, iters: 3072, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 532, iters: 3152, time: 0.094, data: 0.026) loss: 0.004 
(epoch: 532, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 532, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 532, iters: 3392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 532, iters: 3472, time: 0.097, data: 0.048) loss: 0.001 
(epoch: 532, iters: 3552, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 532, iters: 3632, time: 0.090, data: 0.011) loss: 0.089 
(epoch: 532, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 532, iters 1983296
End of epoch 532 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001567
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 532, TEST ACC: [94.689 %]

saving the latest model (epoch 533, total_steps 1983312)
(epoch: 533, iters: 64, time: 0.093, data: 0.003) loss: 0.000 
(epoch: 533, iters: 144, time: 0.094, data: 0.028) loss: 0.001 
(epoch: 533, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 533, iters: 304, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 533, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 533, iters: 464, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 533, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 533, iters: 624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 533, iters: 704, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 533, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 533, iters: 864, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 533, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 533, iters: 1024, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 533, iters: 1104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 533, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 533, iters: 1264, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 533, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 533, iters: 1424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 533, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 533, iters: 1584, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 533, iters: 1664, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 533, iters: 1744, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 533, iters: 1824, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 533, iters: 1904, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 533, iters: 1984, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 533, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 533, iters: 2144, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 533, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 533, iters: 2304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 533, iters: 2384, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 533, iters: 2464, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 533, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 533, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 533, iters: 2704, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 533, iters: 2784, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 533, iters: 2864, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 533, iters: 2944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 533, iters: 3024, time: 0.093, data: 0.012) loss: 0.016 
(epoch: 533, iters: 3104, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 533, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 533, iters: 3264, time: 0.094, data: 0.000) loss: 0.051 
(epoch: 533, iters: 3344, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 533, iters: 3424, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 533, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 533, iters: 3584, time: 0.097, data: 0.000) loss: 0.011 
(epoch: 533, iters: 3664, time: 0.088, data: 0.012) loss: 0.005 
saving the model at the end of epoch 533, iters 1987024
End of epoch 533 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001566
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 533, TEST ACC: [95.599 %]

(epoch: 534, iters: 16, time: 0.108, data: 0.000) loss: 0.000 
saving the latest model (epoch 534, total_steps 1987040)
(epoch: 534, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 534, iters: 176, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 534, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 534, iters: 336, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 534, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 534, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 534, iters: 576, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 534, iters: 656, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 534, iters: 736, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 534, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 534, iters: 896, time: 0.096, data: 0.012) loss: 0.003 
(epoch: 534, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 534, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 534, iters: 1136, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 534, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 534, iters: 1296, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 534, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 534, iters: 1456, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 534, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 534, iters: 1616, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 534, iters: 1696, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 534, iters: 1776, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 534, iters: 1856, time: 0.093, data: 0.011) loss: 0.010 
(epoch: 534, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 534, iters: 2016, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 534, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 534, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 534, iters: 2256, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 534, iters: 2336, time: 0.095, data: 0.000) loss: 0.071 
(epoch: 534, iters: 2416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 534, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 534, iters: 2576, time: 0.093, data: 0.011) loss: 0.316 
(epoch: 534, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 534, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 534, iters: 2816, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 534, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 534, iters: 2976, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 534, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 534, iters: 3136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 534, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 534, iters: 3296, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 534, iters: 3376, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 534, iters: 3456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 534, iters: 3536, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 534, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 534, iters: 3696, time: 0.088, data: 0.012) loss: 0.001 
saving the model at the end of epoch 534, iters 1990752
End of epoch 534 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001565
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 534, TEST ACC: [96.206 %]

saving the latest model (epoch 535, total_steps 1990768)
(epoch: 535, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 535, iters: 128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 535, iters: 208, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 535, iters: 288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 535, iters: 368, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 535, iters: 448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 535, iters: 528, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 535, iters: 608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 535, iters: 688, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 535, iters: 768, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 535, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 535, iters: 928, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 535, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 535, iters: 1088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 535, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 535, iters: 1248, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 535, iters: 1328, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 535, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 535, iters: 1488, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 535, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 535, iters: 1648, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 535, iters: 1728, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 535, iters: 1808, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 535, iters: 1888, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 535, iters: 1968, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 535, iters: 2048, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 535, iters: 2128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 535, iters: 2208, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 535, iters: 2288, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 535, iters: 2368, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 535, iters: 2448, time: 0.094, data: 0.039) loss: 0.013 
(epoch: 535, iters: 2528, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 535, iters: 2608, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 535, iters: 2688, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 535, iters: 2768, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 535, iters: 2848, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 535, iters: 2928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 535, iters: 3008, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 535, iters: 3088, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 535, iters: 3168, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 535, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 535, iters: 3328, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 535, iters: 3408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 535, iters: 3488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 535, iters: 3568, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 535, iters: 3648, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 535, iters: 3728, time: 0.057, data: 0.011) loss: 0.000 
saving the model at the end of epoch 535, iters 1994480
End of epoch 535 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001564
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 535, TEST ACC: [95.599 %]

saving the latest model (epoch 536, total_steps 1994496)
(epoch: 536, iters: 80, time: 0.097, data: 0.527) loss: 0.000 
(epoch: 536, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 536, iters: 240, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 536, iters: 320, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 536, iters: 400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 536, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 536, iters: 560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 536, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 536, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 536, iters: 800, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 536, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 536, iters: 960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 536, iters: 1040, time: 0.092, data: 0.024) loss: 0.000 
(epoch: 536, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 536, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 536, iters: 1280, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 536, iters: 1360, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 536, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 536, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 536, iters: 1600, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 536, iters: 1680, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 536, iters: 1760, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 536, iters: 1840, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 536, iters: 1920, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 536, iters: 2000, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 536, iters: 2080, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 536, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 536, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 536, iters: 2320, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 536, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 536, iters: 2480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 536, iters: 2560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 536, iters: 2640, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 536, iters: 2720, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 536, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 536, iters: 2880, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 536, iters: 2960, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 536, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 536, iters: 3120, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 536, iters: 3200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 536, iters: 3280, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 536, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 536, iters: 3440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 536, iters: 3520, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 536, iters: 3600, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 536, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 536, iters 1998208
End of epoch 536 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001563
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 536, TEST ACC: [94.992 %]

saving the latest model (epoch 537, total_steps 1998224)
(epoch: 537, iters: 32, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 537, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 537, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 537, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 537, iters: 352, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 537, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 537, iters: 512, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 537, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 537, iters: 672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 537, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 537, iters: 832, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 537, iters: 912, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 537, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 537, iters: 1072, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 537, iters: 1152, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 537, iters: 1232, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 537, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 537, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 537, iters: 1472, time: 0.093, data: 0.047) loss: 0.000 
(epoch: 537, iters: 1552, time: 0.095, data: 0.000) loss: 0.018 
(epoch: 537, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 537, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 537, iters: 1792, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 537, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 537, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 537, iters: 2032, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 537, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 537, iters: 2192, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 537, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 537, iters: 2352, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 537, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 537, iters: 2512, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 537, iters: 2592, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 537, iters: 2672, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 537, iters: 2752, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 537, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 537, iters: 2912, time: 0.094, data: 0.011) loss: 0.004 
(epoch: 537, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 537, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 537, iters: 3152, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 537, iters: 3232, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 537, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 537, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 537, iters: 3472, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 537, iters: 3552, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 537, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 537, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 537, iters 2001936
End of epoch 537 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001562
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 537, TEST ACC: [94.992 %]

saving the latest model (epoch 538, total_steps 2001952)
(epoch: 538, iters: 64, time: 0.093, data: 0.003) loss: 0.000 
(epoch: 538, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 538, iters: 224, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 538, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 538, iters: 384, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 538, iters: 464, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 538, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 538, iters: 624, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 538, iters: 704, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 538, iters: 784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 538, iters: 864, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 538, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 538, iters: 1024, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 538, iters: 1104, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 538, iters: 1184, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 538, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 538, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 538, iters: 1424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 538, iters: 1504, time: 0.092, data: 0.036) loss: 0.000 
(epoch: 538, iters: 1584, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 538, iters: 1664, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 538, iters: 1744, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 538, iters: 1824, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 538, iters: 1904, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 538, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 538, iters: 2064, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 538, iters: 2144, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 538, iters: 2224, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 538, iters: 2304, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 538, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 538, iters: 2464, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 538, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 538, iters: 2624, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 538, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 538, iters: 2784, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 538, iters: 2864, time: 0.093, data: 0.039) loss: 0.050 
(epoch: 538, iters: 2944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 538, iters: 3024, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 538, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 538, iters: 3184, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 538, iters: 3264, time: 0.098, data: 0.000) loss: 0.002 
(epoch: 538, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 538, iters: 3424, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 538, iters: 3504, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 538, iters: 3584, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 538, iters: 3664, time: 0.089, data: 0.026) loss: 0.001 
saving the model at the end of epoch 538, iters 2005664
End of epoch 538 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001561
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 538, TEST ACC: [96.055 %]

(epoch: 539, iters: 16, time: 0.107, data: 0.000) loss: 0.000 
saving the latest model (epoch 539, total_steps 2005680)
(epoch: 539, iters: 96, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 539, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 539, iters: 256, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 539, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 539, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 539, iters: 496, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 539, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 539, iters: 656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 539, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 539, iters: 816, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 539, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 539, iters: 976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 539, iters: 1056, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 539, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 539, iters: 1216, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 539, iters: 1296, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 539, iters: 1376, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 539, iters: 1456, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 539, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 539, iters: 1616, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 539, iters: 1696, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 539, iters: 1776, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 539, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 539, iters: 1936, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 539, iters: 2016, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 539, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 539, iters: 2176, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 539, iters: 2256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 539, iters: 2336, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 539, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 539, iters: 2496, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 539, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 539, iters: 2656, time: 0.092, data: 0.000) loss: 0.185 
(epoch: 539, iters: 2736, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 539, iters: 2816, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 539, iters: 2896, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 539, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 539, iters: 3056, time: 0.096, data: 0.011) loss: 0.043 
(epoch: 539, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 539, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 539, iters: 3296, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 539, iters: 3376, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 539, iters: 3456, time: 0.094, data: 0.011) loss: 0.004 
(epoch: 539, iters: 3536, time: 0.094, data: 0.029) loss: 0.001 
(epoch: 539, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 539, iters: 3696, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 539, iters 2009392
End of epoch 539 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001560
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 539, TEST ACC: [96.662 %]

saving the latest model (epoch 540, total_steps 2009408)
(epoch: 540, iters: 48, time: 0.095, data: 0.004) loss: 0.001 
(epoch: 540, iters: 128, time: 0.096, data: 0.057) loss: 0.011 
(epoch: 540, iters: 208, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 540, iters: 288, time: 0.094, data: 0.011) loss: 0.015 
(epoch: 540, iters: 368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 540, iters: 448, time: 0.095, data: 0.021) loss: 0.000 
(epoch: 540, iters: 528, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 540, iters: 608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 540, iters: 688, time: 0.097, data: 0.051) loss: 0.000 
(epoch: 540, iters: 768, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 540, iters: 848, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 540, iters: 928, time: 0.097, data: 0.000) loss: 0.014 
(epoch: 540, iters: 1008, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 540, iters: 1088, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 540, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 540, iters: 1248, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 540, iters: 1328, time: 0.095, data: 0.000) loss: 0.026 
(epoch: 540, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 540, iters: 1488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 540, iters: 1568, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 540, iters: 1648, time: 0.095, data: 0.000) loss: 0.178 
(epoch: 540, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 540, iters: 1808, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 540, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 540, iters: 1968, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 540, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 540, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 540, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 540, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 540, iters: 2368, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 540, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 540, iters: 2528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 540, iters: 2608, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 540, iters: 2688, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 540, iters: 2768, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 540, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 540, iters: 2928, time: 0.095, data: 0.000) loss: 0.021 
(epoch: 540, iters: 3008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 540, iters: 3088, time: 0.093, data: 0.025) loss: 0.005 
(epoch: 540, iters: 3168, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 540, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 540, iters: 3328, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 540, iters: 3408, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 540, iters: 3488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 540, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 540, iters: 3648, time: 0.086, data: 0.012) loss: 0.004 
(epoch: 540, iters: 3728, time: 0.056, data: 0.017) loss: 0.000 
saving the model at the end of epoch 540, iters 2013120
End of epoch 540 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001559
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 540, TEST ACC: [93.778 %]

saving the latest model (epoch 541, total_steps 2013136)
(epoch: 541, iters: 80, time: 0.095, data: 0.470) loss: 0.008 
(epoch: 541, iters: 160, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 541, iters: 240, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 541, iters: 320, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 541, iters: 400, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 541, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 541, iters: 560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 541, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 541, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 541, iters: 800, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 541, iters: 880, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 541, iters: 960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 541, iters: 1040, time: 0.094, data: 0.000) loss: 0.064 
(epoch: 541, iters: 1120, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 541, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 541, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 541, iters: 1360, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 541, iters: 1440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 541, iters: 1520, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 541, iters: 1600, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 541, iters: 1680, time: 0.095, data: 0.012) loss: 0.033 
(epoch: 541, iters: 1760, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 541, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 541, iters: 1920, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 541, iters: 2000, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 541, iters: 2080, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 541, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 541, iters: 2240, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 541, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 541, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 541, iters: 2480, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 541, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 541, iters: 2640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 541, iters: 2720, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 541, iters: 2800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 541, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 541, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 541, iters: 3040, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 541, iters: 3120, time: 0.094, data: 0.000) loss: 0.041 
(epoch: 541, iters: 3200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 541, iters: 3280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 541, iters: 3360, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 541, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 541, iters: 3520, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 541, iters: 3600, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 541, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 541, iters 2016848
End of epoch 541 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001558
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 541, TEST ACC: [96.51 %]

saving the latest model (epoch 542, total_steps 2016864)
(epoch: 542, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 542, iters: 112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 542, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 542, iters: 272, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 542, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 542, iters: 432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 542, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 542, iters: 592, time: 0.093, data: 0.012) loss: 0.009 
(epoch: 542, iters: 672, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 542, iters: 752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 542, iters: 832, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 542, iters: 912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 542, iters: 992, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 542, iters: 1072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 542, iters: 1152, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 542, iters: 1232, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 542, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 542, iters: 1392, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 542, iters: 1472, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 542, iters: 1552, time: 0.092, data: 0.012) loss: 0.006 
(epoch: 542, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 542, iters: 1712, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 542, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 542, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 542, iters: 1952, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 542, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 542, iters: 2112, time: 0.093, data: 0.000) loss: 0.032 
(epoch: 542, iters: 2192, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 542, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 542, iters: 2352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 542, iters: 2432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 542, iters: 2512, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 542, iters: 2592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 542, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 542, iters: 2752, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 542, iters: 2832, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 542, iters: 2912, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 542, iters: 2992, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 542, iters: 3072, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 542, iters: 3152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 542, iters: 3232, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 542, iters: 3312, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 542, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 542, iters: 3472, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 542, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 542, iters: 3632, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 542, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 542, iters 2020576
End of epoch 542 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001557
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 542, TEST ACC: [97.42 %]

saving the latest model (epoch 543, total_steps 2020592)
(epoch: 543, iters: 64, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 543, iters: 144, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 543, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 543, iters: 304, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 543, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 543, iters: 464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 543, iters: 544, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 543, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 543, iters: 704, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 543, iters: 784, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 543, iters: 864, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 543, iters: 944, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 543, iters: 1024, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 543, iters: 1104, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 543, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 543, iters: 1264, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 543, iters: 1344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 543, iters: 1424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 543, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 543, iters: 1584, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 543, iters: 1664, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 543, iters: 1744, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 543, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 543, iters: 1904, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 543, iters: 1984, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 543, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 543, iters: 2144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 543, iters: 2224, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 543, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 543, iters: 2384, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 543, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 543, iters: 2544, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 543, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 543, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 543, iters: 2784, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 543, iters: 2864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 543, iters: 2944, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 543, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 543, iters: 3104, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 543, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 543, iters: 3264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 543, iters: 3344, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 543, iters: 3424, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 543, iters: 3504, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 543, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 543, iters: 3664, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 543, iters 2024304
End of epoch 543 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001556
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 543, TEST ACC: [85.129 %]

(epoch: 544, iters: 16, time: 0.111, data: 0.000) loss: 0.000 
saving the latest model (epoch 544, total_steps 2024320)
(epoch: 544, iters: 96, time: 0.093, data: 0.057) loss: 0.001 
(epoch: 544, iters: 176, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 544, iters: 256, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 544, iters: 336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 544, iters: 416, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 544, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 544, iters: 576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 544, iters: 656, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 544, iters: 736, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 544, iters: 816, time: 0.092, data: 0.012) loss: 0.170 
(epoch: 544, iters: 896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 544, iters: 976, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 544, iters: 1056, time: 0.094, data: 0.000) loss: 0.023 
(epoch: 544, iters: 1136, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 544, iters: 1216, time: 0.095, data: 0.040) loss: 0.228 
(epoch: 544, iters: 1296, time: 0.096, data: 0.000) loss: 0.015 
(epoch: 544, iters: 1376, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 544, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 544, iters: 1536, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 544, iters: 1616, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 544, iters: 1696, time: 0.093, data: 0.000) loss: 0.281 
(epoch: 544, iters: 1776, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 544, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 544, iters: 1936, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 544, iters: 2016, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 544, iters: 2096, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 544, iters: 2176, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 544, iters: 2256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 544, iters: 2336, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 544, iters: 2416, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 544, iters: 2496, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 544, iters: 2576, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 544, iters: 2656, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 544, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 544, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 544, iters: 2896, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 544, iters: 2976, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 544, iters: 3056, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 544, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 544, iters: 3216, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 544, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 544, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 544, iters: 3456, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 544, iters: 3536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 544, iters: 3616, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 544, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 544, iters 2028032
End of epoch 544 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001555
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 544, TEST ACC: [89.226 %]

saving the latest model (epoch 545, total_steps 2028048)
(epoch: 545, iters: 48, time: 0.096, data: 0.005) loss: 0.000 
(epoch: 545, iters: 128, time: 0.097, data: 0.042) loss: 0.000 
(epoch: 545, iters: 208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 545, iters: 288, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 545, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 545, iters: 448, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 545, iters: 528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 545, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 545, iters: 688, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 545, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 545, iters: 848, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 545, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 545, iters: 1008, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 545, iters: 1088, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 545, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 545, iters: 1248, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 545, iters: 1328, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 545, iters: 1408, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 545, iters: 1488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 545, iters: 1568, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 545, iters: 1648, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 545, iters: 1728, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 545, iters: 1808, time: 0.097, data: 0.049) loss: 0.000 
(epoch: 545, iters: 1888, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 545, iters: 1968, time: 0.094, data: 0.013) loss: 0.011 
(epoch: 545, iters: 2048, time: 0.096, data: 0.000) loss: 0.326 
(epoch: 545, iters: 2128, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 545, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 545, iters: 2288, time: 0.095, data: 0.000) loss: 0.073 
(epoch: 545, iters: 2368, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 545, iters: 2448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 545, iters: 2528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 545, iters: 2608, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 545, iters: 2688, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 545, iters: 2768, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 545, iters: 2848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 545, iters: 2928, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 545, iters: 3008, time: 0.096, data: 0.000) loss: 0.043 
(epoch: 545, iters: 3088, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 545, iters: 3168, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 545, iters: 3248, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 545, iters: 3328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 545, iters: 3408, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 545, iters: 3488, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 545, iters: 3568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 545, iters: 3648, time: 0.089, data: 0.012) loss: 0.000 
(epoch: 545, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 545, iters 2031760
End of epoch 545 / 2100 	 Time Taken: 358 sec
learning rate = 0.0001554
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 545, TEST ACC: [95.903 %]

saving the latest model (epoch 546, total_steps 2031776)
(epoch: 546, iters: 80, time: 0.094, data: 0.505) loss: 0.000 
(epoch: 546, iters: 160, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 546, iters: 240, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 546, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 546, iters: 400, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 546, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 546, iters: 560, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 546, iters: 640, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 546, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 546, iters: 800, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 546, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 546, iters: 960, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 546, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 546, iters: 1120, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 546, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 546, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 546, iters: 1360, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 546, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 546, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 546, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 546, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 546, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 546, iters: 1840, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 546, iters: 1920, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 546, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 546, iters: 2080, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 546, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 546, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 546, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 546, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 546, iters: 2480, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 546, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 546, iters: 2640, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 546, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 546, iters: 2800, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 546, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 546, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 546, iters: 3040, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 546, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 546, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 546, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 546, iters: 3360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 546, iters: 3440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 546, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 546, iters: 3600, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 546, iters: 3680, time: 0.088, data: 0.000) loss: 0.024 
saving the model at the end of epoch 546, iters 2035488
End of epoch 546 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001553
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 546, TEST ACC: [93.778 %]

saving the latest model (epoch 547, total_steps 2035504)
(epoch: 547, iters: 32, time: 0.094, data: 0.004) loss: 0.001 
(epoch: 547, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 547, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 547, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 547, iters: 352, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 547, iters: 432, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 547, iters: 512, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 547, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 547, iters: 672, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 547, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 547, iters: 832, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 547, iters: 912, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 547, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 547, iters: 1072, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 547, iters: 1152, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 547, iters: 1232, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 547, iters: 1312, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 547, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 547, iters: 1472, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 547, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 547, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 547, iters: 1712, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 547, iters: 1792, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 547, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 547, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 547, iters: 2032, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 547, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 547, iters: 2192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 547, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 547, iters: 2352, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 547, iters: 2432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 547, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 547, iters: 2592, time: 0.094, data: 0.049) loss: 0.001 
(epoch: 547, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 547, iters: 2752, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 547, iters: 2832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 547, iters: 2912, time: 0.093, data: 0.012) loss: 0.022 
(epoch: 547, iters: 2992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 547, iters: 3072, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 547, iters: 3152, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 547, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 547, iters: 3312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 547, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 547, iters: 3472, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 547, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 547, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 547, iters: 3712, time: 0.088, data: 0.036) loss: 0.000 
saving the model at the end of epoch 547, iters 2039216
End of epoch 547 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001552
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 547, TEST ACC: [97.117 %]

saving the latest model (epoch 548, total_steps 2039232)
(epoch: 548, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 548, iters: 144, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 548, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 548, iters: 304, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 548, iters: 384, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 548, iters: 464, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 548, iters: 544, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 548, iters: 624, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 548, iters: 704, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 548, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 548, iters: 864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 548, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 548, iters: 1024, time: 0.096, data: 0.012) loss: 0.003 
(epoch: 548, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 548, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 548, iters: 1264, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 548, iters: 1344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 548, iters: 1424, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 548, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 548, iters: 1584, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 548, iters: 1664, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 548, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 548, iters: 1824, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 548, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 548, iters: 1984, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 548, iters: 2064, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 548, iters: 2144, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 548, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 548, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 548, iters: 2384, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 548, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 548, iters: 2544, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 548, iters: 2624, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 548, iters: 2704, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 548, iters: 2784, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 548, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 548, iters: 2944, time: 0.098, data: 0.050) loss: 0.000 
(epoch: 548, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 548, iters: 3104, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 548, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 548, iters: 3264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 548, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 548, iters: 3424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 548, iters: 3504, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 548, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 548, iters: 3664, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 548, iters 2042944
End of epoch 548 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001551
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 548, TEST ACC: [96.358 %]

(epoch: 549, iters: 16, time: 0.112, data: 0.013) loss: 0.001 
saving the latest model (epoch 549, total_steps 2042960)
(epoch: 549, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 549, iters: 176, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 549, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 549, iters: 336, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 549, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 549, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 549, iters: 576, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 549, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 549, iters: 736, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 549, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 549, iters: 896, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 549, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 549, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 549, iters: 1136, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 549, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 549, iters: 1296, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 549, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 549, iters: 1456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 549, iters: 1536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 549, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 549, iters: 1696, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 549, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 549, iters: 1856, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 549, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 549, iters: 2016, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 549, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 549, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 549, iters: 2256, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 549, iters: 2336, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 549, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 549, iters: 2496, time: 0.093, data: 0.000) loss: 0.012 
(epoch: 549, iters: 2576, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 549, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 549, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 549, iters: 2816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 549, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 549, iters: 2976, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 549, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 549, iters: 3136, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 549, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 549, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 549, iters: 3376, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 549, iters: 3456, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 549, iters: 3536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 549, iters: 3616, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 549, iters: 3696, time: 0.089, data: 0.012) loss: 0.000 
saving the model at the end of epoch 549, iters 2046672
End of epoch 549 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001550
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 549, TEST ACC: [96.662 %]

saving the latest model (epoch 550, total_steps 2046688)
(epoch: 550, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 550, iters: 128, time: 0.096, data: 0.028) loss: 0.000 
(epoch: 550, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 550, iters: 288, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 550, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 550, iters: 448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 550, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 550, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 550, iters: 688, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 550, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 550, iters: 848, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 550, iters: 928, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 550, iters: 1008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 550, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 550, iters: 1168, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 550, iters: 1248, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 550, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 550, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 550, iters: 1488, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 550, iters: 1568, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 550, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 550, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 550, iters: 1808, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 550, iters: 1888, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 550, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 550, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 550, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 550, iters: 2208, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 550, iters: 2288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 550, iters: 2368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 550, iters: 2448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 550, iters: 2528, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 550, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 550, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 550, iters: 2768, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 550, iters: 2848, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 550, iters: 2928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 550, iters: 3008, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 550, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 550, iters: 3168, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 550, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 550, iters: 3328, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 550, iters: 3408, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 550, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 550, iters: 3568, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 550, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 550, iters: 3728, time: 0.055, data: 0.011) loss: 0.000 
saving the model at the end of epoch 550, iters 2050400
End of epoch 550 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001549
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 550, TEST ACC: [95.903 %]

saving the latest model (epoch 551, total_steps 2050416)
(epoch: 551, iters: 80, time: 0.096, data: 0.509) loss: 0.000 
(epoch: 551, iters: 160, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 551, iters: 240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 551, iters: 320, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 551, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 551, iters: 480, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 551, iters: 560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 551, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 551, iters: 720, time: 0.096, data: 0.055) loss: 0.000 
(epoch: 551, iters: 800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 551, iters: 880, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 551, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 551, iters: 1040, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 551, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 551, iters: 1200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 551, iters: 1280, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 551, iters: 1360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 551, iters: 1440, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 551, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 551, iters: 1600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 551, iters: 1680, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 551, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 551, iters: 1840, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 551, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 551, iters: 2000, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 551, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 551, iters: 2160, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 551, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 551, iters: 2320, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 551, iters: 2400, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 551, iters: 2480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 551, iters: 2560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 551, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 551, iters: 2720, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 551, iters: 2800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 551, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 551, iters: 2960, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 551, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 551, iters: 3120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 551, iters: 3200, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 551, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 551, iters: 3360, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 551, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 551, iters: 3520, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 551, iters: 3600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 551, iters: 3680, time: 0.086, data: 0.000) loss: 0.000 
saving the model at the end of epoch 551, iters 2054128
End of epoch 551 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001548
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 551, TEST ACC: [96.206 %]

saving the latest model (epoch 552, total_steps 2054144)
(epoch: 552, iters: 32, time: 0.093, data: 0.007) loss: 0.000 
(epoch: 552, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 552, iters: 192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 552, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 552, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 552, iters: 432, time: 0.094, data: 0.048) loss: 0.001 
(epoch: 552, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 552, iters: 592, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 552, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 552, iters: 752, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 552, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 552, iters: 912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 552, iters: 992, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 552, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 552, iters: 1152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 552, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 552, iters: 1312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 552, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 552, iters: 1472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 552, iters: 1552, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 552, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 552, iters: 1712, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 552, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 552, iters: 1872, time: 0.093, data: 0.012) loss: 0.024 
(epoch: 552, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 552, iters: 2032, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 552, iters: 2112, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 552, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 552, iters: 2272, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 552, iters: 2352, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 552, iters: 2432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 552, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 552, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 552, iters: 2672, time: 0.095, data: 0.040) loss: 0.089 
(epoch: 552, iters: 2752, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 552, iters: 2832, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 552, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 552, iters: 2992, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 552, iters: 3072, time: 0.091, data: 0.026) loss: 0.002 
(epoch: 552, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 552, iters: 3232, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 552, iters: 3312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 552, iters: 3392, time: 0.092, data: 0.036) loss: 0.000 
(epoch: 552, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 552, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 552, iters: 3632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 552, iters: 3712, time: 0.088, data: 0.023) loss: 0.000 
saving the model at the end of epoch 552, iters 2057856
End of epoch 552 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001547
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 552, TEST ACC: [94.992 %]

saving the latest model (epoch 553, total_steps 2057872)
(epoch: 553, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 553, iters: 144, time: 0.097, data: 0.025) loss: 0.000 
(epoch: 553, iters: 224, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 553, iters: 304, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 553, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 553, iters: 464, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 553, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 553, iters: 624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 553, iters: 704, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 553, iters: 784, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 553, iters: 864, time: 0.094, data: 0.012) loss: 0.007 
(epoch: 553, iters: 944, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 553, iters: 1024, time: 0.093, data: 0.020) loss: 0.004 
(epoch: 553, iters: 1104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 553, iters: 1184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 553, iters: 1264, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 553, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 553, iters: 1424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 553, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 553, iters: 1584, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 553, iters: 1664, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 553, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 553, iters: 1824, time: 0.095, data: 0.041) loss: 0.004 
(epoch: 553, iters: 1904, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 553, iters: 1984, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 553, iters: 2064, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 553, iters: 2144, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 553, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 553, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 553, iters: 2384, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 553, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 553, iters: 2544, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 553, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 553, iters: 2704, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 553, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 553, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 553, iters: 2944, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 553, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 553, iters: 3104, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 553, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 553, iters: 3264, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 553, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 553, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 553, iters: 3504, time: 0.097, data: 0.050) loss: 0.000 
(epoch: 553, iters: 3584, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 553, iters: 3664, time: 0.089, data: 0.013) loss: 0.000 
saving the model at the end of epoch 553, iters 2061584
End of epoch 553 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001546
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 553, TEST ACC: [93.778 %]

(epoch: 554, iters: 16, time: 0.111, data: 0.013) loss: 0.000 
saving the latest model (epoch 554, total_steps 2061600)
(epoch: 554, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 554, iters: 176, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 554, iters: 256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 554, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 554, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 554, iters: 496, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 554, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 554, iters: 656, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 554, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 554, iters: 816, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 554, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 554, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 554, iters: 1056, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 554, iters: 1136, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 554, iters: 1216, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 554, iters: 1296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 554, iters: 1376, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 554, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 554, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 554, iters: 1616, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 554, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 554, iters: 1776, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 554, iters: 1856, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 554, iters: 1936, time: 0.092, data: 0.011) loss: 0.029 
(epoch: 554, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 554, iters: 2096, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 554, iters: 2176, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 554, iters: 2256, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 554, iters: 2336, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 554, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 554, iters: 2496, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 554, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 554, iters: 2656, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 554, iters: 2736, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 554, iters: 2816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 554, iters: 2896, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 554, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 554, iters: 3056, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 554, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 554, iters: 3216, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 554, iters: 3296, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 554, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 554, iters: 3456, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 554, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 554, iters: 3616, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 554, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 554, iters 2065312
End of epoch 554 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001545
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 554, TEST ACC: [95.144 %]

saving the latest model (epoch 555, total_steps 2065328)
(epoch: 555, iters: 48, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 555, iters: 128, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 555, iters: 208, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 555, iters: 288, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 555, iters: 368, time: 0.092, data: 0.011) loss: 0.003 
(epoch: 555, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 555, iters: 528, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 555, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 555, iters: 688, time: 0.093, data: 0.000) loss: 0.066 
(epoch: 555, iters: 768, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 555, iters: 848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 555, iters: 928, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 555, iters: 1008, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 555, iters: 1088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 555, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 555, iters: 1248, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 555, iters: 1328, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 555, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 555, iters: 1488, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 555, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 555, iters: 1648, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 555, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 555, iters: 1808, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 555, iters: 1888, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 555, iters: 1968, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 555, iters: 2048, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 555, iters: 2128, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 555, iters: 2208, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 555, iters: 2288, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 555, iters: 2368, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 555, iters: 2448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 555, iters: 2528, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 555, iters: 2608, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 555, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 555, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 555, iters: 2848, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 555, iters: 2928, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 555, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 555, iters: 3088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 555, iters: 3168, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 555, iters: 3248, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 555, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 555, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 555, iters: 3488, time: 0.092, data: 0.012) loss: 0.022 
(epoch: 555, iters: 3568, time: 0.095, data: 0.025) loss: 0.018 
(epoch: 555, iters: 3648, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 555, iters: 3728, time: 0.056, data: 0.000) loss: 0.008 
saving the model at the end of epoch 555, iters 2069040
End of epoch 555 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001544
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 555, TEST ACC: [95.751 %]

saving the latest model (epoch 556, total_steps 2069056)
(epoch: 556, iters: 80, time: 0.096, data: 0.510) loss: 0.000 
(epoch: 556, iters: 160, time: 0.094, data: 0.000) loss: 0.048 
(epoch: 556, iters: 240, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 556, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 556, iters: 400, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 556, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 556, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 556, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 556, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 556, iters: 800, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 556, iters: 880, time: 0.098, data: 0.000) loss: 0.228 
(epoch: 556, iters: 960, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 556, iters: 1040, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 556, iters: 1120, time: 0.094, data: 0.011) loss: 0.010 
(epoch: 556, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 556, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 556, iters: 1360, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 556, iters: 1440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 556, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 556, iters: 1600, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 556, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 556, iters: 1760, time: 0.096, data: 0.000) loss: 0.198 
(epoch: 556, iters: 1840, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 556, iters: 1920, time: 0.094, data: 0.039) loss: 0.061 
(epoch: 556, iters: 2000, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 556, iters: 2080, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 556, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 556, iters: 2240, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 556, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 556, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 556, iters: 2480, time: 0.094, data: 0.048) loss: 0.001 
(epoch: 556, iters: 2560, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 556, iters: 2640, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 556, iters: 2720, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 556, iters: 2800, time: 0.093, data: 0.020) loss: 0.002 
(epoch: 556, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 556, iters: 2960, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 556, iters: 3040, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 556, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 556, iters: 3200, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 556, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 556, iters: 3360, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 556, iters: 3440, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 556, iters: 3520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 556, iters: 3600, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 556, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 556, iters 2072768
End of epoch 556 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001543
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 556, TEST ACC: [96.358 %]

saving the latest model (epoch 557, total_steps 2072784)
(epoch: 557, iters: 32, time: 0.094, data: 0.004) loss: 0.000 
(epoch: 557, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 557, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 557, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 557, iters: 352, time: 0.093, data: 0.039) loss: 0.002 
(epoch: 557, iters: 432, time: 0.096, data: 0.000) loss: 0.059 
(epoch: 557, iters: 512, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 557, iters: 592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 557, iters: 672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 557, iters: 752, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 557, iters: 832, time: 0.094, data: 0.000) loss: 0.193 
(epoch: 557, iters: 912, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 557, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 557, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 557, iters: 1152, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 557, iters: 1232, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 557, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 557, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 557, iters: 1472, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 557, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 557, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 557, iters: 1712, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 557, iters: 1792, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 557, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 557, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 557, iters: 2032, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 557, iters: 2112, time: 0.094, data: 0.000) loss: 0.198 
(epoch: 557, iters: 2192, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 557, iters: 2272, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 557, iters: 2352, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 557, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 557, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 557, iters: 2592, time: 0.095, data: 0.040) loss: 0.016 
(epoch: 557, iters: 2672, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 557, iters: 2752, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 557, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 557, iters: 2912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 557, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 557, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 557, iters: 3152, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 557, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 557, iters: 3312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 557, iters: 3392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 557, iters: 3472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 557, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 557, iters: 3632, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 557, iters: 3712, time: 0.087, data: 0.035) loss: 0.000 
saving the model at the end of epoch 557, iters 2076496
End of epoch 557 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001542
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 557, TEST ACC: [94.234 %]

saving the latest model (epoch 558, total_steps 2076512)
(epoch: 558, iters: 64, time: 0.092, data: 0.000) loss: 0.003 
(epoch: 558, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 558, iters: 224, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 558, iters: 304, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 558, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 558, iters: 464, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 558, iters: 544, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 558, iters: 624, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 558, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 558, iters: 784, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 558, iters: 864, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 558, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 558, iters: 1024, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 558, iters: 1104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 558, iters: 1184, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 558, iters: 1264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 558, iters: 1344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 558, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 558, iters: 1504, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 558, iters: 1584, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 558, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 558, iters: 1744, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 558, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 558, iters: 1904, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 558, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 558, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 558, iters: 2144, time: 0.093, data: 0.048) loss: 0.019 
(epoch: 558, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 558, iters: 2304, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 558, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 558, iters: 2464, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 558, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 558, iters: 2624, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 558, iters: 2704, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 558, iters: 2784, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 558, iters: 2864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 558, iters: 2944, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 558, iters: 3024, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 558, iters: 3104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 558, iters: 3184, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 558, iters: 3264, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 558, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 558, iters: 3424, time: 0.092, data: 0.011) loss: 0.004 
(epoch: 558, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 558, iters: 3584, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 558, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 558, iters 2080224
End of epoch 558 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001541
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 558, TEST ACC: [96.055 %]

(epoch: 559, iters: 16, time: 0.110, data: 0.000) loss: 0.004 
saving the latest model (epoch 559, total_steps 2080240)
(epoch: 559, iters: 96, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 559, iters: 176, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 559, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 559, iters: 336, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 559, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 559, iters: 496, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 559, iters: 576, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 559, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 559, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 559, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 559, iters: 896, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 559, iters: 976, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 559, iters: 1056, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 559, iters: 1136, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 559, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 559, iters: 1296, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 559, iters: 1376, time: 0.093, data: 0.000) loss: 0.043 
(epoch: 559, iters: 1456, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 559, iters: 1536, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 559, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 559, iters: 1696, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 559, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 559, iters: 1856, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 559, iters: 1936, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 559, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 559, iters: 2096, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 559, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 559, iters: 2256, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 559, iters: 2336, time: 0.094, data: 0.000) loss: 0.024 
(epoch: 559, iters: 2416, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 559, iters: 2496, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 559, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 559, iters: 2656, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 559, iters: 2736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 559, iters: 2816, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 559, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 559, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 559, iters: 3056, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 559, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 559, iters: 3216, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 559, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 559, iters: 3376, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 559, iters: 3456, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 559, iters: 3536, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 559, iters: 3616, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 559, iters: 3696, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 559, iters 2083952
End of epoch 559 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001540
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 559, TEST ACC: [96.358 %]

saving the latest model (epoch 560, total_steps 2083968)
(epoch: 560, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 560, iters: 128, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 560, iters: 208, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 560, iters: 288, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 560, iters: 368, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 560, iters: 448, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 560, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 560, iters: 608, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 560, iters: 688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 560, iters: 768, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 560, iters: 848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 560, iters: 928, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 560, iters: 1008, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 560, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 560, iters: 1168, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 560, iters: 1248, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 560, iters: 1328, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 560, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 560, iters: 1488, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 560, iters: 1568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 560, iters: 1648, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 560, iters: 1728, time: 0.094, data: 0.049) loss: 0.031 
(epoch: 560, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 560, iters: 1888, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 560, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 560, iters: 2048, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 560, iters: 2128, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 560, iters: 2208, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 560, iters: 2288, time: 0.094, data: 0.039) loss: 0.005 
(epoch: 560, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 560, iters: 2448, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 560, iters: 2528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 560, iters: 2608, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 560, iters: 2688, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 560, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 560, iters: 2848, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 560, iters: 2928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 560, iters: 3008, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 560, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 560, iters: 3168, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 560, iters: 3248, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 560, iters: 3328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 560, iters: 3408, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 560, iters: 3488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 560, iters: 3568, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 560, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 560, iters: 3728, time: 0.056, data: 0.011) loss: 0.000 
saving the model at the end of epoch 560, iters 2087680
End of epoch 560 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001539
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 560, TEST ACC: [96.358 %]

saving the latest model (epoch 561, total_steps 2087696)
(epoch: 561, iters: 80, time: 0.095, data: 0.451) loss: 0.000 
(epoch: 561, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 561, iters: 240, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 561, iters: 320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 561, iters: 400, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 561, iters: 480, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 561, iters: 560, time: 0.092, data: 0.025) loss: 0.001 
(epoch: 561, iters: 640, time: 0.094, data: 0.000) loss: 0.021 
(epoch: 561, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 561, iters: 800, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 561, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 561, iters: 960, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 561, iters: 1040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 561, iters: 1120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 561, iters: 1200, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 561, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 561, iters: 1360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 561, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 561, iters: 1520, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 561, iters: 1600, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 561, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 561, iters: 1760, time: 0.097, data: 0.051) loss: 0.000 
(epoch: 561, iters: 1840, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 561, iters: 1920, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 561, iters: 2000, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 561, iters: 2080, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 561, iters: 2160, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 561, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 561, iters: 2320, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 561, iters: 2400, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 561, iters: 2480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 561, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 561, iters: 2640, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 561, iters: 2720, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 561, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 561, iters: 2880, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 561, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 561, iters: 3040, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 561, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 561, iters: 3200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 561, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 561, iters: 3360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 561, iters: 3440, time: 0.097, data: 0.050) loss: 0.000 
(epoch: 561, iters: 3520, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 561, iters: 3600, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 561, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 561, iters 2091408
End of epoch 561 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001538
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 561, TEST ACC: [97.572 %]

saving the latest model (epoch 562, total_steps 2091424)
(epoch: 562, iters: 32, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 562, iters: 112, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 562, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 562, iters: 272, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 562, iters: 352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 562, iters: 432, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 562, iters: 512, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 562, iters: 592, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 562, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 562, iters: 752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 562, iters: 832, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 562, iters: 912, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 562, iters: 992, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 562, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 562, iters: 1152, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 562, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 562, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 562, iters: 1392, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 562, iters: 1472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 562, iters: 1552, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 562, iters: 1632, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 562, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 562, iters: 1792, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 562, iters: 1872, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 562, iters: 1952, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 562, iters: 2032, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 562, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 562, iters: 2192, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 562, iters: 2272, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 562, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 562, iters: 2432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 562, iters: 2512, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 562, iters: 2592, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 562, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 562, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 562, iters: 2832, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 562, iters: 2912, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 562, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 562, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 562, iters: 3152, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 562, iters: 3232, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 562, iters: 3312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 562, iters: 3392, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 562, iters: 3472, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 562, iters: 3552, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 562, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 562, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 562, iters 2095136
End of epoch 562 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001537
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 562, TEST ACC: [96.51 %]

saving the latest model (epoch 563, total_steps 2095152)
(epoch: 563, iters: 64, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 563, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 563, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 563, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 563, iters: 384, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 563, iters: 464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 563, iters: 544, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 563, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 563, iters: 704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 563, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 563, iters: 864, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 563, iters: 944, time: 0.096, data: 0.048) loss: 0.001 
(epoch: 563, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 563, iters: 1104, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 563, iters: 1184, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 563, iters: 1264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 563, iters: 1344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 563, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 563, iters: 1504, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 563, iters: 1584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 563, iters: 1664, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 563, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 563, iters: 1824, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 563, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 563, iters: 1984, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 563, iters: 2064, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 563, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 563, iters: 2224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 563, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 563, iters: 2384, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 563, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 563, iters: 2544, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 563, iters: 2624, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 563, iters: 2704, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 563, iters: 2784, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 563, iters: 2864, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 563, iters: 2944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 563, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 563, iters: 3104, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 563, iters: 3184, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 563, iters: 3264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 563, iters: 3344, time: 0.094, data: 0.000) loss: 0.065 
(epoch: 563, iters: 3424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 563, iters: 3504, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 563, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 563, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 563, iters 2098864
End of epoch 563 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001536
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 563, TEST ACC: [96.206 %]

(epoch: 564, iters: 16, time: 0.111, data: 0.009) loss: 0.000 
saving the latest model (epoch 564, total_steps 2098880)
(epoch: 564, iters: 96, time: 0.093, data: 0.043) loss: 0.000 
(epoch: 564, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 564, iters: 256, time: 0.094, data: 0.011) loss: 0.066 
(epoch: 564, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 564, iters: 416, time: 0.093, data: 0.012) loss: 0.016 
(epoch: 564, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 564, iters: 576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 564, iters: 656, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 564, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 564, iters: 816, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 564, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 564, iters: 976, time: 0.093, data: 0.011) loss: 0.008 
(epoch: 564, iters: 1056, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 564, iters: 1136, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 564, iters: 1216, time: 0.095, data: 0.040) loss: 0.176 
(epoch: 564, iters: 1296, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 564, iters: 1376, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 564, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 564, iters: 1536, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 564, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 564, iters: 1696, time: 0.092, data: 0.000) loss: 0.006 
(epoch: 564, iters: 1776, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 564, iters: 1856, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 564, iters: 1936, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 564, iters: 2016, time: 0.095, data: 0.000) loss: 0.104 
(epoch: 564, iters: 2096, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 564, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 564, iters: 2256, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 564, iters: 2336, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 564, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 564, iters: 2496, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 564, iters: 2576, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 564, iters: 2656, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 564, iters: 2736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 564, iters: 2816, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 564, iters: 2896, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 564, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 564, iters: 3056, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 564, iters: 3136, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 564, iters: 3216, time: 0.093, data: 0.021) loss: 0.001 
(epoch: 564, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 564, iters: 3376, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 564, iters: 3456, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 564, iters: 3536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 564, iters: 3616, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 564, iters: 3696, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 564, iters 2102592
End of epoch 564 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001535
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 564, TEST ACC: [96.51 %]

saving the latest model (epoch 565, total_steps 2102608)
(epoch: 565, iters: 48, time: 0.093, data: 0.004) loss: 0.000 
(epoch: 565, iters: 128, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 565, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 565, iters: 288, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 565, iters: 368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 565, iters: 448, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 565, iters: 528, time: 0.095, data: 0.000) loss: 0.546 
(epoch: 565, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 565, iters: 688, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 565, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 565, iters: 848, time: 0.091, data: 0.012) loss: 0.002 
(epoch: 565, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 565, iters: 1008, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 565, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 565, iters: 1168, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 565, iters: 1248, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 565, iters: 1328, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 565, iters: 1408, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 565, iters: 1488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 565, iters: 1568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 565, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 565, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 565, iters: 1808, time: 0.094, data: 0.047) loss: 0.000 
(epoch: 565, iters: 1888, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 565, iters: 1968, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 565, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 565, iters: 2128, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 565, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 565, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 565, iters: 2368, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 565, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 565, iters: 2528, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 565, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 565, iters: 2688, time: 0.095, data: 0.011) loss: 0.013 
(epoch: 565, iters: 2768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 565, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 565, iters: 2928, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 565, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 565, iters: 3088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 565, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 565, iters: 3248, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 565, iters: 3328, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 565, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 565, iters: 3488, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 565, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 565, iters: 3648, time: 0.086, data: 0.011) loss: 0.000 
(epoch: 565, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 565, iters 2106320
End of epoch 565 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001534
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 565, TEST ACC: [95.144 %]

saving the latest model (epoch 566, total_steps 2106336)
(epoch: 566, iters: 80, time: 0.094, data: 0.441) loss: 0.000 
(epoch: 566, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 566, iters: 240, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 566, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 566, iters: 400, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 566, iters: 480, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 566, iters: 560, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 566, iters: 640, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 566, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 566, iters: 800, time: 0.094, data: 0.039) loss: 0.012 
(epoch: 566, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 566, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 566, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 566, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 566, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 566, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 566, iters: 1360, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 566, iters: 1440, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 566, iters: 1520, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 566, iters: 1600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 566, iters: 1680, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 566, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 566, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 566, iters: 1920, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 566, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 566, iters: 2080, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 566, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 566, iters: 2240, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 566, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 566, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 566, iters: 2480, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 566, iters: 2560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 566, iters: 2640, time: 0.092, data: 0.011) loss: 0.005 
(epoch: 566, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 566, iters: 2800, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 566, iters: 2880, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 566, iters: 2960, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 566, iters: 3040, time: 0.094, data: 0.052) loss: 0.000 
(epoch: 566, iters: 3120, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 566, iters: 3200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 566, iters: 3280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 566, iters: 3360, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 566, iters: 3440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 566, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 566, iters: 3600, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 566, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 566, iters 2110048
End of epoch 566 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001533
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 566, TEST ACC: [95.903 %]

saving the latest model (epoch 567, total_steps 2110064)
(epoch: 567, iters: 32, time: 0.094, data: 0.004) loss: 0.000 
(epoch: 567, iters: 112, time: 0.093, data: 0.026) loss: 0.001 
(epoch: 567, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 567, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 567, iters: 352, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 567, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 567, iters: 512, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 567, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 567, iters: 672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 567, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 567, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 567, iters: 912, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 567, iters: 992, time: 0.096, data: 0.000) loss: 0.066 
(epoch: 567, iters: 1072, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 567, iters: 1152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 567, iters: 1232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 567, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 567, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 567, iters: 1472, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 567, iters: 1552, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 567, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 567, iters: 1712, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 567, iters: 1792, time: 0.094, data: 0.035) loss: 0.000 
(epoch: 567, iters: 1872, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 567, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 567, iters: 2032, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 567, iters: 2112, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 567, iters: 2192, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 567, iters: 2272, time: 0.094, data: 0.000) loss: 0.106 
(epoch: 567, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 567, iters: 2432, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 567, iters: 2512, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 567, iters: 2592, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 567, iters: 2672, time: 0.094, data: 0.011) loss: 0.006 
(epoch: 567, iters: 2752, time: 0.094, data: 0.000) loss: 0.040 
(epoch: 567, iters: 2832, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 567, iters: 2912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 567, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 567, iters: 3072, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 567, iters: 3152, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 567, iters: 3232, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 567, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 567, iters: 3392, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 567, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 567, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 567, iters: 3632, time: 0.092, data: 0.040) loss: 0.000 
(epoch: 567, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 567, iters 2113776
End of epoch 567 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001532
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 567, TEST ACC: [96.51 %]

saving the latest model (epoch 568, total_steps 2113792)
(epoch: 568, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 568, iters: 144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 568, iters: 224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 568, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 568, iters: 384, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 568, iters: 464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 568, iters: 544, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 568, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 568, iters: 704, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 568, iters: 784, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 568, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 568, iters: 944, time: 0.094, data: 0.039) loss: 0.032 
(epoch: 568, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 568, iters: 1104, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 568, iters: 1184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 568, iters: 1264, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 568, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 568, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 568, iters: 1504, time: 0.094, data: 0.041) loss: 0.090 
(epoch: 568, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 568, iters: 1664, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 568, iters: 1744, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 568, iters: 1824, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 568, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 568, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 568, iters: 2064, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 568, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 568, iters: 2224, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 568, iters: 2304, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 568, iters: 2384, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 568, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 568, iters: 2544, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 568, iters: 2624, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 568, iters: 2704, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 568, iters: 2784, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 568, iters: 2864, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 568, iters: 2944, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 568, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 568, iters: 3104, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 568, iters: 3184, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 568, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 568, iters: 3344, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 568, iters: 3424, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 568, iters: 3504, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 568, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 568, iters: 3664, time: 0.087, data: 0.000) loss: 0.002 
saving the model at the end of epoch 568, iters 2117504
End of epoch 568 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001531
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 568, TEST ACC: [96.206 %]

(epoch: 569, iters: 16, time: 0.110, data: 0.012) loss: 0.001 
saving the latest model (epoch 569, total_steps 2117520)
(epoch: 569, iters: 96, time: 0.094, data: 0.044) loss: 0.000 
(epoch: 569, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 569, iters: 256, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 569, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 569, iters: 416, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 569, iters: 496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 569, iters: 576, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 569, iters: 656, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 569, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 569, iters: 816, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 569, iters: 896, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 569, iters: 976, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 569, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 569, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 569, iters: 1216, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 569, iters: 1296, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 569, iters: 1376, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 569, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 569, iters: 1536, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 569, iters: 1616, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 569, iters: 1696, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 569, iters: 1776, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 569, iters: 1856, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 569, iters: 1936, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 569, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 569, iters: 2096, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 569, iters: 2176, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 569, iters: 2256, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 569, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 569, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 569, iters: 2496, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 569, iters: 2576, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 569, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 569, iters: 2736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 569, iters: 2816, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 569, iters: 2896, time: 0.092, data: 0.024) loss: 0.000 
(epoch: 569, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 569, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 569, iters: 3136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 569, iters: 3216, time: 0.092, data: 0.026) loss: 0.004 
(epoch: 569, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 569, iters: 3376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 569, iters: 3456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 569, iters: 3536, time: 0.092, data: 0.024) loss: 0.003 
(epoch: 569, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 569, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 569, iters 2121232
End of epoch 569 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001530
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 569, TEST ACC: [88.923 %]

saving the latest model (epoch 570, total_steps 2121248)
(epoch: 570, iters: 48, time: 0.094, data: 0.004) loss: 0.000 
(epoch: 570, iters: 128, time: 0.094, data: 0.025) loss: 0.014 
(epoch: 570, iters: 208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 570, iters: 288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 570, iters: 368, time: 0.094, data: 0.040) loss: 0.004 
(epoch: 570, iters: 448, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 570, iters: 528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 570, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 570, iters: 688, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 570, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 570, iters: 848, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 570, iters: 928, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 570, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 570, iters: 1088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 570, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 570, iters: 1248, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 570, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 570, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 570, iters: 1488, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 570, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 570, iters: 1648, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 570, iters: 1728, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 570, iters: 1808, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 570, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 570, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 570, iters: 2048, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 570, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 570, iters: 2208, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 570, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 570, iters: 2368, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 570, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 570, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 570, iters: 2608, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 570, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 570, iters: 2768, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 570, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 570, iters: 2928, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 570, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 570, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 570, iters: 3168, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 570, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 570, iters: 3328, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 570, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 570, iters: 3488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 570, iters: 3568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 570, iters: 3648, time: 0.086, data: 0.026) loss: 0.001 
(epoch: 570, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 570, iters 2124960
End of epoch 570 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001529
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 570, TEST ACC: [96.358 %]

saving the latest model (epoch 571, total_steps 2124976)
(epoch: 571, iters: 80, time: 0.093, data: 0.431) loss: 0.001 
(epoch: 571, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 571, iters: 240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 571, iters: 320, time: 0.093, data: 0.051) loss: 0.000 
(epoch: 571, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 571, iters: 480, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 571, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 571, iters: 640, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 571, iters: 720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 571, iters: 800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 571, iters: 880, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 571, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 571, iters: 1040, time: 0.093, data: 0.011) loss: 0.015 
(epoch: 571, iters: 1120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 571, iters: 1200, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 571, iters: 1280, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 571, iters: 1360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 571, iters: 1440, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 571, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 571, iters: 1600, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 571, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 571, iters: 1760, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 571, iters: 1840, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 571, iters: 1920, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 571, iters: 2000, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 571, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 571, iters: 2160, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 571, iters: 2240, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 571, iters: 2320, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 571, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 571, iters: 2480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 571, iters: 2560, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 571, iters: 2640, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 571, iters: 2720, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 571, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 571, iters: 2880, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 571, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 571, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 571, iters: 3120, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 571, iters: 3200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 571, iters: 3280, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 571, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 571, iters: 3440, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 571, iters: 3520, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 571, iters: 3600, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 571, iters: 3680, time: 0.088, data: 0.042) loss: 0.165 
saving the model at the end of epoch 571, iters 2128688
End of epoch 571 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001528
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 571, TEST ACC: [97.117 %]

saving the latest model (epoch 572, total_steps 2128704)
(epoch: 572, iters: 32, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 572, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 572, iters: 192, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 572, iters: 272, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 572, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 572, iters: 432, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 572, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 572, iters: 592, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 572, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 572, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 572, iters: 832, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 572, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 572, iters: 992, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 572, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 572, iters: 1152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 572, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 572, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 572, iters: 1392, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 572, iters: 1472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 572, iters: 1552, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 572, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 572, iters: 1712, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 572, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 572, iters: 1872, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 572, iters: 1952, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 572, iters: 2032, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 572, iters: 2112, time: 0.092, data: 0.011) loss: 0.005 
(epoch: 572, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 572, iters: 2272, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 572, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 572, iters: 2432, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 572, iters: 2512, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 572, iters: 2592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 572, iters: 2672, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 572, iters: 2752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 572, iters: 2832, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 572, iters: 2912, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 572, iters: 2992, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 572, iters: 3072, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 572, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 572, iters: 3232, time: 0.091, data: 0.011) loss: 0.003 
(epoch: 572, iters: 3312, time: 0.094, data: 0.000) loss: 0.102 
(epoch: 572, iters: 3392, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 572, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 572, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 572, iters: 3632, time: 0.092, data: 0.038) loss: 0.000 
(epoch: 572, iters: 3712, time: 0.087, data: 0.000) loss: 0.001 
saving the model at the end of epoch 572, iters 2132416
End of epoch 572 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001527
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 572, TEST ACC: [93.171 %]

saving the latest model (epoch 573, total_steps 2132432)
(epoch: 573, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 573, iters: 144, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 573, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 573, iters: 304, time: 0.092, data: 0.019) loss: 0.000 
(epoch: 573, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 573, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 573, iters: 544, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 573, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 573, iters: 704, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 573, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 573, iters: 864, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 573, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 573, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 573, iters: 1104, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 573, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 573, iters: 1264, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 573, iters: 1344, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 573, iters: 1424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 573, iters: 1504, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 573, iters: 1584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 573, iters: 1664, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 573, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 573, iters: 1824, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 573, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 573, iters: 1984, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 573, iters: 2064, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 573, iters: 2144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 573, iters: 2224, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 573, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 573, iters: 2384, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 573, iters: 2464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 573, iters: 2544, time: 0.093, data: 0.020) loss: 0.001 
(epoch: 573, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 573, iters: 2704, time: 0.093, data: 0.000) loss: 0.017 
(epoch: 573, iters: 2784, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 573, iters: 2864, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 573, iters: 2944, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 573, iters: 3024, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 573, iters: 3104, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 573, iters: 3184, time: 0.093, data: 0.000) loss: 0.019 
(epoch: 573, iters: 3264, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 573, iters: 3344, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 573, iters: 3424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 573, iters: 3504, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 573, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 573, iters: 3664, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 573, iters 2136144
End of epoch 573 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001526
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 573, TEST ACC: [94.234 %]

(epoch: 574, iters: 16, time: 0.110, data: 0.000) loss: 0.000 
saving the latest model (epoch 574, total_steps 2136160)
(epoch: 574, iters: 96, time: 0.095, data: 0.043) loss: 0.000 
(epoch: 574, iters: 176, time: 0.094, data: 0.000) loss: 0.048 
(epoch: 574, iters: 256, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 574, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 574, iters: 416, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 574, iters: 496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 574, iters: 576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 574, iters: 656, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 574, iters: 736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 574, iters: 816, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 574, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 574, iters: 976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 574, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 574, iters: 1136, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 574, iters: 1216, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 574, iters: 1296, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 574, iters: 1376, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 574, iters: 1456, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 574, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 574, iters: 1616, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 574, iters: 1696, time: 0.094, data: 0.000) loss: 0.041 
(epoch: 574, iters: 1776, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 574, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 574, iters: 1936, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 574, iters: 2016, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 574, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 574, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 574, iters: 2256, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 574, iters: 2336, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 574, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 574, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 574, iters: 2576, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 574, iters: 2656, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 574, iters: 2736, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 574, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 574, iters: 2896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 574, iters: 2976, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 574, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 574, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 574, iters: 3216, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 574, iters: 3296, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 574, iters: 3376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 574, iters: 3456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 574, iters: 3536, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 574, iters: 3616, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 574, iters: 3696, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 574, iters 2139872
End of epoch 574 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001525
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 574, TEST ACC: [94.841 %]

saving the latest model (epoch 575, total_steps 2139888)
(epoch: 575, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 575, iters: 128, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 575, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 575, iters: 288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 575, iters: 368, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 575, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 575, iters: 528, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 575, iters: 608, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 575, iters: 688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 575, iters: 768, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 575, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 575, iters: 928, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 575, iters: 1008, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 575, iters: 1088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 575, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 575, iters: 1248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 575, iters: 1328, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 575, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 575, iters: 1488, time: 0.096, data: 0.039) loss: 0.010 
(epoch: 575, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 575, iters: 1648, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 575, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 575, iters: 1808, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 575, iters: 1888, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 575, iters: 1968, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 575, iters: 2048, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 575, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 575, iters: 2208, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 575, iters: 2288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 575, iters: 2368, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 575, iters: 2448, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 575, iters: 2528, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 575, iters: 2608, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 575, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 575, iters: 2768, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 575, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 575, iters: 2928, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 575, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 575, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 575, iters: 3168, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 575, iters: 3248, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 575, iters: 3328, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 575, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 575, iters: 3488, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 575, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 575, iters: 3648, time: 0.087, data: 0.000) loss: 0.002 
(epoch: 575, iters: 3728, time: 0.056, data: 0.023) loss: 0.000 
saving the model at the end of epoch 575, iters 2143600
End of epoch 575 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001524
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 575, TEST ACC: [95.599 %]

saving the latest model (epoch 576, total_steps 2143616)
(epoch: 576, iters: 80, time: 0.096, data: 0.488) loss: 0.000 
(epoch: 576, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 576, iters: 240, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 576, iters: 320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 576, iters: 400, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 576, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 576, iters: 560, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 576, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 576, iters: 720, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 576, iters: 800, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 576, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 576, iters: 960, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 576, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 576, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 576, iters: 1200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 576, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 576, iters: 1360, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 576, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 576, iters: 1520, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 576, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 576, iters: 1680, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 576, iters: 1760, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 576, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 576, iters: 1920, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 576, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 576, iters: 2080, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 576, iters: 2160, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 576, iters: 2240, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 576, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 576, iters: 2400, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 576, iters: 2480, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 576, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 576, iters: 2640, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 576, iters: 2720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 576, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 576, iters: 2880, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 576, iters: 2960, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 576, iters: 3040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 576, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 576, iters: 3200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 576, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 576, iters: 3360, time: 0.092, data: 0.000) loss: 0.007 
(epoch: 576, iters: 3440, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 576, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 576, iters: 3600, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 576, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 576, iters 2147328
End of epoch 576 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001523
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 576, TEST ACC: [94.992 %]

saving the latest model (epoch 577, total_steps 2147344)
(epoch: 577, iters: 32, time: 0.093, data: 0.004) loss: 0.000 
(epoch: 577, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 577, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 577, iters: 272, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 577, iters: 352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 577, iters: 432, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 577, iters: 512, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 577, iters: 592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 577, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 577, iters: 752, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 577, iters: 832, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 577, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 577, iters: 992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 577, iters: 1072, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 577, iters: 1152, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 577, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 577, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 577, iters: 1392, time: 0.094, data: 0.012) loss: 0.016 
(epoch: 577, iters: 1472, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 577, iters: 1552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 577, iters: 1632, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 577, iters: 1712, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 577, iters: 1792, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 577, iters: 1872, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 577, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 577, iters: 2032, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 577, iters: 2112, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 577, iters: 2192, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 577, iters: 2272, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 577, iters: 2352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 577, iters: 2432, time: 0.091, data: 0.025) loss: 0.000 
(epoch: 577, iters: 2512, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 577, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 577, iters: 2672, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 577, iters: 2752, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 577, iters: 2832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 577, iters: 2912, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 577, iters: 2992, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 577, iters: 3072, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 577, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 577, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 577, iters: 3312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 577, iters: 3392, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 577, iters: 3472, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 577, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 577, iters: 3632, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 577, iters: 3712, time: 0.087, data: 0.023) loss: 0.000 
saving the model at the end of epoch 577, iters 2151056
End of epoch 577 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001522
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 577, TEST ACC: [96.813 %]

saving the latest model (epoch 578, total_steps 2151072)
(epoch: 578, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 578, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 578, iters: 224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 578, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 578, iters: 384, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 578, iters: 464, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 578, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 578, iters: 624, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 578, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 578, iters: 784, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 578, iters: 864, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 578, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 578, iters: 1024, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 578, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 578, iters: 1184, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 578, iters: 1264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 578, iters: 1344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 578, iters: 1424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 578, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 578, iters: 1584, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 578, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 578, iters: 1744, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 578, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 578, iters: 1904, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 578, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 578, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 578, iters: 2144, time: 0.093, data: 0.047) loss: 0.000 
(epoch: 578, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 578, iters: 2304, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 578, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 578, iters: 2464, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 578, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 578, iters: 2624, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 578, iters: 2704, time: 0.093, data: 0.038) loss: 0.001 
(epoch: 578, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 578, iters: 2864, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 578, iters: 2944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 578, iters: 3024, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 578, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 578, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 578, iters: 3264, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 578, iters: 3344, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 578, iters: 3424, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 578, iters: 3504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 578, iters: 3584, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 578, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 578, iters 2154784
End of epoch 578 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001521
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 578, TEST ACC: [95.599 %]

(epoch: 579, iters: 16, time: 0.112, data: 0.000) loss: 0.000 
saving the latest model (epoch 579, total_steps 2154800)
(epoch: 579, iters: 96, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 579, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 579, iters: 256, time: 0.093, data: 0.011) loss: 0.075 
(epoch: 579, iters: 336, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 579, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 579, iters: 496, time: 0.096, data: 0.042) loss: 0.426 
(epoch: 579, iters: 576, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 579, iters: 656, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 579, iters: 736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 579, iters: 816, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 579, iters: 896, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 579, iters: 976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 579, iters: 1056, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 579, iters: 1136, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 579, iters: 1216, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 579, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 579, iters: 1376, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 579, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 579, iters: 1536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 579, iters: 1616, time: 0.096, data: 0.041) loss: 0.006 
(epoch: 579, iters: 1696, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 579, iters: 1776, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 579, iters: 1856, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 579, iters: 1936, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 579, iters: 2016, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 579, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 579, iters: 2176, time: 0.095, data: 0.039) loss: 0.283 
(epoch: 579, iters: 2256, time: 0.094, data: 0.000) loss: 0.064 
(epoch: 579, iters: 2336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 579, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 579, iters: 2496, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 579, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 579, iters: 2656, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 579, iters: 2736, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 579, iters: 2816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 579, iters: 2896, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 579, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 579, iters: 3056, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 579, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 579, iters: 3216, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 579, iters: 3296, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 579, iters: 3376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 579, iters: 3456, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 579, iters: 3536, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 579, iters: 3616, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 579, iters: 3696, time: 0.087, data: 0.000) loss: 0.001 
saving the model at the end of epoch 579, iters 2158512
End of epoch 579 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001520
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 579, TEST ACC: [96.206 %]

saving the latest model (epoch 580, total_steps 2158528)
(epoch: 580, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 580, iters: 128, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 580, iters: 208, time: 0.096, data: 0.000) loss: 0.074 
(epoch: 580, iters: 288, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 580, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 580, iters: 448, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 580, iters: 528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 580, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 580, iters: 688, time: 0.096, data: 0.041) loss: 0.025 
(epoch: 580, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 580, iters: 848, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 580, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 580, iters: 1008, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 580, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 580, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 580, iters: 1248, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 580, iters: 1328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 580, iters: 1408, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 580, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 580, iters: 1568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 580, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 580, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 580, iters: 1808, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 580, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 580, iters: 1968, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 580, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 580, iters: 2128, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 580, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 580, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 580, iters: 2368, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 580, iters: 2448, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 580, iters: 2528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 580, iters: 2608, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 580, iters: 2688, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 580, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 580, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 580, iters: 2928, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 580, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 580, iters: 3088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 580, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 580, iters: 3248, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 580, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 580, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 580, iters: 3488, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 580, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 580, iters: 3648, time: 0.088, data: 0.020) loss: 0.000 
(epoch: 580, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 580, iters 2162240
End of epoch 580 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001519
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 580, TEST ACC: [94.234 %]

saving the latest model (epoch 581, total_steps 2162256)
(epoch: 581, iters: 80, time: 0.096, data: 0.487) loss: 0.000 
(epoch: 581, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 581, iters: 240, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 581, iters: 320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 581, iters: 400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 581, iters: 480, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 581, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 581, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 581, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 581, iters: 800, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 581, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 581, iters: 960, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 581, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 581, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 581, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 581, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 581, iters: 1360, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 581, iters: 1440, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 581, iters: 1520, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 581, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 581, iters: 1680, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 581, iters: 1760, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 581, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 581, iters: 1920, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 581, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 581, iters: 2080, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 581, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 581, iters: 2240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 581, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 581, iters: 2400, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 581, iters: 2480, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 581, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 581, iters: 2640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 581, iters: 2720, time: 0.092, data: 0.024) loss: 0.000 
(epoch: 581, iters: 2800, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 581, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 581, iters: 2960, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 581, iters: 3040, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 581, iters: 3120, time: 0.097, data: 0.000) loss: 0.013 
(epoch: 581, iters: 3200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 581, iters: 3280, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 581, iters: 3360, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 581, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 581, iters: 3520, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 581, iters: 3600, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 581, iters: 3680, time: 0.087, data: 0.026) loss: 0.000 
saving the model at the end of epoch 581, iters 2165968
End of epoch 581 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001518
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 581, TEST ACC: [96.965 %]

saving the latest model (epoch 582, total_steps 2165984)
(epoch: 582, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 582, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 582, iters: 192, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 582, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 582, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 582, iters: 432, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 582, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 582, iters: 592, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 582, iters: 672, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 582, iters: 752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 582, iters: 832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 582, iters: 912, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 582, iters: 992, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 582, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 582, iters: 1152, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 582, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 582, iters: 1312, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 582, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 582, iters: 1472, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 582, iters: 1552, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 582, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 582, iters: 1712, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 582, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 582, iters: 1872, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 582, iters: 1952, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 582, iters: 2032, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 582, iters: 2112, time: 0.096, data: 0.040) loss: 0.085 
(epoch: 582, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 582, iters: 2272, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 582, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 582, iters: 2432, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 582, iters: 2512, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 582, iters: 2592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 582, iters: 2672, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 582, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 582, iters: 2832, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 582, iters: 2912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 582, iters: 2992, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 582, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 582, iters: 3152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 582, iters: 3232, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 582, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 582, iters: 3392, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 582, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 582, iters: 3552, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 582, iters: 3632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 582, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 582, iters 2169696
End of epoch 582 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001517
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 582, TEST ACC: [95.751 %]

saving the latest model (epoch 583, total_steps 2169712)
(epoch: 583, iters: 64, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 583, iters: 144, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 583, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 583, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 583, iters: 384, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 583, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 583, iters: 544, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 583, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 583, iters: 704, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 583, iters: 784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 583, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 583, iters: 944, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 583, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 583, iters: 1104, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 583, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 583, iters: 1264, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 583, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 583, iters: 1424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 583, iters: 1504, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 583, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 583, iters: 1664, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 583, iters: 1744, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 583, iters: 1824, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 583, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 583, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 583, iters: 2064, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 583, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 583, iters: 2224, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 583, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 583, iters: 2384, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 583, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 583, iters: 2544, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 583, iters: 2624, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 583, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 583, iters: 2784, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 583, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 583, iters: 2944, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 583, iters: 3024, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 583, iters: 3104, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 583, iters: 3184, time: 0.093, data: 0.038) loss: 0.005 
(epoch: 583, iters: 3264, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 583, iters: 3344, time: 0.093, data: 0.022) loss: 0.000 
(epoch: 583, iters: 3424, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 583, iters: 3504, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 583, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 583, iters: 3664, time: 0.088, data: 0.000) loss: 0.041 
saving the model at the end of epoch 583, iters 2173424
End of epoch 583 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001516
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 583, TEST ACC: [93.475 %]

(epoch: 584, iters: 16, time: 0.111, data: 0.012) loss: 0.000 
saving the latest model (epoch 584, total_steps 2173440)
(epoch: 584, iters: 96, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 584, iters: 176, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 584, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 584, iters: 336, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 584, iters: 416, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 584, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 584, iters: 576, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 584, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 584, iters: 736, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 584, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 584, iters: 896, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 584, iters: 976, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 584, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 584, iters: 1136, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 584, iters: 1216, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 584, iters: 1296, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 584, iters: 1376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 584, iters: 1456, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 584, iters: 1536, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 584, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 584, iters: 1696, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 584, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 584, iters: 1856, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 584, iters: 1936, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 584, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 584, iters: 2096, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 584, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 584, iters: 2256, time: 0.097, data: 0.051) loss: 0.000 
(epoch: 584, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 584, iters: 2416, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 584, iters: 2496, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 584, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 584, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 584, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 584, iters: 2816, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 584, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 584, iters: 2976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 584, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 584, iters: 3136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 584, iters: 3216, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 584, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 584, iters: 3376, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 584, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 584, iters: 3536, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 584, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 584, iters: 3696, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 584, iters 2177152
End of epoch 584 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001515
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 584, TEST ACC: [96.055 %]

saving the latest model (epoch 585, total_steps 2177168)
(epoch: 585, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 585, iters: 128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 585, iters: 208, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 585, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 585, iters: 368, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 585, iters: 448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 585, iters: 528, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 585, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 585, iters: 688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 585, iters: 768, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 585, iters: 848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 585, iters: 928, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 585, iters: 1008, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 585, iters: 1088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 585, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 585, iters: 1248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 585, iters: 1328, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 585, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 585, iters: 1488, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 585, iters: 1568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 585, iters: 1648, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 585, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 585, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 585, iters: 1888, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 585, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 585, iters: 2048, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 585, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 585, iters: 2208, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 585, iters: 2288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 585, iters: 2368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 585, iters: 2448, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 585, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 585, iters: 2608, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 585, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 585, iters: 2768, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 585, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 585, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 585, iters: 3008, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 585, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 585, iters: 3168, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 585, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 585, iters: 3328, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 585, iters: 3408, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 585, iters: 3488, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 585, iters: 3568, time: 0.094, data: 0.048) loss: 0.001 
(epoch: 585, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 585, iters: 3728, time: 0.056, data: 0.012) loss: 0.000 
saving the model at the end of epoch 585, iters 2180880
End of epoch 585 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001514
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 585, TEST ACC: [96.662 %]

saving the latest model (epoch 586, total_steps 2180896)
(epoch: 586, iters: 80, time: 0.094, data: 0.524) loss: 0.000 
(epoch: 586, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 586, iters: 240, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 586, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 586, iters: 400, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 586, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 586, iters: 560, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 586, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 586, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 586, iters: 800, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 586, iters: 880, time: 0.097, data: 0.000) loss: 0.092 
(epoch: 586, iters: 960, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 586, iters: 1040, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 586, iters: 1120, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 586, iters: 1200, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 586, iters: 1280, time: 0.093, data: 0.012) loss: 0.255 
(epoch: 586, iters: 1360, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 586, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 586, iters: 1520, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 586, iters: 1600, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 586, iters: 1680, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 586, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 586, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 586, iters: 1920, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 586, iters: 2000, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 586, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 586, iters: 2160, time: 0.096, data: 0.000) loss: 0.015 
(epoch: 586, iters: 2240, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 586, iters: 2320, time: 0.094, data: 0.025) loss: 0.001 
(epoch: 586, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 586, iters: 2480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 586, iters: 2560, time: 0.093, data: 0.000) loss: 0.021 
(epoch: 586, iters: 2640, time: 0.093, data: 0.040) loss: 0.014 
(epoch: 586, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 586, iters: 2800, time: 0.092, data: 0.012) loss: 0.047 
(epoch: 586, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 586, iters: 2960, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 586, iters: 3040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 586, iters: 3120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 586, iters: 3200, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 586, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 586, iters: 3360, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 586, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 586, iters: 3520, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 586, iters: 3600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 586, iters: 3680, time: 0.087, data: 0.000) loss: 0.002 
saving the model at the end of epoch 586, iters 2184608
End of epoch 586 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001513
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 586, TEST ACC: [87.709 %]

saving the latest model (epoch 587, total_steps 2184624)
(epoch: 587, iters: 32, time: 0.093, data: 0.007) loss: 0.000 
(epoch: 587, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 587, iters: 192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 587, iters: 272, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 587, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 587, iters: 432, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 587, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 587, iters: 592, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 587, iters: 672, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 587, iters: 752, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 587, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 587, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 587, iters: 992, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 587, iters: 1072, time: 0.096, data: 0.000) loss: 0.046 
(epoch: 587, iters: 1152, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 587, iters: 1232, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 587, iters: 1312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 587, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 587, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 587, iters: 1552, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 587, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 587, iters: 1712, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 587, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 587, iters: 1872, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 587, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 587, iters: 2032, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 587, iters: 2112, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 587, iters: 2192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 587, iters: 2272, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 587, iters: 2352, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 587, iters: 2432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 587, iters: 2512, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 587, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 587, iters: 2672, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 587, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 587, iters: 2832, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 587, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 587, iters: 2992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 587, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 587, iters: 3152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 587, iters: 3232, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 587, iters: 3312, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 587, iters: 3392, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 587, iters: 3472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 587, iters: 3552, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 587, iters: 3632, time: 0.094, data: 0.000) loss: 0.303 
(epoch: 587, iters: 3712, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 587, iters 2188336
End of epoch 587 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001512
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 587, TEST ACC: [96.51 %]

saving the latest model (epoch 588, total_steps 2188352)
(epoch: 588, iters: 64, time: 0.093, data: 0.003) loss: 0.000 
(epoch: 588, iters: 144, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 588, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 588, iters: 304, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 588, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 588, iters: 464, time: 0.093, data: 0.012) loss: 0.217 
(epoch: 588, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 588, iters: 624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 588, iters: 704, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 588, iters: 784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 588, iters: 864, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 588, iters: 944, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 588, iters: 1024, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 588, iters: 1104, time: 0.095, data: 0.000) loss: 0.035 
(epoch: 588, iters: 1184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 588, iters: 1264, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 588, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 588, iters: 1424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 588, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 588, iters: 1584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 588, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 588, iters: 1744, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 588, iters: 1824, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 588, iters: 1904, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 588, iters: 1984, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 588, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 588, iters: 2144, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 588, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 588, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 588, iters: 2384, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 588, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 588, iters: 2544, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 588, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 588, iters: 2704, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 588, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 588, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 588, iters: 2944, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 588, iters: 3024, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 588, iters: 3104, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 588, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 588, iters: 3264, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 588, iters: 3344, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 588, iters: 3424, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 588, iters: 3504, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 588, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 588, iters: 3664, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 588, iters 2192064
End of epoch 588 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001511
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 588, TEST ACC: [96.662 %]

(epoch: 589, iters: 16, time: 0.114, data: 0.013) loss: 0.139 
saving the latest model (epoch 589, total_steps 2192080)
(epoch: 589, iters: 96, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 589, iters: 176, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 589, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 589, iters: 336, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 589, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 589, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 589, iters: 576, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 589, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 589, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 589, iters: 816, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 589, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 589, iters: 976, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 589, iters: 1056, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 589, iters: 1136, time: 0.092, data: 0.025) loss: 0.003 
(epoch: 589, iters: 1216, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 589, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 589, iters: 1376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 589, iters: 1456, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 589, iters: 1536, time: 0.096, data: 0.000) loss: 0.020 
(epoch: 589, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 589, iters: 1696, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 589, iters: 1776, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 589, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 589, iters: 1936, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 589, iters: 2016, time: 0.093, data: 0.012) loss: 0.026 
(epoch: 589, iters: 2096, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 589, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 589, iters: 2256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 589, iters: 2336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 589, iters: 2416, time: 0.092, data: 0.027) loss: 0.005 
(epoch: 589, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 589, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 589, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 589, iters: 2736, time: 0.093, data: 0.024) loss: 0.001 
(epoch: 589, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 589, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 589, iters: 2976, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 589, iters: 3056, time: 0.092, data: 0.025) loss: 0.004 
(epoch: 589, iters: 3136, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 589, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 589, iters: 3296, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 589, iters: 3376, time: 0.092, data: 0.036) loss: 0.000 
(epoch: 589, iters: 3456, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 589, iters: 3536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 589, iters: 3616, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 589, iters: 3696, time: 0.087, data: 0.033) loss: 0.000 
saving the model at the end of epoch 589, iters 2195792
End of epoch 589 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001510
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 589, TEST ACC: [96.358 %]

saving the latest model (epoch 590, total_steps 2195808)
(epoch: 590, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 590, iters: 128, time: 0.095, data: 0.056) loss: 0.000 
(epoch: 590, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 590, iters: 288, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 590, iters: 368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 590, iters: 448, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 590, iters: 528, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 590, iters: 608, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 590, iters: 688, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 590, iters: 768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 590, iters: 848, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 590, iters: 928, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 590, iters: 1008, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 590, iters: 1088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 590, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 590, iters: 1248, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 590, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 590, iters: 1408, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 590, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 590, iters: 1568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 590, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 590, iters: 1728, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 590, iters: 1808, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 590, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 590, iters: 1968, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 590, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 590, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 590, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 590, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 590, iters: 2368, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 590, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 590, iters: 2528, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 590, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 590, iters: 2688, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 590, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 590, iters: 2848, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 590, iters: 2928, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 590, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 590, iters: 3088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 590, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 590, iters: 3248, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 590, iters: 3328, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 590, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 590, iters: 3488, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 590, iters: 3568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 590, iters: 3648, time: 0.088, data: 0.011) loss: 0.000 
(epoch: 590, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 590, iters 2199520
End of epoch 590 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001509
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 590, TEST ACC: [97.269 %]

saving the latest model (epoch 591, total_steps 2199536)
(epoch: 591, iters: 80, time: 0.091, data: 0.527) loss: 0.000 
(epoch: 591, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 591, iters: 240, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 591, iters: 320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 591, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 591, iters: 480, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 591, iters: 560, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 591, iters: 640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 591, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 591, iters: 800, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 591, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 591, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 591, iters: 1040, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 591, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 591, iters: 1200, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 591, iters: 1280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 591, iters: 1360, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 591, iters: 1440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 591, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 591, iters: 1600, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 591, iters: 1680, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 591, iters: 1760, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 591, iters: 1840, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 591, iters: 1920, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 591, iters: 2000, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 591, iters: 2080, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 591, iters: 2160, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 591, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 591, iters: 2320, time: 0.093, data: 0.011) loss: 0.011 
(epoch: 591, iters: 2400, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 591, iters: 2480, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 591, iters: 2560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 591, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 591, iters: 2720, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 591, iters: 2800, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 591, iters: 2880, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 591, iters: 2960, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 591, iters: 3040, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 591, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 591, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 591, iters: 3280, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 591, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 591, iters: 3440, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 591, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 591, iters: 3600, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 591, iters: 3680, time: 0.086, data: 0.000) loss: 0.000 
saving the model at the end of epoch 591, iters 2203248
End of epoch 591 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001508
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 591, TEST ACC: [96.51 %]

saving the latest model (epoch 592, total_steps 2203264)
(epoch: 592, iters: 32, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 592, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 592, iters: 192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 592, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 592, iters: 352, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 592, iters: 432, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 592, iters: 512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 592, iters: 592, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 592, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 592, iters: 752, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 592, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 592, iters: 912, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 592, iters: 992, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 592, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 592, iters: 1152, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 592, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 592, iters: 1312, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 592, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 592, iters: 1472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 592, iters: 1552, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 592, iters: 1632, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 592, iters: 1712, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 592, iters: 1792, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 592, iters: 1872, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 592, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 592, iters: 2032, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 592, iters: 2112, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 592, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 592, iters: 2272, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 592, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 592, iters: 2432, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 592, iters: 2512, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 592, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 592, iters: 2672, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 592, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 592, iters: 2832, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 592, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 592, iters: 2992, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 592, iters: 3072, time: 0.096, data: 0.000) loss: 0.015 
(epoch: 592, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 592, iters: 3232, time: 0.096, data: 0.039) loss: 0.001 
(epoch: 592, iters: 3312, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 592, iters: 3392, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 592, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 592, iters: 3552, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 592, iters: 3632, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 592, iters: 3712, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 592, iters 2206976
End of epoch 592 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001507
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 592, TEST ACC: [75.114 %]

saving the latest model (epoch 593, total_steps 2206992)
(epoch: 593, iters: 64, time: 0.094, data: 0.003) loss: 0.000 
(epoch: 593, iters: 144, time: 0.095, data: 0.022) loss: 0.000 
(epoch: 593, iters: 224, time: 0.091, data: 0.027) loss: 0.000 
(epoch: 593, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 593, iters: 384, time: 0.094, data: 0.000) loss: 0.017 
(epoch: 593, iters: 464, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 593, iters: 544, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 593, iters: 624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 593, iters: 704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 593, iters: 784, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 593, iters: 864, time: 0.092, data: 0.025) loss: 0.001 
(epoch: 593, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 593, iters: 1024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 593, iters: 1104, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 593, iters: 1184, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 593, iters: 1264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 593, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 593, iters: 1424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 593, iters: 1504, time: 0.092, data: 0.024) loss: 0.000 
(epoch: 593, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 593, iters: 1664, time: 0.096, data: 0.000) loss: 0.024 
(epoch: 593, iters: 1744, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 593, iters: 1824, time: 0.092, data: 0.025) loss: 0.025 
(epoch: 593, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 593, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 593, iters: 2064, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 593, iters: 2144, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 593, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 593, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 593, iters: 2384, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 593, iters: 2464, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 593, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 593, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 593, iters: 2704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 593, iters: 2784, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 593, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 593, iters: 2944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 593, iters: 3024, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 593, iters: 3104, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 593, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 593, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 593, iters: 3344, time: 0.092, data: 0.013) loss: 0.010 
(epoch: 593, iters: 3424, time: 0.094, data: 0.034) loss: 0.000 
(epoch: 593, iters: 3504, time: 0.094, data: 0.000) loss: 0.042 
(epoch: 593, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 593, iters: 3664, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 593, iters 2210704
End of epoch 593 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001506
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 593, TEST ACC: [97.269 %]

(epoch: 594, iters: 16, time: 0.111, data: 0.012) loss: 0.000 
saving the latest model (epoch 594, total_steps 2210720)
(epoch: 594, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 594, iters: 176, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 594, iters: 256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 594, iters: 336, time: 0.095, data: 0.013) loss: 0.134 
(epoch: 594, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 594, iters: 496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 594, iters: 576, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 594, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 594, iters: 736, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 594, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 594, iters: 896, time: 0.093, data: 0.013) loss: 0.376 
(epoch: 594, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 594, iters: 1056, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 594, iters: 1136, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 594, iters: 1216, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 594, iters: 1296, time: 0.096, data: 0.012) loss: 0.298 
(epoch: 594, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 594, iters: 1456, time: 0.094, data: 0.012) loss: 0.091 
(epoch: 594, iters: 1536, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 594, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 594, iters: 1696, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 594, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 594, iters: 1856, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 594, iters: 1936, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 594, iters: 2016, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 594, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 594, iters: 2176, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 594, iters: 2256, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 594, iters: 2336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 594, iters: 2416, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 594, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 594, iters: 2576, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 594, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 594, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 594, iters: 2816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 594, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 594, iters: 2976, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 594, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 594, iters: 3136, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 594, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 594, iters: 3296, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 594, iters: 3376, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 594, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 594, iters: 3536, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 594, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 594, iters: 3696, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 594, iters 2214432
End of epoch 594 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001505
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 594, TEST ACC: [97.724 %]

saving the latest model (epoch 595, total_steps 2214448)
(epoch: 595, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 595, iters: 128, time: 0.094, data: 0.027) loss: 0.002 
(epoch: 595, iters: 208, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 595, iters: 288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 595, iters: 368, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 595, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 595, iters: 528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 595, iters: 608, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 595, iters: 688, time: 0.094, data: 0.000) loss: 0.174 
(epoch: 595, iters: 768, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 595, iters: 848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 595, iters: 928, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 595, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 595, iters: 1088, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 595, iters: 1168, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 595, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 595, iters: 1328, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 595, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 595, iters: 1488, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 595, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 595, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 595, iters: 1728, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 595, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 595, iters: 1888, time: 0.092, data: 0.013) loss: 0.005 
(epoch: 595, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 595, iters: 2048, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 595, iters: 2128, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 595, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 595, iters: 2288, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 595, iters: 2368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 595, iters: 2448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 595, iters: 2528, time: 0.094, data: 0.047) loss: 0.000 
(epoch: 595, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 595, iters: 2688, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 595, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 595, iters: 2848, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 595, iters: 2928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 595, iters: 3008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 595, iters: 3088, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 595, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 595, iters: 3248, time: 0.093, data: 0.011) loss: 0.043 
(epoch: 595, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 595, iters: 3408, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 595, iters: 3488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 595, iters: 3568, time: 0.094, data: 0.000) loss: 0.386 
(epoch: 595, iters: 3648, time: 0.090, data: 0.050) loss: 0.000 
(epoch: 595, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 595, iters 2218160
End of epoch 595 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001504
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 595, TEST ACC: [96.662 %]

saving the latest model (epoch 596, total_steps 2218176)
(epoch: 596, iters: 80, time: 0.095, data: 0.518) loss: 0.000 
(epoch: 596, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 596, iters: 240, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 596, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 596, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 596, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 596, iters: 560, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 596, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 596, iters: 720, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 596, iters: 800, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 596, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 596, iters: 960, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 596, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 596, iters: 1120, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 596, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 596, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 596, iters: 1360, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 596, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 596, iters: 1520, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 596, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 596, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 596, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 596, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 596, iters: 1920, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 596, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 596, iters: 2080, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 596, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 596, iters: 2240, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 596, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 596, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 596, iters: 2480, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 596, iters: 2560, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 596, iters: 2640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 596, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 596, iters: 2800, time: 0.093, data: 0.012) loss: 0.011 
(epoch: 596, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 596, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 596, iters: 3040, time: 0.097, data: 0.050) loss: 0.000 
(epoch: 596, iters: 3120, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 596, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 596, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 596, iters: 3360, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 596, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 596, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 596, iters: 3600, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 596, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 596, iters 2221888
End of epoch 596 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001503
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 596, TEST ACC: [95.751 %]

saving the latest model (epoch 597, total_steps 2221904)
(epoch: 597, iters: 32, time: 0.092, data: 0.005) loss: 0.000 
(epoch: 597, iters: 112, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 597, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 597, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 597, iters: 352, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 597, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 597, iters: 512, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 597, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 597, iters: 672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 597, iters: 752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 597, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 597, iters: 912, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 597, iters: 992, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 597, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 597, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 597, iters: 1232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 597, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 597, iters: 1392, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 597, iters: 1472, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 597, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 597, iters: 1632, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 597, iters: 1712, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 597, iters: 1792, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 597, iters: 1872, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 597, iters: 1952, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 597, iters: 2032, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 597, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 597, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 597, iters: 2272, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 597, iters: 2352, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 597, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 597, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 597, iters: 2592, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 597, iters: 2672, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 597, iters: 2752, time: 0.096, data: 0.000) loss: 0.013 
(epoch: 597, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 597, iters: 2912, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 597, iters: 2992, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 597, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 597, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 597, iters: 3232, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 597, iters: 3312, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 597, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 597, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 597, iters: 3552, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 597, iters: 3632, time: 0.090, data: 0.034) loss: 0.000 
(epoch: 597, iters: 3712, time: 0.088, data: 0.000) loss: 0.004 
saving the model at the end of epoch 597, iters 2225616
End of epoch 597 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001502
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 597, TEST ACC: [93.323 %]

saving the latest model (epoch 598, total_steps 2225632)
(epoch: 598, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 598, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 598, iters: 224, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 598, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 598, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 598, iters: 464, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 598, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 598, iters: 624, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 598, iters: 704, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 598, iters: 784, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 598, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 598, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 598, iters: 1024, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 598, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 598, iters: 1184, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 598, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 598, iters: 1344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 598, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 598, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 598, iters: 1584, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 598, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 598, iters: 1744, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 598, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 598, iters: 1904, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 598, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 598, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 598, iters: 2144, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 598, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 598, iters: 2304, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 598, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 598, iters: 2464, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 598, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 598, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 598, iters: 2704, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 598, iters: 2784, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 598, iters: 2864, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 598, iters: 2944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 598, iters: 3024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 598, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 598, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 598, iters: 3264, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 598, iters: 3344, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 598, iters: 3424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 598, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 598, iters: 3584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 598, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 598, iters 2229344
End of epoch 598 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001501
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 598, TEST ACC: [96.358 %]

(epoch: 599, iters: 16, time: 0.109, data: 0.000) loss: 0.000 
saving the latest model (epoch 599, total_steps 2229360)
(epoch: 599, iters: 96, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 599, iters: 176, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 599, iters: 256, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 599, iters: 336, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 599, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 599, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 599, iters: 576, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 599, iters: 656, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 599, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 599, iters: 816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 599, iters: 896, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 599, iters: 976, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 599, iters: 1056, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 599, iters: 1136, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 599, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 599, iters: 1296, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 599, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 599, iters: 1456, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 599, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 599, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 599, iters: 1696, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 599, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 599, iters: 1856, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 599, iters: 1936, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 599, iters: 2016, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 599, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 599, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 599, iters: 2256, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 599, iters: 2336, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 599, iters: 2416, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 599, iters: 2496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 599, iters: 2576, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 599, iters: 2656, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 599, iters: 2736, time: 0.093, data: 0.000) loss: 0.025 
(epoch: 599, iters: 2816, time: 0.092, data: 0.039) loss: 0.000 
(epoch: 599, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 599, iters: 2976, time: 0.092, data: 0.011) loss: 0.017 
(epoch: 599, iters: 3056, time: 0.094, data: 0.000) loss: 0.114 
(epoch: 599, iters: 3136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 599, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 599, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 599, iters: 3376, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 599, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 599, iters: 3536, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 599, iters: 3616, time: 0.096, data: 0.029) loss: 0.013 
(epoch: 599, iters: 3696, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 599, iters 2233072
End of epoch 599 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001500
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 599, TEST ACC: [95.144 %]

saving the latest model (epoch 600, total_steps 2233088)
(epoch: 600, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 600, iters: 128, time: 0.095, data: 0.042) loss: 0.007 
(epoch: 600, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 600, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 600, iters: 368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 600, iters: 448, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 600, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 600, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 600, iters: 688, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 600, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 600, iters: 848, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 600, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 600, iters: 1008, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 600, iters: 1088, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 600, iters: 1168, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 600, iters: 1248, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 600, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 600, iters: 1408, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 600, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 600, iters: 1568, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 600, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 600, iters: 1728, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 600, iters: 1808, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 600, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 600, iters: 1968, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 600, iters: 2048, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 600, iters: 2128, time: 0.092, data: 0.012) loss: 0.022 
(epoch: 600, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 600, iters: 2288, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 600, iters: 2368, time: 0.095, data: 0.047) loss: 0.000 
(epoch: 600, iters: 2448, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 600, iters: 2528, time: 0.093, data: 0.012) loss: 0.019 
(epoch: 600, iters: 2608, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 600, iters: 2688, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 600, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 600, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 600, iters: 2928, time: 0.093, data: 0.039) loss: 0.023 
(epoch: 600, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 600, iters: 3088, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 600, iters: 3168, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 600, iters: 3248, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 600, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 600, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 600, iters: 3488, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 600, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 600, iters: 3648, time: 0.085, data: 0.011) loss: 0.000 
(epoch: 600, iters: 3728, time: 0.055, data: 0.000) loss: 0.000 
saving the model at the end of epoch 600, iters 2236800
End of epoch 600 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001499
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 600, TEST ACC: [95.599 %]

saving the latest model (epoch 601, total_steps 2236816)
(epoch: 601, iters: 80, time: 0.095, data: 0.432) loss: 0.000 
(epoch: 601, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 601, iters: 240, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 601, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 601, iters: 400, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 601, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 601, iters: 560, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 601, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 601, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 601, iters: 800, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 601, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 601, iters: 960, time: 0.091, data: 0.012) loss: 0.021 
(epoch: 601, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 601, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 601, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 601, iters: 1280, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 601, iters: 1360, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 601, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 601, iters: 1520, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 601, iters: 1600, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 601, iters: 1680, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 601, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 601, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 601, iters: 1920, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 601, iters: 2000, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 601, iters: 2080, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 601, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 601, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 601, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 601, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 601, iters: 2480, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 601, iters: 2560, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 601, iters: 2640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 601, iters: 2720, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 601, iters: 2800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 601, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 601, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 601, iters: 3040, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 601, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 601, iters: 3200, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 601, iters: 3280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 601, iters: 3360, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 601, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 601, iters: 3520, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 601, iters: 3600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 601, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 601, iters 2240528
End of epoch 601 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001498
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 601, TEST ACC: [95.296 %]

saving the latest model (epoch 602, total_steps 2240544)
(epoch: 602, iters: 32, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 602, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 602, iters: 192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 602, iters: 272, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 602, iters: 352, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 602, iters: 432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 602, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 602, iters: 592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 602, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 602, iters: 752, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 602, iters: 832, time: 0.093, data: 0.040) loss: 0.012 
(epoch: 602, iters: 912, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 602, iters: 992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 602, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 602, iters: 1152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 602, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 602, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 602, iters: 1392, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 602, iters: 1472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 602, iters: 1552, time: 0.092, data: 0.012) loss: 0.978 
(epoch: 602, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 602, iters: 1712, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 602, iters: 1792, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 602, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 602, iters: 1952, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 602, iters: 2032, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 602, iters: 2112, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 602, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 602, iters: 2272, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 602, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 602, iters: 2432, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 602, iters: 2512, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 602, iters: 2592, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 602, iters: 2672, time: 0.091, data: 0.022) loss: 0.003 
(epoch: 602, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 602, iters: 2832, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 602, iters: 2912, time: 0.096, data: 0.000) loss: 0.079 
(epoch: 602, iters: 2992, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 602, iters: 3072, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 602, iters: 3152, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 602, iters: 3232, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 602, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 602, iters: 3392, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 602, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 602, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 602, iters: 3632, time: 0.091, data: 0.041) loss: 0.000 
(epoch: 602, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 602, iters 2244256
End of epoch 602 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001497
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 602, TEST ACC: [93.778 %]

saving the latest model (epoch 603, total_steps 2244272)
(epoch: 603, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 603, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 603, iters: 224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 603, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 603, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 603, iters: 464, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 603, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 603, iters: 624, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 603, iters: 704, time: 0.093, data: 0.000) loss: 0.176 
(epoch: 603, iters: 784, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 603, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 603, iters: 944, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 603, iters: 1024, time: 0.094, data: 0.040) loss: 0.013 
(epoch: 603, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 603, iters: 1184, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 603, iters: 1264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 603, iters: 1344, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 603, iters: 1424, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 603, iters: 1504, time: 0.092, data: 0.000) loss: 0.016 
(epoch: 603, iters: 1584, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 603, iters: 1664, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 603, iters: 1744, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 603, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 603, iters: 1904, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 603, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 603, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 603, iters: 2144, time: 0.093, data: 0.041) loss: 0.178 
(epoch: 603, iters: 2224, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 603, iters: 2304, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 603, iters: 2384, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 603, iters: 2464, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 603, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 603, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 603, iters: 2704, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 603, iters: 2784, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 603, iters: 2864, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 603, iters: 2944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 603, iters: 3024, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 603, iters: 3104, time: 0.095, data: 0.000) loss: 0.070 
(epoch: 603, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 603, iters: 3264, time: 0.093, data: 0.040) loss: 0.023 
(epoch: 603, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 603, iters: 3424, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 603, iters: 3504, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 603, iters: 3584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 603, iters: 3664, time: 0.088, data: 0.000) loss: 0.004 
saving the model at the end of epoch 603, iters 2247984
End of epoch 603 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001496
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 603, TEST ACC: [94.992 %]

(epoch: 604, iters: 16, time: 0.108, data: 0.000) loss: 0.000 
saving the latest model (epoch 604, total_steps 2248000)
(epoch: 604, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 604, iters: 176, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 604, iters: 256, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 604, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 604, iters: 416, time: 0.095, data: 0.000) loss: 0.098 
(epoch: 604, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 604, iters: 576, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 604, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 604, iters: 736, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 604, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 604, iters: 896, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 604, iters: 976, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 604, iters: 1056, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 604, iters: 1136, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 604, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 604, iters: 1296, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 604, iters: 1376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 604, iters: 1456, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 604, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 604, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 604, iters: 1696, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 604, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 604, iters: 1856, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 604, iters: 1936, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 604, iters: 2016, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 604, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 604, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 604, iters: 2256, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 604, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 604, iters: 2416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 604, iters: 2496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 604, iters: 2576, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 604, iters: 2656, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 604, iters: 2736, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 604, iters: 2816, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 604, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 604, iters: 2976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 604, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 604, iters: 3136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 604, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 604, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 604, iters: 3376, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 604, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 604, iters: 3536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 604, iters: 3616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 604, iters: 3696, time: 0.089, data: 0.012) loss: 0.006 
saving the model at the end of epoch 604, iters 2251712
End of epoch 604 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001495
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 604, TEST ACC: [96.813 %]

saving the latest model (epoch 605, total_steps 2251728)
(epoch: 605, iters: 48, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 605, iters: 128, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 605, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 605, iters: 288, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 605, iters: 368, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 605, iters: 448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 605, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 605, iters: 608, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 605, iters: 688, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 605, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 605, iters: 848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 605, iters: 928, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 605, iters: 1008, time: 0.091, data: 0.035) loss: 0.000 
(epoch: 605, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 605, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 605, iters: 1248, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 605, iters: 1328, time: 0.092, data: 0.035) loss: 0.000 
(epoch: 605, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 605, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 605, iters: 1568, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 605, iters: 1648, time: 0.093, data: 0.035) loss: 0.005 
(epoch: 605, iters: 1728, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 605, iters: 1808, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 605, iters: 1888, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 605, iters: 1968, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 605, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 605, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 605, iters: 2208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 605, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 605, iters: 2368, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 605, iters: 2448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 605, iters: 2528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 605, iters: 2608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 605, iters: 2688, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 605, iters: 2768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 605, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 605, iters: 2928, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 605, iters: 3008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 605, iters: 3088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 605, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 605, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 605, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 605, iters: 3408, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 605, iters: 3488, time: 0.093, data: 0.040) loss: 0.002 
(epoch: 605, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 605, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 605, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 605, iters 2255440
End of epoch 605 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001494
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 605, TEST ACC: [95.296 %]

saving the latest model (epoch 606, total_steps 2255456)
(epoch: 606, iters: 80, time: 0.095, data: 0.527) loss: 0.000 
(epoch: 606, iters: 160, time: 0.094, data: 0.031) loss: 0.000 
(epoch: 606, iters: 240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 320, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 606, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 480, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 606, iters: 560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 606, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 720, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 606, iters: 800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 606, iters: 880, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 606, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 1040, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 606, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 1200, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 606, iters: 1280, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 606, iters: 1360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 606, iters: 1440, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 606, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 1600, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 606, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 1840, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 606, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 2000, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 606, iters: 2080, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 606, iters: 2160, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 606, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 2320, time: 0.092, data: 0.000) loss: 0.005 
(epoch: 606, iters: 2400, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 606, iters: 2480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 606, iters: 2560, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 606, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 2720, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 606, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 2880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 606, iters: 2960, time: 0.095, data: 0.049) loss: 0.001 
(epoch: 606, iters: 3040, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 606, iters: 3120, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 606, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 3280, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 606, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 606, iters: 3520, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 606, iters: 3600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 606, iters: 3680, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 606, iters 2259168
End of epoch 606 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001493
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 606, TEST ACC: [93.323 %]

saving the latest model (epoch 607, total_steps 2259184)
(epoch: 607, iters: 32, time: 0.091, data: 0.006) loss: 0.000 
(epoch: 607, iters: 112, time: 0.093, data: 0.059) loss: 0.000 
(epoch: 607, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 272, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 607, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 607, iters: 432, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 607, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 672, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 607, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 607, iters: 832, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 607, iters: 912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 607, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 1232, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 607, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 1392, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 607, iters: 1472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 607, iters: 1552, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 607, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 1712, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 607, iters: 1792, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 607, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 1952, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 607, iters: 2032, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 2112, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 607, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 2272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 607, iters: 2352, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 607, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 2512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 607, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 2672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 607, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 607, iters: 2832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 607, iters: 2912, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 607, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 3072, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 607, iters: 3152, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 607, iters: 3232, time: 0.093, data: 0.019) loss: 0.000 
(epoch: 607, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 3392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 607, iters: 3472, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 607, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 607, iters: 3632, time: 0.090, data: 0.013) loss: 0.000 
(epoch: 607, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 607, iters 2262896
End of epoch 607 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001492
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 607, TEST ACC: [94.689 %]

saving the latest model (epoch 608, total_steps 2262912)
(epoch: 608, iters: 64, time: 0.094, data: 0.003) loss: 0.000 
(epoch: 608, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 608, iters: 224, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 608, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 608, iters: 384, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 608, iters: 464, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 608, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 608, iters: 624, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 608, iters: 704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 608, iters: 784, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 608, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 608, iters: 944, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 608, iters: 1024, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 608, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 608, iters: 1184, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 608, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 608, iters: 1344, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 608, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 608, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 608, iters: 1584, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 608, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 608, iters: 1744, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 608, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 608, iters: 1904, time: 0.093, data: 0.011) loss: 0.016 
(epoch: 608, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 608, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 608, iters: 2144, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 608, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 608, iters: 2304, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 608, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 608, iters: 2464, time: 0.093, data: 0.011) loss: 0.030 
(epoch: 608, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 608, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 608, iters: 2704, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 608, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 608, iters: 2864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 608, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 608, iters: 3024, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 608, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 608, iters: 3184, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 608, iters: 3264, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 608, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 608, iters: 3424, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 608, iters: 3504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 608, iters: 3584, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 608, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 608, iters 2266624
End of epoch 608 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001491
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 608, TEST ACC: [93.93 %]

(epoch: 609, iters: 16, time: 0.107, data: 0.000) loss: 0.000 
saving the latest model (epoch 609, total_steps 2266640)
(epoch: 609, iters: 96, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 609, iters: 176, time: 0.092, data: 0.012) loss: 0.368 
(epoch: 609, iters: 256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 609, iters: 336, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 609, iters: 416, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 609, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 609, iters: 576, time: 0.093, data: 0.040) loss: 0.040 
(epoch: 609, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 609, iters: 736, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 609, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 609, iters: 896, time: 0.093, data: 0.012) loss: 0.115 
(epoch: 609, iters: 976, time: 0.094, data: 0.000) loss: 0.043 
(epoch: 609, iters: 1056, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 609, iters: 1136, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 609, iters: 1216, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 609, iters: 1296, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 609, iters: 1376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 609, iters: 1456, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 609, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 609, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 609, iters: 1696, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 609, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 609, iters: 1856, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 609, iters: 1936, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 609, iters: 2016, time: 0.092, data: 0.011) loss: 0.011 
(epoch: 609, iters: 2096, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 609, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 609, iters: 2256, time: 0.094, data: 0.041) loss: 0.003 
(epoch: 609, iters: 2336, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 609, iters: 2416, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 609, iters: 2496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 609, iters: 2576, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 609, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 609, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 609, iters: 2816, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 609, iters: 2896, time: 0.095, data: 0.000) loss: 0.082 
(epoch: 609, iters: 2976, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 609, iters: 3056, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 609, iters: 3136, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 609, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 609, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 609, iters: 3376, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 609, iters: 3456, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 609, iters: 3536, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 609, iters: 3616, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 609, iters: 3696, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 609, iters 2270352
End of epoch 609 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001490
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 609, TEST ACC: [94.992 %]

saving the latest model (epoch 610, total_steps 2270368)
(epoch: 610, iters: 48, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 610, iters: 128, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 610, iters: 208, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 610, iters: 288, time: 0.093, data: 0.029) loss: 0.001 
(epoch: 610, iters: 368, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 610, iters: 448, time: 0.090, data: 0.013) loss: 0.000 
(epoch: 610, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 610, iters: 608, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 610, iters: 688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 610, iters: 768, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 610, iters: 848, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 610, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 610, iters: 1008, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 610, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 610, iters: 1168, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 610, iters: 1248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 610, iters: 1328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 610, iters: 1408, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 610, iters: 1488, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 610, iters: 1568, time: 0.091, data: 0.011) loss: 0.058 
(epoch: 610, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 610, iters: 1728, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 610, iters: 1808, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 610, iters: 1888, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 610, iters: 1968, time: 0.094, data: 0.039) loss: 0.187 
(epoch: 610, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 610, iters: 2128, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 610, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 610, iters: 2288, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 610, iters: 2368, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 610, iters: 2448, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 610, iters: 2528, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 610, iters: 2608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 610, iters: 2688, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 610, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 610, iters: 2848, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 610, iters: 2928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 610, iters: 3008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 610, iters: 3088, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 610, iters: 3168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 610, iters: 3248, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 610, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 610, iters: 3408, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 610, iters: 3488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 610, iters: 3568, time: 0.092, data: 0.000) loss: 0.003 
(epoch: 610, iters: 3648, time: 0.088, data: 0.038) loss: 0.000 
(epoch: 610, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 610, iters 2274080
End of epoch 610 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001489
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 610, TEST ACC: [97.724 %]

saving the latest model (epoch 611, total_steps 2274096)
(epoch: 611, iters: 80, time: 0.095, data: 0.515) loss: 0.001 
(epoch: 611, iters: 160, time: 0.095, data: 0.031) loss: 0.000 
(epoch: 611, iters: 240, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 611, iters: 320, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 611, iters: 400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 611, iters: 480, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 611, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 611, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 611, iters: 720, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 611, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 611, iters: 880, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 611, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 611, iters: 1040, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 611, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 611, iters: 1200, time: 0.096, data: 0.000) loss: 0.046 
(epoch: 611, iters: 1280, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 611, iters: 1360, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 611, iters: 1440, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 611, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 611, iters: 1600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 611, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 611, iters: 1760, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 611, iters: 1840, time: 0.094, data: 0.047) loss: 0.000 
(epoch: 611, iters: 1920, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 611, iters: 2000, time: 0.093, data: 0.012) loss: 0.007 
(epoch: 611, iters: 2080, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 611, iters: 2160, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 611, iters: 2240, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 611, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 611, iters: 2400, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 611, iters: 2480, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 611, iters: 2560, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 611, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 611, iters: 2720, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 611, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 611, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 611, iters: 2960, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 611, iters: 3040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 611, iters: 3120, time: 0.093, data: 0.012) loss: 0.009 
(epoch: 611, iters: 3200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 611, iters: 3280, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 611, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 611, iters: 3440, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 611, iters: 3520, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 611, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 611, iters: 3680, time: 0.086, data: 0.012) loss: 0.000 
saving the model at the end of epoch 611, iters 2277808
End of epoch 611 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001488
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 611, TEST ACC: [98.331 %]

saving the latest model (epoch 612, total_steps 2277824)
(epoch: 612, iters: 32, time: 0.091, data: 0.007) loss: 0.000 
(epoch: 612, iters: 112, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 612, iters: 192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 612, iters: 272, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 612, iters: 352, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 612, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 612, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 612, iters: 592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 612, iters: 672, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 612, iters: 752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 612, iters: 832, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 612, iters: 912, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 612, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 612, iters: 1072, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 612, iters: 1152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 612, iters: 1232, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 612, iters: 1312, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 612, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 612, iters: 1472, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 612, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 612, iters: 1632, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 612, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 612, iters: 1792, time: 0.093, data: 0.014) loss: 0.009 
(epoch: 612, iters: 1872, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 612, iters: 1952, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 612, iters: 2032, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 612, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 612, iters: 2192, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 612, iters: 2272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 612, iters: 2352, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 612, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 612, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 612, iters: 2592, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 612, iters: 2672, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 612, iters: 2752, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 612, iters: 2832, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 612, iters: 2912, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 612, iters: 2992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 612, iters: 3072, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 612, iters: 3152, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 612, iters: 3232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 612, iters: 3312, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 612, iters: 3392, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 612, iters: 3472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 612, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 612, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 612, iters: 3712, time: 0.089, data: 0.035) loss: 0.000 
saving the model at the end of epoch 612, iters 2281536
End of epoch 612 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001487
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 612, TEST ACC: [97.724 %]

saving the latest model (epoch 613, total_steps 2281552)
(epoch: 613, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 613, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 613, iters: 224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 613, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 613, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 613, iters: 464, time: 0.094, data: 0.039) loss: 0.014 
(epoch: 613, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 613, iters: 624, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 613, iters: 704, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 613, iters: 784, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 613, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 613, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 613, iters: 1024, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 613, iters: 1104, time: 0.094, data: 0.000) loss: 0.085 
(epoch: 613, iters: 1184, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 613, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 613, iters: 1344, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 613, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 613, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 613, iters: 1584, time: 0.094, data: 0.041) loss: 0.003 
(epoch: 613, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 613, iters: 1744, time: 0.092, data: 0.011) loss: 0.055 
(epoch: 613, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 613, iters: 1904, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 613, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 613, iters: 2064, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 613, iters: 2144, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 613, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 613, iters: 2304, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 613, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 613, iters: 2464, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 613, iters: 2544, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 613, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 613, iters: 2704, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 613, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 613, iters: 2864, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 613, iters: 2944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 613, iters: 3024, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 613, iters: 3104, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 613, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 613, iters: 3264, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 613, iters: 3344, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 613, iters: 3424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 613, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 613, iters: 3584, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 613, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 613, iters 2285264
End of epoch 613 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001486
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 613, TEST ACC: [98.027 %]

(epoch: 614, iters: 16, time: 0.110, data: 0.000) loss: 0.000 
saving the latest model (epoch 614, total_steps 2285280)
(epoch: 614, iters: 96, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 614, iters: 176, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 614, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 614, iters: 336, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 614, iters: 416, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 614, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 614, iters: 576, time: 0.094, data: 0.049) loss: 0.001 
(epoch: 614, iters: 656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 614, iters: 736, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 614, iters: 816, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 614, iters: 896, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 614, iters: 976, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 614, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 614, iters: 1136, time: 0.094, data: 0.050) loss: 0.005 
(epoch: 614, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 614, iters: 1296, time: 0.092, data: 0.012) loss: 0.433 
(epoch: 614, iters: 1376, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 614, iters: 1456, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 614, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 614, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 614, iters: 1696, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 614, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 614, iters: 1856, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 614, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 614, iters: 2016, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 614, iters: 2096, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 614, iters: 2176, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 614, iters: 2256, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 614, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 614, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 614, iters: 2496, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 614, iters: 2576, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 614, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 614, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 614, iters: 2816, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 614, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 614, iters: 2976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 614, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 614, iters: 3136, time: 0.093, data: 0.011) loss: 0.015 
(epoch: 614, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 614, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 614, iters: 3376, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 614, iters: 3456, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 614, iters: 3536, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 614, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 614, iters: 3696, time: 0.090, data: 0.011) loss: 0.000 
saving the model at the end of epoch 614, iters 2288992
End of epoch 614 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001485
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 614, TEST ACC: [96.358 %]

saving the latest model (epoch 615, total_steps 2289008)
(epoch: 615, iters: 48, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 615, iters: 128, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 615, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 615, iters: 288, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 615, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 615, iters: 448, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 615, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 615, iters: 608, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 615, iters: 688, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 615, iters: 768, time: 0.095, data: 0.000) loss: 0.103 
(epoch: 615, iters: 848, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 615, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 615, iters: 1008, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 615, iters: 1088, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 615, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 615, iters: 1248, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 615, iters: 1328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 615, iters: 1408, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 615, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 615, iters: 1568, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 615, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 615, iters: 1728, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 615, iters: 1808, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 615, iters: 1888, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 615, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 615, iters: 2048, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 615, iters: 2128, time: 0.094, data: 0.012) loss: 0.006 
(epoch: 615, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 615, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 615, iters: 2368, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 615, iters: 2448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 615, iters: 2528, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 615, iters: 2608, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 615, iters: 2688, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 615, iters: 2768, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 615, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 615, iters: 2928, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 615, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 615, iters: 3088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 615, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 615, iters: 3248, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 615, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 615, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 615, iters: 3488, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 615, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 615, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 615, iters: 3728, time: 0.056, data: 0.000) loss: 0.013 
saving the model at the end of epoch 615, iters 2292720
End of epoch 615 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001484
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 615, TEST ACC: [97.269 %]

saving the latest model (epoch 616, total_steps 2292736)
(epoch: 616, iters: 80, time: 0.097, data: 0.478) loss: 0.000 
(epoch: 616, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 616, iters: 240, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 616, iters: 320, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 616, iters: 400, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 616, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 616, iters: 560, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 616, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 616, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 616, iters: 800, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 616, iters: 880, time: 0.096, data: 0.000) loss: 0.029 
(epoch: 616, iters: 960, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 616, iters: 1040, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 616, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 616, iters: 1200, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 616, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 616, iters: 1360, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 616, iters: 1440, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 616, iters: 1520, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 616, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 616, iters: 1680, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 616, iters: 1760, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 616, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 616, iters: 1920, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 616, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 616, iters: 2080, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 616, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 616, iters: 2240, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 616, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 616, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 616, iters: 2480, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 616, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 616, iters: 2640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 616, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 616, iters: 2800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 616, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 616, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 616, iters: 3040, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 616, iters: 3120, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 616, iters: 3200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 616, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 616, iters: 3360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 616, iters: 3440, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 616, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 616, iters: 3600, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 616, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 616, iters 2296448
End of epoch 616 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001483
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 616, TEST ACC: [93.778 %]

saving the latest model (epoch 617, total_steps 2296464)
(epoch: 617, iters: 32, time: 0.095, data: 0.005) loss: 0.000 
(epoch: 617, iters: 112, time: 0.094, data: 0.012) loss: 0.047 
(epoch: 617, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 617, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 617, iters: 352, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 617, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 617, iters: 512, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 617, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 617, iters: 672, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 617, iters: 752, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 617, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 617, iters: 912, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 617, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 617, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 617, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 617, iters: 1232, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 617, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 617, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 617, iters: 1472, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 617, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 617, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 617, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 617, iters: 1792, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 617, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 617, iters: 1952, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 617, iters: 2032, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 617, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 617, iters: 2192, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 617, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 617, iters: 2352, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 617, iters: 2432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 617, iters: 2512, time: 0.094, data: 0.000) loss: 0.038 
(epoch: 617, iters: 2592, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 617, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 617, iters: 2752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 617, iters: 2832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 617, iters: 2912, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 617, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 617, iters: 3072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 617, iters: 3152, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 617, iters: 3232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 617, iters: 3312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 617, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 617, iters: 3472, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 617, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 617, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 617, iters: 3712, time: 0.087, data: 0.037) loss: 0.001 
saving the model at the end of epoch 617, iters 2300176
End of epoch 617 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001482
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 617, TEST ACC: [95.599 %]

saving the latest model (epoch 618, total_steps 2300192)
(epoch: 618, iters: 64, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 618, iters: 144, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 618, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 618, iters: 304, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 618, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 618, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 618, iters: 544, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 618, iters: 624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 618, iters: 704, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 618, iters: 784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 618, iters: 864, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 618, iters: 944, time: 0.096, data: 0.000) loss: 0.006 
(epoch: 618, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 618, iters: 1104, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 618, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 618, iters: 1264, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 618, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 618, iters: 1424, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 618, iters: 1504, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 618, iters: 1584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 618, iters: 1664, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 618, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 618, iters: 1824, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 618, iters: 1904, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 618, iters: 1984, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 618, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 618, iters: 2144, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 618, iters: 2224, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 618, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 618, iters: 2384, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 618, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 618, iters: 2544, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 618, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 618, iters: 2704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 618, iters: 2784, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 618, iters: 2864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 618, iters: 2944, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 618, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 618, iters: 3104, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 618, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 618, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 618, iters: 3344, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 618, iters: 3424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 618, iters: 3504, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 618, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 618, iters: 3664, time: 0.086, data: 0.012) loss: 0.006 
saving the model at the end of epoch 618, iters 2303904
End of epoch 618 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001481
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 618, TEST ACC: [95.599 %]

(epoch: 619, iters: 16, time: 0.111, data: 0.000) loss: 0.000 
saving the latest model (epoch 619, total_steps 2303920)
(epoch: 619, iters: 96, time: 0.094, data: 0.043) loss: 0.000 
(epoch: 619, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 619, iters: 256, time: 0.092, data: 0.011) loss: 0.006 
(epoch: 619, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 619, iters: 416, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 619, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 619, iters: 576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 619, iters: 656, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 619, iters: 736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 619, iters: 816, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 619, iters: 896, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 619, iters: 976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 619, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 619, iters: 1136, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 619, iters: 1216, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 619, iters: 1296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 619, iters: 1376, time: 0.092, data: 0.012) loss: 0.028 
(epoch: 619, iters: 1456, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 619, iters: 1536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 619, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 619, iters: 1696, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 619, iters: 1776, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 619, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 619, iters: 1936, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 619, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 619, iters: 2096, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 619, iters: 2176, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 619, iters: 2256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 619, iters: 2336, time: 0.093, data: 0.040) loss: 0.010 
(epoch: 619, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 619, iters: 2496, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 619, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 619, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 619, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 619, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 619, iters: 2896, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 619, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 619, iters: 3056, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 619, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 619, iters: 3216, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 619, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 619, iters: 3376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 619, iters: 3456, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 619, iters: 3536, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 619, iters: 3616, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 619, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 619, iters 2307632
End of epoch 619 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001480
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 619, TEST ACC: [94.385 %]

saving the latest model (epoch 620, total_steps 2307648)
(epoch: 620, iters: 48, time: 0.094, data: 0.005) loss: 0.001 
(epoch: 620, iters: 128, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 620, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 620, iters: 288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 620, iters: 368, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 620, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 620, iters: 528, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 620, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 620, iters: 688, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 620, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 620, iters: 848, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 620, iters: 928, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 620, iters: 1008, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 620, iters: 1088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 620, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 620, iters: 1248, time: 0.095, data: 0.011) loss: 0.006 
(epoch: 620, iters: 1328, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 620, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 620, iters: 1488, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 620, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 620, iters: 1648, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 620, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 620, iters: 1808, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 620, iters: 1888, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 620, iters: 1968, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 620, iters: 2048, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 620, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 620, iters: 2208, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 620, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 620, iters: 2368, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 620, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 620, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 620, iters: 2608, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 620, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 620, iters: 2768, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 620, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 620, iters: 2928, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 620, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 620, iters: 3088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 620, iters: 3168, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 620, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 620, iters: 3328, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 620, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 620, iters: 3488, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 620, iters: 3568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 620, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 620, iters: 3728, time: 0.056, data: 0.015) loss: 0.000 
saving the model at the end of epoch 620, iters 2311360
End of epoch 620 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001479
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 620, TEST ACC: [96.813 %]

saving the latest model (epoch 621, total_steps 2311376)
(epoch: 621, iters: 80, time: 0.094, data: 0.451) loss: 0.000 
(epoch: 621, iters: 160, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 621, iters: 240, time: 0.093, data: 0.041) loss: 0.001 
(epoch: 621, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 621, iters: 400, time: 0.093, data: 0.012) loss: 0.009 
(epoch: 621, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 621, iters: 560, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 621, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 621, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 621, iters: 800, time: 0.094, data: 0.040) loss: 0.004 
(epoch: 621, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 621, iters: 960, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 621, iters: 1040, time: 0.093, data: 0.000) loss: 0.225 
(epoch: 621, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 621, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 621, iters: 1280, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 621, iters: 1360, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 621, iters: 1440, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 621, iters: 1520, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 621, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 621, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 621, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 621, iters: 1840, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 621, iters: 1920, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 621, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 621, iters: 2080, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 621, iters: 2160, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 621, iters: 2240, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 621, iters: 2320, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 621, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 621, iters: 2480, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 621, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 621, iters: 2640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 621, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 621, iters: 2800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 621, iters: 2880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 621, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 621, iters: 3040, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 621, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 621, iters: 3200, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 621, iters: 3280, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 621, iters: 3360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 621, iters: 3440, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 621, iters: 3520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 621, iters: 3600, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 621, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 621, iters 2315088
End of epoch 621 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001478
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 621, TEST ACC: [97.269 %]

saving the latest model (epoch 622, total_steps 2315104)
(epoch: 622, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 622, iters: 112, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 622, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 622, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 622, iters: 352, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 622, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 622, iters: 512, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 622, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 622, iters: 672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 622, iters: 752, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 622, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 622, iters: 912, time: 0.096, data: 0.040) loss: 0.002 
(epoch: 622, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 622, iters: 1072, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 622, iters: 1152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 622, iters: 1232, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 622, iters: 1312, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 622, iters: 1392, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 622, iters: 1472, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 622, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 622, iters: 1632, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 622, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 622, iters: 1792, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 622, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 622, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 622, iters: 2032, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 622, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 622, iters: 2192, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 622, iters: 2272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 622, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 622, iters: 2432, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 622, iters: 2512, time: 0.092, data: 0.026) loss: 0.002 
(epoch: 622, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 622, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 622, iters: 2752, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 622, iters: 2832, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 622, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 622, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 622, iters: 3072, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 622, iters: 3152, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 622, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 622, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 622, iters: 3392, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 622, iters: 3472, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 622, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 622, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 622, iters: 3712, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 622, iters 2318816
End of epoch 622 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001477
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 622, TEST ACC: [97.117 %]

saving the latest model (epoch 623, total_steps 2318832)
(epoch: 623, iters: 64, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 623, iters: 144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 623, iters: 224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 623, iters: 304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 623, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 623, iters: 464, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 623, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 623, iters: 624, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 623, iters: 704, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 623, iters: 784, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 623, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 623, iters: 944, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 623, iters: 1024, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 623, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 623, iters: 1184, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 623, iters: 1264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 623, iters: 1344, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 623, iters: 1424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 623, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 623, iters: 1584, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 623, iters: 1664, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 623, iters: 1744, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 623, iters: 1824, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 623, iters: 1904, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 623, iters: 1984, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 623, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 623, iters: 2144, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 623, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 623, iters: 2304, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 623, iters: 2384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 623, iters: 2464, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 623, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 623, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 623, iters: 2704, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 623, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 623, iters: 2864, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 623, iters: 2944, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 623, iters: 3024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 623, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 623, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 623, iters: 3264, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 623, iters: 3344, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 623, iters: 3424, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 623, iters: 3504, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 623, iters: 3584, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 623, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 623, iters 2322544
End of epoch 623 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001476
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 623, TEST ACC: [97.42 %]

(epoch: 624, iters: 16, time: 0.112, data: 0.000) loss: 0.003 
saving the latest model (epoch 624, total_steps 2322560)
(epoch: 624, iters: 96, time: 0.094, data: 0.058) loss: 0.000 
(epoch: 624, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 624, iters: 256, time: 0.092, data: 0.014) loss: 0.000 
(epoch: 624, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 624, iters: 416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 624, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 624, iters: 576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 624, iters: 656, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 624, iters: 736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 624, iters: 816, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 624, iters: 896, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 624, iters: 976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 624, iters: 1056, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 624, iters: 1136, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 624, iters: 1216, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 624, iters: 1296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 624, iters: 1376, time: 0.092, data: 0.011) loss: 0.052 
(epoch: 624, iters: 1456, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 624, iters: 1536, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 624, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 624, iters: 1696, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 624, iters: 1776, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 624, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 624, iters: 1936, time: 0.092, data: 0.011) loss: 0.071 
(epoch: 624, iters: 2016, time: 0.095, data: 0.000) loss: 0.042 
(epoch: 624, iters: 2096, time: 0.096, data: 0.012) loss: 0.377 
(epoch: 624, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 624, iters: 2256, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 624, iters: 2336, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 624, iters: 2416, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 624, iters: 2496, time: 0.092, data: 0.012) loss: 0.006 
(epoch: 624, iters: 2576, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 624, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 624, iters: 2736, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 624, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 624, iters: 2896, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 624, iters: 2976, time: 0.094, data: 0.000) loss: 0.429 
(epoch: 624, iters: 3056, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 624, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 624, iters: 3216, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 624, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 624, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 624, iters: 3456, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 624, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 624, iters: 3616, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 624, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 624, iters 2326272
End of epoch 624 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001475
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 624, TEST ACC: [94.385 %]

saving the latest model (epoch 625, total_steps 2326288)
(epoch: 625, iters: 48, time: 0.096, data: 0.005) loss: 0.000 
(epoch: 625, iters: 128, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 625, iters: 208, time: 0.094, data: 0.040) loss: 0.005 
(epoch: 625, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 625, iters: 368, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 625, iters: 448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 625, iters: 528, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 625, iters: 608, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 625, iters: 688, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 625, iters: 768, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 625, iters: 848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 625, iters: 928, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 625, iters: 1008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 625, iters: 1088, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 625, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 625, iters: 1248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 625, iters: 1328, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 625, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 625, iters: 1488, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 625, iters: 1568, time: 0.092, data: 0.035) loss: 0.003 
(epoch: 625, iters: 1648, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 625, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 625, iters: 1808, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 625, iters: 1888, time: 0.092, data: 0.026) loss: 0.001 
(epoch: 625, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 625, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 625, iters: 2128, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 625, iters: 2208, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 625, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 625, iters: 2368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 625, iters: 2448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 625, iters: 2528, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 625, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 625, iters: 2688, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 625, iters: 2768, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 625, iters: 2848, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 625, iters: 2928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 625, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 625, iters: 3088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 625, iters: 3168, time: 0.092, data: 0.024) loss: 0.000 
(epoch: 625, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 625, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 625, iters: 3408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 625, iters: 3488, time: 0.091, data: 0.025) loss: 0.000 
(epoch: 625, iters: 3568, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 625, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 625, iters: 3728, time: 0.056, data: 0.012) loss: 0.000 
saving the model at the end of epoch 625, iters 2330000
End of epoch 625 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001474
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 625, TEST ACC: [86.646 %]

saving the latest model (epoch 626, total_steps 2330016)
(epoch: 626, iters: 80, time: 0.095, data: 0.450) loss: 0.003 
(epoch: 626, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 626, iters: 240, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 626, iters: 320, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 626, iters: 400, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 626, iters: 480, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 626, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 626, iters: 640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 626, iters: 720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 626, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 626, iters: 880, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 626, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 626, iters: 1040, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 626, iters: 1120, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 626, iters: 1200, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 626, iters: 1280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 626, iters: 1360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 626, iters: 1440, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 626, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 626, iters: 1600, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 626, iters: 1680, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 626, iters: 1760, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 626, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 626, iters: 1920, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 626, iters: 2000, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 626, iters: 2080, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 626, iters: 2160, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 626, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 626, iters: 2320, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 626, iters: 2400, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 626, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 626, iters: 2560, time: 0.095, data: 0.039) loss: 0.072 
(epoch: 626, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 626, iters: 2720, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 626, iters: 2800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 626, iters: 2880, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 626, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 626, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 626, iters: 3120, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 626, iters: 3200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 626, iters: 3280, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 626, iters: 3360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 626, iters: 3440, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 626, iters: 3520, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 626, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 626, iters: 3680, time: 0.087, data: 0.040) loss: 0.000 
saving the model at the end of epoch 626, iters 2333728
End of epoch 626 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001473
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 626, TEST ACC: [92.716 %]

saving the latest model (epoch 627, total_steps 2333744)
(epoch: 627, iters: 32, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 627, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 627, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 627, iters: 272, time: 0.094, data: 0.050) loss: 0.265 
(epoch: 627, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 627, iters: 432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 627, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 627, iters: 592, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 627, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 627, iters: 752, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 627, iters: 832, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 627, iters: 912, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 627, iters: 992, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 627, iters: 1072, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 627, iters: 1152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 627, iters: 1232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 627, iters: 1312, time: 0.093, data: 0.000) loss: 0.033 
(epoch: 627, iters: 1392, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 627, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 627, iters: 1552, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 627, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 627, iters: 1712, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 627, iters: 1792, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 627, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 627, iters: 1952, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 627, iters: 2032, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 627, iters: 2112, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 627, iters: 2192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 627, iters: 2272, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 627, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 627, iters: 2432, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 627, iters: 2512, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 627, iters: 2592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 627, iters: 2672, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 627, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 627, iters: 2832, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 627, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 627, iters: 2992, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 627, iters: 3072, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 627, iters: 3152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 627, iters: 3232, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 627, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 627, iters: 3392, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 627, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 627, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 627, iters: 3632, time: 0.092, data: 0.039) loss: 0.000 
(epoch: 627, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 627, iters 2337456
End of epoch 627 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001472
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 627, TEST ACC: [95.903 %]

saving the latest model (epoch 628, total_steps 2337472)
(epoch: 628, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 628, iters: 144, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 628, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 628, iters: 304, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 628, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 628, iters: 464, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 628, iters: 544, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 628, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 628, iters: 704, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 628, iters: 784, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 628, iters: 864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 628, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 628, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 628, iters: 1104, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 628, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 628, iters: 1264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 628, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 628, iters: 1424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 628, iters: 1504, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 628, iters: 1584, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 628, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 628, iters: 1744, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 628, iters: 1824, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 628, iters: 1904, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 628, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 628, iters: 2064, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 628, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 628, iters: 2224, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 628, iters: 2304, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 628, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 628, iters: 2464, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 628, iters: 2544, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 628, iters: 2624, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 628, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 628, iters: 2784, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 628, iters: 2864, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 628, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 628, iters: 3024, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 628, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 628, iters: 3184, time: 0.093, data: 0.012) loss: 0.151 
(epoch: 628, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 628, iters: 3344, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 628, iters: 3424, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 628, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 628, iters: 3584, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 628, iters: 3664, time: 0.089, data: 0.000) loss: 0.021 
saving the model at the end of epoch 628, iters 2341184
End of epoch 628 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001471
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 628, TEST ACC: [94.082 %]

(epoch: 629, iters: 16, time: 0.111, data: 0.008) loss: 0.001 
saving the latest model (epoch 629, total_steps 2341200)
(epoch: 629, iters: 96, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 629, iters: 176, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 629, iters: 256, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 629, iters: 336, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 629, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 629, iters: 496, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 629, iters: 576, time: 0.094, data: 0.049) loss: 0.002 
(epoch: 629, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 629, iters: 736, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 629, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 629, iters: 896, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 629, iters: 976, time: 0.096, data: 0.000) loss: 0.062 
(epoch: 629, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 629, iters: 1136, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 629, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 629, iters: 1296, time: 0.091, data: 0.011) loss: 0.001 
(epoch: 629, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 629, iters: 1456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 629, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 629, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 629, iters: 1696, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 629, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 629, iters: 1856, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 629, iters: 1936, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 629, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 629, iters: 2096, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 629, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 629, iters: 2256, time: 0.093, data: 0.038) loss: 0.032 
(epoch: 629, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 629, iters: 2416, time: 0.090, data: 0.011) loss: 0.000 
(epoch: 629, iters: 2496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 629, iters: 2576, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 629, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 629, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 629, iters: 2816, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 629, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 629, iters: 2976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 629, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 629, iters: 3136, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 629, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 629, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 629, iters: 3376, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 629, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 629, iters: 3536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 629, iters: 3616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 629, iters: 3696, time: 0.089, data: 0.011) loss: 0.001 
saving the model at the end of epoch 629, iters 2344912
End of epoch 629 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001470
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 629, TEST ACC: [94.689 %]

saving the latest model (epoch 630, total_steps 2344928)
(epoch: 630, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 630, iters: 128, time: 0.093, data: 0.058) loss: 0.000 
(epoch: 630, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 630, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 630, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 630, iters: 448, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 630, iters: 528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 630, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 630, iters: 688, time: 0.096, data: 0.053) loss: 0.000 
(epoch: 630, iters: 768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 630, iters: 848, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 630, iters: 928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 630, iters: 1008, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 630, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 630, iters: 1168, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 630, iters: 1248, time: 0.094, data: 0.050) loss: 0.002 
(epoch: 630, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 630, iters: 1408, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 630, iters: 1488, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 630, iters: 1568, time: 0.093, data: 0.013) loss: 0.033 
(epoch: 630, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 630, iters: 1728, time: 0.093, data: 0.000) loss: 0.023 
(epoch: 630, iters: 1808, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 630, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 630, iters: 1968, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 630, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 630, iters: 2128, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 630, iters: 2208, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 630, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 630, iters: 2368, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 630, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 630, iters: 2528, time: 0.091, data: 0.011) loss: 0.004 
(epoch: 630, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 630, iters: 2688, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 630, iters: 2768, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 630, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 630, iters: 2928, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 630, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 630, iters: 3088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 630, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 630, iters: 3248, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 630, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 630, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 630, iters: 3488, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 630, iters: 3568, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 630, iters: 3648, time: 0.085, data: 0.011) loss: 0.000 
(epoch: 630, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 630, iters 2348640
End of epoch 630 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001469
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 630, TEST ACC: [95.751 %]

saving the latest model (epoch 631, total_steps 2348656)
(epoch: 631, iters: 80, time: 0.095, data: 0.512) loss: 0.000 
(epoch: 631, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 631, iters: 240, time: 0.093, data: 0.039) loss: 0.023 
(epoch: 631, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 631, iters: 400, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 631, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 631, iters: 560, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 631, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 631, iters: 720, time: 0.092, data: 0.000) loss: 0.006 
(epoch: 631, iters: 800, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 631, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 631, iters: 960, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 631, iters: 1040, time: 0.093, data: 0.000) loss: 0.027 
(epoch: 631, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 631, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 631, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 631, iters: 1360, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 631, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 631, iters: 1520, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 631, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 631, iters: 1680, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 631, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 631, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 631, iters: 1920, time: 0.095, data: 0.042) loss: 0.002 
(epoch: 631, iters: 2000, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 631, iters: 2080, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 631, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 631, iters: 2240, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 631, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 631, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 631, iters: 2480, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 631, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 631, iters: 2640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 631, iters: 2720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 631, iters: 2800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 631, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 631, iters: 2960, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 631, iters: 3040, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 631, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 631, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 631, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 631, iters: 3360, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 631, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 631, iters: 3520, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 631, iters: 3600, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 631, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 631, iters 2352368
End of epoch 631 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001468
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 631, TEST ACC: [95.751 %]

saving the latest model (epoch 632, total_steps 2352384)
(epoch: 632, iters: 32, time: 0.092, data: 0.004) loss: 0.001 
(epoch: 632, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 632, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 632, iters: 272, time: 0.092, data: 0.000) loss: 0.005 
(epoch: 632, iters: 352, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 632, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 632, iters: 512, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 632, iters: 592, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 632, iters: 672, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 632, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 632, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 632, iters: 912, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 632, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 632, iters: 1072, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 632, iters: 1152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 632, iters: 1232, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 632, iters: 1312, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 632, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 632, iters: 1472, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 632, iters: 1552, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 632, iters: 1632, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 632, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 632, iters: 1792, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 632, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 632, iters: 1952, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 632, iters: 2032, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 632, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 632, iters: 2192, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 632, iters: 2272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 632, iters: 2352, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 632, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 632, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 632, iters: 2592, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 632, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 632, iters: 2752, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 632, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 632, iters: 2912, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 632, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 632, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 632, iters: 3152, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 632, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 632, iters: 3312, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 632, iters: 3392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 632, iters: 3472, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 632, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 632, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 632, iters: 3712, time: 0.088, data: 0.036) loss: 0.000 
saving the model at the end of epoch 632, iters 2356096
End of epoch 632 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001467
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 632, TEST ACC: [95.296 %]

saving the latest model (epoch 633, total_steps 2356112)
(epoch: 633, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 633, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 633, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 633, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 633, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 633, iters: 464, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 633, iters: 544, time: 0.095, data: 0.000) loss: 0.043 
(epoch: 633, iters: 624, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 633, iters: 704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 633, iters: 784, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 633, iters: 864, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 633, iters: 944, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 633, iters: 1024, time: 0.095, data: 0.039) loss: 0.006 
(epoch: 633, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 633, iters: 1184, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 633, iters: 1264, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 633, iters: 1344, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 633, iters: 1424, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 633, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 633, iters: 1584, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 633, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 633, iters: 1744, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 633, iters: 1824, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 633, iters: 1904, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 633, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 633, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 633, iters: 2144, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 633, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 633, iters: 2304, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 633, iters: 2384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 633, iters: 2464, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 633, iters: 2544, time: 0.094, data: 0.000) loss: 0.239 
(epoch: 633, iters: 2624, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 633, iters: 2704, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 633, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 633, iters: 2864, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 633, iters: 2944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 633, iters: 3024, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 633, iters: 3104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 633, iters: 3184, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 633, iters: 3264, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 633, iters: 3344, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 633, iters: 3424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 633, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 633, iters: 3584, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 633, iters: 3664, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 633, iters 2359824
End of epoch 633 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001466
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 633, TEST ACC: [96.055 %]

(epoch: 634, iters: 16, time: 0.110, data: 0.000) loss: 0.000 
saving the latest model (epoch 634, total_steps 2359840)
(epoch: 634, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 634, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 634, iters: 256, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 634, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 634, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 634, iters: 496, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 634, iters: 576, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 634, iters: 656, time: 0.091, data: 0.021) loss: 0.000 
(epoch: 634, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 634, iters: 816, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 634, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 634, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 634, iters: 1056, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 634, iters: 1136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 634, iters: 1216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 634, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 634, iters: 1376, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 634, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 634, iters: 1536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 634, iters: 1616, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 634, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 634, iters: 1776, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 634, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 634, iters: 1936, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 634, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 634, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 634, iters: 2176, time: 0.092, data: 0.036) loss: 0.000 
(epoch: 634, iters: 2256, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 634, iters: 2336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 634, iters: 2416, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 634, iters: 2496, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 634, iters: 2576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 634, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 634, iters: 2736, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 634, iters: 2816, time: 0.091, data: 0.025) loss: 0.000 
(epoch: 634, iters: 2896, time: 0.095, data: 0.000) loss: 0.044 
(epoch: 634, iters: 2976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 634, iters: 3056, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 634, iters: 3136, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 634, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 634, iters: 3296, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 634, iters: 3376, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 634, iters: 3456, time: 0.094, data: 0.026) loss: 0.003 
(epoch: 634, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 634, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 634, iters: 3696, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 634, iters 2363552
End of epoch 634 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001465
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 634, TEST ACC: [90.288 %]

saving the latest model (epoch 635, total_steps 2363568)
(epoch: 635, iters: 48, time: 0.095, data: 0.004) loss: 0.000 
(epoch: 635, iters: 128, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 635, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 635, iters: 288, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 635, iters: 368, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 635, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 635, iters: 528, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 635, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 635, iters: 688, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 635, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 635, iters: 848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 635, iters: 928, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 635, iters: 1008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 635, iters: 1088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 635, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 635, iters: 1248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 635, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 635, iters: 1408, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 635, iters: 1488, time: 0.098, data: 0.039) loss: 0.000 
(epoch: 635, iters: 1568, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 635, iters: 1648, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 635, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 635, iters: 1808, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 635, iters: 1888, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 635, iters: 1968, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 635, iters: 2048, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 635, iters: 2128, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 635, iters: 2208, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 635, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 635, iters: 2368, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 635, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 635, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 635, iters: 2608, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 635, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 635, iters: 2768, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 635, iters: 2848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 635, iters: 2928, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 635, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 635, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 635, iters: 3168, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 635, iters: 3248, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 635, iters: 3328, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 635, iters: 3408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 635, iters: 3488, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 635, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 635, iters: 3648, time: 0.087, data: 0.000) loss: 0.000 
(epoch: 635, iters: 3728, time: 0.057, data: 0.015) loss: 0.798 
saving the model at the end of epoch 635, iters 2367280
End of epoch 635 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001464
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 635, TEST ACC: [98.027 %]

saving the latest model (epoch 636, total_steps 2367296)
(epoch: 636, iters: 80, time: 0.095, data: 0.525) loss: 0.000 
(epoch: 636, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 636, iters: 240, time: 0.095, data: 0.050) loss: 0.002 
(epoch: 636, iters: 320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 636, iters: 400, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 636, iters: 480, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 636, iters: 560, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 636, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 636, iters: 720, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 636, iters: 800, time: 0.093, data: 0.048) loss: 0.004 
(epoch: 636, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 636, iters: 960, time: 0.092, data: 0.011) loss: 0.003 
(epoch: 636, iters: 1040, time: 0.094, data: 0.000) loss: 0.020 
(epoch: 636, iters: 1120, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 636, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 636, iters: 1280, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 636, iters: 1360, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 636, iters: 1440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 636, iters: 1520, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 636, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 636, iters: 1680, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 636, iters: 1760, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 636, iters: 1840, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 636, iters: 1920, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 636, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 636, iters: 2080, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 636, iters: 2160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 636, iters: 2240, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 636, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 636, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 636, iters: 2480, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 636, iters: 2560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 636, iters: 2640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 636, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 636, iters: 2800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 636, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 636, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 636, iters: 3040, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 636, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 636, iters: 3200, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 636, iters: 3280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 636, iters: 3360, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 636, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 636, iters: 3520, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 636, iters: 3600, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 636, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 636, iters 2371008
End of epoch 636 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001463
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 636, TEST ACC: [97.42 %]

saving the latest model (epoch 637, total_steps 2371024)
(epoch: 637, iters: 32, time: 0.091, data: 0.004) loss: 0.000 
(epoch: 637, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 637, iters: 192, time: 0.095, data: 0.011) loss: 0.012 
(epoch: 637, iters: 272, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 637, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 637, iters: 432, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 637, iters: 512, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 637, iters: 592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 637, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 637, iters: 752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 637, iters: 832, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 637, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 637, iters: 992, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 637, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 637, iters: 1152, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 637, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 637, iters: 1312, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 637, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 637, iters: 1472, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 637, iters: 1552, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 637, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 637, iters: 1712, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 637, iters: 1792, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 637, iters: 1872, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 637, iters: 1952, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 637, iters: 2032, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 637, iters: 2112, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 637, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 637, iters: 2272, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 637, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 637, iters: 2432, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 637, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 637, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 637, iters: 2672, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 637, iters: 2752, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 637, iters: 2832, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 637, iters: 2912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 637, iters: 2992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 637, iters: 3072, time: 0.095, data: 0.000) loss: 0.200 
(epoch: 637, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 637, iters: 3232, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 637, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 637, iters: 3392, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 637, iters: 3472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 637, iters: 3552, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 637, iters: 3632, time: 0.094, data: 0.000) loss: 0.122 
(epoch: 637, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 637, iters 2374736
End of epoch 637 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001462
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 637, TEST ACC: [97.269 %]

saving the latest model (epoch 638, total_steps 2374752)
(epoch: 638, iters: 64, time: 0.093, data: 0.002) loss: 0.000 
(epoch: 638, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 638, iters: 224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 638, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 638, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 638, iters: 464, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 638, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 638, iters: 624, time: 0.092, data: 0.012) loss: 0.063 
(epoch: 638, iters: 704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 638, iters: 784, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 638, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 638, iters: 944, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 638, iters: 1024, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 638, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 638, iters: 1184, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 638, iters: 1264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 638, iters: 1344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 638, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 638, iters: 1504, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 638, iters: 1584, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 638, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 638, iters: 1744, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 638, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 638, iters: 1904, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 638, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 638, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 638, iters: 2144, time: 0.094, data: 0.039) loss: 0.088 
(epoch: 638, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 638, iters: 2304, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 638, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 638, iters: 2464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 638, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 638, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 638, iters: 2704, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 638, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 638, iters: 2864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 638, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 638, iters: 3024, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 638, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 638, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 638, iters: 3264, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 638, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 638, iters: 3424, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 638, iters: 3504, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 638, iters: 3584, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 638, iters: 3664, time: 0.089, data: 0.000) loss: 0.018 
saving the model at the end of epoch 638, iters 2378464
End of epoch 638 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001461
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 638, TEST ACC: [96.51 %]

(epoch: 639, iters: 16, time: 0.110, data: 0.000) loss: 0.000 
saving the latest model (epoch 639, total_steps 2378480)
(epoch: 639, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 639, iters: 176, time: 0.093, data: 0.000) loss: 0.103 
(epoch: 639, iters: 256, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 639, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 639, iters: 416, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 639, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 639, iters: 576, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 639, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 639, iters: 736, time: 0.093, data: 0.000) loss: 0.010 
(epoch: 639, iters: 816, time: 0.094, data: 0.040) loss: 0.068 
(epoch: 639, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 639, iters: 976, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 639, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 639, iters: 1136, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 639, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 639, iters: 1296, time: 0.093, data: 0.000) loss: 0.065 
(epoch: 639, iters: 1376, time: 0.094, data: 0.040) loss: 0.013 
(epoch: 639, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 639, iters: 1536, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 639, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 639, iters: 1696, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 639, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 639, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 639, iters: 1936, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 639, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 639, iters: 2096, time: 0.092, data: 0.012) loss: 0.005 
(epoch: 639, iters: 2176, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 639, iters: 2256, time: 0.093, data: 0.012) loss: 0.190 
(epoch: 639, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 639, iters: 2416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 639, iters: 2496, time: 0.094, data: 0.051) loss: 0.014 
(epoch: 639, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 639, iters: 2656, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 639, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 639, iters: 2816, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 639, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 639, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 639, iters: 3056, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 639, iters: 3136, time: 0.094, data: 0.000) loss: 0.050 
(epoch: 639, iters: 3216, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 639, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 639, iters: 3376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 639, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 639, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 639, iters: 3616, time: 0.094, data: 0.041) loss: 0.006 
(epoch: 639, iters: 3696, time: 0.088, data: 0.000) loss: 0.008 
saving the model at the end of epoch 639, iters 2382192
End of epoch 639 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001460
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 639, TEST ACC: [97.42 %]

saving the latest model (epoch 640, total_steps 2382208)
(epoch: 640, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 640, iters: 128, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 640, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 640, iters: 288, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 640, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 640, iters: 448, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 640, iters: 528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 640, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 640, iters: 688, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 640, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 640, iters: 848, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 640, iters: 928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 640, iters: 1008, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 640, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 640, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 640, iters: 1248, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 640, iters: 1328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 640, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 640, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 640, iters: 1568, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 640, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 640, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 640, iters: 1808, time: 0.094, data: 0.041) loss: 0.002 
(epoch: 640, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 640, iters: 1968, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 640, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 640, iters: 2128, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 640, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 640, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 640, iters: 2368, time: 0.094, data: 0.042) loss: 0.008 
(epoch: 640, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 640, iters: 2528, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 640, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 640, iters: 2688, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 640, iters: 2768, time: 0.095, data: 0.000) loss: 0.067 
(epoch: 640, iters: 2848, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 640, iters: 2928, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 640, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 640, iters: 3088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 640, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 640, iters: 3248, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 640, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 640, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 640, iters: 3488, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 640, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 640, iters: 3648, time: 0.085, data: 0.012) loss: 0.000 
(epoch: 640, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 640, iters 2385920
End of epoch 640 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001459
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 640, TEST ACC: [96.51 %]

saving the latest model (epoch 641, total_steps 2385936)
(epoch: 641, iters: 80, time: 0.095, data: 0.442) loss: 0.000 
(epoch: 641, iters: 160, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 641, iters: 240, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 641, iters: 320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 641, iters: 400, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 641, iters: 480, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 641, iters: 560, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 641, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 641, iters: 720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 641, iters: 800, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 641, iters: 880, time: 0.095, data: 0.000) loss: 0.030 
(epoch: 641, iters: 960, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 641, iters: 1040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 641, iters: 1120, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 641, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 641, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 641, iters: 1360, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 641, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 641, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 641, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 641, iters: 1680, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 641, iters: 1760, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 641, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 641, iters: 1920, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 641, iters: 2000, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 641, iters: 2080, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 641, iters: 2160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 641, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 641, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 641, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 641, iters: 2480, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 641, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 641, iters: 2640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 641, iters: 2720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 641, iters: 2800, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 641, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 641, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 641, iters: 3040, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 641, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 641, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 641, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 641, iters: 3360, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 641, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 641, iters: 3520, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 641, iters: 3600, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 641, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 641, iters 2389648
End of epoch 641 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001458
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 641, TEST ACC: [96.055 %]

saving the latest model (epoch 642, total_steps 2389664)
(epoch: 642, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 642, iters: 112, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 642, iters: 192, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 642, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 642, iters: 352, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 642, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 642, iters: 512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 642, iters: 592, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 642, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 642, iters: 752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 642, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 642, iters: 912, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 642, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 642, iters: 1072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 642, iters: 1152, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 642, iters: 1232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 642, iters: 1312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 642, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 642, iters: 1472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 642, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 642, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 642, iters: 1712, time: 0.094, data: 0.043) loss: 0.000 
(epoch: 642, iters: 1792, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 642, iters: 1872, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 642, iters: 1952, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 642, iters: 2032, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 642, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 642, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 642, iters: 2272, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 642, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 642, iters: 2432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 642, iters: 2512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 642, iters: 2592, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 642, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 642, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 642, iters: 2832, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 642, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 642, iters: 2992, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 642, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 642, iters: 3152, time: 0.095, data: 0.021) loss: 0.000 
(epoch: 642, iters: 3232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 642, iters: 3312, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 642, iters: 3392, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 642, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 642, iters: 3552, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 642, iters: 3632, time: 0.091, data: 0.000) loss: 0.010 
(epoch: 642, iters: 3712, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 642, iters 2393376
End of epoch 642 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001457
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 642, TEST ACC: [97.269 %]

saving the latest model (epoch 643, total_steps 2393392)
(epoch: 643, iters: 64, time: 0.094, data: 0.003) loss: 0.000 
(epoch: 643, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 643, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 643, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 643, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 643, iters: 464, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 643, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 643, iters: 624, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 643, iters: 704, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 643, iters: 784, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 643, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 643, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 643, iters: 1024, time: 0.097, data: 0.039) loss: 0.000 
(epoch: 643, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 643, iters: 1184, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 643, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 643, iters: 1344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 643, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 643, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 643, iters: 1584, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 643, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 643, iters: 1744, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 643, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 643, iters: 1904, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 643, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 643, iters: 2064, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 643, iters: 2144, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 643, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 643, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 643, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 643, iters: 2464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 643, iters: 2544, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 643, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 643, iters: 2704, time: 0.094, data: 0.040) loss: 0.008 
(epoch: 643, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 643, iters: 2864, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 643, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 643, iters: 3024, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 643, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 643, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 643, iters: 3264, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 643, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 643, iters: 3424, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 643, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 643, iters: 3584, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 643, iters: 3664, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 643, iters 2397104
End of epoch 643 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001456
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 643, TEST ACC: [96.813 %]

(epoch: 644, iters: 16, time: 0.110, data: 0.000) loss: 0.000 
saving the latest model (epoch 644, total_steps 2397120)
(epoch: 644, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 644, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 644, iters: 256, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 644, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 644, iters: 416, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 644, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 644, iters: 576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 644, iters: 656, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 644, iters: 736, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 644, iters: 816, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 644, iters: 896, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 644, iters: 976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 644, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 644, iters: 1136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 644, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 644, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 644, iters: 1376, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 644, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 644, iters: 1536, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 644, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 644, iters: 1696, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 644, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 644, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 644, iters: 1936, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 644, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 644, iters: 2096, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 644, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 644, iters: 2256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 644, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 644, iters: 2416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 644, iters: 2496, time: 0.097, data: 0.049) loss: 0.000 
(epoch: 644, iters: 2576, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 644, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 644, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 644, iters: 2816, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 644, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 644, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 644, iters: 3056, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 644, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 644, iters: 3216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 644, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 644, iters: 3376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 644, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 644, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 644, iters: 3616, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 644, iters: 3696, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 644, iters 2400832
End of epoch 644 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001455
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 644, TEST ACC: [96.965 %]

saving the latest model (epoch 645, total_steps 2400848)
(epoch: 645, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 645, iters: 128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 645, iters: 208, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 645, iters: 288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 645, iters: 368, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 645, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 645, iters: 528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 645, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 645, iters: 688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 645, iters: 768, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 645, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 645, iters: 928, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 645, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 645, iters: 1088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 645, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 645, iters: 1248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 645, iters: 1328, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 645, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 645, iters: 1488, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 645, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 645, iters: 1648, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 645, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 645, iters: 1808, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 645, iters: 1888, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 645, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 645, iters: 2048, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 645, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 645, iters: 2208, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 645, iters: 2288, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 645, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 645, iters: 2448, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 645, iters: 2528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 645, iters: 2608, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 645, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 645, iters: 2768, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 645, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 645, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 645, iters: 3008, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 645, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 645, iters: 3168, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 645, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 645, iters: 3328, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 645, iters: 3408, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 645, iters: 3488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 645, iters: 3568, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 645, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 645, iters: 3728, time: 0.055, data: 0.012) loss: 0.000 
saving the model at the end of epoch 645, iters 2404560
End of epoch 645 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001454
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 645, TEST ACC: [95.751 %]

saving the latest model (epoch 646, total_steps 2404576)
(epoch: 646, iters: 80, time: 0.096, data: 0.480) loss: 0.000 
(epoch: 646, iters: 160, time: 0.096, data: 0.031) loss: 0.000 
(epoch: 646, iters: 240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 646, iters: 320, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 646, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 646, iters: 480, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 646, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 646, iters: 640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 646, iters: 720, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 646, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 646, iters: 880, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 646, iters: 960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 646, iters: 1040, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 646, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 646, iters: 1200, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 646, iters: 1280, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 646, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 646, iters: 1440, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 646, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 646, iters: 1600, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 646, iters: 1680, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 646, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 646, iters: 1840, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 646, iters: 1920, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 646, iters: 2000, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 646, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 646, iters: 2160, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 646, iters: 2240, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 646, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 646, iters: 2400, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 646, iters: 2480, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 646, iters: 2560, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 646, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 646, iters: 2720, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 646, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 646, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 646, iters: 2960, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 646, iters: 3040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 646, iters: 3120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 646, iters: 3200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 646, iters: 3280, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 646, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 646, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 646, iters: 3520, time: 0.098, data: 0.050) loss: 0.000 
(epoch: 646, iters: 3600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 646, iters: 3680, time: 0.089, data: 0.012) loss: 0.000 
saving the model at the end of epoch 646, iters 2408288
End of epoch 646 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001453
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 646, TEST ACC: [97.876 %]

saving the latest model (epoch 647, total_steps 2408304)
(epoch: 647, iters: 32, time: 0.092, data: 0.006) loss: 0.000 
(epoch: 647, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 647, iters: 192, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 647, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 647, iters: 352, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 647, iters: 432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 647, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 647, iters: 592, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 647, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 647, iters: 752, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 647, iters: 832, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 647, iters: 912, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 647, iters: 992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 647, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 647, iters: 1152, time: 0.097, data: 0.050) loss: 0.000 
(epoch: 647, iters: 1232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 647, iters: 1312, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 647, iters: 1392, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 647, iters: 1472, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 647, iters: 1552, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 647, iters: 1632, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 647, iters: 1712, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 647, iters: 1792, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 647, iters: 1872, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 647, iters: 1952, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 647, iters: 2032, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 647, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 647, iters: 2192, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 647, iters: 2272, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 647, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 647, iters: 2432, time: 0.094, data: 0.012) loss: 0.009 
(epoch: 647, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 647, iters: 2592, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 647, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 647, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 647, iters: 2832, time: 0.097, data: 0.049) loss: 0.000 
(epoch: 647, iters: 2912, time: 0.096, data: 0.000) loss: 0.057 
(epoch: 647, iters: 2992, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 647, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 647, iters: 3152, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 647, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 647, iters: 3312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 647, iters: 3392, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 647, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 647, iters: 3552, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 647, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 647, iters: 3712, time: 0.089, data: 0.011) loss: 0.000 
saving the model at the end of epoch 647, iters 2412016
End of epoch 647 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001452
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 647, TEST ACC: [98.027 %]

saving the latest model (epoch 648, total_steps 2412032)
(epoch: 648, iters: 64, time: 0.092, data: 0.003) loss: 0.000 
(epoch: 648, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 648, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 648, iters: 304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 648, iters: 384, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 648, iters: 464, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 648, iters: 544, time: 0.096, data: 0.000) loss: 0.169 
(epoch: 648, iters: 624, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 648, iters: 704, time: 0.094, data: 0.000) loss: 0.019 
(epoch: 648, iters: 784, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 648, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 648, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 648, iters: 1024, time: 0.095, data: 0.052) loss: 0.000 
(epoch: 648, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 648, iters: 1184, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 648, iters: 1264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 648, iters: 1344, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 648, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 648, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 648, iters: 1584, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 648, iters: 1664, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 648, iters: 1744, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 648, iters: 1824, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 648, iters: 1904, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 648, iters: 1984, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 648, iters: 2064, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 648, iters: 2144, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 648, iters: 2224, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 648, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 648, iters: 2384, time: 0.094, data: 0.000) loss: 0.144 
(epoch: 648, iters: 2464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 648, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 648, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 648, iters: 2704, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 648, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 648, iters: 2864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 648, iters: 2944, time: 0.094, data: 0.000) loss: 0.045 
(epoch: 648, iters: 3024, time: 0.093, data: 0.020) loss: 0.005 
(epoch: 648, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 648, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 648, iters: 3264, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 648, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 648, iters: 3424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 648, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 648, iters: 3584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 648, iters: 3664, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 648, iters 2415744
End of epoch 648 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001451
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 648, TEST ACC: [96.965 %]

(epoch: 649, iters: 16, time: 0.111, data: 0.000) loss: 0.000 
saving the latest model (epoch 649, total_steps 2415760)
(epoch: 649, iters: 96, time: 0.094, data: 0.061) loss: 0.000 
(epoch: 649, iters: 176, time: 0.095, data: 0.000) loss: 0.161 
(epoch: 649, iters: 256, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 649, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 649, iters: 416, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 649, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 649, iters: 576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 649, iters: 656, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 649, iters: 736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 649, iters: 816, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 649, iters: 896, time: 0.094, data: 0.000) loss: 0.016 
(epoch: 649, iters: 976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 649, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 649, iters: 1136, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 649, iters: 1216, time: 0.098, data: 0.040) loss: 0.008 
(epoch: 649, iters: 1296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 649, iters: 1376, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 649, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 649, iters: 1536, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 649, iters: 1616, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 649, iters: 1696, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 649, iters: 1776, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 649, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 649, iters: 1936, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 649, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 649, iters: 2096, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 649, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 649, iters: 2256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 649, iters: 2336, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 649, iters: 2416, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 649, iters: 2496, time: 0.094, data: 0.022) loss: 0.000 
(epoch: 649, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 649, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 649, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 649, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 649, iters: 2896, time: 0.094, data: 0.040) loss: 0.044 
(epoch: 649, iters: 2976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 649, iters: 3056, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 649, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 649, iters: 3216, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 649, iters: 3296, time: 0.094, data: 0.000) loss: 0.024 
(epoch: 649, iters: 3376, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 649, iters: 3456, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 649, iters: 3536, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 649, iters: 3616, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 649, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 649, iters 2419472
End of epoch 649 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001450
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 649, TEST ACC: [96.813 %]

saving the latest model (epoch 650, total_steps 2419488)
(epoch: 650, iters: 48, time: 0.094, data: 0.004) loss: 0.000 
(epoch: 650, iters: 128, time: 0.095, data: 0.043) loss: 0.000 
(epoch: 650, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 650, iters: 288, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 650, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 650, iters: 448, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 650, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 650, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 650, iters: 688, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 650, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 650, iters: 848, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 650, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 650, iters: 1008, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 650, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 650, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 650, iters: 1248, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 650, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 650, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 650, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 650, iters: 1568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 650, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 650, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 650, iters: 1808, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 650, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 650, iters: 1968, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 650, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 650, iters: 2128, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 650, iters: 2208, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 650, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 650, iters: 2368, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 650, iters: 2448, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 650, iters: 2528, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 650, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 650, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 650, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 650, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 650, iters: 2928, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 650, iters: 3008, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 650, iters: 3088, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 650, iters: 3168, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 650, iters: 3248, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 650, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 650, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 650, iters: 3488, time: 0.097, data: 0.044) loss: 0.001 
(epoch: 650, iters: 3568, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 650, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 650, iters: 3728, time: 0.056, data: 0.000) loss: 0.044 
saving the model at the end of epoch 650, iters 2423200
End of epoch 650 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001449
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 650, TEST ACC: [93.323 %]

saving the latest model (epoch 651, total_steps 2423216)
(epoch: 651, iters: 80, time: 0.097, data: 0.528) loss: 0.013 
(epoch: 651, iters: 160, time: 0.096, data: 0.032) loss: 0.000 
(epoch: 651, iters: 240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 651, iters: 320, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 651, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 651, iters: 480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 651, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 651, iters: 640, time: 0.094, data: 0.000) loss: 0.041 
(epoch: 651, iters: 720, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 651, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 651, iters: 880, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 651, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 651, iters: 1040, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 651, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 651, iters: 1200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 651, iters: 1280, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 651, iters: 1360, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 651, iters: 1440, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 651, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 651, iters: 1600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 651, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 651, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 651, iters: 1840, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 651, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 651, iters: 2000, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 651, iters: 2080, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 651, iters: 2160, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 651, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 651, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 651, iters: 2400, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 651, iters: 2480, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 651, iters: 2560, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 651, iters: 2640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 651, iters: 2720, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 651, iters: 2800, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 651, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 651, iters: 2960, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 651, iters: 3040, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 651, iters: 3120, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 651, iters: 3200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 651, iters: 3280, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 651, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 651, iters: 3440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 651, iters: 3520, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 651, iters: 3600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 651, iters: 3680, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 651, iters 2426928
End of epoch 651 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001448
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 651, TEST ACC: [97.724 %]

saving the latest model (epoch 652, total_steps 2426944)
(epoch: 652, iters: 32, time: 0.092, data: 0.006) loss: 0.000 
(epoch: 652, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 652, iters: 192, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 652, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 652, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 652, iters: 432, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 652, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 652, iters: 592, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 652, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 652, iters: 752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 652, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 652, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 652, iters: 992, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 652, iters: 1072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 652, iters: 1152, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 652, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 652, iters: 1312, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 652, iters: 1392, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 652, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 652, iters: 1552, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 652, iters: 1632, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 652, iters: 1712, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 652, iters: 1792, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 652, iters: 1872, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 652, iters: 1952, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 652, iters: 2032, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 652, iters: 2112, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 652, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 652, iters: 2272, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 652, iters: 2352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 652, iters: 2432, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 652, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 652, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 652, iters: 2672, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 652, iters: 2752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 652, iters: 2832, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 652, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 652, iters: 2992, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 652, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 652, iters: 3152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 652, iters: 3232, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 652, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 652, iters: 3392, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 652, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 652, iters: 3552, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 652, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 652, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 652, iters 2430656
End of epoch 652 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001447
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 652, TEST ACC: [97.572 %]

saving the latest model (epoch 653, total_steps 2430672)
(epoch: 653, iters: 64, time: 0.096, data: 0.004) loss: 0.021 
(epoch: 653, iters: 144, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 653, iters: 224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 653, iters: 304, time: 0.095, data: 0.021) loss: 0.000 
(epoch: 653, iters: 384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 653, iters: 464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 653, iters: 544, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 653, iters: 624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 653, iters: 704, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 653, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 653, iters: 864, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 653, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 653, iters: 1024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 653, iters: 1104, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 653, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 653, iters: 1264, time: 0.091, data: 0.021) loss: 0.000 
(epoch: 653, iters: 1344, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 653, iters: 1424, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 653, iters: 1504, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 653, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 653, iters: 1664, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 653, iters: 1744, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 653, iters: 1824, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 653, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 653, iters: 1984, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 653, iters: 2064, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 653, iters: 2144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 653, iters: 2224, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 653, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 653, iters: 2384, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 653, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 653, iters: 2544, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 653, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 653, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 653, iters: 2784, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 653, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 653, iters: 2944, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 653, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 653, iters: 3104, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 653, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 653, iters: 3264, time: 0.092, data: 0.000) loss: 0.133 
(epoch: 653, iters: 3344, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 653, iters: 3424, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 653, iters: 3504, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 653, iters: 3584, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 653, iters: 3664, time: 0.087, data: 0.013) loss: 0.009 
saving the model at the end of epoch 653, iters 2434384
End of epoch 653 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001446
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 653, TEST ACC: [94.537 %]

(epoch: 654, iters: 16, time: 0.113, data: 0.000) loss: 0.001 
saving the latest model (epoch 654, total_steps 2434400)
(epoch: 654, iters: 96, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 654, iters: 176, time: 0.091, data: 0.011) loss: 0.033 
(epoch: 654, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 654, iters: 336, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 654, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 654, iters: 496, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 654, iters: 576, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 654, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 654, iters: 736, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 654, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 654, iters: 896, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 654, iters: 976, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 654, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 654, iters: 1136, time: 0.093, data: 0.041) loss: 0.001 
(epoch: 654, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 654, iters: 1296, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 654, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 654, iters: 1456, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 654, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 654, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 654, iters: 1696, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 654, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 654, iters: 1856, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 654, iters: 1936, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 654, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 654, iters: 2096, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 654, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 654, iters: 2256, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 654, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 654, iters: 2416, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 654, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 654, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 654, iters: 2656, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 654, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 654, iters: 2816, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 654, iters: 2896, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 654, iters: 2976, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 654, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 654, iters: 3136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 654, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 654, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 654, iters: 3376, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 654, iters: 3456, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 654, iters: 3536, time: 0.092, data: 0.011) loss: 0.006 
(epoch: 654, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 654, iters: 3696, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 654, iters 2438112
End of epoch 654 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001445
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 654, TEST ACC: [98.027 %]

saving the latest model (epoch 655, total_steps 2438128)
(epoch: 655, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 655, iters: 128, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 655, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 655, iters: 288, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 655, iters: 368, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 655, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 655, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 655, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 655, iters: 688, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 655, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 655, iters: 848, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 655, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 655, iters: 1008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 655, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 655, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 655, iters: 1248, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 655, iters: 1328, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 655, iters: 1408, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 655, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 655, iters: 1568, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 655, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 655, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 655, iters: 1808, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 655, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 655, iters: 1968, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 655, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 655, iters: 2128, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 655, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 655, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 655, iters: 2368, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 655, iters: 2448, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 655, iters: 2528, time: 0.092, data: 0.022) loss: 0.002 
(epoch: 655, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 655, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 655, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 655, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 655, iters: 2928, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 655, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 655, iters: 3088, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 655, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 655, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 655, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 655, iters: 3408, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 655, iters: 3488, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 655, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 655, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 655, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 655, iters 2441840
End of epoch 655 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001444
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 655, TEST ACC: [97.876 %]

saving the latest model (epoch 656, total_steps 2441856)
(epoch: 656, iters: 80, time: 0.093, data: 0.445) loss: 0.000 
(epoch: 656, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 656, iters: 240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 656, iters: 320, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 656, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 656, iters: 480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 656, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 656, iters: 640, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 656, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 656, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 656, iters: 880, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 656, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 656, iters: 1040, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 656, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 656, iters: 1200, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 656, iters: 1280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 656, iters: 1360, time: 0.093, data: 0.000) loss: 0.074 
(epoch: 656, iters: 1440, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 656, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 656, iters: 1600, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 656, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 656, iters: 1760, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 656, iters: 1840, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 656, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 656, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 656, iters: 2080, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 656, iters: 2160, time: 0.092, data: 0.027) loss: 0.022 
(epoch: 656, iters: 2240, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 656, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 656, iters: 2400, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 656, iters: 2480, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 656, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 656, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 656, iters: 2720, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 656, iters: 2800, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 656, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 656, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 656, iters: 3040, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 656, iters: 3120, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 656, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 656, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 656, iters: 3360, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 656, iters: 3440, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 656, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 656, iters: 3600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 656, iters: 3680, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 656, iters 2445568
End of epoch 656 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001443
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 656, TEST ACC: [95.751 %]

saving the latest model (epoch 657, total_steps 2445584)
(epoch: 657, iters: 32, time: 0.092, data: 0.006) loss: 0.014 
(epoch: 657, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 657, iters: 192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 657, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 657, iters: 352, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 657, iters: 432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 657, iters: 512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 657, iters: 592, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 657, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 657, iters: 752, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 657, iters: 832, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 657, iters: 912, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 657, iters: 992, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 657, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 657, iters: 1152, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 657, iters: 1232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 657, iters: 1312, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 657, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 657, iters: 1472, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 657, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 657, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 657, iters: 1712, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 657, iters: 1792, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 657, iters: 1872, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 657, iters: 1952, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 657, iters: 2032, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 657, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 657, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 657, iters: 2272, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 657, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 657, iters: 2432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 657, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 657, iters: 2592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 657, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 657, iters: 2752, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 657, iters: 2832, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 657, iters: 2912, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 657, iters: 2992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 657, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 657, iters: 3152, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 657, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 657, iters: 3312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 657, iters: 3392, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 657, iters: 3472, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 657, iters: 3552, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 657, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 657, iters: 3712, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 657, iters 2449296
End of epoch 657 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001442
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 657, TEST ACC: [97.876 %]

saving the latest model (epoch 658, total_steps 2449312)
(epoch: 658, iters: 64, time: 0.094, data: 0.003) loss: 0.007 
(epoch: 658, iters: 144, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 658, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 658, iters: 304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 658, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 658, iters: 464, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 658, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 658, iters: 624, time: 0.093, data: 0.000) loss: 0.047 
(epoch: 658, iters: 704, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 658, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 658, iters: 864, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 658, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 658, iters: 1024, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 658, iters: 1104, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 658, iters: 1184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 658, iters: 1264, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 658, iters: 1344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 658, iters: 1424, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 658, iters: 1504, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 658, iters: 1584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 658, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 658, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 658, iters: 1824, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 658, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 658, iters: 1984, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 658, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 658, iters: 2144, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 658, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 658, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 658, iters: 2384, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 658, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 658, iters: 2544, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 658, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 658, iters: 2704, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 658, iters: 2784, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 658, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 658, iters: 2944, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 658, iters: 3024, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 658, iters: 3104, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 658, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 658, iters: 3264, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 658, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 658, iters: 3424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 658, iters: 3504, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 658, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 658, iters: 3664, time: 0.086, data: 0.012) loss: 0.000 
saving the model at the end of epoch 658, iters 2453024
End of epoch 658 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001441
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 658, TEST ACC: [97.572 %]

(epoch: 659, iters: 16, time: 0.108, data: 0.011) loss: 0.000 
saving the latest model (epoch 659, total_steps 2453040)
(epoch: 659, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 659, iters: 176, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 659, iters: 256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 659, iters: 336, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 659, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 659, iters: 496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 659, iters: 576, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 659, iters: 656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 659, iters: 736, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 659, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 659, iters: 896, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 659, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 659, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 659, iters: 1136, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 659, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 659, iters: 1296, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 659, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 659, iters: 1456, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 659, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 659, iters: 1616, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 659, iters: 1696, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 659, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 659, iters: 1856, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 659, iters: 1936, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 659, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 659, iters: 2096, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 659, iters: 2176, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 659, iters: 2256, time: 0.097, data: 0.050) loss: 0.000 
(epoch: 659, iters: 2336, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 659, iters: 2416, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 659, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 659, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 659, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 659, iters: 2736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 659, iters: 2816, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 659, iters: 2896, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 659, iters: 2976, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 659, iters: 3056, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 659, iters: 3136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 659, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 659, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 659, iters: 3376, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 659, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 659, iters: 3536, time: 0.092, data: 0.011) loss: 0.022 
(epoch: 659, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 659, iters: 3696, time: 0.088, data: 0.013) loss: 0.000 
saving the model at the end of epoch 659, iters 2456752
End of epoch 659 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001440
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 659, TEST ACC: [97.572 %]

saving the latest model (epoch 660, total_steps 2456768)
(epoch: 660, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 660, iters: 128, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 660, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 660, iters: 288, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 660, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 660, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 660, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 660, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 660, iters: 688, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 660, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 660, iters: 848, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 660, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 660, iters: 1008, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 660, iters: 1088, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 660, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 660, iters: 1248, time: 0.094, data: 0.049) loss: 0.001 
(epoch: 660, iters: 1328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 660, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 660, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 660, iters: 1568, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 660, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 660, iters: 1728, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 660, iters: 1808, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 660, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 660, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 660, iters: 2048, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 660, iters: 2128, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 660, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 660, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 660, iters: 2368, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 660, iters: 2448, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 660, iters: 2528, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 660, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 660, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 660, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 660, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 660, iters: 2928, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 660, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 660, iters: 3088, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 660, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 660, iters: 3248, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 660, iters: 3328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 660, iters: 3408, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 660, iters: 3488, time: 0.098, data: 0.050) loss: 0.000 
(epoch: 660, iters: 3568, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 660, iters: 3648, time: 0.087, data: 0.011) loss: 0.000 
(epoch: 660, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 660, iters 2460480
End of epoch 660 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001439
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 660, TEST ACC: [96.965 %]

saving the latest model (epoch 661, total_steps 2460496)
(epoch: 661, iters: 80, time: 0.093, data: 0.467) loss: 0.000 
(epoch: 661, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 661, iters: 240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 661, iters: 320, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 661, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 661, iters: 480, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 661, iters: 560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 661, iters: 640, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 661, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 661, iters: 800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 661, iters: 880, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 661, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 661, iters: 1040, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 661, iters: 1120, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 661, iters: 1200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 661, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 661, iters: 1360, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 661, iters: 1440, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 661, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 661, iters: 1600, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 661, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 661, iters: 1760, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 661, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 661, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 661, iters: 2000, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 661, iters: 2080, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 661, iters: 2160, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 661, iters: 2240, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 661, iters: 2320, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 661, iters: 2400, time: 0.096, data: 0.000) loss: 0.055 
(epoch: 661, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 661, iters: 2560, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 661, iters: 2640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 661, iters: 2720, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 661, iters: 2800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 661, iters: 2880, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 661, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 661, iters: 3040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 661, iters: 3120, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 661, iters: 3200, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 661, iters: 3280, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 661, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 661, iters: 3440, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 661, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 661, iters: 3600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 661, iters: 3680, time: 0.087, data: 0.039) loss: 0.000 
saving the model at the end of epoch 661, iters 2464208
End of epoch 661 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001438
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 661, TEST ACC: [96.662 %]

saving the latest model (epoch 662, total_steps 2464224)
(epoch: 662, iters: 32, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 662, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 662, iters: 192, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 662, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 662, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 662, iters: 432, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 662, iters: 512, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 662, iters: 592, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 662, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 662, iters: 752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 662, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 662, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 662, iters: 992, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 662, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 662, iters: 1152, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 662, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 662, iters: 1312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 662, iters: 1392, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 662, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 662, iters: 1552, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 662, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 662, iters: 1712, time: 0.095, data: 0.012) loss: 0.011 
(epoch: 662, iters: 1792, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 662, iters: 1872, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 662, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 662, iters: 2032, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 662, iters: 2112, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 662, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 662, iters: 2272, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 662, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 662, iters: 2432, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 662, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 662, iters: 2592, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 662, iters: 2672, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 662, iters: 2752, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 662, iters: 2832, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 662, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 662, iters: 2992, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 662, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 662, iters: 3152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 662, iters: 3232, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 662, iters: 3312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 662, iters: 3392, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 662, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 662, iters: 3552, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 662, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 662, iters: 3712, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 662, iters 2467936
End of epoch 662 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001437
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 662, TEST ACC: [95.903 %]

saving the latest model (epoch 663, total_steps 2467952)
(epoch: 663, iters: 64, time: 0.096, data: 0.003) loss: 0.000 
(epoch: 663, iters: 144, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 663, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 663, iters: 304, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 663, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 663, iters: 464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 663, iters: 544, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 663, iters: 624, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 663, iters: 704, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 663, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 663, iters: 864, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 663, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 663, iters: 1024, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 663, iters: 1104, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 663, iters: 1184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 663, iters: 1264, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 663, iters: 1344, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 663, iters: 1424, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 663, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 663, iters: 1584, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 663, iters: 1664, time: 0.094, data: 0.039) loss: 0.006 
(epoch: 663, iters: 1744, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 663, iters: 1824, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 663, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 663, iters: 1984, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 663, iters: 2064, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 663, iters: 2144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 663, iters: 2224, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 663, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 663, iters: 2384, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 663, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 663, iters: 2544, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 663, iters: 2624, time: 0.095, data: 0.000) loss: 0.017 
(epoch: 663, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 663, iters: 2784, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 663, iters: 2864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 663, iters: 2944, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 663, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 663, iters: 3104, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 663, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 663, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 663, iters: 3344, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 663, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 663, iters: 3504, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 663, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 663, iters: 3664, time: 0.089, data: 0.011) loss: 0.000 
saving the model at the end of epoch 663, iters 2471664
End of epoch 663 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001436
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 663, TEST ACC: [95.751 %]

(epoch: 664, iters: 16, time: 0.107, data: 0.000) loss: 0.000 
saving the latest model (epoch 664, total_steps 2471680)
(epoch: 664, iters: 96, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 664, iters: 176, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 664, iters: 256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 664, iters: 336, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 664, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 664, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 664, iters: 576, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 664, iters: 656, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 664, iters: 736, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 664, iters: 816, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 664, iters: 896, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 664, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 664, iters: 1056, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 664, iters: 1136, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 664, iters: 1216, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 664, iters: 1296, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 664, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 664, iters: 1456, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 664, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 664, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 664, iters: 1696, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 664, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 664, iters: 1856, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 664, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 664, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 664, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 664, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 664, iters: 2256, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 664, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 664, iters: 2416, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 664, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 664, iters: 2576, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 664, iters: 2656, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 664, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 664, iters: 2816, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 664, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 664, iters: 2976, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 664, iters: 3056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 664, iters: 3136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 664, iters: 3216, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 664, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 664, iters: 3376, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 664, iters: 3456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 664, iters: 3536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 664, iters: 3616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 664, iters: 3696, time: 0.087, data: 0.021) loss: 0.001 
saving the model at the end of epoch 664, iters 2475392
End of epoch 664 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001435
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 664, TEST ACC: [96.813 %]

saving the latest model (epoch 665, total_steps 2475408)
(epoch: 665, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 665, iters: 128, time: 0.094, data: 0.028) loss: 0.017 
(epoch: 665, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 665, iters: 288, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 665, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 665, iters: 448, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 665, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 665, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 665, iters: 688, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 665, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 665, iters: 848, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 665, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 665, iters: 1008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 665, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 665, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 665, iters: 1248, time: 0.094, data: 0.039) loss: 0.011 
(epoch: 665, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 665, iters: 1408, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 665, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 665, iters: 1568, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 665, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 665, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 665, iters: 1808, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 665, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 665, iters: 1968, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 665, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 665, iters: 2128, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 665, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 665, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 665, iters: 2368, time: 0.095, data: 0.040) loss: 0.178 
(epoch: 665, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 665, iters: 2528, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 665, iters: 2608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 665, iters: 2688, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 665, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 665, iters: 2848, time: 0.094, data: 0.000) loss: 0.144 
(epoch: 665, iters: 2928, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 665, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 665, iters: 3088, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 665, iters: 3168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 665, iters: 3248, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 665, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 665, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 665, iters: 3488, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 665, iters: 3568, time: 0.094, data: 0.000) loss: 0.014 
(epoch: 665, iters: 3648, time: 0.086, data: 0.022) loss: 0.000 
(epoch: 665, iters: 3728, time: 0.056, data: 0.000) loss: 0.043 
saving the model at the end of epoch 665, iters 2479120
End of epoch 665 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001434
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 665, TEST ACC: [94.689 %]

saving the latest model (epoch 666, total_steps 2479136)
(epoch: 666, iters: 80, time: 0.096, data: 0.533) loss: 0.001 
(epoch: 666, iters: 160, time: 0.094, data: 0.000) loss: 0.055 
(epoch: 666, iters: 240, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 666, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 666, iters: 400, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 666, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 666, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 666, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 666, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 666, iters: 800, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 666, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 666, iters: 960, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 666, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 666, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 666, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 666, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 666, iters: 1360, time: 0.094, data: 0.042) loss: 0.001 
(epoch: 666, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 666, iters: 1520, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 666, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 666, iters: 1680, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 666, iters: 1760, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 666, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 666, iters: 1920, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 666, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 666, iters: 2080, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 666, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 666, iters: 2240, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 666, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 666, iters: 2400, time: 0.093, data: 0.000) loss: 0.021 
(epoch: 666, iters: 2480, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 666, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 666, iters: 2640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 666, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 666, iters: 2800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 666, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 666, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 666, iters: 3040, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 666, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 666, iters: 3200, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 666, iters: 3280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 666, iters: 3360, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 666, iters: 3440, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 666, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 666, iters: 3600, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 666, iters: 3680, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 666, iters 2482848
End of epoch 666 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001433
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 666, TEST ACC: [97.572 %]

saving the latest model (epoch 667, total_steps 2482864)
(epoch: 667, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 667, iters: 112, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 667, iters: 192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 667, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 667, iters: 352, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 667, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 667, iters: 512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 667, iters: 592, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 667, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 667, iters: 752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 667, iters: 832, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 667, iters: 912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 667, iters: 992, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 667, iters: 1072, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 667, iters: 1152, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 667, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 667, iters: 1312, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 667, iters: 1392, time: 0.093, data: 0.034) loss: 0.000 
(epoch: 667, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 667, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 667, iters: 1632, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 667, iters: 1712, time: 0.092, data: 0.036) loss: 0.000 
(epoch: 667, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 667, iters: 1872, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 667, iters: 1952, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 667, iters: 2032, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 667, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 667, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 667, iters: 2272, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 667, iters: 2352, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 667, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 667, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 667, iters: 2592, time: 0.095, data: 0.012) loss: 0.012 
(epoch: 667, iters: 2672, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 667, iters: 2752, time: 0.095, data: 0.000) loss: 0.014 
(epoch: 667, iters: 2832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 667, iters: 2912, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 667, iters: 2992, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 667, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 667, iters: 3152, time: 0.095, data: 0.000) loss: 0.059 
(epoch: 667, iters: 3232, time: 0.094, data: 0.012) loss: 0.015 
(epoch: 667, iters: 3312, time: 0.095, data: 0.027) loss: 0.004 
(epoch: 667, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 667, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 667, iters: 3552, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 667, iters: 3632, time: 0.090, data: 0.026) loss: 0.000 
(epoch: 667, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 667, iters 2486576
End of epoch 667 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001432
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 667, TEST ACC: [97.117 %]

saving the latest model (epoch 668, total_steps 2486592)
(epoch: 668, iters: 64, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 668, iters: 144, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 668, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 668, iters: 304, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 668, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 668, iters: 464, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 668, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 668, iters: 624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 668, iters: 704, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 668, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 668, iters: 864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 668, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 668, iters: 1024, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 668, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 668, iters: 1184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 668, iters: 1264, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 668, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 668, iters: 1424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 668, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 668, iters: 1584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 668, iters: 1664, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 668, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 668, iters: 1824, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 668, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 668, iters: 1984, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 668, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 668, iters: 2144, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 668, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 668, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 668, iters: 2384, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 668, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 668, iters: 2544, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 668, iters: 2624, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 668, iters: 2704, time: 0.095, data: 0.012) loss: 0.003 
(epoch: 668, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 668, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 668, iters: 2944, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 668, iters: 3024, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 668, iters: 3104, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 668, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 668, iters: 3264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 668, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 668, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 668, iters: 3504, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 668, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 668, iters: 3664, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 668, iters 2490304
End of epoch 668 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001431
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 668, TEST ACC: [95.903 %]

(epoch: 669, iters: 16, time: 0.112, data: 0.012) loss: 0.000 
saving the latest model (epoch 669, total_steps 2490320)
(epoch: 669, iters: 96, time: 0.093, data: 0.043) loss: 0.000 
(epoch: 669, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 669, iters: 256, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 669, iters: 336, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 669, iters: 416, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 669, iters: 496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 669, iters: 576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 669, iters: 656, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 669, iters: 736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 669, iters: 816, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 669, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 669, iters: 976, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 669, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 669, iters: 1136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 669, iters: 1216, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 669, iters: 1296, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 669, iters: 1376, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 669, iters: 1456, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 669, iters: 1536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 669, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 669, iters: 1696, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 669, iters: 1776, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 669, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 669, iters: 1936, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 669, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 669, iters: 2096, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 669, iters: 2176, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 669, iters: 2256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 669, iters: 2336, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 669, iters: 2416, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 669, iters: 2496, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 669, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 669, iters: 2656, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 669, iters: 2736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 669, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 669, iters: 2896, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 669, iters: 2976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 669, iters: 3056, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 669, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 669, iters: 3216, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 669, iters: 3296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 669, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 669, iters: 3456, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 669, iters: 3536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 669, iters: 3616, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 669, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 669, iters 2494032
End of epoch 669 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001430
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 669, TEST ACC: [96.965 %]

saving the latest model (epoch 670, total_steps 2494048)
(epoch: 670, iters: 48, time: 0.093, data: 0.004) loss: 0.000 
(epoch: 670, iters: 128, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 670, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 670, iters: 288, time: 0.093, data: 0.011) loss: 0.253 
(epoch: 670, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 670, iters: 448, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 670, iters: 528, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 670, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 670, iters: 688, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 670, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 670, iters: 848, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 670, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 670, iters: 1008, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 670, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 670, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 670, iters: 1248, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 670, iters: 1328, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 670, iters: 1408, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 670, iters: 1488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 670, iters: 1568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 670, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 670, iters: 1728, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 670, iters: 1808, time: 0.096, data: 0.048) loss: 0.000 
(epoch: 670, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 670, iters: 1968, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 670, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 670, iters: 2128, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 670, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 670, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 670, iters: 2368, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 670, iters: 2448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 670, iters: 2528, time: 0.093, data: 0.022) loss: 0.000 
(epoch: 670, iters: 2608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 670, iters: 2688, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 670, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 670, iters: 2848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 670, iters: 2928, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 670, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 670, iters: 3088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 670, iters: 3168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 670, iters: 3248, time: 0.096, data: 0.020) loss: 0.003 
(epoch: 670, iters: 3328, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 670, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 670, iters: 3488, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 670, iters: 3568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 670, iters: 3648, time: 0.085, data: 0.012) loss: 0.000 
(epoch: 670, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 670, iters 2497760
End of epoch 670 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001429
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 670, TEST ACC: [96.965 %]

saving the latest model (epoch 671, total_steps 2497776)
(epoch: 671, iters: 80, time: 0.095, data: 0.456) loss: 0.000 
(epoch: 671, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 671, iters: 240, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 671, iters: 320, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 671, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 671, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 671, iters: 560, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 671, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 671, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 671, iters: 800, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 671, iters: 880, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 671, iters: 960, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 671, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 671, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 671, iters: 1200, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 671, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 671, iters: 1360, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 671, iters: 1440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 671, iters: 1520, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 671, iters: 1600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 671, iters: 1680, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 671, iters: 1760, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 671, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 671, iters: 1920, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 671, iters: 2000, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 671, iters: 2080, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 671, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 671, iters: 2240, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 671, iters: 2320, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 671, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 671, iters: 2480, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 671, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 671, iters: 2640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 671, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 671, iters: 2800, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 671, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 671, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 671, iters: 3040, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 671, iters: 3120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 671, iters: 3200, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 671, iters: 3280, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 671, iters: 3360, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 671, iters: 3440, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 671, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 671, iters: 3600, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 671, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 671, iters 2501488
End of epoch 671 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001428
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 671, TEST ACC: [94.689 %]

saving the latest model (epoch 672, total_steps 2501504)
(epoch: 672, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 672, iters: 112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 672, iters: 192, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 672, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 672, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 672, iters: 432, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 672, iters: 512, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 672, iters: 592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 672, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 672, iters: 752, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 672, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 672, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 672, iters: 992, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 672, iters: 1072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 672, iters: 1152, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 672, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 672, iters: 1312, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 672, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 672, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 672, iters: 1552, time: 0.092, data: 0.050) loss: 0.000 
(epoch: 672, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 672, iters: 1712, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 672, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 672, iters: 1872, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 672, iters: 1952, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 672, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 672, iters: 2112, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 672, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 672, iters: 2272, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 672, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 672, iters: 2432, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 672, iters: 2512, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 672, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 672, iters: 2672, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 672, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 672, iters: 2832, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 672, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 672, iters: 2992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 672, iters: 3072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 672, iters: 3152, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 672, iters: 3232, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 672, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 672, iters: 3392, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 672, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 672, iters: 3552, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 672, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 672, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 672, iters 2505216
End of epoch 672 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001427
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 672, TEST ACC: [97.42 %]

saving the latest model (epoch 673, total_steps 2505232)
(epoch: 673, iters: 64, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 673, iters: 144, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 673, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 673, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 673, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 673, iters: 464, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 673, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 673, iters: 624, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 673, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 673, iters: 784, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 673, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 673, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 673, iters: 1024, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 673, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 673, iters: 1184, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 673, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 673, iters: 1344, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 673, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 673, iters: 1504, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 673, iters: 1584, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 673, iters: 1664, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 673, iters: 1744, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 673, iters: 1824, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 673, iters: 1904, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 673, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 673, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 673, iters: 2144, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 673, iters: 2224, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 673, iters: 2304, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 673, iters: 2384, time: 0.097, data: 0.000) loss: 0.094 
(epoch: 673, iters: 2464, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 673, iters: 2544, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 673, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 673, iters: 2704, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 673, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 673, iters: 2864, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 673, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 673, iters: 3024, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 673, iters: 3104, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 673, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 673, iters: 3264, time: 0.094, data: 0.050) loss: 0.001 
(epoch: 673, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 673, iters: 3424, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 673, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 673, iters: 3584, time: 0.093, data: 0.020) loss: 0.003 
(epoch: 673, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 673, iters 2508944
End of epoch 673 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001426
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 673, TEST ACC: [95.296 %]

(epoch: 674, iters: 16, time: 0.111, data: 0.000) loss: 0.000 
saving the latest model (epoch 674, total_steps 2508960)
(epoch: 674, iters: 96, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 674, iters: 176, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 674, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 674, iters: 336, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 674, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 674, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 674, iters: 576, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 674, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 674, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 674, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 674, iters: 896, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 674, iters: 976, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 674, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 674, iters: 1136, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 674, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 674, iters: 1296, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 674, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 674, iters: 1456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 674, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 674, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 674, iters: 1696, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 674, iters: 1776, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 674, iters: 1856, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 674, iters: 1936, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 674, iters: 2016, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 674, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 674, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 674, iters: 2256, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 674, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 674, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 674, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 674, iters: 2576, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 674, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 674, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 674, iters: 2816, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 674, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 674, iters: 2976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 674, iters: 3056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 674, iters: 3136, time: 0.096, data: 0.021) loss: 0.001 
(epoch: 674, iters: 3216, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 674, iters: 3296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 674, iters: 3376, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 674, iters: 3456, time: 0.097, data: 0.000) loss: 0.012 
(epoch: 674, iters: 3536, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 674, iters: 3616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 674, iters: 3696, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 674, iters 2512672
End of epoch 674 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001425
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 674, TEST ACC: [95.448 %]

saving the latest model (epoch 675, total_steps 2512688)
(epoch: 675, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 675, iters: 128, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 675, iters: 208, time: 0.095, data: 0.000) loss: 0.088 
(epoch: 675, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 675, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 675, iters: 448, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 675, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 675, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 675, iters: 688, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 675, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 675, iters: 848, time: 0.093, data: 0.012) loss: 0.019 
(epoch: 675, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 675, iters: 1008, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 675, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 675, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 675, iters: 1248, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 675, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 675, iters: 1408, time: 0.091, data: 0.012) loss: 0.025 
(epoch: 675, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 675, iters: 1568, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 675, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 675, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 675, iters: 1808, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 675, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 675, iters: 1968, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 675, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 675, iters: 2128, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 675, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 675, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 675, iters: 2368, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 675, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 675, iters: 2528, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 675, iters: 2608, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 675, iters: 2688, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 675, iters: 2768, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 675, iters: 2848, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 675, iters: 2928, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 675, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 675, iters: 3088, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 675, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 675, iters: 3248, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 675, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 675, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 675, iters: 3488, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 675, iters: 3568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 675, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 675, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 675, iters 2516400
End of epoch 675 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001424
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 675, TEST ACC: [90.137 %]

saving the latest model (epoch 676, total_steps 2516416)
(epoch: 676, iters: 80, time: 0.095, data: 0.506) loss: 0.005 
(epoch: 676, iters: 160, time: 0.094, data: 0.041) loss: 0.004 
(epoch: 676, iters: 240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 676, iters: 320, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 676, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 676, iters: 480, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 676, iters: 560, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 676, iters: 640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 676, iters: 720, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 676, iters: 800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 676, iters: 880, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 676, iters: 960, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 676, iters: 1040, time: 0.092, data: 0.012) loss: 0.138 
(epoch: 676, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 676, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 676, iters: 1280, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 676, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 676, iters: 1440, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 676, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 676, iters: 1600, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 676, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 676, iters: 1760, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 676, iters: 1840, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 676, iters: 1920, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 676, iters: 2000, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 676, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 676, iters: 2160, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 676, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 676, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 676, iters: 2400, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 676, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 676, iters: 2560, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 676, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 676, iters: 2720, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 676, iters: 2800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 676, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 676, iters: 2960, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 676, iters: 3040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 676, iters: 3120, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 676, iters: 3200, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 676, iters: 3280, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 676, iters: 3360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 676, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 676, iters: 3520, time: 0.095, data: 0.051) loss: 0.001 
(epoch: 676, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 676, iters: 3680, time: 0.089, data: 0.012) loss: 0.010 
saving the model at the end of epoch 676, iters 2520128
End of epoch 676 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001423
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 676, TEST ACC: [94.234 %]

saving the latest model (epoch 677, total_steps 2520144)
(epoch: 677, iters: 32, time: 0.094, data: 0.007) loss: 0.000 
(epoch: 677, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 677, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 677, iters: 272, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 677, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 677, iters: 432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 677, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 677, iters: 592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 677, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 677, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 677, iters: 832, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 677, iters: 912, time: 0.097, data: 0.000) loss: 0.003 
(epoch: 677, iters: 992, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 677, iters: 1072, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 677, iters: 1152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 677, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 677, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 677, iters: 1392, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 677, iters: 1472, time: 0.095, data: 0.000) loss: 0.186 
(epoch: 677, iters: 1552, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 677, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 677, iters: 1712, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 677, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 677, iters: 1872, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 677, iters: 1952, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 677, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 677, iters: 2112, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 677, iters: 2192, time: 0.095, data: 0.000) loss: 0.049 
(epoch: 677, iters: 2272, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 677, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 677, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 677, iters: 2512, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 677, iters: 2592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 677, iters: 2672, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 677, iters: 2752, time: 0.094, data: 0.000) loss: 0.332 
(epoch: 677, iters: 2832, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 677, iters: 2912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 677, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 677, iters: 3072, time: 0.097, data: 0.049) loss: 0.000 
(epoch: 677, iters: 3152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 677, iters: 3232, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 677, iters: 3312, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 677, iters: 3392, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 677, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 677, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 677, iters: 3632, time: 0.091, data: 0.039) loss: 0.000 
(epoch: 677, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 677, iters 2523856
End of epoch 677 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001422
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 677, TEST ACC: [96.965 %]

saving the latest model (epoch 678, total_steps 2523872)
(epoch: 678, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 678, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 678, iters: 224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 678, iters: 304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 678, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 678, iters: 464, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 678, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 678, iters: 624, time: 0.096, data: 0.012) loss: 0.009 
(epoch: 678, iters: 704, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 678, iters: 784, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 678, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 678, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 678, iters: 1024, time: 0.094, data: 0.052) loss: 0.000 
(epoch: 678, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 678, iters: 1184, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 678, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 678, iters: 1344, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 678, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 678, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 678, iters: 1584, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 678, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 678, iters: 1744, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 678, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 678, iters: 1904, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 678, iters: 1984, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 678, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 678, iters: 2144, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 678, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 678, iters: 2304, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 678, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 678, iters: 2464, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 678, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 678, iters: 2624, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 678, iters: 2704, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 678, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 678, iters: 2864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 678, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 678, iters: 3024, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 678, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 678, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 678, iters: 3264, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 678, iters: 3344, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 678, iters: 3424, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 678, iters: 3504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 678, iters: 3584, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 678, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 678, iters 2527584
End of epoch 678 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001421
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 678, TEST ACC: [97.269 %]

(epoch: 679, iters: 16, time: 0.111, data: 0.000) loss: 0.000 
saving the latest model (epoch 679, total_steps 2527600)
(epoch: 679, iters: 96, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 679, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 679, iters: 256, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 679, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 679, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 679, iters: 496, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 679, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 679, iters: 656, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 679, iters: 736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 679, iters: 816, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 679, iters: 896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 679, iters: 976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 679, iters: 1056, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 679, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 679, iters: 1216, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 679, iters: 1296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 679, iters: 1376, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 679, iters: 1456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 679, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 679, iters: 1616, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 679, iters: 1696, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 679, iters: 1776, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 679, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 679, iters: 1936, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 679, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 679, iters: 2096, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 679, iters: 2176, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 679, iters: 2256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 679, iters: 2336, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 679, iters: 2416, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 679, iters: 2496, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 679, iters: 2576, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 679, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 679, iters: 2736, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 679, iters: 2816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 679, iters: 2896, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 679, iters: 2976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 679, iters: 3056, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 679, iters: 3136, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 679, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 679, iters: 3296, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 679, iters: 3376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 679, iters: 3456, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 679, iters: 3536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 679, iters: 3616, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 679, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 679, iters 2531312
End of epoch 679 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001420
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 679, TEST ACC: [96.055 %]

saving the latest model (epoch 680, total_steps 2531328)
(epoch: 680, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 680, iters: 128, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 680, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 680, iters: 288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 680, iters: 368, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 680, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 680, iters: 528, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 680, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 680, iters: 688, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 680, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 680, iters: 848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 680, iters: 928, time: 0.096, data: 0.050) loss: 0.009 
(epoch: 680, iters: 1008, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 680, iters: 1088, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 680, iters: 1168, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 680, iters: 1248, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 680, iters: 1328, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 680, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 680, iters: 1488, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 680, iters: 1568, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 680, iters: 1648, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 680, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 680, iters: 1808, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 680, iters: 1888, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 680, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 680, iters: 2048, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 680, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 680, iters: 2208, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 680, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 680, iters: 2368, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 680, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 680, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 680, iters: 2608, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 680, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 680, iters: 2768, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 680, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 680, iters: 2928, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 680, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 680, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 680, iters: 3168, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 680, iters: 3248, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 680, iters: 3328, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 680, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 680, iters: 3488, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 680, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 680, iters: 3648, time: 0.087, data: 0.000) loss: 0.000 
(epoch: 680, iters: 3728, time: 0.056, data: 0.014) loss: 0.000 
saving the model at the end of epoch 680, iters 2535040
End of epoch 680 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001419
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 680, TEST ACC: [97.724 %]

saving the latest model (epoch 681, total_steps 2535056)
(epoch: 681, iters: 80, time: 0.095, data: 0.482) loss: 0.000 
(epoch: 681, iters: 160, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 681, iters: 240, time: 0.094, data: 0.039) loss: 0.007 
(epoch: 681, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 681, iters: 400, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 681, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 681, iters: 560, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 681, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 681, iters: 720, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 681, iters: 800, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 681, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 681, iters: 960, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 681, iters: 1040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 681, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 681, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 681, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 681, iters: 1360, time: 0.094, data: 0.041) loss: 0.002 
(epoch: 681, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 681, iters: 1520, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 681, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 681, iters: 1680, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 681, iters: 1760, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 681, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 681, iters: 1920, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 681, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 681, iters: 2080, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 681, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 681, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 681, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 681, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 681, iters: 2480, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 681, iters: 2560, time: 0.094, data: 0.000) loss: 0.033 
(epoch: 681, iters: 2640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 681, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 681, iters: 2800, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 681, iters: 2880, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 681, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 681, iters: 3040, time: 0.096, data: 0.052) loss: 0.000 
(epoch: 681, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 681, iters: 3200, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 681, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 681, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 681, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 681, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 681, iters: 3600, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 681, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 681, iters 2538768
End of epoch 681 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001418
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 681, TEST ACC: [96.358 %]

saving the latest model (epoch 682, total_steps 2538784)
(epoch: 682, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 682, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 682, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 682, iters: 272, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 682, iters: 352, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 682, iters: 432, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 682, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 682, iters: 592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 682, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 682, iters: 752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 682, iters: 832, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 682, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 682, iters: 992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 682, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 682, iters: 1152, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 682, iters: 1232, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 682, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 682, iters: 1392, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 682, iters: 1472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 682, iters: 1552, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 682, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 682, iters: 1712, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 682, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 682, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 682, iters: 1952, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 682, iters: 2032, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 682, iters: 2112, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 682, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 682, iters: 2272, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 682, iters: 2352, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 682, iters: 2432, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 682, iters: 2512, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 682, iters: 2592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 682, iters: 2672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 682, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 682, iters: 2832, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 682, iters: 2912, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 682, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 682, iters: 3072, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 682, iters: 3152, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 682, iters: 3232, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 682, iters: 3312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 682, iters: 3392, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 682, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 682, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 682, iters: 3632, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 682, iters: 3712, time: 0.090, data: 0.000) loss: 0.002 
saving the model at the end of epoch 682, iters 2542496
End of epoch 682 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001417
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 682, TEST ACC: [97.269 %]

saving the latest model (epoch 683, total_steps 2542512)
(epoch: 683, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 683, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 683, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 683, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 683, iters: 384, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 683, iters: 464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 683, iters: 544, time: 0.094, data: 0.013) loss: 0.005 
(epoch: 683, iters: 624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 683, iters: 704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 683, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 683, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 683, iters: 944, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 683, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 683, iters: 1104, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 683, iters: 1184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 683, iters: 1264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 683, iters: 1344, time: 0.096, data: 0.000) loss: 0.157 
(epoch: 683, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 683, iters: 1504, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 683, iters: 1584, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 683, iters: 1664, time: 0.092, data: 0.012) loss: 0.019 
(epoch: 683, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 683, iters: 1824, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 683, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 683, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 683, iters: 2064, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 683, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 683, iters: 2224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 683, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 683, iters: 2384, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 683, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 683, iters: 2544, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 683, iters: 2624, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 683, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 683, iters: 2784, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 683, iters: 2864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 683, iters: 2944, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 683, iters: 3024, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 683, iters: 3104, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 683, iters: 3184, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 683, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 683, iters: 3344, time: 0.093, data: 0.011) loss: 0.032 
(epoch: 683, iters: 3424, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 683, iters: 3504, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 683, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 683, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 683, iters 2546224
End of epoch 683 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001416
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 683, TEST ACC: [97.42 %]

(epoch: 684, iters: 16, time: 0.108, data: 0.012) loss: 0.000 
saving the latest model (epoch 684, total_steps 2546240)
(epoch: 684, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 684, iters: 176, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 684, iters: 256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 684, iters: 336, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 684, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 684, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 684, iters: 576, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 684, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 684, iters: 736, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 684, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 684, iters: 896, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 684, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 684, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 684, iters: 1136, time: 0.094, data: 0.050) loss: 0.003 
(epoch: 684, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 684, iters: 1296, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 684, iters: 1376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 684, iters: 1456, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 684, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 684, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 684, iters: 1696, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 684, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 684, iters: 1856, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 684, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 684, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 684, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 684, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 684, iters: 2256, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 684, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 684, iters: 2416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 684, iters: 2496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 684, iters: 2576, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 684, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 684, iters: 2736, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 684, iters: 2816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 684, iters: 2896, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 684, iters: 2976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 684, iters: 3056, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 684, iters: 3136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 684, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 684, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 684, iters: 3376, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 684, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 684, iters: 3536, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 684, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 684, iters: 3696, time: 0.089, data: 0.011) loss: 0.000 
saving the model at the end of epoch 684, iters 2549952
End of epoch 684 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001415
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 684, TEST ACC: [94.234 %]

saving the latest model (epoch 685, total_steps 2549968)
(epoch: 685, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 685, iters: 128, time: 0.096, data: 0.042) loss: 0.002 
(epoch: 685, iters: 208, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 685, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 685, iters: 368, time: 0.096, data: 0.000) loss: 0.387 
(epoch: 685, iters: 448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 685, iters: 528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 685, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 685, iters: 688, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 685, iters: 768, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 685, iters: 848, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 685, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 685, iters: 1008, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 685, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 685, iters: 1168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 685, iters: 1248, time: 0.097, data: 0.052) loss: 0.000 
(epoch: 685, iters: 1328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 685, iters: 1408, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 685, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 685, iters: 1568, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 685, iters: 1648, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 685, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 685, iters: 1808, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 685, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 685, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 685, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 685, iters: 2128, time: 0.094, data: 0.011) loss: 0.047 
(epoch: 685, iters: 2208, time: 0.094, data: 0.000) loss: 0.123 
(epoch: 685, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 685, iters: 2368, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 685, iters: 2448, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 685, iters: 2528, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 685, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 685, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 685, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 685, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 685, iters: 2928, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 685, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 685, iters: 3088, time: 0.094, data: 0.011) loss: 0.008 
(epoch: 685, iters: 3168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 685, iters: 3248, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 685, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 685, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 685, iters: 3488, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 685, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 685, iters: 3648, time: 0.087, data: 0.012) loss: 0.000 
(epoch: 685, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 685, iters 2553680
End of epoch 685 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001414
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 685, TEST ACC: [97.269 %]

saving the latest model (epoch 686, total_steps 2553696)
(epoch: 686, iters: 80, time: 0.093, data: 0.453) loss: 0.000 
(epoch: 686, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 686, iters: 240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 686, iters: 320, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 686, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 686, iters: 480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 686, iters: 560, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 686, iters: 640, time: 0.094, data: 0.012) loss: 0.009 
(epoch: 686, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 686, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 686, iters: 880, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 686, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 686, iters: 1040, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 686, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 686, iters: 1200, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 686, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 686, iters: 1360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 686, iters: 1440, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 686, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 686, iters: 1600, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 686, iters: 1680, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 686, iters: 1760, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 686, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 686, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 686, iters: 2000, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 686, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 686, iters: 2160, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 686, iters: 2240, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 686, iters: 2320, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 686, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 686, iters: 2480, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 686, iters: 2560, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 686, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 686, iters: 2720, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 686, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 686, iters: 2880, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 686, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 686, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 686, iters: 3120, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 686, iters: 3200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 686, iters: 3280, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 686, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 686, iters: 3440, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 686, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 686, iters: 3600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 686, iters: 3680, time: 0.089, data: 0.039) loss: 0.000 
saving the model at the end of epoch 686, iters 2557408
End of epoch 686 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001413
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 686, TEST ACC: [95.448 %]

saving the latest model (epoch 687, total_steps 2557424)
(epoch: 687, iters: 32, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 687, iters: 112, time: 0.093, data: 0.027) loss: 0.070 
(epoch: 687, iters: 192, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 687, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 687, iters: 352, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 687, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 687, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 687, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 687, iters: 672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 687, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 687, iters: 832, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 687, iters: 912, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 687, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 687, iters: 1072, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 687, iters: 1152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 687, iters: 1232, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 687, iters: 1312, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 687, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 687, iters: 1472, time: 0.097, data: 0.050) loss: 0.000 
(epoch: 687, iters: 1552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 687, iters: 1632, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 687, iters: 1712, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 687, iters: 1792, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 687, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 687, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 687, iters: 2032, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 687, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 687, iters: 2192, time: 0.094, data: 0.023) loss: 0.000 
(epoch: 687, iters: 2272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 687, iters: 2352, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 687, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 687, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 687, iters: 2592, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 687, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 687, iters: 2752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 687, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 687, iters: 2912, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 687, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 687, iters: 3072, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 687, iters: 3152, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 687, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 687, iters: 3312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 687, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 687, iters: 3472, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 687, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 687, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 687, iters: 3712, time: 0.087, data: 0.035) loss: 0.000 
saving the model at the end of epoch 687, iters 2561136
End of epoch 687 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001412
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 687, TEST ACC: [96.358 %]

saving the latest model (epoch 688, total_steps 2561152)
(epoch: 688, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 688, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 688, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 688, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 688, iters: 384, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 688, iters: 464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 688, iters: 544, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 688, iters: 624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 688, iters: 704, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 688, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 688, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 688, iters: 944, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 688, iters: 1024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 688, iters: 1104, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 688, iters: 1184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 688, iters: 1264, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 688, iters: 1344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 688, iters: 1424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 688, iters: 1504, time: 0.094, data: 0.052) loss: 0.000 
(epoch: 688, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 688, iters: 1664, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 688, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 688, iters: 1824, time: 0.092, data: 0.021) loss: 0.001 
(epoch: 688, iters: 1904, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 688, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 688, iters: 2064, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 688, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 688, iters: 2224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 688, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 688, iters: 2384, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 688, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 688, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 688, iters: 2624, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 688, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 688, iters: 2784, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 688, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 688, iters: 2944, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 688, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 688, iters: 3104, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 688, iters: 3184, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 688, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 688, iters: 3344, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 688, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 688, iters: 3504, time: 0.093, data: 0.012) loss: 0.097 
(epoch: 688, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 688, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 688, iters 2564864
End of epoch 688 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001411
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 688, TEST ACC: [96.358 %]

(epoch: 689, iters: 16, time: 0.109, data: 0.013) loss: 0.000 
saving the latest model (epoch 689, total_steps 2564880)
(epoch: 689, iters: 96, time: 0.092, data: 0.000) loss: 0.387 
(epoch: 689, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 689, iters: 256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 689, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 689, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 689, iters: 496, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 689, iters: 576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 689, iters: 656, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 689, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 689, iters: 816, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 689, iters: 896, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 689, iters: 976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 689, iters: 1056, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 689, iters: 1136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 689, iters: 1216, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 689, iters: 1296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 689, iters: 1376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 689, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 689, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 689, iters: 1616, time: 0.096, data: 0.052) loss: 0.004 
(epoch: 689, iters: 1696, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 689, iters: 1776, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 689, iters: 1856, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 689, iters: 1936, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 689, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 689, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 689, iters: 2176, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 689, iters: 2256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 689, iters: 2336, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 689, iters: 2416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 689, iters: 2496, time: 0.093, data: 0.011) loss: 0.059 
(epoch: 689, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 689, iters: 2656, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 689, iters: 2736, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 689, iters: 2816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 689, iters: 2896, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 689, iters: 2976, time: 0.093, data: 0.000) loss: 0.013 
(epoch: 689, iters: 3056, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 689, iters: 3136, time: 0.097, data: 0.000) loss: 0.010 
(epoch: 689, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 689, iters: 3296, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 689, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 689, iters: 3456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 689, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 689, iters: 3616, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 689, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 689, iters 2568592
End of epoch 689 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001410
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 689, TEST ACC: [96.813 %]

saving the latest model (epoch 690, total_steps 2568608)
(epoch: 690, iters: 48, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 690, iters: 128, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 690, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 690, iters: 288, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 690, iters: 368, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 690, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 690, iters: 528, time: 0.097, data: 0.000) loss: 0.008 
(epoch: 690, iters: 608, time: 0.094, data: 0.000) loss: 0.165 
(epoch: 690, iters: 688, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 690, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 690, iters: 848, time: 0.092, data: 0.012) loss: 0.088 
(epoch: 690, iters: 928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 690, iters: 1008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 690, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 690, iters: 1168, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 690, iters: 1248, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 690, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 690, iters: 1408, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 690, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 690, iters: 1568, time: 0.093, data: 0.012) loss: 0.010 
(epoch: 690, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 690, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 690, iters: 1808, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 690, iters: 1888, time: 0.094, data: 0.000) loss: 0.076 
(epoch: 690, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 690, iters: 2048, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 690, iters: 2128, time: 0.095, data: 0.012) loss: 0.031 
(epoch: 690, iters: 2208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 690, iters: 2288, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 690, iters: 2368, time: 0.094, data: 0.048) loss: 0.001 
(epoch: 690, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 690, iters: 2528, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 690, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 690, iters: 2688, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 690, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 690, iters: 2848, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 690, iters: 2928, time: 0.097, data: 0.050) loss: 0.000 
(epoch: 690, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 690, iters: 3088, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 690, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 690, iters: 3248, time: 0.094, data: 0.012) loss: 0.009 
(epoch: 690, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 690, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 690, iters: 3488, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 690, iters: 3568, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 690, iters: 3648, time: 0.085, data: 0.011) loss: 0.005 
(epoch: 690, iters: 3728, time: 0.058, data: 0.000) loss: 0.000 
saving the model at the end of epoch 690, iters 2572320
End of epoch 690 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001409
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 690, TEST ACC: [96.055 %]

saving the latest model (epoch 691, total_steps 2572336)
(epoch: 691, iters: 80, time: 0.094, data: 0.555) loss: 0.000 
(epoch: 691, iters: 160, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 691, iters: 240, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 691, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 691, iters: 400, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 691, iters: 480, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 691, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 691, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 691, iters: 720, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 691, iters: 800, time: 0.095, data: 0.039) loss: 0.002 
(epoch: 691, iters: 880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 691, iters: 960, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 691, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 691, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 691, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 691, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 691, iters: 1360, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 691, iters: 1440, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 691, iters: 1520, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 691, iters: 1600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 691, iters: 1680, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 691, iters: 1760, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 691, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 691, iters: 1920, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 691, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 691, iters: 2080, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 691, iters: 2160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 691, iters: 2240, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 691, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 691, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 691, iters: 2480, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 691, iters: 2560, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 691, iters: 2640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 691, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 691, iters: 2800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 691, iters: 2880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 691, iters: 2960, time: 0.092, data: 0.000) loss: 0.003 
(epoch: 691, iters: 3040, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 691, iters: 3120, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 691, iters: 3200, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 691, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 691, iters: 3360, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 691, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 691, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 691, iters: 3600, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 691, iters: 3680, time: 0.087, data: 0.000) loss: 0.028 
saving the model at the end of epoch 691, iters 2576048
End of epoch 691 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001408
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 691, TEST ACC: [95.903 %]

saving the latest model (epoch 692, total_steps 2576064)
(epoch: 692, iters: 32, time: 0.092, data: 0.005) loss: 0.000 
(epoch: 692, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 692, iters: 192, time: 0.091, data: 0.012) loss: 0.003 
(epoch: 692, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 692, iters: 352, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 692, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 692, iters: 512, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 692, iters: 592, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 692, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 692, iters: 752, time: 0.094, data: 0.023) loss: 0.001 
(epoch: 692, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 692, iters: 912, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 692, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 692, iters: 1072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 692, iters: 1152, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 692, iters: 1232, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 692, iters: 1312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 692, iters: 1392, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 692, iters: 1472, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 692, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 692, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 692, iters: 1712, time: 0.094, data: 0.039) loss: 0.004 
(epoch: 692, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 692, iters: 1872, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 692, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 692, iters: 2032, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 692, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 692, iters: 2192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 692, iters: 2272, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 692, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 692, iters: 2432, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 692, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 692, iters: 2592, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 692, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 692, iters: 2752, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 692, iters: 2832, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 692, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 692, iters: 2992, time: 0.092, data: 0.011) loss: 0.003 
(epoch: 692, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 692, iters: 3152, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 692, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 692, iters: 3312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 692, iters: 3392, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 692, iters: 3472, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 692, iters: 3552, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 692, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 692, iters: 3712, time: 0.087, data: 0.012) loss: 0.001 
saving the model at the end of epoch 692, iters 2579776
End of epoch 692 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001407
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 692, TEST ACC: [96.965 %]

saving the latest model (epoch 693, total_steps 2579792)
(epoch: 693, iters: 64, time: 0.094, data: 0.003) loss: 0.000 
(epoch: 693, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 693, iters: 224, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 693, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 693, iters: 384, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 693, iters: 464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 693, iters: 544, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 693, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 693, iters: 704, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 693, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 693, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 693, iters: 944, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 693, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 693, iters: 1104, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 693, iters: 1184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 693, iters: 1264, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 693, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 693, iters: 1424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 693, iters: 1504, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 693, iters: 1584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 693, iters: 1664, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 693, iters: 1744, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 693, iters: 1824, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 693, iters: 1904, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 693, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 693, iters: 2064, time: 0.094, data: 0.039) loss: 0.009 
(epoch: 693, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 693, iters: 2224, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 693, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 693, iters: 2384, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 693, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 693, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 693, iters: 2624, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 693, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 693, iters: 2784, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 693, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 693, iters: 2944, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 693, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 693, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 693, iters: 3184, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 693, iters: 3264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 693, iters: 3344, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 693, iters: 3424, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 693, iters: 3504, time: 0.093, data: 0.011) loss: 0.009 
(epoch: 693, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 693, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 693, iters 2583504
End of epoch 693 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001406
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 693, TEST ACC: [97.572 %]

(epoch: 694, iters: 16, time: 0.108, data: 0.013) loss: 0.000 
saving the latest model (epoch 694, total_steps 2583520)
(epoch: 694, iters: 96, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 694, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 694, iters: 256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 694, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 694, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 694, iters: 496, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 694, iters: 576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 694, iters: 656, time: 0.092, data: 0.011) loss: 0.005 
(epoch: 694, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 694, iters: 816, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 694, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 694, iters: 976, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 694, iters: 1056, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 694, iters: 1136, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 694, iters: 1216, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 694, iters: 1296, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 694, iters: 1376, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 694, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 694, iters: 1536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 694, iters: 1616, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 694, iters: 1696, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 694, iters: 1776, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 694, iters: 1856, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 694, iters: 1936, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 694, iters: 2016, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 694, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 694, iters: 2176, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 694, iters: 2256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 694, iters: 2336, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 694, iters: 2416, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 694, iters: 2496, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 694, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 694, iters: 2656, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 694, iters: 2736, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 694, iters: 2816, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 694, iters: 2896, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 694, iters: 2976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 694, iters: 3056, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 694, iters: 3136, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 694, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 694, iters: 3296, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 694, iters: 3376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 694, iters: 3456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 694, iters: 3536, time: 0.096, data: 0.000) loss: 0.012 
(epoch: 694, iters: 3616, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 694, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 694, iters 2587232
End of epoch 694 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001405
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 694, TEST ACC: [96.358 %]

saving the latest model (epoch 695, total_steps 2587248)
(epoch: 695, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 695, iters: 128, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 695, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 695, iters: 288, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 695, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 695, iters: 448, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 695, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 695, iters: 608, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 695, iters: 688, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 695, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 695, iters: 848, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 695, iters: 928, time: 0.093, data: 0.000) loss: 0.014 
(epoch: 695, iters: 1008, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 695, iters: 1088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 695, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 695, iters: 1248, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 695, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 695, iters: 1408, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 695, iters: 1488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 695, iters: 1568, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 695, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 695, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 695, iters: 1808, time: 0.094, data: 0.040) loss: 0.132 
(epoch: 695, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 695, iters: 1968, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 695, iters: 2048, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 695, iters: 2128, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 695, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 695, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 695, iters: 2368, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 695, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 695, iters: 2528, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 695, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 695, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 695, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 695, iters: 2848, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 695, iters: 2928, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 695, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 695, iters: 3088, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 695, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 695, iters: 3248, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 695, iters: 3328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 695, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 695, iters: 3488, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 695, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 695, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 695, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 695, iters 2590960
End of epoch 695 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001404
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 695, TEST ACC: [96.055 %]

saving the latest model (epoch 696, total_steps 2590976)
(epoch: 696, iters: 80, time: 0.093, data: 0.419) loss: 0.000 
(epoch: 696, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 696, iters: 240, time: 0.094, data: 0.000) loss: 0.114 
(epoch: 696, iters: 320, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 696, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 696, iters: 480, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 696, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 696, iters: 640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 696, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 696, iters: 800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 696, iters: 880, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 696, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 696, iters: 1040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 696, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 696, iters: 1200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 696, iters: 1280, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 696, iters: 1360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 696, iters: 1440, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 696, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 696, iters: 1600, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 696, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 696, iters: 1760, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 696, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 696, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 696, iters: 2000, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 696, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 696, iters: 2160, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 696, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 696, iters: 2320, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 696, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 696, iters: 2480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 696, iters: 2560, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 696, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 696, iters: 2720, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 696, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 696, iters: 2880, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 696, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 696, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 696, iters: 3120, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 696, iters: 3200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 696, iters: 3280, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 696, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 696, iters: 3440, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 696, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 696, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 696, iters: 3680, time: 0.089, data: 0.039) loss: 0.000 
saving the model at the end of epoch 696, iters 2594688
End of epoch 696 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001403
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 696, TEST ACC: [97.42 %]

saving the latest model (epoch 697, total_steps 2594704)
(epoch: 697, iters: 32, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 697, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 697, iters: 192, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 697, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 697, iters: 352, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 697, iters: 432, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 697, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 697, iters: 592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 697, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 697, iters: 752, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 697, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 697, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 697, iters: 992, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 697, iters: 1072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 697, iters: 1152, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 697, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 697, iters: 1312, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 697, iters: 1392, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 697, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 697, iters: 1552, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 697, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 697, iters: 1712, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 697, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 697, iters: 1872, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 697, iters: 1952, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 697, iters: 2032, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 697, iters: 2112, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 697, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 697, iters: 2272, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 697, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 697, iters: 2432, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 697, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 697, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 697, iters: 2672, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 697, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 697, iters: 2832, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 697, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 697, iters: 2992, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 697, iters: 3072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 697, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 697, iters: 3232, time: 0.098, data: 0.040) loss: 0.000 
(epoch: 697, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 697, iters: 3392, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 697, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 697, iters: 3552, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 697, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 697, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 697, iters 2598416
End of epoch 697 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001402
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 697, TEST ACC: [97.42 %]

saving the latest model (epoch 698, total_steps 2598432)
(epoch: 698, iters: 64, time: 0.094, data: 0.002) loss: 0.000 
(epoch: 698, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 698, iters: 224, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 698, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 698, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 698, iters: 464, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 698, iters: 544, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 698, iters: 624, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 698, iters: 704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 698, iters: 784, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 698, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 698, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 698, iters: 1024, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 698, iters: 1104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 698, iters: 1184, time: 0.094, data: 0.022) loss: 0.000 
(epoch: 698, iters: 1264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 698, iters: 1344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 698, iters: 1424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 698, iters: 1504, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 698, iters: 1584, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 698, iters: 1664, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 698, iters: 1744, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 698, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 698, iters: 1904, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 698, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 698, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 698, iters: 2144, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 698, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 698, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 698, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 698, iters: 2464, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 698, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 698, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 698, iters: 2704, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 698, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 698, iters: 2864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 698, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 698, iters: 3024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 698, iters: 3104, time: 0.096, data: 0.000) loss: 0.121 
(epoch: 698, iters: 3184, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 698, iters: 3264, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 698, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 698, iters: 3424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 698, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 698, iters: 3584, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 698, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 698, iters 2602144
End of epoch 698 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001401
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 698, TEST ACC: [98.483 %]

(epoch: 699, iters: 16, time: 0.107, data: 0.000) loss: 0.000 
saving the latest model (epoch 699, total_steps 2602160)
(epoch: 699, iters: 96, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 699, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 699, iters: 256, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 699, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 699, iters: 416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 699, iters: 496, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 699, iters: 576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 699, iters: 656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 699, iters: 736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 699, iters: 816, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 699, iters: 896, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 699, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 699, iters: 1056, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 699, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 699, iters: 1216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 699, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 699, iters: 1376, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 699, iters: 1456, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 699, iters: 1536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 699, iters: 1616, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 699, iters: 1696, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 699, iters: 1776, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 699, iters: 1856, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 699, iters: 1936, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 699, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 699, iters: 2096, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 699, iters: 2176, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 699, iters: 2256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 699, iters: 2336, time: 0.092, data: 0.011) loss: 0.073 
(epoch: 699, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 699, iters: 2496, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 699, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 699, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 699, iters: 2736, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 699, iters: 2816, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 699, iters: 2896, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 699, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 699, iters: 3056, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 699, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 699, iters: 3216, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 699, iters: 3296, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 699, iters: 3376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 699, iters: 3456, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 699, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 699, iters: 3616, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 699, iters: 3696, time: 0.086, data: 0.000) loss: 0.000 
saving the model at the end of epoch 699, iters 2605872
End of epoch 699 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001400
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 699, TEST ACC: [98.483 %]

saving the latest model (epoch 700, total_steps 2605888)
(epoch: 700, iters: 48, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 700, iters: 128, time: 0.094, data: 0.027) loss: 0.003 
(epoch: 700, iters: 208, time: 0.092, data: 0.011) loss: 0.012 
(epoch: 700, iters: 288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 700, iters: 368, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 700, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 700, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 700, iters: 608, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 700, iters: 688, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 700, iters: 768, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 700, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 700, iters: 928, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 700, iters: 1008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 700, iters: 1088, time: 0.094, data: 0.000) loss: 0.017 
(epoch: 700, iters: 1168, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 700, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 700, iters: 1328, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 700, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 700, iters: 1488, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 700, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 700, iters: 1648, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 700, iters: 1728, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 700, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 700, iters: 1888, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 700, iters: 1968, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 700, iters: 2048, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 700, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 700, iters: 2208, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 700, iters: 2288, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 700, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 700, iters: 2448, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 700, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 700, iters: 2608, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 700, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 700, iters: 2768, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 700, iters: 2848, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 700, iters: 2928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 700, iters: 3008, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 700, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 700, iters: 3168, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 700, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 700, iters: 3328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 700, iters: 3408, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 700, iters: 3488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 700, iters: 3568, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 700, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 700, iters: 3728, time: 0.056, data: 0.011) loss: 0.000 
saving the model at the end of epoch 700, iters 2609600
End of epoch 700 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001399
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 700, TEST ACC: [98.027 %]

saving the latest model (epoch 701, total_steps 2609616)
(epoch: 701, iters: 80, time: 0.095, data: 0.466) loss: 0.000 
(epoch: 701, iters: 160, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 701, iters: 240, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 701, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 701, iters: 400, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 701, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 701, iters: 560, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 701, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 701, iters: 720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 701, iters: 800, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 701, iters: 880, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 701, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 701, iters: 1040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 701, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 701, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 701, iters: 1280, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 701, iters: 1360, time: 0.096, data: 0.042) loss: 0.074 
(epoch: 701, iters: 1440, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 701, iters: 1520, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 701, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 701, iters: 1680, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 701, iters: 1760, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 701, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 701, iters: 1920, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 701, iters: 2000, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 701, iters: 2080, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 701, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 701, iters: 2240, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 701, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 701, iters: 2400, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 701, iters: 2480, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 701, iters: 2560, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 701, iters: 2640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 701, iters: 2720, time: 0.094, data: 0.000) loss: 0.025 
(epoch: 701, iters: 2800, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 701, iters: 2880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 701, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 701, iters: 3040, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 701, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 701, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 701, iters: 3280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 701, iters: 3360, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 701, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 701, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 701, iters: 3600, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 701, iters: 3680, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 701, iters 2613328
End of epoch 701 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001398
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 701, TEST ACC: [97.572 %]

saving the latest model (epoch 702, total_steps 2613344)
(epoch: 702, iters: 32, time: 0.093, data: 0.005) loss: 0.000 
(epoch: 702, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 702, iters: 192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 702, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 702, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 702, iters: 432, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 702, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 702, iters: 592, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 702, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 702, iters: 752, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 702, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 702, iters: 912, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 702, iters: 992, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 702, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 702, iters: 1152, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 702, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 702, iters: 1312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 702, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 702, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 702, iters: 1552, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 702, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 702, iters: 1712, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 702, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 702, iters: 1872, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 702, iters: 1952, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 702, iters: 2032, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 702, iters: 2112, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 702, iters: 2192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 702, iters: 2272, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 702, iters: 2352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 702, iters: 2432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 702, iters: 2512, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 702, iters: 2592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 702, iters: 2672, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 702, iters: 2752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 702, iters: 2832, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 702, iters: 2912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 702, iters: 2992, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 702, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 702, iters: 3152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 702, iters: 3232, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 702, iters: 3312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 702, iters: 3392, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 702, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 702, iters: 3552, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 702, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 702, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 702, iters 2617056
End of epoch 702 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001397
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 702, TEST ACC: [97.876 %]

saving the latest model (epoch 703, total_steps 2617072)
(epoch: 703, iters: 64, time: 0.094, data: 0.003) loss: 0.000 
(epoch: 703, iters: 144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 703, iters: 224, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 703, iters: 304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 703, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 703, iters: 464, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 703, iters: 544, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 703, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 703, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 703, iters: 784, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 703, iters: 864, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 703, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 703, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 703, iters: 1104, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 703, iters: 1184, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 703, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 703, iters: 1344, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 703, iters: 1424, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 703, iters: 1504, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 703, iters: 1584, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 703, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 703, iters: 1744, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 703, iters: 1824, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 703, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 703, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 703, iters: 2064, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 703, iters: 2144, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 703, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 703, iters: 2304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 703, iters: 2384, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 703, iters: 2464, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 703, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 703, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 703, iters: 2704, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 703, iters: 2784, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 703, iters: 2864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 703, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 703, iters: 3024, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 703, iters: 3104, time: 0.091, data: 0.037) loss: 0.000 
(epoch: 703, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 703, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 703, iters: 3344, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 703, iters: 3424, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 703, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 703, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 703, iters: 3664, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 703, iters 2620784
End of epoch 703 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001396
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 703, TEST ACC: [97.876 %]

(epoch: 704, iters: 16, time: 0.109, data: 0.012) loss: 0.000 
saving the latest model (epoch 704, total_steps 2620800)
(epoch: 704, iters: 96, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 704, iters: 176, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 704, iters: 256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 704, iters: 336, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 704, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 704, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 576, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 704, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 704, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 704, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 704, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 704, iters: 1136, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 704, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 704, iters: 1296, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 704, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 1456, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 704, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 704, iters: 1696, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 704, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 1856, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 704, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 704, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 704, iters: 2256, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 704, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 2416, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 704, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 2576, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 704, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 704, iters: 2816, time: 0.094, data: 0.049) loss: 0.003 
(epoch: 704, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 2976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 704, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 3136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 704, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 3296, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 704, iters: 3376, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 704, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 704, iters: 3536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 704, iters: 3616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 704, iters: 3696, time: 0.088, data: 0.011) loss: 0.004 
saving the model at the end of epoch 704, iters 2624512
End of epoch 704 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001395
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 704, TEST ACC: [87.86 %]

saving the latest model (epoch 705, total_steps 2624528)
(epoch: 705, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 705, iters: 128, time: 0.094, data: 0.026) loss: 0.002 
(epoch: 705, iters: 208, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 705, iters: 288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 705, iters: 368, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 705, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 705, iters: 528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 705, iters: 608, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 705, iters: 688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 705, iters: 768, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 705, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 705, iters: 928, time: 0.093, data: 0.012) loss: 0.351 
(epoch: 705, iters: 1008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 705, iters: 1088, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 705, iters: 1168, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 705, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 705, iters: 1328, time: 0.092, data: 0.011) loss: 0.003 
(epoch: 705, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 705, iters: 1488, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 705, iters: 1568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 705, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 705, iters: 1728, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 705, iters: 1808, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 705, iters: 1888, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 705, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 705, iters: 2048, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 705, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 705, iters: 2208, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 705, iters: 2288, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 705, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 705, iters: 2448, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 705, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 705, iters: 2608, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 705, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 705, iters: 2768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 705, iters: 2848, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 705, iters: 2928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 705, iters: 3008, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 705, iters: 3088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 705, iters: 3168, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 705, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 705, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 705, iters: 3408, time: 0.094, data: 0.049) loss: 0.001 
(epoch: 705, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 705, iters: 3568, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 705, iters: 3648, time: 0.088, data: 0.000) loss: 0.016 
(epoch: 705, iters: 3728, time: 0.056, data: 0.012) loss: 0.000 
saving the model at the end of epoch 705, iters 2628240
End of epoch 705 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001394
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 705, TEST ACC: [97.572 %]

saving the latest model (epoch 706, total_steps 2628256)
(epoch: 706, iters: 80, time: 0.094, data: 0.425) loss: 0.000 
(epoch: 706, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 706, iters: 240, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 706, iters: 320, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 706, iters: 400, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 706, iters: 480, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 706, iters: 560, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 706, iters: 640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 706, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 706, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 706, iters: 880, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 706, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 706, iters: 1040, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 706, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 706, iters: 1200, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 706, iters: 1280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 706, iters: 1360, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 706, iters: 1440, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 706, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 706, iters: 1600, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 706, iters: 1680, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 706, iters: 1760, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 706, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 706, iters: 1920, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 706, iters: 2000, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 706, iters: 2080, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 706, iters: 2160, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 706, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 706, iters: 2320, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 706, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 706, iters: 2480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 706, iters: 2560, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 706, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 706, iters: 2720, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 706, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 706, iters: 2880, time: 0.093, data: 0.012) loss: 0.026 
(epoch: 706, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 706, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 706, iters: 3120, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 706, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 706, iters: 3280, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 706, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 706, iters: 3440, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 706, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 706, iters: 3600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 706, iters: 3680, time: 0.087, data: 0.040) loss: 0.000 
saving the model at the end of epoch 706, iters 2631968
End of epoch 706 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001393
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 706, TEST ACC: [97.269 %]

saving the latest model (epoch 707, total_steps 2631984)
(epoch: 707, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 707, iters: 112, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 707, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 707, iters: 272, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 707, iters: 352, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 707, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 707, iters: 512, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 707, iters: 592, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 707, iters: 672, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 707, iters: 752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 707, iters: 832, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 707, iters: 912, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 707, iters: 992, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 707, iters: 1072, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 707, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 707, iters: 1232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 707, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 707, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 707, iters: 1472, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 707, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 707, iters: 1632, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 707, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 707, iters: 1792, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 707, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 707, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 707, iters: 2032, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 707, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 707, iters: 2192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 707, iters: 2272, time: 0.095, data: 0.000) loss: 0.027 
(epoch: 707, iters: 2352, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 707, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 707, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 707, iters: 2592, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 707, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 707, iters: 2752, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 707, iters: 2832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 707, iters: 2912, time: 0.095, data: 0.021) loss: 0.000 
(epoch: 707, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 707, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 707, iters: 3152, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 707, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 707, iters: 3312, time: 0.091, data: 0.012) loss: 0.015 
(epoch: 707, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 707, iters: 3472, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 707, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 707, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 707, iters: 3712, time: 0.088, data: 0.035) loss: 0.000 
saving the model at the end of epoch 707, iters 2635696
End of epoch 707 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001392
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 707, TEST ACC: [96.51 %]

saving the latest model (epoch 708, total_steps 2635712)
(epoch: 708, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 708, iters: 144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 708, iters: 224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 708, iters: 304, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 708, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 708, iters: 464, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 708, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 708, iters: 624, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 708, iters: 704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 708, iters: 784, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 708, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 708, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 708, iters: 1024, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 708, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 708, iters: 1184, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 708, iters: 1264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 708, iters: 1344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 708, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 708, iters: 1504, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 708, iters: 1584, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 708, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 708, iters: 1744, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 708, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 708, iters: 1904, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 708, iters: 1984, time: 0.094, data: 0.000) loss: 0.086 
(epoch: 708, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 708, iters: 2144, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 708, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 708, iters: 2304, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 708, iters: 2384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 708, iters: 2464, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 708, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 708, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 708, iters: 2704, time: 0.097, data: 0.052) loss: 0.000 
(epoch: 708, iters: 2784, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 708, iters: 2864, time: 0.093, data: 0.011) loss: 0.012 
(epoch: 708, iters: 2944, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 708, iters: 3024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 708, iters: 3104, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 708, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 708, iters: 3264, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 708, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 708, iters: 3424, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 708, iters: 3504, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 708, iters: 3584, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 708, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 708, iters 2639424
End of epoch 708 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001391
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 708, TEST ACC: [96.965 %]

(epoch: 709, iters: 16, time: 0.111, data: 0.000) loss: 0.000 
saving the latest model (epoch 709, total_steps 2639440)
(epoch: 709, iters: 96, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 709, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 709, iters: 256, time: 0.093, data: 0.040) loss: 0.038 
(epoch: 709, iters: 336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 709, iters: 416, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 709, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 709, iters: 576, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 709, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 709, iters: 736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 709, iters: 816, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 709, iters: 896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 709, iters: 976, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 709, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 709, iters: 1136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 709, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 709, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 709, iters: 1376, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 709, iters: 1456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 709, iters: 1536, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 709, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 709, iters: 1696, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 709, iters: 1776, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 709, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 709, iters: 1936, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 709, iters: 2016, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 709, iters: 2096, time: 0.093, data: 0.012) loss: 0.188 
(epoch: 709, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 709, iters: 2256, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 709, iters: 2336, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 709, iters: 2416, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 709, iters: 2496, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 709, iters: 2576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 709, iters: 2656, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 709, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 709, iters: 2816, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 709, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 709, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 709, iters: 3056, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 709, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 709, iters: 3216, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 709, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 709, iters: 3376, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 709, iters: 3456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 709, iters: 3536, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 709, iters: 3616, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 709, iters: 3696, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 709, iters 2643152
End of epoch 709 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001390
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 709, TEST ACC: [96.51 %]

saving the latest model (epoch 710, total_steps 2643168)
(epoch: 710, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 710, iters: 128, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 710, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 710, iters: 288, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 710, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 710, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 710, iters: 528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 710, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 710, iters: 688, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 710, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 710, iters: 848, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 710, iters: 928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 710, iters: 1008, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 710, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 710, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 710, iters: 1248, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 710, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 710, iters: 1408, time: 0.092, data: 0.011) loss: 0.011 
(epoch: 710, iters: 1488, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 710, iters: 1568, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 710, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 710, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 710, iters: 1808, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 710, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 710, iters: 1968, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 710, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 710, iters: 2128, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 710, iters: 2208, time: 0.096, data: 0.000) loss: 0.007 
(epoch: 710, iters: 2288, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 710, iters: 2368, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 710, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 710, iters: 2528, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 710, iters: 2608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 710, iters: 2688, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 710, iters: 2768, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 710, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 710, iters: 2928, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 710, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 710, iters: 3088, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 710, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 710, iters: 3248, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 710, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 710, iters: 3408, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 710, iters: 3488, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 710, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 710, iters: 3648, time: 0.086, data: 0.013) loss: 0.000 
(epoch: 710, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 710, iters 2646880
End of epoch 710 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001389
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 710, TEST ACC: [95.599 %]

saving the latest model (epoch 711, total_steps 2646896)
(epoch: 711, iters: 80, time: 0.093, data: 0.432) loss: 0.000 
(epoch: 711, iters: 160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 711, iters: 240, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 711, iters: 320, time: 0.093, data: 0.039) loss: 0.004 
(epoch: 711, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 711, iters: 480, time: 0.094, data: 0.012) loss: 0.314 
(epoch: 711, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 711, iters: 640, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 711, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 711, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 711, iters: 880, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 711, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 711, iters: 1040, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 711, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 711, iters: 1200, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 711, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 711, iters: 1360, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 711, iters: 1440, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 711, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 711, iters: 1600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 711, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 711, iters: 1760, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 711, iters: 1840, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 711, iters: 1920, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 711, iters: 2000, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 711, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 711, iters: 2160, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 711, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 711, iters: 2320, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 711, iters: 2400, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 711, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 711, iters: 2560, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 711, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 711, iters: 2720, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 711, iters: 2800, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 711, iters: 2880, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 711, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 711, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 711, iters: 3120, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 711, iters: 3200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 711, iters: 3280, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 711, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 711, iters: 3440, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 711, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 711, iters: 3600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 711, iters: 3680, time: 0.088, data: 0.039) loss: 0.000 
saving the model at the end of epoch 711, iters 2650608
End of epoch 711 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001388
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 711, TEST ACC: [97.572 %]

saving the latest model (epoch 712, total_steps 2650624)
(epoch: 712, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 712, iters: 112, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 712, iters: 192, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 712, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 712, iters: 352, time: 0.094, data: 0.012) loss: 0.101 
(epoch: 712, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 712, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 712, iters: 592, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 712, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 712, iters: 752, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 712, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 712, iters: 912, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 712, iters: 992, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 712, iters: 1072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 712, iters: 1152, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 712, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 712, iters: 1312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 712, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 712, iters: 1472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 712, iters: 1552, time: 0.095, data: 0.000) loss: 0.134 
(epoch: 712, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 712, iters: 1712, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 712, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 712, iters: 1872, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 712, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 712, iters: 2032, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 712, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 712, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 712, iters: 2272, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 712, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 712, iters: 2432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 712, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 712, iters: 2592, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 712, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 712, iters: 2752, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 712, iters: 2832, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 712, iters: 2912, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 712, iters: 2992, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 712, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 712, iters: 3152, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 712, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 712, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 712, iters: 3392, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 712, iters: 3472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 712, iters: 3552, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 712, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 712, iters: 3712, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 712, iters 2654336
End of epoch 712 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001387
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 712, TEST ACC: [97.572 %]

saving the latest model (epoch 713, total_steps 2654352)
(epoch: 713, iters: 64, time: 0.091, data: 0.003) loss: 0.000 
(epoch: 713, iters: 144, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 713, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 713, iters: 304, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 713, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 713, iters: 464, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 713, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 713, iters: 624, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 713, iters: 704, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 713, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 713, iters: 864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 713, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 713, iters: 1024, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 713, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 713, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 713, iters: 1264, time: 0.097, data: 0.044) loss: 0.000 
(epoch: 713, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 713, iters: 1424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 713, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 713, iters: 1584, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 713, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 713, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 713, iters: 1824, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 713, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 713, iters: 1984, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 713, iters: 2064, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 713, iters: 2144, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 713, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 713, iters: 2304, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 713, iters: 2384, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 713, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 713, iters: 2544, time: 0.093, data: 0.011) loss: 0.262 
(epoch: 713, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 713, iters: 2704, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 713, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 713, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 713, iters: 2944, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 713, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 713, iters: 3104, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 713, iters: 3184, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 713, iters: 3264, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 713, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 713, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 713, iters: 3504, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 713, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 713, iters: 3664, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 713, iters 2658064
End of epoch 713 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001386
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 713, TEST ACC: [97.269 %]

(epoch: 714, iters: 16, time: 0.112, data: 0.013) loss: 0.000 
saving the latest model (epoch 714, total_steps 2658080)
(epoch: 714, iters: 96, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 714, iters: 176, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 714, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 714, iters: 336, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 714, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 714, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 714, iters: 576, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 714, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 714, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 714, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 714, iters: 896, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 714, iters: 976, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 714, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 714, iters: 1136, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 714, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 714, iters: 1296, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 714, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 714, iters: 1456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 714, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 714, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 714, iters: 1696, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 714, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 714, iters: 1856, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 714, iters: 1936, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 714, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 714, iters: 2096, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 714, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 714, iters: 2256, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 714, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 714, iters: 2416, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 714, iters: 2496, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 714, iters: 2576, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 714, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 714, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 714, iters: 2816, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 714, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 714, iters: 2976, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 714, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 714, iters: 3136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 714, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 714, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 714, iters: 3376, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 714, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 714, iters: 3536, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 714, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 714, iters: 3696, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 714, iters 2661792
End of epoch 714 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001385
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 714, TEST ACC: [97.724 %]

saving the latest model (epoch 715, total_steps 2661808)
(epoch: 715, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 715, iters: 128, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 715, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 715, iters: 288, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 715, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 715, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 715, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 715, iters: 608, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 715, iters: 688, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 715, iters: 768, time: 0.094, data: 0.000) loss: 0.072 
(epoch: 715, iters: 848, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 715, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 715, iters: 1008, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 715, iters: 1088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 715, iters: 1168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 715, iters: 1248, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 715, iters: 1328, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 715, iters: 1408, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 715, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 715, iters: 1568, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 715, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 715, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 715, iters: 1808, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 715, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 715, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 715, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 715, iters: 2128, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 715, iters: 2208, time: 0.095, data: 0.000) loss: 0.011 
(epoch: 715, iters: 2288, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 715, iters: 2368, time: 0.093, data: 0.039) loss: 0.003 
(epoch: 715, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 715, iters: 2528, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 715, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 715, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 715, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 715, iters: 2848, time: 0.093, data: 0.000) loss: 0.040 
(epoch: 715, iters: 2928, time: 0.094, data: 0.048) loss: 0.001 
(epoch: 715, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 715, iters: 3088, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 715, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 715, iters: 3248, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 715, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 715, iters: 3408, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 715, iters: 3488, time: 0.094, data: 0.039) loss: 0.153 
(epoch: 715, iters: 3568, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 715, iters: 3648, time: 0.086, data: 0.012) loss: 0.058 
(epoch: 715, iters: 3728, time: 0.057, data: 0.000) loss: 0.002 
saving the model at the end of epoch 715, iters 2665520
End of epoch 715 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001384
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 715, TEST ACC: [95.751 %]

saving the latest model (epoch 716, total_steps 2665536)
(epoch: 716, iters: 80, time: 0.096, data: 0.522) loss: 0.020 
(epoch: 716, iters: 160, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 716, iters: 240, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 716, iters: 320, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 716, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 716, iters: 480, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 716, iters: 560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 716, iters: 640, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 716, iters: 720, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 716, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 716, iters: 880, time: 0.091, data: 0.012) loss: 0.042 
(epoch: 716, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 716, iters: 1040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 716, iters: 1120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 716, iters: 1200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 716, iters: 1280, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 716, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 716, iters: 1440, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 716, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 716, iters: 1600, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 716, iters: 1680, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 716, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 716, iters: 1840, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 716, iters: 1920, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 716, iters: 2000, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 716, iters: 2080, time: 0.093, data: 0.000) loss: 0.013 
(epoch: 716, iters: 2160, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 716, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 716, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 716, iters: 2400, time: 0.094, data: 0.042) loss: 0.001 
(epoch: 716, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 716, iters: 2560, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 716, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 716, iters: 2720, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 716, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 716, iters: 2880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 716, iters: 2960, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 716, iters: 3040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 716, iters: 3120, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 716, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 716, iters: 3280, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 716, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 716, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 716, iters: 3520, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 716, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 716, iters: 3680, time: 0.087, data: 0.012) loss: 0.005 
saving the model at the end of epoch 716, iters 2669248
End of epoch 716 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001383
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 716, TEST ACC: [97.269 %]

saving the latest model (epoch 717, total_steps 2669264)
(epoch: 717, iters: 32, time: 0.092, data: 0.006) loss: 0.000 
(epoch: 717, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 717, iters: 192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 717, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 717, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 717, iters: 432, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 717, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 717, iters: 592, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 717, iters: 672, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 717, iters: 752, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 717, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 717, iters: 912, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 717, iters: 992, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 717, iters: 1072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 717, iters: 1152, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 717, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 717, iters: 1312, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 717, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 717, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 717, iters: 1552, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 717, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 717, iters: 1712, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 717, iters: 1792, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 717, iters: 1872, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 717, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 717, iters: 2032, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 717, iters: 2112, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 717, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 717, iters: 2272, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 717, iters: 2352, time: 0.095, data: 0.000) loss: 0.019 
(epoch: 717, iters: 2432, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 717, iters: 2512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 717, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 717, iters: 2672, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 717, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 717, iters: 2832, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 717, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 717, iters: 2992, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 717, iters: 3072, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 717, iters: 3152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 717, iters: 3232, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 717, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 717, iters: 3392, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 717, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 717, iters: 3552, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 717, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 717, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 717, iters 2672976
End of epoch 717 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001382
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 717, TEST ACC: [97.269 %]

saving the latest model (epoch 718, total_steps 2672992)
(epoch: 718, iters: 64, time: 0.094, data: 0.003) loss: 0.000 
(epoch: 718, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 718, iters: 224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 718, iters: 304, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 718, iters: 384, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 718, iters: 464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 718, iters: 544, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 718, iters: 624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 718, iters: 704, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 718, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 718, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 718, iters: 944, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 718, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 718, iters: 1104, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 718, iters: 1184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 718, iters: 1264, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 718, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 718, iters: 1424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 718, iters: 1504, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 718, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 718, iters: 1664, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 718, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 718, iters: 1824, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 718, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 718, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 718, iters: 2064, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 718, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 718, iters: 2224, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 718, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 718, iters: 2384, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 718, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 718, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 718, iters: 2624, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 718, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 718, iters: 2784, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 718, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 718, iters: 2944, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 718, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 718, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 718, iters: 3184, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 718, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 718, iters: 3344, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 718, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 718, iters: 3504, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 718, iters: 3584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 718, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 718, iters 2676704
End of epoch 718 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001381
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 718, TEST ACC: [97.724 %]

(epoch: 719, iters: 16, time: 0.115, data: 0.012) loss: 0.000 
saving the latest model (epoch 719, total_steps 2676720)
(epoch: 719, iters: 96, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 719, iters: 176, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 719, iters: 256, time: 0.095, data: 0.000) loss: 0.018 
(epoch: 719, iters: 336, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 719, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 719, iters: 496, time: 0.093, data: 0.000) loss: 0.021 
(epoch: 719, iters: 576, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 719, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 719, iters: 736, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 719, iters: 816, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 719, iters: 896, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 719, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 719, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 719, iters: 1136, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 719, iters: 1216, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 719, iters: 1296, time: 0.093, data: 0.022) loss: 0.000 
(epoch: 719, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 719, iters: 1456, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 719, iters: 1536, time: 0.095, data: 0.000) loss: 0.024 
(epoch: 719, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 719, iters: 1696, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 719, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 719, iters: 1856, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 719, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 719, iters: 2016, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 719, iters: 2096, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 719, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 719, iters: 2256, time: 0.094, data: 0.047) loss: 0.000 
(epoch: 719, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 719, iters: 2416, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 719, iters: 2496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 719, iters: 2576, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 719, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 719, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 719, iters: 2816, time: 0.095, data: 0.052) loss: 0.000 
(epoch: 719, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 719, iters: 2976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 719, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 719, iters: 3136, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 719, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 719, iters: 3296, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 719, iters: 3376, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 719, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 719, iters: 3536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 719, iters: 3616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 719, iters: 3696, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 719, iters 2680432
End of epoch 719 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001380
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 719, TEST ACC: [96.055 %]

saving the latest model (epoch 720, total_steps 2680448)
(epoch: 720, iters: 48, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 720, iters: 128, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 720, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 720, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 720, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 720, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 720, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 720, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 720, iters: 688, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 720, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 720, iters: 848, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 720, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 720, iters: 1008, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 720, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 720, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 720, iters: 1248, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 720, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 720, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 720, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 720, iters: 1568, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 720, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 720, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 720, iters: 1808, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 720, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 720, iters: 1968, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 720, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 720, iters: 2128, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 720, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 720, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 720, iters: 2368, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 720, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 720, iters: 2528, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 720, iters: 2608, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 720, iters: 2688, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 720, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 720, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 720, iters: 2928, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 720, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 720, iters: 3088, time: 0.091, data: 0.011) loss: 0.001 
(epoch: 720, iters: 3168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 720, iters: 3248, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 720, iters: 3328, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 720, iters: 3408, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 720, iters: 3488, time: 0.092, data: 0.039) loss: 0.000 
(epoch: 720, iters: 3568, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 720, iters: 3648, time: 0.085, data: 0.012) loss: 0.000 
(epoch: 720, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 720, iters 2684160
End of epoch 720 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001379
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 720, TEST ACC: [96.965 %]

saving the latest model (epoch 721, total_steps 2684176)
(epoch: 721, iters: 80, time: 0.095, data: 0.504) loss: 0.000 
(epoch: 721, iters: 160, time: 0.093, data: 0.030) loss: 0.000 
(epoch: 721, iters: 240, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 721, iters: 320, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 721, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 721, iters: 480, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 721, iters: 560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 721, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 721, iters: 720, time: 0.095, data: 0.040) loss: 0.005 
(epoch: 721, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 721, iters: 880, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 721, iters: 960, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 721, iters: 1040, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 721, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 721, iters: 1200, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 721, iters: 1280, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 721, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 721, iters: 1440, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 721, iters: 1520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 721, iters: 1600, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 721, iters: 1680, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 721, iters: 1760, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 721, iters: 1840, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 721, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 721, iters: 2000, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 721, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 721, iters: 2160, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 721, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 721, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 721, iters: 2400, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 721, iters: 2480, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 721, iters: 2560, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 721, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 721, iters: 2720, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 721, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 721, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 721, iters: 2960, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 721, iters: 3040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 721, iters: 3120, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 721, iters: 3200, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 721, iters: 3280, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 721, iters: 3360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 721, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 721, iters: 3520, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 721, iters: 3600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 721, iters: 3680, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 721, iters 2687888
End of epoch 721 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001378
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 721, TEST ACC: [97.117 %]

saving the latest model (epoch 722, total_steps 2687904)
(epoch: 722, iters: 32, time: 0.093, data: 0.006) loss: 0.000 
(epoch: 722, iters: 112, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 722, iters: 192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 722, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 722, iters: 352, time: 0.094, data: 0.048) loss: 0.013 
(epoch: 722, iters: 432, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 722, iters: 512, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 722, iters: 592, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 722, iters: 672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 722, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 722, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 722, iters: 912, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 722, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 722, iters: 1072, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 722, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 722, iters: 1232, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 722, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 722, iters: 1392, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 722, iters: 1472, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 722, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 722, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 722, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 722, iters: 1792, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 722, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 722, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 722, iters: 2032, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 722, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 722, iters: 2192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 722, iters: 2272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 722, iters: 2352, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 722, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 722, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 722, iters: 2592, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 722, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 722, iters: 2752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 722, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 722, iters: 2912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 722, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 722, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 722, iters: 3152, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 722, iters: 3232, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 722, iters: 3312, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 722, iters: 3392, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 722, iters: 3472, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 722, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 722, iters: 3632, time: 0.092, data: 0.000) loss: 0.010 
(epoch: 722, iters: 3712, time: 0.089, data: 0.035) loss: 0.000 
saving the model at the end of epoch 722, iters 2691616
End of epoch 722 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001377
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 722, TEST ACC: [96.055 %]

saving the latest model (epoch 723, total_steps 2691632)
(epoch: 723, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 723, iters: 144, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 723, iters: 224, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 723, iters: 304, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 723, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 723, iters: 464, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 723, iters: 544, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 723, iters: 624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 723, iters: 704, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 723, iters: 784, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 723, iters: 864, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 723, iters: 944, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 723, iters: 1024, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 723, iters: 1104, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 723, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 723, iters: 1264, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 723, iters: 1344, time: 0.093, data: 0.000) loss: 0.012 
(epoch: 723, iters: 1424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 723, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 723, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 723, iters: 1664, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 723, iters: 1744, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 723, iters: 1824, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 723, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 723, iters: 1984, time: 0.093, data: 0.011) loss: 0.040 
(epoch: 723, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 723, iters: 2144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 723, iters: 2224, time: 0.093, data: 0.048) loss: 0.002 
(epoch: 723, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 723, iters: 2384, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 723, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 723, iters: 2544, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 723, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 723, iters: 2704, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 723, iters: 2784, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 723, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 723, iters: 2944, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 723, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 723, iters: 3104, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 723, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 723, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 723, iters: 3344, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 723, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 723, iters: 3504, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 723, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 723, iters: 3664, time: 0.086, data: 0.011) loss: 0.000 
saving the model at the end of epoch 723, iters 2695344
End of epoch 723 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001376
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 723, TEST ACC: [94.992 %]

(epoch: 724, iters: 16, time: 0.111, data: 0.000) loss: 0.000 
saving the latest model (epoch 724, total_steps 2695360)
(epoch: 724, iters: 96, time: 0.096, data: 0.043) loss: 0.000 
(epoch: 724, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 724, iters: 256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 724, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 724, iters: 416, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 724, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 724, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 724, iters: 656, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 724, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 724, iters: 816, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 724, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 724, iters: 976, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 724, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 724, iters: 1136, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 724, iters: 1216, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 724, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 724, iters: 1376, time: 0.091, data: 0.011) loss: 0.004 
(epoch: 724, iters: 1456, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 724, iters: 1536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 724, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 724, iters: 1696, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 724, iters: 1776, time: 0.095, data: 0.051) loss: 0.057 
(epoch: 724, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 724, iters: 1936, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 724, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 724, iters: 2096, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 724, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 724, iters: 2256, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 724, iters: 2336, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 724, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 724, iters: 2496, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 724, iters: 2576, time: 0.093, data: 0.000) loss: 0.308 
(epoch: 724, iters: 2656, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 724, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 724, iters: 2816, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 724, iters: 2896, time: 0.095, data: 0.039) loss: 0.195 
(epoch: 724, iters: 2976, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 724, iters: 3056, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 724, iters: 3136, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 724, iters: 3216, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 724, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 724, iters: 3376, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 724, iters: 3456, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 724, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 724, iters: 3616, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 724, iters: 3696, time: 0.088, data: 0.000) loss: 0.167 
saving the model at the end of epoch 724, iters 2699072
End of epoch 724 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001375
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 724, TEST ACC: [94.841 %]

saving the latest model (epoch 725, total_steps 2699088)
(epoch: 725, iters: 48, time: 0.093, data: 0.004) loss: 0.001 
(epoch: 725, iters: 128, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 725, iters: 208, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 725, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 725, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 725, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 725, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 725, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 725, iters: 688, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 725, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 725, iters: 848, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 725, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 725, iters: 1008, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 725, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 725, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 725, iters: 1248, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 725, iters: 1328, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 725, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 725, iters: 1488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 725, iters: 1568, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 725, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 725, iters: 1728, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 725, iters: 1808, time: 0.096, data: 0.041) loss: 0.006 
(epoch: 725, iters: 1888, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 725, iters: 1968, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 725, iters: 2048, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 725, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 725, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 725, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 725, iters: 2368, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 725, iters: 2448, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 725, iters: 2528, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 725, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 725, iters: 2688, time: 0.093, data: 0.012) loss: 0.007 
(epoch: 725, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 725, iters: 2848, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 725, iters: 2928, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 725, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 725, iters: 3088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 725, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 725, iters: 3248, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 725, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 725, iters: 3408, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 725, iters: 3488, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 725, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 725, iters: 3648, time: 0.085, data: 0.012) loss: 0.000 
(epoch: 725, iters: 3728, time: 0.055, data: 0.000) loss: 0.000 
saving the model at the end of epoch 725, iters 2702800
End of epoch 725 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001374
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 725, TEST ACC: [96.055 %]

saving the latest model (epoch 726, total_steps 2702816)
(epoch: 726, iters: 80, time: 0.094, data: 0.512) loss: 0.000 
(epoch: 726, iters: 160, time: 0.094, data: 0.031) loss: 0.025 
(epoch: 726, iters: 240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 726, iters: 320, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 726, iters: 400, time: 0.093, data: 0.000) loss: 0.178 
(epoch: 726, iters: 480, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 726, iters: 560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 726, iters: 640, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 726, iters: 720, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 726, iters: 800, time: 0.095, data: 0.000) loss: 0.029 
(epoch: 726, iters: 880, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 726, iters: 960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 726, iters: 1040, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 726, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 726, iters: 1200, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 726, iters: 1280, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 726, iters: 1360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 726, iters: 1440, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 726, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 726, iters: 1600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 726, iters: 1680, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 726, iters: 1760, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 726, iters: 1840, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 726, iters: 1920, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 726, iters: 2000, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 726, iters: 2080, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 726, iters: 2160, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 726, iters: 2240, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 726, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 726, iters: 2400, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 726, iters: 2480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 726, iters: 2560, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 726, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 726, iters: 2720, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 726, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 726, iters: 2880, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 726, iters: 2960, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 726, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 726, iters: 3120, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 726, iters: 3200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 726, iters: 3280, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 726, iters: 3360, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 726, iters: 3440, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 726, iters: 3520, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 726, iters: 3600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 726, iters: 3680, time: 0.086, data: 0.013) loss: 0.001 
saving the model at the end of epoch 726, iters 2706528
End of epoch 726 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001373
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 726, TEST ACC: [88.923 %]

saving the latest model (epoch 727, total_steps 2706544)
(epoch: 727, iters: 32, time: 0.094, data: 0.006) loss: 0.000 
(epoch: 727, iters: 112, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 727, iters: 192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 727, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 727, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 727, iters: 432, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 727, iters: 512, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 727, iters: 592, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 727, iters: 672, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 727, iters: 752, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 727, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 727, iters: 912, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 727, iters: 992, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 727, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 727, iters: 1152, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 727, iters: 1232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 727, iters: 1312, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 727, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 727, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 727, iters: 1552, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 727, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 727, iters: 1712, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 727, iters: 1792, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 727, iters: 1872, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 727, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 727, iters: 2032, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 727, iters: 2112, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 727, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 727, iters: 2272, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 727, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 727, iters: 2432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 727, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 727, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 727, iters: 2672, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 727, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 727, iters: 2832, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 727, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 727, iters: 2992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 727, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 727, iters: 3152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 727, iters: 3232, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 727, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 727, iters: 3392, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 727, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 727, iters: 3552, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 727, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 727, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 727, iters 2710256
End of epoch 727 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001372
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 727, TEST ACC: [96.358 %]

saving the latest model (epoch 728, total_steps 2710272)
(epoch: 728, iters: 64, time: 0.092, data: 0.003) loss: 0.002 
(epoch: 728, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 728, iters: 224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 728, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 728, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 728, iters: 464, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 728, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 728, iters: 624, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 728, iters: 704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 728, iters: 784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 728, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 728, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 728, iters: 1024, time: 0.094, data: 0.039) loss: 0.004 
(epoch: 728, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 728, iters: 1184, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 728, iters: 1264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 728, iters: 1344, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 728, iters: 1424, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 728, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 728, iters: 1584, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 728, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 728, iters: 1744, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 728, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 728, iters: 1904, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 728, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 728, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 728, iters: 2144, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 728, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 728, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 728, iters: 2384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 728, iters: 2464, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 728, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 728, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 728, iters: 2704, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 728, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 728, iters: 2864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 728, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 728, iters: 3024, time: 0.094, data: 0.011) loss: 0.107 
(epoch: 728, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 728, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 728, iters: 3264, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 728, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 728, iters: 3424, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 728, iters: 3504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 728, iters: 3584, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 728, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 728, iters 2713984
End of epoch 728 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001371
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 728, TEST ACC: [95.903 %]

(epoch: 729, iters: 16, time: 0.108, data: 0.000) loss: 0.000 
saving the latest model (epoch 729, total_steps 2714000)
(epoch: 729, iters: 96, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 729, iters: 176, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 729, iters: 256, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 729, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 729, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 729, iters: 496, time: 0.096, data: 0.040) loss: 0.045 
(epoch: 729, iters: 576, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 729, iters: 656, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 729, iters: 736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 729, iters: 816, time: 0.092, data: 0.012) loss: 0.286 
(epoch: 729, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 729, iters: 976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 729, iters: 1056, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 729, iters: 1136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 729, iters: 1216, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 729, iters: 1296, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 729, iters: 1376, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 729, iters: 1456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 729, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 729, iters: 1616, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 729, iters: 1696, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 729, iters: 1776, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 729, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 729, iters: 1936, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 729, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 729, iters: 2096, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 729, iters: 2176, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 729, iters: 2256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 729, iters: 2336, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 729, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 729, iters: 2496, time: 0.092, data: 0.011) loss: 0.008 
(epoch: 729, iters: 2576, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 729, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 729, iters: 2736, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 729, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 729, iters: 2896, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 729, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 729, iters: 3056, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 729, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 729, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 729, iters: 3296, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 729, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 729, iters: 3456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 729, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 729, iters: 3616, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 729, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 729, iters 2717712
End of epoch 729 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001370
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 729, TEST ACC: [97.876 %]

saving the latest model (epoch 730, total_steps 2717728)
(epoch: 730, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 730, iters: 128, time: 0.094, data: 0.043) loss: 0.000 
(epoch: 730, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 730, iters: 288, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 730, iters: 368, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 730, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 730, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 730, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 730, iters: 688, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 730, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 730, iters: 848, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 730, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 730, iters: 1008, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 730, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 730, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 730, iters: 1248, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 730, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 730, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 730, iters: 1488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 730, iters: 1568, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 730, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 730, iters: 1728, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 730, iters: 1808, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 730, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 730, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 730, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 730, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 730, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 730, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 730, iters: 2368, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 730, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 730, iters: 2528, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 730, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 730, iters: 2688, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 730, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 730, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 730, iters: 2928, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 730, iters: 3008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 730, iters: 3088, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 730, iters: 3168, time: 0.095, data: 0.000) loss: 0.038 
(epoch: 730, iters: 3248, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 730, iters: 3328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 730, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 730, iters: 3488, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 730, iters: 3568, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 730, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 730, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 730, iters 2721440
End of epoch 730 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001369
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 730, TEST ACC: [96.662 %]

saving the latest model (epoch 731, total_steps 2721456)
(epoch: 731, iters: 80, time: 0.093, data: 0.453) loss: 0.000 
(epoch: 731, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 731, iters: 240, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 731, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 731, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 731, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 731, iters: 560, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 731, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 731, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 731, iters: 800, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 731, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 731, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 731, iters: 1040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 731, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 731, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 731, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 731, iters: 1360, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 731, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 731, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 731, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 731, iters: 1680, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 731, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 731, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 731, iters: 1920, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 731, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 731, iters: 2080, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 731, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 731, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 731, iters: 2320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 731, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 731, iters: 2480, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 731, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 731, iters: 2640, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 731, iters: 2720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 731, iters: 2800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 731, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 731, iters: 2960, time: 0.092, data: 0.000) loss: 0.098 
(epoch: 731, iters: 3040, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 731, iters: 3120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 731, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 731, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 731, iters: 3360, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 731, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 731, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 731, iters: 3600, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 731, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 731, iters 2725168
End of epoch 731 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001368
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 731, TEST ACC: [96.813 %]

saving the latest model (epoch 732, total_steps 2725184)
(epoch: 732, iters: 32, time: 0.093, data: 0.005) loss: 0.000 
(epoch: 732, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 732, iters: 192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 732, iters: 272, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 732, iters: 352, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 732, iters: 432, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 732, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 732, iters: 592, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 732, iters: 672, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 732, iters: 752, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 732, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 732, iters: 912, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 732, iters: 992, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 732, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 732, iters: 1152, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 732, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 732, iters: 1312, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 732, iters: 1392, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 732, iters: 1472, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 732, iters: 1552, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 732, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 732, iters: 1712, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 732, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 732, iters: 1872, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 732, iters: 1952, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 732, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 732, iters: 2112, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 732, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 732, iters: 2272, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 732, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 732, iters: 2432, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 732, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 732, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 732, iters: 2672, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 732, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 732, iters: 2832, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 732, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 732, iters: 2992, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 732, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 732, iters: 3152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 732, iters: 3232, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 732, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 732, iters: 3392, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 732, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 732, iters: 3552, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 732, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 732, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 732, iters 2728896
End of epoch 732 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001367
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 732, TEST ACC: [97.42 %]

saving the latest model (epoch 733, total_steps 2728912)
(epoch: 733, iters: 64, time: 0.095, data: 0.002) loss: 0.000 
(epoch: 733, iters: 144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 733, iters: 224, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 733, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 733, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 733, iters: 464, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 733, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 733, iters: 624, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 733, iters: 704, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 733, iters: 784, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 733, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 733, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 733, iters: 1024, time: 0.093, data: 0.051) loss: 0.000 
(epoch: 733, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 733, iters: 1184, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 733, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 733, iters: 1344, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 733, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 733, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 733, iters: 1584, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 733, iters: 1664, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 733, iters: 1744, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 733, iters: 1824, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 733, iters: 1904, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 733, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 733, iters: 2064, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 733, iters: 2144, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 733, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 733, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 733, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 733, iters: 2464, time: 0.094, data: 0.012) loss: 0.005 
(epoch: 733, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 733, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 733, iters: 2704, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 733, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 733, iters: 2864, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 733, iters: 2944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 733, iters: 3024, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 733, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 733, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 733, iters: 3264, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 733, iters: 3344, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 733, iters: 3424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 733, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 733, iters: 3584, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 733, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 733, iters 2732624
End of epoch 733 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001366
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 733, TEST ACC: [97.572 %]

(epoch: 734, iters: 16, time: 0.116, data: 0.000) loss: 0.000 
saving the latest model (epoch 734, total_steps 2732640)
(epoch: 734, iters: 96, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 734, iters: 176, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 734, iters: 256, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 734, iters: 336, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 734, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 734, iters: 496, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 734, iters: 576, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 734, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 734, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 734, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 734, iters: 896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 734, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 734, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 734, iters: 1136, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 734, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 734, iters: 1296, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 734, iters: 1376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 734, iters: 1456, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 734, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 734, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 734, iters: 1696, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 734, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 734, iters: 1856, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 734, iters: 1936, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 734, iters: 2016, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 734, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 734, iters: 2176, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 734, iters: 2256, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 734, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 734, iters: 2416, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 734, iters: 2496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 734, iters: 2576, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 734, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 734, iters: 2736, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 734, iters: 2816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 734, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 734, iters: 2976, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 734, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 734, iters: 3136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 734, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 734, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 734, iters: 3376, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 734, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 734, iters: 3536, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 734, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 734, iters: 3696, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 734, iters 2736352
End of epoch 734 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001365
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 734, TEST ACC: [97.42 %]

saving the latest model (epoch 735, total_steps 2736368)
(epoch: 735, iters: 48, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 735, iters: 128, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 735, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 735, iters: 288, time: 0.092, data: 0.011) loss: 0.112 
(epoch: 735, iters: 368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 735, iters: 448, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 735, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 735, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 735, iters: 688, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 735, iters: 768, time: 0.094, data: 0.000) loss: 0.096 
(epoch: 735, iters: 848, time: 0.091, data: 0.012) loss: 0.002 
(epoch: 735, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 735, iters: 1008, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 735, iters: 1088, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 735, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 735, iters: 1248, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 735, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 735, iters: 1408, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 735, iters: 1488, time: 0.095, data: 0.000) loss: 0.020 
(epoch: 735, iters: 1568, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 735, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 735, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 735, iters: 1808, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 735, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 735, iters: 1968, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 735, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 735, iters: 2128, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 735, iters: 2208, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 735, iters: 2288, time: 0.092, data: 0.000) loss: 0.035 
(epoch: 735, iters: 2368, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 735, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 735, iters: 2528, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 735, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 735, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 735, iters: 2768, time: 0.095, data: 0.000) loss: 0.222 
(epoch: 735, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 735, iters: 2928, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 735, iters: 3008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 735, iters: 3088, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 735, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 735, iters: 3248, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 735, iters: 3328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 735, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 735, iters: 3488, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 735, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 735, iters: 3648, time: 0.085, data: 0.011) loss: 0.000 
(epoch: 735, iters: 3728, time: 0.055, data: 0.000) loss: 0.000 
saving the model at the end of epoch 735, iters 2740080
End of epoch 735 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001364
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 735, TEST ACC: [97.117 %]

saving the latest model (epoch 736, total_steps 2740096)
(epoch: 736, iters: 80, time: 0.096, data: 0.513) loss: 0.000 
(epoch: 736, iters: 160, time: 0.093, data: 0.000) loss: 0.104 
(epoch: 736, iters: 240, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 736, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 736, iters: 400, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 736, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 736, iters: 560, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 736, iters: 640, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 736, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 736, iters: 800, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 736, iters: 880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 736, iters: 960, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 736, iters: 1040, time: 0.094, data: 0.000) loss: 0.023 
(epoch: 736, iters: 1120, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 736, iters: 1200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 736, iters: 1280, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 736, iters: 1360, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 736, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 736, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 736, iters: 1600, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 736, iters: 1680, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 736, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 736, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 736, iters: 1920, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 736, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 736, iters: 2080, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 736, iters: 2160, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 736, iters: 2240, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 736, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 736, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 736, iters: 2480, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 736, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 736, iters: 2640, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 736, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 736, iters: 2800, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 736, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 736, iters: 2960, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 736, iters: 3040, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 736, iters: 3120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 736, iters: 3200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 736, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 736, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 736, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 736, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 736, iters: 3600, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 736, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 736, iters 2743808
End of epoch 736 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001363
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 736, TEST ACC: [95.751 %]

saving the latest model (epoch 737, total_steps 2743824)
(epoch: 737, iters: 32, time: 0.092, data: 0.004) loss: 0.001 
(epoch: 737, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 737, iters: 192, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 737, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 737, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 737, iters: 432, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 737, iters: 512, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 737, iters: 592, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 737, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 737, iters: 752, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 737, iters: 832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 737, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 737, iters: 992, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 737, iters: 1072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 737, iters: 1152, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 737, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 737, iters: 1312, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 737, iters: 1392, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 737, iters: 1472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 737, iters: 1552, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 737, iters: 1632, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 737, iters: 1712, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 737, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 737, iters: 1872, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 737, iters: 1952, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 737, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 737, iters: 2112, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 737, iters: 2192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 737, iters: 2272, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 737, iters: 2352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 737, iters: 2432, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 737, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 737, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 737, iters: 2672, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 737, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 737, iters: 2832, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 737, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 737, iters: 2992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 737, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 737, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 737, iters: 3232, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 737, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 737, iters: 3392, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 737, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 737, iters: 3552, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 737, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 737, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 737, iters 2747536
End of epoch 737 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001362
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 737, TEST ACC: [97.117 %]

saving the latest model (epoch 738, total_steps 2747552)
(epoch: 738, iters: 64, time: 0.091, data: 0.002) loss: 0.000 
(epoch: 738, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 738, iters: 224, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 738, iters: 304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 738, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 738, iters: 464, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 738, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 738, iters: 624, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 738, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 738, iters: 784, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 738, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 738, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 738, iters: 1024, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 738, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 738, iters: 1184, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 738, iters: 1264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 738, iters: 1344, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 738, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 738, iters: 1504, time: 0.094, data: 0.000) loss: 0.033 
(epoch: 738, iters: 1584, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 738, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 738, iters: 1744, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 738, iters: 1824, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 738, iters: 1904, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 738, iters: 1984, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 738, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 738, iters: 2144, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 738, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 738, iters: 2304, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 738, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 738, iters: 2464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 738, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 738, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 738, iters: 2704, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 738, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 738, iters: 2864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 738, iters: 2944, time: 0.093, data: 0.000) loss: 0.010 
(epoch: 738, iters: 3024, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 738, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 738, iters: 3184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 738, iters: 3264, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 738, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 738, iters: 3424, time: 0.091, data: 0.011) loss: 0.480 
(epoch: 738, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 738, iters: 3584, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 738, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 738, iters 2751264
End of epoch 738 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001361
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 738, TEST ACC: [96.662 %]

(epoch: 739, iters: 16, time: 0.109, data: 0.000) loss: 0.039 
saving the latest model (epoch 739, total_steps 2751280)
(epoch: 739, iters: 96, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 739, iters: 176, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 739, iters: 256, time: 0.093, data: 0.048) loss: 0.001 
(epoch: 739, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 739, iters: 416, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 739, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 739, iters: 576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 739, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 739, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 739, iters: 816, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 739, iters: 896, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 739, iters: 976, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 739, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 739, iters: 1136, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 739, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 739, iters: 1296, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 739, iters: 1376, time: 0.096, data: 0.050) loss: 0.004 
(epoch: 739, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 739, iters: 1536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 739, iters: 1616, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 739, iters: 1696, time: 0.095, data: 0.012) loss: 0.012 
(epoch: 739, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 739, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 739, iters: 1936, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 739, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 739, iters: 2096, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 739, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 739, iters: 2256, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 739, iters: 2336, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 739, iters: 2416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 739, iters: 2496, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 739, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 739, iters: 2656, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 739, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 739, iters: 2816, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 739, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 739, iters: 2976, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 739, iters: 3056, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 739, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 739, iters: 3216, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 739, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 739, iters: 3376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 739, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 739, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 739, iters: 3616, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 739, iters: 3696, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 739, iters 2754992
End of epoch 739 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001360
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 739, TEST ACC: [97.876 %]

saving the latest model (epoch 740, total_steps 2755008)
(epoch: 740, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 740, iters: 128, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 740, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 740, iters: 288, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 740, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 740, iters: 448, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 740, iters: 528, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 740, iters: 608, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 740, iters: 688, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 740, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 740, iters: 848, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 740, iters: 928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 740, iters: 1008, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 740, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 740, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 740, iters: 1248, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 740, iters: 1328, time: 0.094, data: 0.000) loss: 0.174 
(epoch: 740, iters: 1408, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 740, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 740, iters: 1568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 740, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 740, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 740, iters: 1808, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 740, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 740, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 740, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 740, iters: 2128, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 740, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 740, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 740, iters: 2368, time: 0.095, data: 0.040) loss: 0.027 
(epoch: 740, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 740, iters: 2528, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 740, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 740, iters: 2688, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 740, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 740, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 740, iters: 2928, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 740, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 740, iters: 3088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 740, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 740, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 740, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 740, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 740, iters: 3488, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 740, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 740, iters: 3648, time: 0.086, data: 0.011) loss: 0.000 
(epoch: 740, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 740, iters 2758720
End of epoch 740 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001359
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 740, TEST ACC: [96.662 %]

saving the latest model (epoch 741, total_steps 2758736)
(epoch: 741, iters: 80, time: 0.095, data: 0.472) loss: 0.000 
(epoch: 741, iters: 160, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 741, iters: 240, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 741, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 741, iters: 400, time: 0.091, data: 0.011) loss: 0.002 
(epoch: 741, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 741, iters: 560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 741, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 741, iters: 720, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 741, iters: 800, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 741, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 741, iters: 960, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 741, iters: 1040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 741, iters: 1120, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 741, iters: 1200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 741, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 741, iters: 1360, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 741, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 741, iters: 1520, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 741, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 741, iters: 1680, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 741, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 741, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 741, iters: 1920, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 741, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 741, iters: 2080, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 741, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 741, iters: 2240, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 741, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 741, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 741, iters: 2480, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 741, iters: 2560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 741, iters: 2640, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 741, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 741, iters: 2800, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 741, iters: 2880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 741, iters: 2960, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 741, iters: 3040, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 741, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 741, iters: 3200, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 741, iters: 3280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 741, iters: 3360, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 741, iters: 3440, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 741, iters: 3520, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 741, iters: 3600, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 741, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 741, iters 2762448
End of epoch 741 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001358
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 741, TEST ACC: [96.055 %]

saving the latest model (epoch 742, total_steps 2762464)
(epoch: 742, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 742, iters: 112, time: 0.092, data: 0.027) loss: 0.015 
(epoch: 742, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 742, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 742, iters: 352, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 742, iters: 432, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 742, iters: 512, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 742, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 742, iters: 672, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 742, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 742, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 742, iters: 912, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 742, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 742, iters: 1072, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 742, iters: 1152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 742, iters: 1232, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 742, iters: 1312, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 742, iters: 1392, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 742, iters: 1472, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 742, iters: 1552, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 742, iters: 1632, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 742, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 742, iters: 1792, time: 0.092, data: 0.011) loss: 0.005 
(epoch: 742, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 742, iters: 1952, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 742, iters: 2032, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 742, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 742, iters: 2192, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 742, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 742, iters: 2352, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 742, iters: 2432, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 742, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 742, iters: 2592, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 742, iters: 2672, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 742, iters: 2752, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 742, iters: 2832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 742, iters: 2912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 742, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 742, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 742, iters: 3152, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 742, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 742, iters: 3312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 742, iters: 3392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 742, iters: 3472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 742, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 742, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 742, iters: 3712, time: 0.089, data: 0.037) loss: 0.000 
saving the model at the end of epoch 742, iters 2766176
End of epoch 742 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001357
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 742, TEST ACC: [97.42 %]

saving the latest model (epoch 743, total_steps 2766192)
(epoch: 743, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 743, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 743, iters: 224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 743, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 743, iters: 384, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 743, iters: 464, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 743, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 743, iters: 624, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 743, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 743, iters: 784, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 743, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 743, iters: 944, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 743, iters: 1024, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 743, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 743, iters: 1184, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 743, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 743, iters: 1344, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 743, iters: 1424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 743, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 743, iters: 1584, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 743, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 743, iters: 1744, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 743, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 743, iters: 1904, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 743, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 743, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 743, iters: 2144, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 743, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 743, iters: 2304, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 743, iters: 2384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 743, iters: 2464, time: 0.092, data: 0.013) loss: 0.004 
(epoch: 743, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 743, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 743, iters: 2704, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 743, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 743, iters: 2864, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 743, iters: 2944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 743, iters: 3024, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 743, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 743, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 743, iters: 3264, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 743, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 743, iters: 3424, time: 0.093, data: 0.022) loss: 0.000 
(epoch: 743, iters: 3504, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 743, iters: 3584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 743, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 743, iters 2769904
End of epoch 743 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001356
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 743, TEST ACC: [97.724 %]

(epoch: 744, iters: 16, time: 0.109, data: 0.000) loss: 0.000 
saving the latest model (epoch 744, total_steps 2769920)
(epoch: 744, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 744, iters: 176, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 744, iters: 256, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 744, iters: 336, time: 0.093, data: 0.012) loss: 0.018 
(epoch: 744, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 744, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 744, iters: 576, time: 0.094, data: 0.039) loss: 0.002 
(epoch: 744, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 744, iters: 736, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 744, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 744, iters: 896, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 744, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 744, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 744, iters: 1136, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 744, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 744, iters: 1296, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 744, iters: 1376, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 744, iters: 1456, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 744, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 744, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 744, iters: 1696, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 744, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 744, iters: 1856, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 744, iters: 1936, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 744, iters: 2016, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 744, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 744, iters: 2176, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 744, iters: 2256, time: 0.097, data: 0.041) loss: 0.001 
(epoch: 744, iters: 2336, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 744, iters: 2416, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 744, iters: 2496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 744, iters: 2576, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 744, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 744, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 744, iters: 2816, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 744, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 744, iters: 2976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 744, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 744, iters: 3136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 744, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 744, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 744, iters: 3376, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 744, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 744, iters: 3536, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 744, iters: 3616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 744, iters: 3696, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 744, iters 2773632
End of epoch 744 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001355
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 744, TEST ACC: [96.206 %]

saving the latest model (epoch 745, total_steps 2773648)
(epoch: 745, iters: 48, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 745, iters: 128, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 745, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 745, iters: 288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 745, iters: 368, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 745, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 745, iters: 528, time: 0.091, data: 0.021) loss: 0.000 
(epoch: 745, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 745, iters: 688, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 745, iters: 768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 745, iters: 848, time: 0.093, data: 0.000) loss: 0.024 
(epoch: 745, iters: 928, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 745, iters: 1008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 745, iters: 1088, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 745, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 745, iters: 1248, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 745, iters: 1328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 745, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 745, iters: 1488, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 745, iters: 1568, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 745, iters: 1648, time: 0.093, data: 0.022) loss: 0.000 
(epoch: 745, iters: 1728, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 745, iters: 1808, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 745, iters: 1888, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 745, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 745, iters: 2048, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 745, iters: 2128, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 745, iters: 2208, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 745, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 745, iters: 2368, time: 0.092, data: 0.012) loss: 0.007 
(epoch: 745, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 745, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 745, iters: 2608, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 745, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 745, iters: 2768, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 745, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 745, iters: 2928, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 745, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 745, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 745, iters: 3168, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 745, iters: 3248, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 745, iters: 3328, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 745, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 745, iters: 3488, time: 0.094, data: 0.012) loss: 0.301 
(epoch: 745, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 745, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 745, iters: 3728, time: 0.055, data: 0.015) loss: 0.000 
saving the model at the end of epoch 745, iters 2777360
End of epoch 745 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001354
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 745, TEST ACC: [88.771 %]

saving the latest model (epoch 746, total_steps 2777376)
(epoch: 746, iters: 80, time: 0.092, data: 0.510) loss: 0.000 
(epoch: 746, iters: 160, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 746, iters: 240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 746, iters: 320, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 746, iters: 400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 746, iters: 480, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 746, iters: 560, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 746, iters: 640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 746, iters: 720, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 746, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 746, iters: 880, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 746, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 746, iters: 1040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 746, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 746, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 746, iters: 1280, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 746, iters: 1360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 746, iters: 1440, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 746, iters: 1520, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 746, iters: 1600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 746, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 746, iters: 1760, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 746, iters: 1840, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 746, iters: 1920, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 746, iters: 2000, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 746, iters: 2080, time: 0.092, data: 0.000) loss: 0.043 
(epoch: 746, iters: 2160, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 746, iters: 2240, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 746, iters: 2320, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 746, iters: 2400, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 746, iters: 2480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 746, iters: 2560, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 746, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 746, iters: 2720, time: 0.092, data: 0.013) loss: 0.008 
(epoch: 746, iters: 2800, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 746, iters: 2880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 746, iters: 2960, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 746, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 746, iters: 3120, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 746, iters: 3200, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 746, iters: 3280, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 746, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 746, iters: 3440, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 746, iters: 3520, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 746, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 746, iters: 3680, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 746, iters 2781088
End of epoch 746 / 2100 	 Time Taken: 349 sec
learning rate = 0.0001353
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 746, TEST ACC: [94.689 %]

saving the latest model (epoch 747, total_steps 2781104)
(epoch: 747, iters: 32, time: 0.092, data: 0.007) loss: 0.000 
(epoch: 747, iters: 112, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 747, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 747, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 747, iters: 352, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 747, iters: 432, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 747, iters: 512, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 747, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 747, iters: 672, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 747, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 747, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 747, iters: 912, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 747, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 747, iters: 1072, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 747, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 747, iters: 1232, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 747, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 747, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 747, iters: 1472, time: 0.095, data: 0.040) loss: 0.002 
(epoch: 747, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 747, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 747, iters: 1712, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 747, iters: 1792, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 747, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 747, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 747, iters: 2032, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 747, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 747, iters: 2192, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 747, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 747, iters: 2352, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 747, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 747, iters: 2512, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 747, iters: 2592, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 747, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 747, iters: 2752, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 747, iters: 2832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 747, iters: 2912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 747, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 747, iters: 3072, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 747, iters: 3152, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 747, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 747, iters: 3312, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 747, iters: 3392, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 747, iters: 3472, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 747, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 747, iters: 3632, time: 0.091, data: 0.000) loss: 0.002 
(epoch: 747, iters: 3712, time: 0.087, data: 0.035) loss: 0.000 
saving the model at the end of epoch 747, iters 2784816
End of epoch 747 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001352
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 747, TEST ACC: [97.42 %]

saving the latest model (epoch 748, total_steps 2784832)
(epoch: 748, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 748, iters: 144, time: 0.094, data: 0.000) loss: 0.084 
(epoch: 748, iters: 224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 748, iters: 304, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 748, iters: 384, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 748, iters: 464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 748, iters: 544, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 748, iters: 624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 748, iters: 704, time: 0.093, data: 0.011) loss: 0.094 
(epoch: 748, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 748, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 748, iters: 944, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 748, iters: 1024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 748, iters: 1104, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 748, iters: 1184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 748, iters: 1264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 748, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 748, iters: 1424, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 748, iters: 1504, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 748, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 748, iters: 1664, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 748, iters: 1744, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 748, iters: 1824, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 748, iters: 1904, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 748, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 748, iters: 2064, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 748, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 748, iters: 2224, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 748, iters: 2304, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 748, iters: 2384, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 748, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 748, iters: 2544, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 748, iters: 2624, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 748, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 748, iters: 2784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 748, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 748, iters: 2944, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 748, iters: 3024, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 748, iters: 3104, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 748, iters: 3184, time: 0.093, data: 0.050) loss: 0.002 
(epoch: 748, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 748, iters: 3344, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 748, iters: 3424, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 748, iters: 3504, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 748, iters: 3584, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 748, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 748, iters 2788544
End of epoch 748 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001351
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 748, TEST ACC: [93.02 %]

(epoch: 749, iters: 16, time: 0.108, data: 0.021) loss: 0.000 
saving the latest model (epoch 749, total_steps 2788560)
(epoch: 749, iters: 96, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 749, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 749, iters: 256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 749, iters: 336, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 749, iters: 416, time: 0.096, data: 0.000) loss: 0.016 
(epoch: 749, iters: 496, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 749, iters: 576, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 749, iters: 656, time: 0.092, data: 0.012) loss: 0.006 
(epoch: 749, iters: 736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 749, iters: 816, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 749, iters: 896, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 749, iters: 976, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 749, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 749, iters: 1136, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 749, iters: 1216, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 749, iters: 1296, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 749, iters: 1376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 749, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 749, iters: 1536, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 749, iters: 1616, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 749, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 749, iters: 1776, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 749, iters: 1856, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 749, iters: 1936, time: 0.093, data: 0.024) loss: 0.000 
(epoch: 749, iters: 2016, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 749, iters: 2096, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 749, iters: 2176, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 749, iters: 2256, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 749, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 749, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 749, iters: 2496, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 749, iters: 2576, time: 0.091, data: 0.025) loss: 0.013 
(epoch: 749, iters: 2656, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 749, iters: 2736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 749, iters: 2816, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 749, iters: 2896, time: 0.093, data: 0.036) loss: 0.000 
(epoch: 749, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 749, iters: 3056, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 749, iters: 3136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 749, iters: 3216, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 749, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 749, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 749, iters: 3456, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 749, iters: 3536, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 749, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 749, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 749, iters 2792272
End of epoch 749 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001350
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 749, TEST ACC: [96.813 %]

saving the latest model (epoch 750, total_steps 2792288)
(epoch: 750, iters: 48, time: 0.095, data: 0.005) loss: 0.000 
(epoch: 750, iters: 128, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 750, iters: 208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 750, iters: 288, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 750, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 750, iters: 448, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 750, iters: 528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 750, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 750, iters: 688, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 750, iters: 768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 750, iters: 848, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 750, iters: 928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 750, iters: 1008, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 750, iters: 1088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 750, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 750, iters: 1248, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 750, iters: 1328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 750, iters: 1408, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 750, iters: 1488, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 750, iters: 1568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 750, iters: 1648, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 750, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 750, iters: 1808, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 750, iters: 1888, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 750, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 750, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 750, iters: 2128, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 750, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 750, iters: 2288, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 750, iters: 2368, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 750, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 750, iters: 2528, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 750, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 750, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 750, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 750, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 750, iters: 2928, time: 0.094, data: 0.052) loss: 0.000 
(epoch: 750, iters: 3008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 750, iters: 3088, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 750, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 750, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 750, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 750, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 750, iters: 3488, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 750, iters: 3568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 750, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 750, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 750, iters 2796000
End of epoch 750 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001349
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 750, TEST ACC: [95.448 %]

saving the latest model (epoch 751, total_steps 2796016)
(epoch: 751, iters: 80, time: 0.095, data: 0.451) loss: 0.000 
(epoch: 751, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 751, iters: 240, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 751, iters: 320, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 751, iters: 400, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 751, iters: 480, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 751, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 751, iters: 640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 751, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 751, iters: 800, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 751, iters: 880, time: 0.094, data: 0.041) loss: 0.005 
(epoch: 751, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 751, iters: 1040, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 751, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 751, iters: 1200, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 751, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 751, iters: 1360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 751, iters: 1440, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 751, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 751, iters: 1600, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 751, iters: 1680, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 751, iters: 1760, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 751, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 751, iters: 1920, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 751, iters: 2000, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 751, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 751, iters: 2160, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 751, iters: 2240, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 751, iters: 2320, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 751, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 751, iters: 2480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 751, iters: 2560, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 751, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 751, iters: 2720, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 751, iters: 2800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 751, iters: 2880, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 751, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 751, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 751, iters: 3120, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 751, iters: 3200, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 751, iters: 3280, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 751, iters: 3360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 751, iters: 3440, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 751, iters: 3520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 751, iters: 3600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 751, iters: 3680, time: 0.088, data: 0.041) loss: 0.000 
saving the model at the end of epoch 751, iters 2799728
End of epoch 751 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001348
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 751, TEST ACC: [96.51 %]

saving the latest model (epoch 752, total_steps 2799744)
(epoch: 752, iters: 32, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 752, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 752, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 752, iters: 272, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 752, iters: 352, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 752, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 752, iters: 512, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 752, iters: 592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 752, iters: 672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 752, iters: 752, time: 0.098, data: 0.000) loss: 0.001 
(epoch: 752, iters: 832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 752, iters: 912, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 752, iters: 992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 752, iters: 1072, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 752, iters: 1152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 752, iters: 1232, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 752, iters: 1312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 752, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 752, iters: 1472, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 752, iters: 1552, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 752, iters: 1632, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 752, iters: 1712, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 752, iters: 1792, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 752, iters: 1872, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 752, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 752, iters: 2032, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 752, iters: 2112, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 752, iters: 2192, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 752, iters: 2272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 752, iters: 2352, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 752, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 752, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 752, iters: 2592, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 752, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 752, iters: 2752, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 752, iters: 2832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 752, iters: 2912, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 752, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 752, iters: 3072, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 752, iters: 3152, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 752, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 752, iters: 3312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 752, iters: 3392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 752, iters: 3472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 752, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 752, iters: 3632, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 752, iters: 3712, time: 0.087, data: 0.037) loss: 0.000 
saving the model at the end of epoch 752, iters 2803456
End of epoch 752 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001347
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 752, TEST ACC: [96.662 %]

saving the latest model (epoch 753, total_steps 2803472)
(epoch: 753, iters: 64, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 753, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 304, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 753, iters: 384, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 753, iters: 464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 753, iters: 544, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 753, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 704, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 753, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 753, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 753, iters: 944, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 753, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 1104, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 753, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 1264, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 753, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 753, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 1504, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 753, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 1664, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 753, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 1824, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 753, iters: 1904, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 753, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 2064, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 753, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 2224, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 753, iters: 2304, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 753, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 2464, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 753, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 2624, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 753, iters: 2704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 753, iters: 2784, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 753, iters: 2864, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 753, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 3024, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 753, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 3184, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 753, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 3424, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 753, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 753, iters: 3584, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 753, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 753, iters 2807184
End of epoch 753 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001346
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 753, TEST ACC: [96.662 %]

(epoch: 754, iters: 16, time: 0.111, data: 0.008) loss: 0.000 
saving the latest model (epoch 754, total_steps 2807200)
(epoch: 754, iters: 96, time: 0.094, data: 0.043) loss: 0.000 
(epoch: 754, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 754, iters: 256, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 754, iters: 336, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 754, iters: 416, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 754, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 754, iters: 576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 754, iters: 656, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 754, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 754, iters: 816, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 754, iters: 896, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 754, iters: 976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 754, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 754, iters: 1136, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 754, iters: 1216, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 754, iters: 1296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 754, iters: 1376, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 754, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 754, iters: 1536, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 754, iters: 1616, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 754, iters: 1696, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 754, iters: 1776, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 754, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 754, iters: 1936, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 754, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 754, iters: 2096, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 754, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 754, iters: 2256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 754, iters: 2336, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 754, iters: 2416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 754, iters: 2496, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 754, iters: 2576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 754, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 754, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 754, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 754, iters: 2896, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 754, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 754, iters: 3056, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 754, iters: 3136, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 754, iters: 3216, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 754, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 754, iters: 3376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 754, iters: 3456, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 754, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 754, iters: 3616, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 754, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 754, iters 2810912
End of epoch 754 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001345
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 754, TEST ACC: [94.385 %]

saving the latest model (epoch 755, total_steps 2810928)
(epoch: 755, iters: 48, time: 0.096, data: 0.004) loss: 0.000 
(epoch: 755, iters: 128, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 755, iters: 208, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 755, iters: 288, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 755, iters: 368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 755, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 755, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 755, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 755, iters: 688, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 755, iters: 768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 755, iters: 848, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 755, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 755, iters: 1008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 755, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 755, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 755, iters: 1248, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 755, iters: 1328, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 755, iters: 1408, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 755, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 755, iters: 1568, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 755, iters: 1648, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 755, iters: 1728, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 755, iters: 1808, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 755, iters: 1888, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 755, iters: 1968, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 755, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 755, iters: 2128, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 755, iters: 2208, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 755, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 755, iters: 2368, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 755, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 755, iters: 2528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 755, iters: 2608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 755, iters: 2688, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 755, iters: 2768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 755, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 755, iters: 2928, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 755, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 755, iters: 3088, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 755, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 755, iters: 3248, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 755, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 755, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 755, iters: 3488, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 755, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 755, iters: 3648, time: 0.085, data: 0.012) loss: 0.000 
(epoch: 755, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 755, iters 2814640
End of epoch 755 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001344
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 755, TEST ACC: [97.117 %]

saving the latest model (epoch 756, total_steps 2814656)
(epoch: 756, iters: 80, time: 0.097, data: 0.471) loss: 0.000 
(epoch: 756, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 756, iters: 240, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 756, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 400, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 756, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 756, iters: 560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 756, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 720, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 756, iters: 800, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 756, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 756, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 756, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 1360, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 756, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 1520, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 756, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 1680, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 756, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 756, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 1920, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 756, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 2080, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 756, iters: 2160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 756, iters: 2240, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 756, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 756, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 756, iters: 2480, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 756, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 2640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 756, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 2800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 756, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 3040, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 756, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 756, iters: 3200, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 756, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 756, iters: 3360, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 756, iters: 3440, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 756, iters: 3520, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 756, iters: 3600, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 756, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 756, iters 2818368
End of epoch 756 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001343
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 756, TEST ACC: [97.269 %]

saving the latest model (epoch 757, total_steps 2818384)
(epoch: 757, iters: 32, time: 0.092, data: 0.005) loss: 0.000 
(epoch: 757, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 757, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 757, iters: 272, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 757, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 757, iters: 432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 757, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 757, iters: 592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 757, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 757, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 757, iters: 832, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 757, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 757, iters: 992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 757, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 757, iters: 1152, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 757, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 757, iters: 1312, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 757, iters: 1392, time: 0.096, data: 0.048) loss: 0.000 
(epoch: 757, iters: 1472, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 757, iters: 1552, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 757, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 757, iters: 1712, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 757, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 757, iters: 1872, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 757, iters: 1952, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 757, iters: 2032, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 757, iters: 2112, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 757, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 757, iters: 2272, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 757, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 757, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 757, iters: 2512, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 757, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 757, iters: 2672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 757, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 757, iters: 2832, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 757, iters: 2912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 757, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 757, iters: 3072, time: 0.094, data: 0.052) loss: 0.000 
(epoch: 757, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 757, iters: 3232, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 757, iters: 3312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 757, iters: 3392, time: 0.095, data: 0.020) loss: 0.021 
(epoch: 757, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 757, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 757, iters: 3632, time: 0.092, data: 0.039) loss: 0.000 
(epoch: 757, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 757, iters 2822096
End of epoch 757 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001342
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 757, TEST ACC: [95.448 %]

saving the latest model (epoch 758, total_steps 2822112)
(epoch: 758, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 758, iters: 144, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 758, iters: 224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 758, iters: 304, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 758, iters: 384, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 758, iters: 464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 758, iters: 544, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 758, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 758, iters: 704, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 758, iters: 784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 758, iters: 864, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 758, iters: 944, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 758, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 758, iters: 1104, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 758, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 758, iters: 1264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 758, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 758, iters: 1424, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 758, iters: 1504, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 758, iters: 1584, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 758, iters: 1664, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 758, iters: 1744, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 758, iters: 1824, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 758, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 758, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 758, iters: 2064, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 758, iters: 2144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 758, iters: 2224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 758, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 758, iters: 2384, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 758, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 758, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 758, iters: 2624, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 758, iters: 2704, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 758, iters: 2784, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 758, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 758, iters: 2944, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 758, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 758, iters: 3104, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 758, iters: 3184, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 758, iters: 3264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 758, iters: 3344, time: 0.091, data: 0.021) loss: 0.000 
(epoch: 758, iters: 3424, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 758, iters: 3504, time: 0.094, data: 0.011) loss: 0.011 
(epoch: 758, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 758, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 758, iters 2825824
End of epoch 758 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001341
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 758, TEST ACC: [96.662 %]

(epoch: 759, iters: 16, time: 0.111, data: 0.012) loss: 0.000 
saving the latest model (epoch 759, total_steps 2825840)
(epoch: 759, iters: 96, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 759, iters: 176, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 759, iters: 256, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 759, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 759, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 759, iters: 496, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 759, iters: 576, time: 0.095, data: 0.043) loss: 0.000 
(epoch: 759, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 759, iters: 736, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 759, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 759, iters: 896, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 759, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 759, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 759, iters: 1136, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 759, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 759, iters: 1296, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 759, iters: 1376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 759, iters: 1456, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 759, iters: 1536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 759, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 759, iters: 1696, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 759, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 759, iters: 1856, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 759, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 759, iters: 2016, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 759, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 759, iters: 2176, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 759, iters: 2256, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 759, iters: 2336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 759, iters: 2416, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 759, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 759, iters: 2576, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 759, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 759, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 759, iters: 2816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 759, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 759, iters: 2976, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 759, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 759, iters: 3136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 759, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 759, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 759, iters: 3376, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 759, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 759, iters: 3536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 759, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 759, iters: 3696, time: 0.087, data: 0.011) loss: 0.001 
saving the model at the end of epoch 759, iters 2829552
End of epoch 759 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001340
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 759, TEST ACC: [96.358 %]

saving the latest model (epoch 760, total_steps 2829568)
(epoch: 760, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 760, iters: 128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 760, iters: 208, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 760, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 760, iters: 368, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 760, iters: 448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 760, iters: 528, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 760, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 760, iters: 688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 760, iters: 768, time: 0.093, data: 0.039) loss: 0.006 
(epoch: 760, iters: 848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 760, iters: 928, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 760, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 760, iters: 1088, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 760, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 760, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 760, iters: 1328, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 760, iters: 1408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 760, iters: 1488, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 760, iters: 1568, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 760, iters: 1648, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 760, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 760, iters: 1808, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 760, iters: 1888, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 760, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 760, iters: 2048, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 760, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 760, iters: 2208, time: 0.092, data: 0.012) loss: 0.097 
(epoch: 760, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 760, iters: 2368, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 760, iters: 2448, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 760, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 760, iters: 2608, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 760, iters: 2688, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 760, iters: 2768, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 760, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 760, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 760, iters: 3008, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 760, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 760, iters: 3168, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 760, iters: 3248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 760, iters: 3328, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 760, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 760, iters: 3488, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 760, iters: 3568, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 760, iters: 3648, time: 0.087, data: 0.000) loss: 0.000 
(epoch: 760, iters: 3728, time: 0.056, data: 0.011) loss: 0.000 
saving the model at the end of epoch 760, iters 2833280
End of epoch 760 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001339
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 760, TEST ACC: [95.296 %]

saving the latest model (epoch 761, total_steps 2833296)
(epoch: 761, iters: 80, time: 0.092, data: 0.516) loss: 0.012 
(epoch: 761, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 761, iters: 240, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 761, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 761, iters: 400, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 761, iters: 480, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 761, iters: 560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 761, iters: 640, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 761, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 761, iters: 800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 761, iters: 880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 761, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 761, iters: 1040, time: 0.093, data: 0.040) loss: 0.001 
(epoch: 761, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 761, iters: 1200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 761, iters: 1280, time: 0.093, data: 0.000) loss: 0.013 
(epoch: 761, iters: 1360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 761, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 761, iters: 1520, time: 0.092, data: 0.000) loss: 0.007 
(epoch: 761, iters: 1600, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 761, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 761, iters: 1760, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 761, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 761, iters: 1920, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 761, iters: 2000, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 761, iters: 2080, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 761, iters: 2160, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 761, iters: 2240, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 761, iters: 2320, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 761, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 761, iters: 2480, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 761, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 761, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 761, iters: 2720, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 761, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 761, iters: 2880, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 761, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 761, iters: 3040, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 761, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 761, iters: 3200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 761, iters: 3280, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 761, iters: 3360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 761, iters: 3440, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 761, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 761, iters: 3600, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 761, iters: 3680, time: 0.087, data: 0.000) loss: 0.002 
saving the model at the end of epoch 761, iters 2837008
End of epoch 761 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001338
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 761, TEST ACC: [95.751 %]

saving the latest model (epoch 762, total_steps 2837024)
(epoch: 762, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 762, iters: 112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 762, iters: 192, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 762, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 762, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 762, iters: 432, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 762, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 762, iters: 592, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 762, iters: 672, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 762, iters: 752, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 762, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 762, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 762, iters: 992, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 762, iters: 1072, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 762, iters: 1152, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 762, iters: 1232, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 762, iters: 1312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 762, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 762, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 762, iters: 1552, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 762, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 762, iters: 1712, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 762, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 762, iters: 1872, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 762, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 762, iters: 2032, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 762, iters: 2112, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 762, iters: 2192, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 762, iters: 2272, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 762, iters: 2352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 762, iters: 2432, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 762, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 762, iters: 2592, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 762, iters: 2672, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 762, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 762, iters: 2832, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 762, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 762, iters: 2992, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 762, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 762, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 762, iters: 3232, time: 0.096, data: 0.048) loss: 0.000 
(epoch: 762, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 762, iters: 3392, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 762, iters: 3472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 762, iters: 3552, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 762, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 762, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 762, iters 2840736
End of epoch 762 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001337
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 762, TEST ACC: [96.055 %]

saving the latest model (epoch 763, total_steps 2840752)
(epoch: 763, iters: 64, time: 0.094, data: 0.003) loss: 0.000 
(epoch: 763, iters: 144, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 763, iters: 224, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 763, iters: 304, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 763, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 763, iters: 464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 763, iters: 544, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 763, iters: 624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 763, iters: 704, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 763, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 763, iters: 864, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 763, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 763, iters: 1024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 763, iters: 1104, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 763, iters: 1184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 763, iters: 1264, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 763, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 763, iters: 1424, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 763, iters: 1504, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 763, iters: 1584, time: 0.094, data: 0.000) loss: 0.020 
(epoch: 763, iters: 1664, time: 0.094, data: 0.053) loss: 0.000 
(epoch: 763, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 763, iters: 1824, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 763, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 763, iters: 1984, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 763, iters: 2064, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 763, iters: 2144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 763, iters: 2224, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 763, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 763, iters: 2384, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 763, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 763, iters: 2544, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 763, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 763, iters: 2704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 763, iters: 2784, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 763, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 763, iters: 2944, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 763, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 763, iters: 3104, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 763, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 763, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 763, iters: 3344, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 763, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 763, iters: 3504, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 763, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 763, iters: 3664, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 763, iters 2844464
End of epoch 763 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001336
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 763, TEST ACC: [95.448 %]

(epoch: 764, iters: 16, time: 0.107, data: 0.000) loss: 0.000 
saving the latest model (epoch 764, total_steps 2844480)
(epoch: 764, iters: 96, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 764, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 764, iters: 256, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 764, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 764, iters: 416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 764, iters: 496, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 764, iters: 576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 764, iters: 656, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 764, iters: 736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 764, iters: 816, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 764, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 764, iters: 976, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 764, iters: 1056, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 764, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 764, iters: 1216, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 764, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 764, iters: 1376, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 764, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 764, iters: 1536, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 764, iters: 1616, time: 0.094, data: 0.047) loss: 0.000 
(epoch: 764, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 764, iters: 1776, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 764, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 764, iters: 1936, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 764, iters: 2016, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 764, iters: 2096, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 764, iters: 2176, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 764, iters: 2256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 764, iters: 2336, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 764, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 764, iters: 2496, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 764, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 764, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 764, iters: 2736, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 764, iters: 2816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 764, iters: 2896, time: 0.093, data: 0.011) loss: 0.006 
(epoch: 764, iters: 2976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 764, iters: 3056, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 764, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 764, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 764, iters: 3296, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 764, iters: 3376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 764, iters: 3456, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 764, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 764, iters: 3616, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 764, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 764, iters 2848192
End of epoch 764 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001335
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 764, TEST ACC: [96.206 %]

saving the latest model (epoch 765, total_steps 2848208)
(epoch: 765, iters: 48, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 765, iters: 128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 765, iters: 208, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 765, iters: 288, time: 0.094, data: 0.000) loss: 0.371 
(epoch: 765, iters: 368, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 765, iters: 448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 765, iters: 528, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 765, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 765, iters: 688, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 765, iters: 768, time: 0.094, data: 0.039) loss: 0.031 
(epoch: 765, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 765, iters: 928, time: 0.092, data: 0.021) loss: 0.001 
(epoch: 765, iters: 1008, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 765, iters: 1088, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 765, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 765, iters: 1248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 765, iters: 1328, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 765, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 765, iters: 1488, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 765, iters: 1568, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 765, iters: 1648, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 765, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 765, iters: 1808, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 765, iters: 1888, time: 0.093, data: 0.041) loss: 0.001 
(epoch: 765, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 765, iters: 2048, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 765, iters: 2128, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 765, iters: 2208, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 765, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 765, iters: 2368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 765, iters: 2448, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 765, iters: 2528, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 765, iters: 2608, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 765, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 765, iters: 2768, time: 0.095, data: 0.011) loss: 0.013 
(epoch: 765, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 765, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 765, iters: 3008, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 765, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 765, iters: 3168, time: 0.091, data: 0.011) loss: 0.001 
(epoch: 765, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 765, iters: 3328, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 765, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 765, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 765, iters: 3568, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 765, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 765, iters: 3728, time: 0.056, data: 0.012) loss: 0.000 
saving the model at the end of epoch 765, iters 2851920
End of epoch 765 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001334
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 765, TEST ACC: [93.323 %]

saving the latest model (epoch 766, total_steps 2851936)
(epoch: 766, iters: 80, time: 0.096, data: 0.512) loss: 0.010 
(epoch: 766, iters: 160, time: 0.094, data: 0.031) loss: 0.000 
(epoch: 766, iters: 240, time: 0.094, data: 0.000) loss: 0.022 
(epoch: 766, iters: 320, time: 0.092, data: 0.012) loss: 0.012 
(epoch: 766, iters: 400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 766, iters: 480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 766, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 766, iters: 640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 766, iters: 720, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 766, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 766, iters: 880, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 766, iters: 960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 766, iters: 1040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 766, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 766, iters: 1200, time: 0.093, data: 0.000) loss: 0.215 
(epoch: 766, iters: 1280, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 766, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 766, iters: 1440, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 766, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 766, iters: 1600, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 766, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 766, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 766, iters: 1840, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 766, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 766, iters: 2000, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 766, iters: 2080, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 766, iters: 2160, time: 0.095, data: 0.012) loss: 0.022 
(epoch: 766, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 766, iters: 2320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 766, iters: 2400, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 766, iters: 2480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 766, iters: 2560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 766, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 766, iters: 2720, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 766, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 766, iters: 2880, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 766, iters: 2960, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 766, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 766, iters: 3120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 766, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 766, iters: 3280, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 766, iters: 3360, time: 0.094, data: 0.000) loss: 0.066 
(epoch: 766, iters: 3440, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 766, iters: 3520, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 766, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 766, iters: 3680, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 766, iters 2855648
End of epoch 766 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001333
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 766, TEST ACC: [92.868 %]

saving the latest model (epoch 767, total_steps 2855664)
(epoch: 767, iters: 32, time: 0.091, data: 0.007) loss: 0.001 
(epoch: 767, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 767, iters: 192, time: 0.093, data: 0.012) loss: 0.009 
(epoch: 767, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 767, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 767, iters: 432, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 767, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 767, iters: 592, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 767, iters: 672, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 767, iters: 752, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 767, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 767, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 767, iters: 992, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 767, iters: 1072, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 767, iters: 1152, time: 0.091, data: 0.020) loss: 0.000 
(epoch: 767, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 767, iters: 1312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 767, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 767, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 767, iters: 1552, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 767, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 767, iters: 1712, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 767, iters: 1792, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 767, iters: 1872, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 767, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 767, iters: 2032, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 767, iters: 2112, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 767, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 767, iters: 2272, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 767, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 767, iters: 2432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 767, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 767, iters: 2592, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 767, iters: 2672, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 767, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 767, iters: 2832, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 767, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 767, iters: 2992, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 767, iters: 3072, time: 0.095, data: 0.000) loss: 0.015 
(epoch: 767, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 767, iters: 3232, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 767, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 767, iters: 3392, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 767, iters: 3472, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 767, iters: 3552, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 767, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 767, iters: 3712, time: 0.086, data: 0.000) loss: 0.001 
saving the model at the end of epoch 767, iters 2859376
End of epoch 767 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001332
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 767, TEST ACC: [95.448 %]

saving the latest model (epoch 768, total_steps 2859392)
(epoch: 768, iters: 64, time: 0.094, data: 0.003) loss: 0.000 
(epoch: 768, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 768, iters: 224, time: 0.092, data: 0.011) loss: 0.032 
(epoch: 768, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 768, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 768, iters: 464, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 768, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 768, iters: 624, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 768, iters: 704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 768, iters: 784, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 768, iters: 864, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 768, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 768, iters: 1024, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 768, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 768, iters: 1184, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 768, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 768, iters: 1344, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 768, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 768, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 768, iters: 1584, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 768, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 768, iters: 1744, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 768, iters: 1824, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 768, iters: 1904, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 768, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 768, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 768, iters: 2144, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 768, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 768, iters: 2304, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 768, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 768, iters: 2464, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 768, iters: 2544, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 768, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 768, iters: 2704, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 768, iters: 2784, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 768, iters: 2864, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 768, iters: 2944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 768, iters: 3024, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 768, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 768, iters: 3184, time: 0.093, data: 0.000) loss: 0.019 
(epoch: 768, iters: 3264, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 768, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 768, iters: 3424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 768, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 768, iters: 3584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 768, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 768, iters 2863104
End of epoch 768 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001331
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 768, TEST ACC: [94.537 %]

(epoch: 769, iters: 16, time: 0.108, data: 0.000) loss: 0.046 
saving the latest model (epoch 769, total_steps 2863120)
(epoch: 769, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 769, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 769, iters: 256, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 769, iters: 336, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 769, iters: 416, time: 0.091, data: 0.012) loss: 0.006 
(epoch: 769, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 769, iters: 576, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 769, iters: 656, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 769, iters: 736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 769, iters: 816, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 769, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 769, iters: 976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 769, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 769, iters: 1136, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 769, iters: 1216, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 769, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 769, iters: 1376, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 769, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 769, iters: 1536, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 769, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 769, iters: 1696, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 769, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 769, iters: 1856, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 769, iters: 1936, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 769, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 769, iters: 2096, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 769, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 769, iters: 2256, time: 0.094, data: 0.011) loss: 0.048 
(epoch: 769, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 769, iters: 2416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 769, iters: 2496, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 769, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 769, iters: 2656, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 769, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 769, iters: 2816, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 769, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 769, iters: 2976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 769, iters: 3056, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 769, iters: 3136, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 769, iters: 3216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 769, iters: 3296, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 769, iters: 3376, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 769, iters: 3456, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 769, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 769, iters: 3616, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 769, iters: 3696, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 769, iters 2866832
End of epoch 769 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001330
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 769, TEST ACC: [95.144 %]

saving the latest model (epoch 770, total_steps 2866848)
(epoch: 770, iters: 48, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 770, iters: 128, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 770, iters: 208, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 770, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 770, iters: 368, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 770, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 770, iters: 528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 770, iters: 608, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 770, iters: 688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 770, iters: 768, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 770, iters: 848, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 770, iters: 928, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 770, iters: 1008, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 770, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 770, iters: 1168, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 770, iters: 1248, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 770, iters: 1328, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 770, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 770, iters: 1488, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 770, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 770, iters: 1648, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 770, iters: 1728, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 770, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 770, iters: 1888, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 770, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 770, iters: 2048, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 770, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 770, iters: 2208, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 770, iters: 2288, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 770, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 770, iters: 2448, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 770, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 770, iters: 2608, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 770, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 770, iters: 2768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 770, iters: 2848, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 770, iters: 2928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 770, iters: 3008, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 770, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 770, iters: 3168, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 770, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 770, iters: 3328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 770, iters: 3408, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 770, iters: 3488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 770, iters: 3568, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 770, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 770, iters: 3728, time: 0.056, data: 0.012) loss: 0.000 
saving the model at the end of epoch 770, iters 2870560
End of epoch 770 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001329
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 770, TEST ACC: [95.751 %]

saving the latest model (epoch 771, total_steps 2870576)
(epoch: 771, iters: 80, time: 0.092, data: 0.463) loss: 0.000 
(epoch: 771, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 771, iters: 240, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 771, iters: 320, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 771, iters: 400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 771, iters: 480, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 771, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 771, iters: 640, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 771, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 771, iters: 800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 771, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 771, iters: 960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 771, iters: 1040, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 771, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 771, iters: 1200, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 771, iters: 1280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 771, iters: 1360, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 771, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 771, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 771, iters: 1600, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 771, iters: 1680, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 771, iters: 1760, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 771, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 771, iters: 1920, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 771, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 771, iters: 2080, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 771, iters: 2160, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 771, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 771, iters: 2320, time: 0.092, data: 0.011) loss: 0.008 
(epoch: 771, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 771, iters: 2480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 771, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 771, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 771, iters: 2720, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 771, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 771, iters: 2880, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 771, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 771, iters: 3040, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 771, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 771, iters: 3200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 771, iters: 3280, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 771, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 771, iters: 3440, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 771, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 771, iters: 3600, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 771, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 771, iters 2874288
End of epoch 771 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001328
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 771, TEST ACC: [94.385 %]

saving the latest model (epoch 772, total_steps 2874304)
(epoch: 772, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 772, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 772, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 772, iters: 272, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 772, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 772, iters: 432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 772, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 772, iters: 592, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 772, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 772, iters: 752, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 772, iters: 832, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 772, iters: 912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 772, iters: 992, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 772, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 772, iters: 1152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 772, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 772, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 772, iters: 1392, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 772, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 772, iters: 1552, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 772, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 772, iters: 1712, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 772, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 772, iters: 1872, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 772, iters: 1952, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 772, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 772, iters: 2112, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 772, iters: 2192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 772, iters: 2272, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 772, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 772, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 772, iters: 2512, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 772, iters: 2592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 772, iters: 2672, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 772, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 772, iters: 2832, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 772, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 772, iters: 2992, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 772, iters: 3072, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 772, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 772, iters: 3232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 772, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 772, iters: 3392, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 772, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 772, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 772, iters: 3632, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 772, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 772, iters 2878016
End of epoch 772 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001327
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 772, TEST ACC: [95.751 %]

saving the latest model (epoch 773, total_steps 2878032)
(epoch: 773, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 773, iters: 144, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 773, iters: 224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 773, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 773, iters: 384, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 773, iters: 464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 773, iters: 544, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 773, iters: 624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 773, iters: 704, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 773, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 773, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 773, iters: 944, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 773, iters: 1024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 773, iters: 1104, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 773, iters: 1184, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 773, iters: 1264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 773, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 773, iters: 1424, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 773, iters: 1504, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 773, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 773, iters: 1664, time: 0.094, data: 0.011) loss: 0.125 
(epoch: 773, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 773, iters: 1824, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 773, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 773, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 773, iters: 2064, time: 0.093, data: 0.043) loss: 0.000 
(epoch: 773, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 773, iters: 2224, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 773, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 773, iters: 2384, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 773, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 773, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 773, iters: 2624, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 773, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 773, iters: 2784, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 773, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 773, iters: 2944, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 773, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 773, iters: 3104, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 773, iters: 3184, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 773, iters: 3264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 773, iters: 3344, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 773, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 773, iters: 3504, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 773, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 773, iters: 3664, time: 0.088, data: 0.000) loss: 0.010 
saving the model at the end of epoch 773, iters 2881744
End of epoch 773 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001326
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 773, TEST ACC: [93.778 %]

(epoch: 774, iters: 16, time: 0.113, data: 0.012) loss: 0.000 
saving the latest model (epoch 774, total_steps 2881760)
(epoch: 774, iters: 96, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 774, iters: 176, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 774, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 774, iters: 336, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 774, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 774, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 774, iters: 576, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 774, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 774, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 774, iters: 816, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 774, iters: 896, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 774, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 774, iters: 1056, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 774, iters: 1136, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 774, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 774, iters: 1296, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 774, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 774, iters: 1456, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 774, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 774, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 774, iters: 1696, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 774, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 774, iters: 1856, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 774, iters: 1936, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 774, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 774, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 774, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 774, iters: 2256, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 774, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 774, iters: 2416, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 774, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 774, iters: 2576, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 774, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 774, iters: 2736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 774, iters: 2816, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 774, iters: 2896, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 774, iters: 2976, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 774, iters: 3056, time: 0.094, data: 0.000) loss: 0.211 
(epoch: 774, iters: 3136, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 774, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 774, iters: 3296, time: 0.093, data: 0.000) loss: 0.007 
(epoch: 774, iters: 3376, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 774, iters: 3456, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 774, iters: 3536, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 774, iters: 3616, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 774, iters: 3696, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 774, iters 2885472
End of epoch 774 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001325
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 774, TEST ACC: [90.895 %]

saving the latest model (epoch 775, total_steps 2885488)
(epoch: 775, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 775, iters: 128, time: 0.094, data: 0.043) loss: 0.000 
(epoch: 775, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 775, iters: 288, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 775, iters: 368, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 775, iters: 448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 775, iters: 528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 775, iters: 608, time: 0.093, data: 0.000) loss: 0.011 
(epoch: 775, iters: 688, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 775, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 775, iters: 848, time: 0.093, data: 0.012) loss: 0.049 
(epoch: 775, iters: 928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 775, iters: 1008, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 775, iters: 1088, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 775, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 775, iters: 1248, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 775, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 775, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 775, iters: 1488, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 775, iters: 1568, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 775, iters: 1648, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 775, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 775, iters: 1808, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 775, iters: 1888, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 775, iters: 1968, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 775, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 775, iters: 2128, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 775, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 775, iters: 2288, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 775, iters: 2368, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 775, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 775, iters: 2528, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 775, iters: 2608, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 775, iters: 2688, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 775, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 775, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 775, iters: 2928, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 775, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 775, iters: 3088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 775, iters: 3168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 775, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 775, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 775, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 775, iters: 3488, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 775, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 775, iters: 3648, time: 0.087, data: 0.012) loss: 0.000 
(epoch: 775, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 775, iters 2889200
End of epoch 775 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001324
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 775, TEST ACC: [93.627 %]

saving the latest model (epoch 776, total_steps 2889216)
(epoch: 776, iters: 80, time: 0.095, data: 0.421) loss: 0.000 
(epoch: 776, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 776, iters: 240, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 776, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 776, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 776, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 776, iters: 560, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 776, iters: 640, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 776, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 776, iters: 800, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 776, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 776, iters: 960, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 776, iters: 1040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 776, iters: 1120, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 776, iters: 1200, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 776, iters: 1280, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 776, iters: 1360, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 776, iters: 1440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 776, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 776, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 776, iters: 1680, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 776, iters: 1760, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 776, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 776, iters: 1920, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 776, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 776, iters: 2080, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 776, iters: 2160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 776, iters: 2240, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 776, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 776, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 776, iters: 2480, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 776, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 776, iters: 2640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 776, iters: 2720, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 776, iters: 2800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 776, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 776, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 776, iters: 3040, time: 0.094, data: 0.040) loss: 0.007 
(epoch: 776, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 776, iters: 3200, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 776, iters: 3280, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 776, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 776, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 776, iters: 3520, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 776, iters: 3600, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 776, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 776, iters 2892928
End of epoch 776 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001323
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 776, TEST ACC: [93.93 %]

saving the latest model (epoch 777, total_steps 2892944)
(epoch: 777, iters: 32, time: 0.093, data: 0.004) loss: 0.000 
(epoch: 777, iters: 112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 777, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 777, iters: 272, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 777, iters: 352, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 777, iters: 432, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 777, iters: 512, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 777, iters: 592, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 777, iters: 672, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 777, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 777, iters: 832, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 777, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 777, iters: 992, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 777, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 777, iters: 1152, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 777, iters: 1232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 777, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 777, iters: 1392, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 777, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 777, iters: 1552, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 777, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 777, iters: 1712, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 777, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 777, iters: 1872, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 777, iters: 1952, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 777, iters: 2032, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 777, iters: 2112, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 777, iters: 2192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 777, iters: 2272, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 777, iters: 2352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 777, iters: 2432, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 777, iters: 2512, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 777, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 777, iters: 2672, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 777, iters: 2752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 777, iters: 2832, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 777, iters: 2912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 777, iters: 2992, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 777, iters: 3072, time: 0.095, data: 0.045) loss: 0.000 
(epoch: 777, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 777, iters: 3232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 777, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 777, iters: 3392, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 777, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 777, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 777, iters: 3632, time: 0.091, data: 0.040) loss: 0.000 
(epoch: 777, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 777, iters 2896656
End of epoch 777 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001322
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 777, TEST ACC: [96.51 %]

saving the latest model (epoch 778, total_steps 2896672)
(epoch: 778, iters: 64, time: 0.092, data: 0.000) loss: 0.024 
(epoch: 778, iters: 144, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 778, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 778, iters: 304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 778, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 778, iters: 464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 778, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 778, iters: 624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 778, iters: 704, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 778, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 778, iters: 864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 778, iters: 944, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 778, iters: 1024, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 778, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 778, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 778, iters: 1264, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 778, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 778, iters: 1424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 778, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 778, iters: 1584, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 778, iters: 1664, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 778, iters: 1744, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 778, iters: 1824, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 778, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 778, iters: 1984, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 778, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 778, iters: 2144, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 778, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 778, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 778, iters: 2384, time: 0.096, data: 0.043) loss: 0.000 
(epoch: 778, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 778, iters: 2544, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 778, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 778, iters: 2704, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 778, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 778, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 778, iters: 2944, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 778, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 778, iters: 3104, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 778, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 778, iters: 3264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 778, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 778, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 778, iters: 3504, time: 0.095, data: 0.040) loss: 0.004 
(epoch: 778, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 778, iters: 3664, time: 0.086, data: 0.012) loss: 0.000 
saving the model at the end of epoch 778, iters 2900384
End of epoch 778 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001321
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 778, TEST ACC: [95.296 %]

(epoch: 779, iters: 16, time: 0.107, data: 0.011) loss: 0.000 
saving the latest model (epoch 779, total_steps 2900400)
(epoch: 779, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 779, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 779, iters: 256, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 779, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 779, iters: 416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 779, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 779, iters: 576, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 779, iters: 656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 779, iters: 736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 779, iters: 816, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 779, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 779, iters: 976, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 779, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 779, iters: 1136, time: 0.094, data: 0.012) loss: 0.004 
(epoch: 779, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 779, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 779, iters: 1376, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 779, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 779, iters: 1536, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 779, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 779, iters: 1696, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 779, iters: 1776, time: 0.094, data: 0.000) loss: 0.041 
(epoch: 779, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 779, iters: 1936, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 779, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 779, iters: 2096, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 779, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 779, iters: 2256, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 779, iters: 2336, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 779, iters: 2416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 779, iters: 2496, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 779, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 779, iters: 2656, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 779, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 779, iters: 2816, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 779, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 779, iters: 2976, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 779, iters: 3056, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 779, iters: 3136, time: 0.095, data: 0.000) loss: 0.056 
(epoch: 779, iters: 3216, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 779, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 779, iters: 3376, time: 0.092, data: 0.011) loss: 0.032 
(epoch: 779, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 779, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 779, iters: 3616, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 779, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 779, iters 2904112
End of epoch 779 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001320
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 779, TEST ACC: [97.269 %]

saving the latest model (epoch 780, total_steps 2904128)
(epoch: 780, iters: 48, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 780, iters: 128, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 780, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 780, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 780, iters: 368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 780, iters: 448, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 780, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 780, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 780, iters: 688, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 780, iters: 768, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 780, iters: 848, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 780, iters: 928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 780, iters: 1008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 780, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 780, iters: 1168, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 780, iters: 1248, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 780, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 780, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 780, iters: 1488, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 780, iters: 1568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 780, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 780, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 780, iters: 1808, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 780, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 780, iters: 1968, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 780, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 780, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 780, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 780, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 780, iters: 2368, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 780, iters: 2448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 780, iters: 2528, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 780, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 780, iters: 2688, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 780, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 780, iters: 2848, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 780, iters: 2928, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 780, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 780, iters: 3088, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 780, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 780, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 780, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 780, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 780, iters: 3488, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 780, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 780, iters: 3648, time: 0.085, data: 0.012) loss: 0.002 
(epoch: 780, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 780, iters 2907840
End of epoch 780 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001319
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 780, TEST ACC: [94.992 %]

saving the latest model (epoch 781, total_steps 2907856)
(epoch: 781, iters: 80, time: 0.093, data: 0.476) loss: 0.002 
(epoch: 781, iters: 160, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 781, iters: 240, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 781, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 781, iters: 400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 781, iters: 480, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 781, iters: 560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 781, iters: 640, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 781, iters: 720, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 781, iters: 800, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 781, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 781, iters: 960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 781, iters: 1040, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 781, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 781, iters: 1200, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 781, iters: 1280, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 781, iters: 1360, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 781, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 781, iters: 1520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 781, iters: 1600, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 781, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 781, iters: 1760, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 781, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 781, iters: 1920, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 781, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 781, iters: 2080, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 781, iters: 2160, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 781, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 781, iters: 2320, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 781, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 781, iters: 2480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 781, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 781, iters: 2640, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 781, iters: 2720, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 781, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 781, iters: 2880, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 781, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 781, iters: 3040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 781, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 781, iters: 3200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 781, iters: 3280, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 781, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 781, iters: 3440, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 781, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 781, iters: 3600, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 781, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 781, iters 2911568
End of epoch 781 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001318
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 781, TEST ACC: [97.117 %]

saving the latest model (epoch 782, total_steps 2911584)
(epoch: 782, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 782, iters: 112, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 782, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 782, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 782, iters: 352, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 782, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 782, iters: 512, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 782, iters: 592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 782, iters: 672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 782, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 782, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 782, iters: 912, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 782, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 782, iters: 1072, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 782, iters: 1152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 782, iters: 1232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 782, iters: 1312, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 782, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 782, iters: 1472, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 782, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 782, iters: 1632, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 782, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 782, iters: 1792, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 782, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 782, iters: 1952, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 782, iters: 2032, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 782, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 782, iters: 2192, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 782, iters: 2272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 782, iters: 2352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 782, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 782, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 782, iters: 2592, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 782, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 782, iters: 2752, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 782, iters: 2832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 782, iters: 2912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 782, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 782, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 782, iters: 3152, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 782, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 782, iters: 3312, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 782, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 782, iters: 3472, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 782, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 782, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 782, iters: 3712, time: 0.088, data: 0.036) loss: 0.000 
saving the model at the end of epoch 782, iters 2915296
End of epoch 782 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001317
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 782, TEST ACC: [96.662 %]

saving the latest model (epoch 783, total_steps 2915312)
(epoch: 783, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 783, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 783, iters: 224, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 783, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 783, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 783, iters: 464, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 783, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 783, iters: 624, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 783, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 783, iters: 784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 783, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 783, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 783, iters: 1024, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 783, iters: 1104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 783, iters: 1184, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 783, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 783, iters: 1344, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 783, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 783, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 783, iters: 1584, time: 0.093, data: 0.040) loss: 0.016 
(epoch: 783, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 783, iters: 1744, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 783, iters: 1824, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 783, iters: 1904, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 783, iters: 1984, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 783, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 783, iters: 2144, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 783, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 783, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 783, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 783, iters: 2464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 783, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 783, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 783, iters: 2704, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 783, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 783, iters: 2864, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 783, iters: 2944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 783, iters: 3024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 783, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 783, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 783, iters: 3264, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 783, iters: 3344, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 783, iters: 3424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 783, iters: 3504, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 783, iters: 3584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 783, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 783, iters 2919024
End of epoch 783 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001316
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 783, TEST ACC: [95.144 %]

(epoch: 784, iters: 16, time: 0.107, data: 0.000) loss: 0.008 
saving the latest model (epoch 784, total_steps 2919040)
(epoch: 784, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 784, iters: 176, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 784, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 784, iters: 336, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 784, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 784, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 784, iters: 576, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 784, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 784, iters: 736, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 784, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 784, iters: 896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 784, iters: 976, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 784, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 784, iters: 1136, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 784, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 784, iters: 1296, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 784, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 784, iters: 1456, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 784, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 784, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 784, iters: 1696, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 784, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 784, iters: 1856, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 784, iters: 1936, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 784, iters: 2016, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 784, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 784, iters: 2176, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 784, iters: 2256, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 784, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 784, iters: 2416, time: 0.091, data: 0.011) loss: 0.003 
(epoch: 784, iters: 2496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 784, iters: 2576, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 784, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 784, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 784, iters: 2816, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 784, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 784, iters: 2976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 784, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 784, iters: 3136, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 784, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 784, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 784, iters: 3376, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 784, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 784, iters: 3536, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 784, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 784, iters: 3696, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 784, iters 2922752
End of epoch 784 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001315
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 784, TEST ACC: [96.206 %]

saving the latest model (epoch 785, total_steps 2922768)
(epoch: 785, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 785, iters: 128, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 785, iters: 208, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 785, iters: 288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 785, iters: 368, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 785, iters: 448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 785, iters: 528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 785, iters: 608, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 785, iters: 688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 785, iters: 768, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 785, iters: 848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 785, iters: 928, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 785, iters: 1008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 785, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 785, iters: 1168, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 785, iters: 1248, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 785, iters: 1328, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 785, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 785, iters: 1488, time: 0.093, data: 0.012) loss: 0.031 
(epoch: 785, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 785, iters: 1648, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 785, iters: 1728, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 785, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 785, iters: 1888, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 785, iters: 1968, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 785, iters: 2048, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 785, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 785, iters: 2208, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 785, iters: 2288, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 785, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 785, iters: 2448, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 785, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 785, iters: 2608, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 785, iters: 2688, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 785, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 785, iters: 2848, time: 0.097, data: 0.040) loss: 0.004 
(epoch: 785, iters: 2928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 785, iters: 3008, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 785, iters: 3088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 785, iters: 3168, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 785, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 785, iters: 3328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 785, iters: 3408, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 785, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 785, iters: 3568, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 785, iters: 3648, time: 0.087, data: 0.000) loss: 0.000 
(epoch: 785, iters: 3728, time: 0.055, data: 0.012) loss: 0.000 
saving the model at the end of epoch 785, iters 2926480
End of epoch 785 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001314
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 785, TEST ACC: [97.117 %]

saving the latest model (epoch 786, total_steps 2926496)
(epoch: 786, iters: 80, time: 0.094, data: 0.498) loss: 0.000 
(epoch: 786, iters: 160, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 786, iters: 240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 786, iters: 320, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 786, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 786, iters: 480, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 786, iters: 560, time: 0.093, data: 0.000) loss: 0.017 
(epoch: 786, iters: 640, time: 0.093, data: 0.000) loss: 0.057 
(epoch: 786, iters: 720, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 786, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 786, iters: 880, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 786, iters: 960, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 786, iters: 1040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 786, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 786, iters: 1200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 786, iters: 1280, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 786, iters: 1360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 786, iters: 1440, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 786, iters: 1520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 786, iters: 1600, time: 0.095, data: 0.020) loss: 0.000 
(epoch: 786, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 786, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 786, iters: 1840, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 786, iters: 1920, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 786, iters: 2000, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 786, iters: 2080, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 786, iters: 2160, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 786, iters: 2240, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 786, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 786, iters: 2400, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 786, iters: 2480, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 786, iters: 2560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 786, iters: 2640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 786, iters: 2720, time: 0.096, data: 0.021) loss: 0.000 
(epoch: 786, iters: 2800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 786, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 786, iters: 2960, time: 0.096, data: 0.053) loss: 0.000 
(epoch: 786, iters: 3040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 786, iters: 3120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 786, iters: 3200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 786, iters: 3280, time: 0.095, data: 0.021) loss: 0.000 
(epoch: 786, iters: 3360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 786, iters: 3440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 786, iters: 3520, time: 0.097, data: 0.050) loss: 0.000 
(epoch: 786, iters: 3600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 786, iters: 3680, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 786, iters 2930208
End of epoch 786 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001313
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 786, TEST ACC: [90.137 %]

saving the latest model (epoch 787, total_steps 2930224)
(epoch: 787, iters: 32, time: 0.094, data: 0.007) loss: 0.000 
(epoch: 787, iters: 112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 787, iters: 192, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 787, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 787, iters: 352, time: 0.095, data: 0.052) loss: 0.000 
(epoch: 787, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 787, iters: 512, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 787, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 787, iters: 672, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 787, iters: 752, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 787, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 787, iters: 912, time: 0.097, data: 0.052) loss: 0.000 
(epoch: 787, iters: 992, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 787, iters: 1072, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 787, iters: 1152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 787, iters: 1232, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 787, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 787, iters: 1392, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 787, iters: 1472, time: 0.094, data: 0.052) loss: 0.000 
(epoch: 787, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 787, iters: 1632, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 787, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 787, iters: 1792, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 787, iters: 1872, time: 0.094, data: 0.000) loss: 0.011 
(epoch: 787, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 787, iters: 2032, time: 0.096, data: 0.050) loss: 0.004 
(epoch: 787, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 787, iters: 2192, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 787, iters: 2272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 787, iters: 2352, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 787, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 787, iters: 2512, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 787, iters: 2592, time: 0.094, data: 0.039) loss: 0.011 
(epoch: 787, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 787, iters: 2752, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 787, iters: 2832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 787, iters: 2912, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 787, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 787, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 787, iters: 3152, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 787, iters: 3232, time: 0.094, data: 0.000) loss: 0.026 
(epoch: 787, iters: 3312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 787, iters: 3392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 787, iters: 3472, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 787, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 787, iters: 3632, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 787, iters: 3712, time: 0.087, data: 0.035) loss: 0.000 
saving the model at the end of epoch 787, iters 2933936
End of epoch 787 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001312
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 787, TEST ACC: [97.269 %]

saving the latest model (epoch 788, total_steps 2933952)
(epoch: 788, iters: 64, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 788, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 788, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 788, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 788, iters: 384, time: 0.095, data: 0.041) loss: 0.001 
(epoch: 788, iters: 464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 788, iters: 544, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 788, iters: 624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 788, iters: 704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 788, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 788, iters: 864, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 788, iters: 944, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 788, iters: 1024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 788, iters: 1104, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 788, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 788, iters: 1264, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 788, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 788, iters: 1424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 788, iters: 1504, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 788, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 788, iters: 1664, time: 0.091, data: 0.021) loss: 0.000 
(epoch: 788, iters: 1744, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 788, iters: 1824, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 788, iters: 1904, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 788, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 788, iters: 2064, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 788, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 788, iters: 2224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 788, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 788, iters: 2384, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 788, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 788, iters: 2544, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 788, iters: 2624, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 788, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 788, iters: 2784, time: 0.091, data: 0.011) loss: 0.003 
(epoch: 788, iters: 2864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 788, iters: 2944, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 788, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 788, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 788, iters: 3184, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 788, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 788, iters: 3344, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 788, iters: 3424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 788, iters: 3504, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 788, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 788, iters: 3664, time: 0.087, data: 0.000) loss: 0.001 
saving the model at the end of epoch 788, iters 2937664
End of epoch 788 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001311
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 788, TEST ACC: [97.117 %]

(epoch: 789, iters: 16, time: 0.111, data: 0.012) loss: 0.000 
saving the latest model (epoch 789, total_steps 2937680)
(epoch: 789, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 789, iters: 176, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 789, iters: 256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 789, iters: 336, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 789, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 789, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 789, iters: 576, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 789, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 789, iters: 736, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 789, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 789, iters: 896, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 789, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 789, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 789, iters: 1136, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 789, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 789, iters: 1296, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 789, iters: 1376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 789, iters: 1456, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 789, iters: 1536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 789, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 789, iters: 1696, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 789, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 789, iters: 1856, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 789, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 789, iters: 2016, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 789, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 789, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 789, iters: 2256, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 789, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 789, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 789, iters: 2496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 789, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 789, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 789, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 789, iters: 2816, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 789, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 789, iters: 2976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 789, iters: 3056, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 789, iters: 3136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 789, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 789, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 789, iters: 3376, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 789, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 789, iters: 3536, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 789, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 789, iters: 3696, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 789, iters 2941392
End of epoch 789 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001310
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 789, TEST ACC: [96.965 %]

saving the latest model (epoch 790, total_steps 2941408)
(epoch: 790, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 790, iters: 128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 790, iters: 208, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 790, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 790, iters: 368, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 790, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 790, iters: 528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 790, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 790, iters: 688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 790, iters: 768, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 790, iters: 848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 790, iters: 928, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 790, iters: 1008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 790, iters: 1088, time: 0.095, data: 0.011) loss: 0.039 
(epoch: 790, iters: 1168, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 790, iters: 1248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 790, iters: 1328, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 790, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 790, iters: 1488, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 790, iters: 1568, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 790, iters: 1648, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 790, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 790, iters: 1808, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 790, iters: 1888, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 790, iters: 1968, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 790, iters: 2048, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 790, iters: 2128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 790, iters: 2208, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 790, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 790, iters: 2368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 790, iters: 2448, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 790, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 790, iters: 2608, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 790, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 790, iters: 2768, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 790, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 790, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 790, iters: 3008, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 790, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 790, iters: 3168, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 790, iters: 3248, time: 0.093, data: 0.000) loss: 0.012 
(epoch: 790, iters: 3328, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 790, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 790, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 790, iters: 3568, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 790, iters: 3648, time: 0.087, data: 0.000) loss: 0.000 
(epoch: 790, iters: 3728, time: 0.056, data: 0.021) loss: 0.000 
saving the model at the end of epoch 790, iters 2945120
End of epoch 790 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001309
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 790, TEST ACC: [96.813 %]

saving the latest model (epoch 791, total_steps 2945136)
(epoch: 791, iters: 80, time: 0.095, data: 0.508) loss: 0.000 
(epoch: 791, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 791, iters: 240, time: 0.096, data: 0.042) loss: 0.001 
(epoch: 791, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 791, iters: 400, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 791, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 791, iters: 560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 791, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 791, iters: 720, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 791, iters: 800, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 791, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 791, iters: 960, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 791, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 791, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 791, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 791, iters: 1280, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 791, iters: 1360, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 791, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 791, iters: 1520, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 791, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 791, iters: 1680, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 791, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 791, iters: 1840, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 791, iters: 1920, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 791, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 791, iters: 2080, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 791, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 791, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 791, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 791, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 791, iters: 2480, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 791, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 791, iters: 2640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 791, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 791, iters: 2800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 791, iters: 2880, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 791, iters: 2960, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 791, iters: 3040, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 791, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 791, iters: 3200, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 791, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 791, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 791, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 791, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 791, iters: 3600, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 791, iters: 3680, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 791, iters 2948848
End of epoch 791 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001308
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 791, TEST ACC: [96.662 %]

saving the latest model (epoch 792, total_steps 2948864)
(epoch: 792, iters: 32, time: 0.092, data: 0.005) loss: 0.020 
(epoch: 792, iters: 112, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 792, iters: 192, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 792, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 792, iters: 352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 792, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 792, iters: 512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 792, iters: 592, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 792, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 792, iters: 752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 792, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 792, iters: 912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 792, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 792, iters: 1072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 792, iters: 1152, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 792, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 792, iters: 1312, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 792, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 792, iters: 1472, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 792, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 792, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 792, iters: 1712, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 792, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 792, iters: 1872, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 792, iters: 1952, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 792, iters: 2032, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 792, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 792, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 792, iters: 2272, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 792, iters: 2352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 792, iters: 2432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 792, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 792, iters: 2592, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 792, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 792, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 792, iters: 2832, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 792, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 792, iters: 2992, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 792, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 792, iters: 3152, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 792, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 792, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 792, iters: 3392, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 792, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 792, iters: 3552, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 792, iters: 3632, time: 0.091, data: 0.000) loss: 0.120 
(epoch: 792, iters: 3712, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 792, iters 2952576
End of epoch 792 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001307
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 792, TEST ACC: [95.751 %]

saving the latest model (epoch 793, total_steps 2952592)
(epoch: 793, iters: 64, time: 0.094, data: 0.003) loss: 0.001 
(epoch: 793, iters: 144, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 793, iters: 224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 793, iters: 304, time: 0.096, data: 0.012) loss: 0.018 
(epoch: 793, iters: 384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 793, iters: 464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 793, iters: 544, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 793, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 793, iters: 704, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 793, iters: 784, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 793, iters: 864, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 793, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 793, iters: 1024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 793, iters: 1104, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 793, iters: 1184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 793, iters: 1264, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 793, iters: 1344, time: 0.094, data: 0.000) loss: 0.018 
(epoch: 793, iters: 1424, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 793, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 793, iters: 1584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 793, iters: 1664, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 793, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 793, iters: 1824, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 793, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 793, iters: 1984, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 793, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 793, iters: 2144, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 793, iters: 2224, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 793, iters: 2304, time: 0.094, data: 0.000) loss: 0.198 
(epoch: 793, iters: 2384, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 793, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 793, iters: 2544, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 793, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 793, iters: 2704, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 793, iters: 2784, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 793, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 793, iters: 2944, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 793, iters: 3024, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 793, iters: 3104, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 793, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 793, iters: 3264, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 793, iters: 3344, time: 0.094, data: 0.049) loss: 0.005 
(epoch: 793, iters: 3424, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 793, iters: 3504, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 793, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 793, iters: 3664, time: 0.087, data: 0.020) loss: 0.000 
saving the model at the end of epoch 793, iters 2956304
End of epoch 793 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001306
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 793, TEST ACC: [96.662 %]

(epoch: 794, iters: 16, time: 0.109, data: 0.000) loss: 0.001 
saving the latest model (epoch 794, total_steps 2956320)
(epoch: 794, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 794, iters: 176, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 794, iters: 256, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 794, iters: 336, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 794, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 794, iters: 496, time: 0.094, data: 0.000) loss: 0.085 
(epoch: 794, iters: 576, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 794, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 794, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 794, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 794, iters: 896, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 794, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 794, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 794, iters: 1136, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 794, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 794, iters: 1296, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 794, iters: 1376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 794, iters: 1456, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 794, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 794, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 794, iters: 1696, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 794, iters: 1776, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 794, iters: 1856, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 794, iters: 1936, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 794, iters: 2016, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 794, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 794, iters: 2176, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 794, iters: 2256, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 794, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 794, iters: 2416, time: 0.092, data: 0.012) loss: 0.131 
(epoch: 794, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 794, iters: 2576, time: 0.092, data: 0.012) loss: 0.027 
(epoch: 794, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 794, iters: 2736, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 794, iters: 2816, time: 0.096, data: 0.043) loss: 0.000 
(epoch: 794, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 794, iters: 2976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 794, iters: 3056, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 794, iters: 3136, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 794, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 794, iters: 3296, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 794, iters: 3376, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 794, iters: 3456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 794, iters: 3536, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 794, iters: 3616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 794, iters: 3696, time: 0.089, data: 0.012) loss: 0.000 
saving the model at the end of epoch 794, iters 2960032
End of epoch 794 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001305
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 794, TEST ACC: [95.296 %]

saving the latest model (epoch 795, total_steps 2960048)
(epoch: 795, iters: 48, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 795, iters: 128, time: 0.097, data: 0.042) loss: 0.000 
(epoch: 795, iters: 208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 795, iters: 288, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 795, iters: 368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 795, iters: 448, time: 0.095, data: 0.012) loss: 0.009 
(epoch: 795, iters: 528, time: 0.096, data: 0.000) loss: 0.018 
(epoch: 795, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 795, iters: 688, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 795, iters: 768, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 795, iters: 848, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 795, iters: 928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 795, iters: 1008, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 795, iters: 1088, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 795, iters: 1168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 795, iters: 1248, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 795, iters: 1328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 795, iters: 1408, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 795, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 795, iters: 1568, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 795, iters: 1648, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 795, iters: 1728, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 795, iters: 1808, time: 0.097, data: 0.042) loss: 0.000 
(epoch: 795, iters: 1888, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 795, iters: 1968, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 795, iters: 2048, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 795, iters: 2128, time: 0.095, data: 0.012) loss: 0.005 
(epoch: 795, iters: 2208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 795, iters: 2288, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 795, iters: 2368, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 795, iters: 2448, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 795, iters: 2528, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 795, iters: 2608, time: 0.096, data: 0.000) loss: 0.020 
(epoch: 795, iters: 2688, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 795, iters: 2768, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 795, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 795, iters: 2928, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 795, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 795, iters: 3088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 795, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 795, iters: 3248, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 795, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 795, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 795, iters: 3488, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 795, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 795, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 795, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 795, iters 2963760
End of epoch 795 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001304
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 795, TEST ACC: [95.448 %]

saving the latest model (epoch 796, total_steps 2963776)
(epoch: 796, iters: 80, time: 0.094, data: 0.498) loss: 0.000 
(epoch: 796, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 796, iters: 240, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 796, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 796, iters: 400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 796, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 796, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 796, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 796, iters: 720, time: 0.092, data: 0.000) loss: 0.009 
(epoch: 796, iters: 800, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 796, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 796, iters: 960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 796, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 796, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 796, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 796, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 796, iters: 1360, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 796, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 796, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 796, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 796, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 796, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 796, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 796, iters: 1920, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 796, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 796, iters: 2080, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 796, iters: 2160, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 796, iters: 2240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 796, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 796, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 796, iters: 2480, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 796, iters: 2560, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 796, iters: 2640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 796, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 796, iters: 2800, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 796, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 796, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 796, iters: 3040, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 796, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 796, iters: 3200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 796, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 796, iters: 3360, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 796, iters: 3440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 796, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 796, iters: 3600, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 796, iters: 3680, time: 0.087, data: 0.000) loss: 0.007 
saving the model at the end of epoch 796, iters 2967488
End of epoch 796 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001303
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 796, TEST ACC: [95.751 %]

saving the latest model (epoch 797, total_steps 2967504)
(epoch: 797, iters: 32, time: 0.093, data: 0.004) loss: 0.000 
(epoch: 797, iters: 112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 797, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 797, iters: 272, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 797, iters: 352, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 797, iters: 432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 797, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 797, iters: 592, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 797, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 797, iters: 752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 797, iters: 832, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 797, iters: 912, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 797, iters: 992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 797, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 797, iters: 1152, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 797, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 797, iters: 1312, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 797, iters: 1392, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 797, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 797, iters: 1552, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 797, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 797, iters: 1712, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 797, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 797, iters: 1872, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 797, iters: 1952, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 797, iters: 2032, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 797, iters: 2112, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 797, iters: 2192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 797, iters: 2272, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 797, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 797, iters: 2432, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 797, iters: 2512, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 797, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 797, iters: 2672, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 797, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 797, iters: 2832, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 797, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 797, iters: 2992, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 797, iters: 3072, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 797, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 797, iters: 3232, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 797, iters: 3312, time: 0.093, data: 0.000) loss: 0.092 
(epoch: 797, iters: 3392, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 797, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 797, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 797, iters: 3632, time: 0.091, data: 0.039) loss: 0.000 
(epoch: 797, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 797, iters 2971216
End of epoch 797 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001302
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 797, TEST ACC: [95.751 %]

saving the latest model (epoch 798, total_steps 2971232)
(epoch: 798, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 798, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 798, iters: 224, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 798, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 798, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 798, iters: 464, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 798, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 798, iters: 624, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 798, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 798, iters: 784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 798, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 798, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 798, iters: 1024, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 798, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 798, iters: 1184, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 798, iters: 1264, time: 0.093, data: 0.000) loss: 0.015 
(epoch: 798, iters: 1344, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 798, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 798, iters: 1504, time: 0.094, data: 0.000) loss: 0.029 
(epoch: 798, iters: 1584, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 798, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 798, iters: 1744, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 798, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 798, iters: 1904, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 798, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 798, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 798, iters: 2144, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 798, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 798, iters: 2304, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 798, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 798, iters: 2464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 798, iters: 2544, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 798, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 798, iters: 2704, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 798, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 798, iters: 2864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 798, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 798, iters: 3024, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 798, iters: 3104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 798, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 798, iters: 3264, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 798, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 798, iters: 3424, time: 0.091, data: 0.012) loss: 0.012 
(epoch: 798, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 798, iters: 3584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 798, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 798, iters 2974944
End of epoch 798 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001301
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 798, TEST ACC: [96.662 %]

(epoch: 799, iters: 16, time: 0.107, data: 0.000) loss: 0.000 
saving the latest model (epoch 799, total_steps 2974960)
(epoch: 799, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 799, iters: 176, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 799, iters: 256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 799, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 799, iters: 416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 799, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 799, iters: 576, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 799, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 799, iters: 736, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 799, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 799, iters: 896, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 799, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 799, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 799, iters: 1136, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 799, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 799, iters: 1296, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 799, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 799, iters: 1456, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 799, iters: 1536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 799, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 799, iters: 1696, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 799, iters: 1776, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 799, iters: 1856, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 799, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 799, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 799, iters: 2096, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 799, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 799, iters: 2256, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 799, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 799, iters: 2416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 799, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 799, iters: 2576, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 799, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 799, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 799, iters: 2816, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 799, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 799, iters: 2976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 799, iters: 3056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 799, iters: 3136, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 799, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 799, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 799, iters: 3376, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 799, iters: 3456, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 799, iters: 3536, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 799, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 799, iters: 3696, time: 0.087, data: 0.021) loss: 0.000 
saving the model at the end of epoch 799, iters 2978672
End of epoch 799 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001300
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 799, TEST ACC: [96.358 %]

saving the latest model (epoch 800, total_steps 2978688)
(epoch: 800, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 128, time: 0.093, data: 0.028) loss: 0.000 
(epoch: 800, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 800, iters: 368, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 800, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 800, iters: 528, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 800, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 800, iters: 688, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 800, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 800, iters: 928, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 800, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 1088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 800, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 1248, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 800, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 800, iters: 1488, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 800, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 1648, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 800, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 1808, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 800, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 1968, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 800, iters: 2048, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 800, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 2208, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 800, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 2368, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 800, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 800, iters: 2608, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 800, iters: 2688, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 800, iters: 2768, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 800, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 2928, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 800, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 800, iters: 3168, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 800, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 3328, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 800, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 3488, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 800, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 800, iters: 3648, time: 0.087, data: 0.000) loss: 0.000 
(epoch: 800, iters: 3728, time: 0.056, data: 0.015) loss: 0.000 
saving the model at the end of epoch 800, iters 2982400
End of epoch 800 / 2100 	 Time Taken: 350 sec
learning rate = 0.0001299
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 800, TEST ACC: [96.662 %]

saving the latest model (epoch 801, total_steps 2982416)
(epoch: 801, iters: 80, time: 0.095, data: 0.525) loss: 0.000 
(epoch: 801, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 801, iters: 240, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 801, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 801, iters: 400, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 801, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 801, iters: 560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 801, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 801, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 801, iters: 800, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 801, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 801, iters: 960, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 801, iters: 1040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 801, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 801, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 801, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 801, iters: 1360, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 801, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 801, iters: 1520, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 801, iters: 1600, time: 0.096, data: 0.000) loss: 0.062 
(epoch: 801, iters: 1680, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 801, iters: 1760, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 801, iters: 1840, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 801, iters: 1920, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 801, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 801, iters: 2080, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 801, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 801, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 801, iters: 2320, time: 0.093, data: 0.000) loss: 0.026 
(epoch: 801, iters: 2400, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 801, iters: 2480, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 801, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 801, iters: 2640, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 801, iters: 2720, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 801, iters: 2800, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 801, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 801, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 801, iters: 3040, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 801, iters: 3120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 801, iters: 3200, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 801, iters: 3280, time: 0.096, data: 0.000) loss: 0.011 
(epoch: 801, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 801, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 801, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 801, iters: 3600, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 801, iters: 3680, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 801, iters 2986128
End of epoch 801 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001298
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 801, TEST ACC: [95.599 %]

saving the latest model (epoch 802, total_steps 2986144)
(epoch: 802, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 802, iters: 112, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 802, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 802, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 802, iters: 352, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 802, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 802, iters: 512, time: 0.092, data: 0.012) loss: 0.015 
(epoch: 802, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 802, iters: 672, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 802, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 802, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 802, iters: 912, time: 0.096, data: 0.041) loss: 0.024 
(epoch: 802, iters: 992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 802, iters: 1072, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 802, iters: 1152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 802, iters: 1232, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 802, iters: 1312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 802, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 802, iters: 1472, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 802, iters: 1552, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 802, iters: 1632, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 802, iters: 1712, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 802, iters: 1792, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 802, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 802, iters: 1952, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 802, iters: 2032, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 802, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 802, iters: 2192, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 802, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 802, iters: 2352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 802, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 802, iters: 2512, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 802, iters: 2592, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 802, iters: 2672, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 802, iters: 2752, time: 0.092, data: 0.011) loss: 0.008 
(epoch: 802, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 802, iters: 2912, time: 0.093, data: 0.014) loss: 0.037 
(epoch: 802, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 802, iters: 3072, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 802, iters: 3152, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 802, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 802, iters: 3312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 802, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 802, iters: 3472, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 802, iters: 3552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 802, iters: 3632, time: 0.091, data: 0.000) loss: 0.006 
(epoch: 802, iters: 3712, time: 0.088, data: 0.035) loss: 0.000 
saving the model at the end of epoch 802, iters 2989856
End of epoch 802 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001297
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 802, TEST ACC: [96.965 %]

saving the latest model (epoch 803, total_steps 2989872)
(epoch: 803, iters: 64, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 803, iters: 144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 803, iters: 224, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 803, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 803, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 803, iters: 464, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 803, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 803, iters: 624, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 803, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 803, iters: 784, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 803, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 803, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 803, iters: 1024, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 803, iters: 1104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 803, iters: 1184, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 803, iters: 1264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 803, iters: 1344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 803, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 803, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 803, iters: 1584, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 803, iters: 1664, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 803, iters: 1744, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 803, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 803, iters: 1904, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 803, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 803, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 803, iters: 2144, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 803, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 803, iters: 2304, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 803, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 803, iters: 2464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 803, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 803, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 803, iters: 2704, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 803, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 803, iters: 2864, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 803, iters: 2944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 803, iters: 3024, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 803, iters: 3104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 803, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 803, iters: 3264, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 803, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 803, iters: 3424, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 803, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 803, iters: 3584, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 803, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 803, iters 2993584
End of epoch 803 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001296
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 803, TEST ACC: [97.724 %]

(epoch: 804, iters: 16, time: 0.109, data: 0.000) loss: 0.000 
saving the latest model (epoch 804, total_steps 2993600)
(epoch: 804, iters: 96, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 804, iters: 176, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 804, iters: 256, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 804, iters: 336, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 804, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 804, iters: 496, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 804, iters: 576, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 804, iters: 656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 804, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 804, iters: 816, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 804, iters: 896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 804, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 804, iters: 1056, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 804, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 804, iters: 1216, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 804, iters: 1296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 804, iters: 1376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 804, iters: 1456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 804, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 804, iters: 1616, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 804, iters: 1696, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 804, iters: 1776, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 804, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 804, iters: 1936, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 804, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 804, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 804, iters: 2176, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 804, iters: 2256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 804, iters: 2336, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 804, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 804, iters: 2496, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 804, iters: 2576, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 804, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 804, iters: 2736, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 804, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 804, iters: 2896, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 804, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 804, iters: 3056, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 804, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 804, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 804, iters: 3296, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 804, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 804, iters: 3456, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 804, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 804, iters: 3616, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 804, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 804, iters 2997312
End of epoch 804 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001295
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 804, TEST ACC: [97.724 %]

saving the latest model (epoch 805, total_steps 2997328)
(epoch: 805, iters: 48, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 805, iters: 128, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 805, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 805, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 805, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 805, iters: 448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 805, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 805, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 805, iters: 688, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 805, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 805, iters: 848, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 805, iters: 928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 805, iters: 1008, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 805, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 805, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 805, iters: 1248, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 805, iters: 1328, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 805, iters: 1408, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 805, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 805, iters: 1568, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 805, iters: 1648, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 805, iters: 1728, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 805, iters: 1808, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 805, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 805, iters: 1968, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 805, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 805, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 805, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 805, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 805, iters: 2368, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 805, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 805, iters: 2528, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 805, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 805, iters: 2688, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 805, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 805, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 805, iters: 2928, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 805, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 805, iters: 3088, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 805, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 805, iters: 3248, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 805, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 805, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 805, iters: 3488, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 805, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 805, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 805, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 805, iters 3001040
End of epoch 805 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001294
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 805, TEST ACC: [95.599 %]

saving the latest model (epoch 806, total_steps 3001056)
(epoch: 806, iters: 80, time: 0.094, data: 0.449) loss: 0.000 
(epoch: 806, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 806, iters: 240, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 806, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 806, iters: 400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 806, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 806, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 806, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 806, iters: 720, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 806, iters: 800, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 806, iters: 880, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 806, iters: 960, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 806, iters: 1040, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 806, iters: 1120, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 806, iters: 1200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 806, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 806, iters: 1360, time: 0.094, data: 0.040) loss: 0.061 
(epoch: 806, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 806, iters: 1520, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 806, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 806, iters: 1680, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 806, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 806, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 806, iters: 1920, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 806, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 806, iters: 2080, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 806, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 806, iters: 2240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 806, iters: 2320, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 806, iters: 2400, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 806, iters: 2480, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 806, iters: 2560, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 806, iters: 2640, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 806, iters: 2720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 806, iters: 2800, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 806, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 806, iters: 2960, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 806, iters: 3040, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 806, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 806, iters: 3200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 806, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 806, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 806, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 806, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 806, iters: 3600, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 806, iters: 3680, time: 0.089, data: 0.000) loss: 0.004 
saving the model at the end of epoch 806, iters 3004768
End of epoch 806 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001293
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 806, TEST ACC: [96.813 %]

saving the latest model (epoch 807, total_steps 3004784)
(epoch: 807, iters: 32, time: 0.091, data: 0.005) loss: 0.003 
(epoch: 807, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 807, iters: 192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 807, iters: 272, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 807, iters: 352, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 807, iters: 432, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 807, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 807, iters: 592, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 807, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 807, iters: 752, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 807, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 807, iters: 912, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 807, iters: 992, time: 0.094, data: 0.049) loss: 0.001 
(epoch: 807, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 807, iters: 1152, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 807, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 807, iters: 1312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 807, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 807, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 807, iters: 1552, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 807, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 807, iters: 1712, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 807, iters: 1792, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 807, iters: 1872, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 807, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 807, iters: 2032, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 807, iters: 2112, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 807, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 807, iters: 2272, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 807, iters: 2352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 807, iters: 2432, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 807, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 807, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 807, iters: 2672, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 807, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 807, iters: 2832, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 807, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 807, iters: 2992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 807, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 807, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 807, iters: 3232, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 807, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 807, iters: 3392, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 807, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 807, iters: 3552, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 807, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 807, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 807, iters 3008496
End of epoch 807 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001292
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 807, TEST ACC: [97.117 %]

saving the latest model (epoch 808, total_steps 3008512)
(epoch: 808, iters: 64, time: 0.092, data: 0.003) loss: 0.000 
(epoch: 808, iters: 144, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 808, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 808, iters: 304, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 808, iters: 384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 808, iters: 464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 808, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 808, iters: 624, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 808, iters: 704, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 808, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 808, iters: 864, time: 0.091, data: 0.011) loss: 0.001 
(epoch: 808, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 808, iters: 1024, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 808, iters: 1104, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 808, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 808, iters: 1264, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 808, iters: 1344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 808, iters: 1424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 808, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 808, iters: 1584, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 808, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 808, iters: 1744, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 808, iters: 1824, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 808, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 808, iters: 1984, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 808, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 808, iters: 2144, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 808, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 808, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 808, iters: 2384, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 808, iters: 2464, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 808, iters: 2544, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 808, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 808, iters: 2704, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 808, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 808, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 808, iters: 2944, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 808, iters: 3024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 808, iters: 3104, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 808, iters: 3184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 808, iters: 3264, time: 0.093, data: 0.012) loss: 0.188 
(epoch: 808, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 808, iters: 3424, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 808, iters: 3504, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 808, iters: 3584, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 808, iters: 3664, time: 0.086, data: 0.011) loss: 0.000 
saving the model at the end of epoch 808, iters 3012224
End of epoch 808 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001291
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 808, TEST ACC: [89.833 %]

(epoch: 809, iters: 16, time: 0.109, data: 0.012) loss: 0.000 
saving the latest model (epoch 809, total_steps 3012240)
(epoch: 809, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 809, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 809, iters: 256, time: 0.094, data: 0.040) loss: 0.017 
(epoch: 809, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 809, iters: 416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 809, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 809, iters: 576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 809, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 809, iters: 736, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 809, iters: 816, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 809, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 809, iters: 976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 809, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 809, iters: 1136, time: 0.093, data: 0.012) loss: 0.013 
(epoch: 809, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 809, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 809, iters: 1376, time: 0.094, data: 0.049) loss: 0.005 
(epoch: 809, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 809, iters: 1536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 809, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 809, iters: 1696, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 809, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 809, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 809, iters: 1936, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 809, iters: 2016, time: 0.095, data: 0.000) loss: 0.047 
(epoch: 809, iters: 2096, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 809, iters: 2176, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 809, iters: 2256, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 809, iters: 2336, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 809, iters: 2416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 809, iters: 2496, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 809, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 809, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 809, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 809, iters: 2816, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 809, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 809, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 809, iters: 3056, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 809, iters: 3136, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 809, iters: 3216, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 809, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 809, iters: 3376, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 809, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 809, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 809, iters: 3616, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 809, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 809, iters 3015952
End of epoch 809 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001290
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 809, TEST ACC: [97.269 %]

saving the latest model (epoch 810, total_steps 3015968)
(epoch: 810, iters: 48, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 810, iters: 128, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 810, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 810, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 810, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 810, iters: 448, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 810, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 810, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 810, iters: 688, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 810, iters: 768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 810, iters: 848, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 810, iters: 928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 810, iters: 1008, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 810, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 810, iters: 1168, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 810, iters: 1248, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 810, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 810, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 810, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 810, iters: 1568, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 810, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 810, iters: 1728, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 810, iters: 1808, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 810, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 810, iters: 1968, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 810, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 810, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 810, iters: 2208, time: 0.095, data: 0.000) loss: 0.044 
(epoch: 810, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 810, iters: 2368, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 810, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 810, iters: 2528, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 810, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 810, iters: 2688, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 810, iters: 2768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 810, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 810, iters: 2928, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 810, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 810, iters: 3088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 810, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 810, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 810, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 810, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 810, iters: 3488, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 810, iters: 3568, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 810, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 810, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 810, iters 3019680
End of epoch 810 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001289
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 810, TEST ACC: [96.358 %]

saving the latest model (epoch 811, total_steps 3019696)
(epoch: 811, iters: 80, time: 0.093, data: 0.525) loss: 0.000 
(epoch: 811, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 811, iters: 240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 811, iters: 320, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 811, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 811, iters: 480, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 811, iters: 560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 811, iters: 640, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 811, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 811, iters: 800, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 811, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 811, iters: 960, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 811, iters: 1040, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 811, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 811, iters: 1200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 811, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 811, iters: 1360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 811, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 811, iters: 1520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 811, iters: 1600, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 811, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 811, iters: 1760, time: 0.091, data: 0.022) loss: 0.000 
(epoch: 811, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 811, iters: 1920, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 811, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 811, iters: 2080, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 811, iters: 2160, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 811, iters: 2240, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 811, iters: 2320, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 811, iters: 2400, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 811, iters: 2480, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 811, iters: 2560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 811, iters: 2640, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 811, iters: 2720, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 811, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 811, iters: 2880, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 811, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 811, iters: 3040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 811, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 811, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 811, iters: 3280, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 811, iters: 3360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 811, iters: 3440, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 811, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 811, iters: 3600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 811, iters: 3680, time: 0.086, data: 0.000) loss: 0.000 
saving the model at the end of epoch 811, iters 3023408
End of epoch 811 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001288
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 811, TEST ACC: [89.074 %]

saving the latest model (epoch 812, total_steps 3023424)
(epoch: 812, iters: 32, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 812, iters: 112, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 812, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 812, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 812, iters: 352, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 812, iters: 432, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 812, iters: 512, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 812, iters: 592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 812, iters: 672, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 812, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 812, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 812, iters: 912, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 812, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 812, iters: 1072, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 812, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 812, iters: 1232, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 812, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 812, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 812, iters: 1472, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 812, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 812, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 812, iters: 1712, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 812, iters: 1792, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 812, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 812, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 812, iters: 2032, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 812, iters: 2112, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 812, iters: 2192, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 812, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 812, iters: 2352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 812, iters: 2432, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 812, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 812, iters: 2592, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 812, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 812, iters: 2752, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 812, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 812, iters: 2912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 812, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 812, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 812, iters: 3152, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 812, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 812, iters: 3312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 812, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 812, iters: 3472, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 812, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 812, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 812, iters: 3712, time: 0.088, data: 0.035) loss: 0.000 
saving the model at the end of epoch 812, iters 3027136
End of epoch 812 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001287
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 812, TEST ACC: [97.42 %]

saving the latest model (epoch 813, total_steps 3027152)
(epoch: 813, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 813, iters: 144, time: 0.097, data: 0.038) loss: 0.000 
(epoch: 813, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 813, iters: 304, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 813, iters: 384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 813, iters: 464, time: 0.094, data: 0.011) loss: 0.189 
(epoch: 813, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 813, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 813, iters: 704, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 813, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 813, iters: 864, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 813, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 813, iters: 1024, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 813, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 813, iters: 1184, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 813, iters: 1264, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 813, iters: 1344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 813, iters: 1424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 813, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 813, iters: 1584, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 813, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 813, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 813, iters: 1824, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 813, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 813, iters: 1984, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 813, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 813, iters: 2144, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 813, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 813, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 813, iters: 2384, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 813, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 813, iters: 2544, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 813, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 813, iters: 2704, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 813, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 813, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 813, iters: 2944, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 813, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 813, iters: 3104, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 813, iters: 3184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 813, iters: 3264, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 813, iters: 3344, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 813, iters: 3424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 813, iters: 3504, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 813, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 813, iters: 3664, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 813, iters 3030864
End of epoch 813 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001286
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 813, TEST ACC: [97.42 %]

(epoch: 814, iters: 16, time: 0.109, data: 0.012) loss: 0.000 
saving the latest model (epoch 814, total_steps 3030880)
(epoch: 814, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 176, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 814, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 336, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 814, iters: 416, time: 0.096, data: 0.000) loss: 0.217 
(epoch: 814, iters: 496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 814, iters: 576, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 814, iters: 656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 814, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 814, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 814, iters: 896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 814, iters: 976, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 814, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 1136, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 814, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 1296, time: 0.092, data: 0.011) loss: 0.029 
(epoch: 814, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 1456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 814, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 814, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 1696, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 814, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 1856, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 814, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 2016, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 814, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 2256, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 814, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 2416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 814, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 2576, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 814, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 814, iters: 2816, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 814, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 2976, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 814, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 814, iters: 3136, time: 0.093, data: 0.011) loss: 0.004 
(epoch: 814, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 3376, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 814, iters: 3456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 814, iters: 3536, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 814, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 814, iters: 3696, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 814, iters 3034592
End of epoch 814 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001285
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 814, TEST ACC: [95.144 %]

saving the latest model (epoch 815, total_steps 3034608)
(epoch: 815, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 815, iters: 128, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 815, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 815, iters: 288, time: 0.091, data: 0.011) loss: 0.006 
(epoch: 815, iters: 368, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 815, iters: 448, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 815, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 815, iters: 608, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 815, iters: 688, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 815, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 815, iters: 848, time: 0.092, data: 0.021) loss: 0.008 
(epoch: 815, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 815, iters: 1008, time: 0.093, data: 0.012) loss: 0.157 
(epoch: 815, iters: 1088, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 815, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 815, iters: 1248, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 815, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 815, iters: 1408, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 815, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 815, iters: 1568, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 815, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 815, iters: 1728, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 815, iters: 1808, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 815, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 815, iters: 1968, time: 0.096, data: 0.011) loss: 0.002 
(epoch: 815, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 815, iters: 2128, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 815, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 815, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 815, iters: 2368, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 815, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 815, iters: 2528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 815, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 815, iters: 2688, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 815, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 815, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 815, iters: 2928, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 815, iters: 3008, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 815, iters: 3088, time: 0.092, data: 0.012) loss: 0.066 
(epoch: 815, iters: 3168, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 815, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 815, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 815, iters: 3408, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 815, iters: 3488, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 815, iters: 3568, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 815, iters: 3648, time: 0.085, data: 0.012) loss: 0.000 
(epoch: 815, iters: 3728, time: 0.058, data: 0.000) loss: 0.000 
saving the model at the end of epoch 815, iters 3038320
End of epoch 815 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001284
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 815, TEST ACC: [95.144 %]

saving the latest model (epoch 816, total_steps 3038336)
(epoch: 816, iters: 80, time: 0.094, data: 0.502) loss: 0.000 
(epoch: 816, iters: 160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 816, iters: 240, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 816, iters: 320, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 816, iters: 400, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 816, iters: 480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 816, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 816, iters: 640, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 816, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 816, iters: 800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 816, iters: 880, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 816, iters: 960, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 816, iters: 1040, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 816, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 816, iters: 1200, time: 0.094, data: 0.012) loss: 0.022 
(epoch: 816, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 816, iters: 1360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 816, iters: 1440, time: 0.095, data: 0.040) loss: 0.002 
(epoch: 816, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 816, iters: 1600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 816, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 816, iters: 1760, time: 0.095, data: 0.012) loss: 0.009 
(epoch: 816, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 816, iters: 1920, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 816, iters: 2000, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 816, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 816, iters: 2160, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 816, iters: 2240, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 816, iters: 2320, time: 0.094, data: 0.011) loss: 0.005 
(epoch: 816, iters: 2400, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 816, iters: 2480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 816, iters: 2560, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 816, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 816, iters: 2720, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 816, iters: 2800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 816, iters: 2880, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 816, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 816, iters: 3040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 816, iters: 3120, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 816, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 816, iters: 3280, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 816, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 816, iters: 3440, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 816, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 816, iters: 3600, time: 0.093, data: 0.000) loss: 0.023 
(epoch: 816, iters: 3680, time: 0.088, data: 0.048) loss: 0.000 
saving the model at the end of epoch 816, iters 3042048
End of epoch 816 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001283
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 816, TEST ACC: [96.358 %]

saving the latest model (epoch 817, total_steps 3042064)
(epoch: 817, iters: 32, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 817, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 817, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 817, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 817, iters: 352, time: 0.097, data: 0.050) loss: 0.000 
(epoch: 817, iters: 432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 817, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 817, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 817, iters: 672, time: 0.094, data: 0.020) loss: 0.006 
(epoch: 817, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 817, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 817, iters: 912, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 817, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 817, iters: 1072, time: 0.093, data: 0.013) loss: 0.004 
(epoch: 817, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 817, iters: 1232, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 817, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 817, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 817, iters: 1472, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 817, iters: 1552, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 817, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 817, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 817, iters: 1792, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 817, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 817, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 817, iters: 2032, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 817, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 817, iters: 2192, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 817, iters: 2272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 817, iters: 2352, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 817, iters: 2432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 817, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 817, iters: 2592, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 817, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 817, iters: 2752, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 817, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 817, iters: 2912, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 817, iters: 2992, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 817, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 817, iters: 3152, time: 0.097, data: 0.039) loss: 0.000 
(epoch: 817, iters: 3232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 817, iters: 3312, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 817, iters: 3392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 817, iters: 3472, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 817, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 817, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 817, iters: 3712, time: 0.088, data: 0.035) loss: 0.000 
saving the model at the end of epoch 817, iters 3045776
End of epoch 817 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001282
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 817, TEST ACC: [97.269 %]

saving the latest model (epoch 818, total_steps 3045792)
(epoch: 818, iters: 64, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 818, iters: 144, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 818, iters: 224, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 818, iters: 304, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 818, iters: 384, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 818, iters: 464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 818, iters: 544, time: 0.097, data: 0.051) loss: 0.000 
(epoch: 818, iters: 624, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 818, iters: 704, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 818, iters: 784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 818, iters: 864, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 818, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 818, iters: 1024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 818, iters: 1104, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 818, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 818, iters: 1264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 818, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 818, iters: 1424, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 818, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 818, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 818, iters: 1664, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 818, iters: 1744, time: 0.095, data: 0.000) loss: 0.031 
(epoch: 818, iters: 1824, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 818, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 818, iters: 1984, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 818, iters: 2064, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 818, iters: 2144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 818, iters: 2224, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 818, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 818, iters: 2384, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 818, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 818, iters: 2544, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 818, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 818, iters: 2704, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 818, iters: 2784, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 818, iters: 2864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 818, iters: 2944, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 818, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 818, iters: 3104, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 818, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 818, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 818, iters: 3344, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 818, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 818, iters: 3504, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 818, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 818, iters: 3664, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 818, iters 3049504
End of epoch 818 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001281
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 818, TEST ACC: [96.358 %]

(epoch: 819, iters: 16, time: 0.114, data: 0.000) loss: 0.000 
saving the latest model (epoch 819, total_steps 3049520)
(epoch: 819, iters: 96, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 819, iters: 176, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 819, iters: 256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 819, iters: 336, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 819, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 819, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 819, iters: 576, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 819, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 819, iters: 736, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 819, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 819, iters: 896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 819, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 819, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 819, iters: 1136, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 819, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 819, iters: 1296, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 819, iters: 1376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 819, iters: 1456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 819, iters: 1536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 819, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 819, iters: 1696, time: 0.097, data: 0.051) loss: 0.000 
(epoch: 819, iters: 1776, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 819, iters: 1856, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 819, iters: 1936, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 819, iters: 2016, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 819, iters: 2096, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 819, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 819, iters: 2256, time: 0.095, data: 0.040) loss: 0.002 
(epoch: 819, iters: 2336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 819, iters: 2416, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 819, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 819, iters: 2576, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 819, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 819, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 819, iters: 2816, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 819, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 819, iters: 2976, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 819, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 819, iters: 3136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 819, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 819, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 819, iters: 3376, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 819, iters: 3456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 819, iters: 3536, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 819, iters: 3616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 819, iters: 3696, time: 0.087, data: 0.013) loss: 0.000 
saving the model at the end of epoch 819, iters 3053232
End of epoch 819 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001280
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 819, TEST ACC: [96.358 %]

saving the latest model (epoch 820, total_steps 3053248)
(epoch: 820, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 820, iters: 128, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 820, iters: 208, time: 0.094, data: 0.053) loss: 0.000 
(epoch: 820, iters: 288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 820, iters: 368, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 820, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 820, iters: 528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 820, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 820, iters: 688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 820, iters: 768, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 820, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 820, iters: 928, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 820, iters: 1008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 820, iters: 1088, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 820, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 820, iters: 1248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 820, iters: 1328, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 820, iters: 1408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 820, iters: 1488, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 820, iters: 1568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 820, iters: 1648, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 820, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 820, iters: 1808, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 820, iters: 1888, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 820, iters: 1968, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 820, iters: 2048, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 820, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 820, iters: 2208, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 820, iters: 2288, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 820, iters: 2368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 820, iters: 2448, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 820, iters: 2528, time: 0.095, data: 0.000) loss: 0.082 
(epoch: 820, iters: 2608, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 820, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 820, iters: 2768, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 820, iters: 2848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 820, iters: 2928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 820, iters: 3008, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 820, iters: 3088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 820, iters: 3168, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 820, iters: 3248, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 820, iters: 3328, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 820, iters: 3408, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 820, iters: 3488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 820, iters: 3568, time: 0.095, data: 0.053) loss: 0.000 
(epoch: 820, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 820, iters: 3728, time: 0.056, data: 0.012) loss: 0.000 
saving the model at the end of epoch 820, iters 3056960
End of epoch 820 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001279
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 820, TEST ACC: [96.358 %]

saving the latest model (epoch 821, total_steps 3056976)
(epoch: 821, iters: 80, time: 0.096, data: 0.467) loss: 0.003 
(epoch: 821, iters: 160, time: 0.095, data: 0.000) loss: 0.053 
(epoch: 821, iters: 240, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 821, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 821, iters: 400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 821, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 821, iters: 560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 821, iters: 640, time: 0.095, data: 0.000) loss: 0.033 
(epoch: 821, iters: 720, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 821, iters: 800, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 821, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 821, iters: 960, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 821, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 821, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 821, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 821, iters: 1280, time: 0.093, data: 0.000) loss: 0.013 
(epoch: 821, iters: 1360, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 821, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 821, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 821, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 821, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 821, iters: 1760, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 821, iters: 1840, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 821, iters: 1920, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 821, iters: 2000, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 821, iters: 2080, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 821, iters: 2160, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 821, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 821, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 821, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 821, iters: 2480, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 821, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 821, iters: 2640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 821, iters: 2720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 821, iters: 2800, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 821, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 821, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 821, iters: 3040, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 821, iters: 3120, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 821, iters: 3200, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 821, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 821, iters: 3360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 821, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 821, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 821, iters: 3600, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 821, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 821, iters 3060688
End of epoch 821 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001278
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 821, TEST ACC: [95.751 %]

saving the latest model (epoch 822, total_steps 3060704)
(epoch: 822, iters: 32, time: 0.093, data: 0.004) loss: 0.000 
(epoch: 822, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 822, iters: 192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 822, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 822, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 822, iters: 432, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 822, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 822, iters: 592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 822, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 822, iters: 752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 822, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 822, iters: 912, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 822, iters: 992, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 822, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 822, iters: 1152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 822, iters: 1232, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 822, iters: 1312, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 822, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 822, iters: 1472, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 822, iters: 1552, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 822, iters: 1632, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 822, iters: 1712, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 822, iters: 1792, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 822, iters: 1872, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 822, iters: 1952, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 822, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 822, iters: 2112, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 822, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 822, iters: 2272, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 822, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 822, iters: 2432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 822, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 822, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 822, iters: 2672, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 822, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 822, iters: 2832, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 822, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 822, iters: 2992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 822, iters: 3072, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 822, iters: 3152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 822, iters: 3232, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 822, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 822, iters: 3392, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 822, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 822, iters: 3552, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 822, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 822, iters: 3712, time: 0.089, data: 0.000) loss: 0.016 
saving the model at the end of epoch 822, iters 3064416
End of epoch 822 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001277
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 822, TEST ACC: [91.351 %]

saving the latest model (epoch 823, total_steps 3064432)
(epoch: 823, iters: 64, time: 0.093, data: 0.002) loss: 0.000 
(epoch: 823, iters: 144, time: 0.093, data: 0.000) loss: 0.021 
(epoch: 823, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 823, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 823, iters: 384, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 823, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 823, iters: 544, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 823, iters: 624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 823, iters: 704, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 823, iters: 784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 823, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 823, iters: 944, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 823, iters: 1024, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 823, iters: 1104, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 823, iters: 1184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 823, iters: 1264, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 823, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 823, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 823, iters: 1504, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 823, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 823, iters: 1664, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 823, iters: 1744, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 823, iters: 1824, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 823, iters: 1904, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 823, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 823, iters: 2064, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 823, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 823, iters: 2224, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 823, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 823, iters: 2384, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 823, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 823, iters: 2544, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 823, iters: 2624, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 823, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 823, iters: 2784, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 823, iters: 2864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 823, iters: 2944, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 823, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 823, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 823, iters: 3184, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 823, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 823, iters: 3344, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 823, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 823, iters: 3504, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 823, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 823, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 823, iters 3068144
End of epoch 823 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001276
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 823, TEST ACC: [95.144 %]

(epoch: 824, iters: 16, time: 0.108, data: 0.014) loss: 0.000 
saving the latest model (epoch 824, total_steps 3068160)
(epoch: 824, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 824, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 824, iters: 256, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 824, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 824, iters: 416, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 824, iters: 496, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 824, iters: 576, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 824, iters: 656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 824, iters: 736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 824, iters: 816, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 824, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 824, iters: 976, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 824, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 824, iters: 1136, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 824, iters: 1216, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 824, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 824, iters: 1376, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 824, iters: 1456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 824, iters: 1536, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 824, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 824, iters: 1696, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 824, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 824, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 824, iters: 1936, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 824, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 824, iters: 2096, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 824, iters: 2176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 824, iters: 2256, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 824, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 824, iters: 2416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 824, iters: 2496, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 824, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 824, iters: 2656, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 824, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 824, iters: 2816, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 824, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 824, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 824, iters: 3056, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 824, iters: 3136, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 824, iters: 3216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 824, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 824, iters: 3376, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 824, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 824, iters: 3536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 824, iters: 3616, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 824, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 824, iters 3071872
End of epoch 824 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001275
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 824, TEST ACC: [95.599 %]

saving the latest model (epoch 825, total_steps 3071888)
(epoch: 825, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 825, iters: 128, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 825, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 825, iters: 288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 825, iters: 368, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 825, iters: 448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 825, iters: 528, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 825, iters: 608, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 825, iters: 688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 825, iters: 768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 825, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 825, iters: 928, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 825, iters: 1008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 825, iters: 1088, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 825, iters: 1168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 825, iters: 1248, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 825, iters: 1328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 825, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 825, iters: 1488, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 825, iters: 1568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 825, iters: 1648, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 825, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 825, iters: 1808, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 825, iters: 1888, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 825, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 825, iters: 2048, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 825, iters: 2128, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 825, iters: 2208, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 825, iters: 2288, time: 0.094, data: 0.000) loss: 0.017 
(epoch: 825, iters: 2368, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 825, iters: 2448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 825, iters: 2528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 825, iters: 2608, time: 0.096, data: 0.052) loss: 0.000 
(epoch: 825, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 825, iters: 2768, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 825, iters: 2848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 825, iters: 2928, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 825, iters: 3008, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 825, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 825, iters: 3168, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 825, iters: 3248, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 825, iters: 3328, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 825, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 825, iters: 3488, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 825, iters: 3568, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 825, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 825, iters: 3728, time: 0.055, data: 0.015) loss: 0.000 
saving the model at the end of epoch 825, iters 3075600
End of epoch 825 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001274
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 825, TEST ACC: [95.903 %]

saving the latest model (epoch 826, total_steps 3075616)
(epoch: 826, iters: 80, time: 0.094, data: 0.484) loss: 0.000 
(epoch: 826, iters: 160, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 826, iters: 240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 826, iters: 320, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 826, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 826, iters: 480, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 826, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 826, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 826, iters: 720, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 826, iters: 800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 826, iters: 880, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 826, iters: 960, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 826, iters: 1040, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 826, iters: 1120, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 826, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 826, iters: 1280, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 826, iters: 1360, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 826, iters: 1440, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 826, iters: 1520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 826, iters: 1600, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 826, iters: 1680, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 826, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 826, iters: 1840, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 826, iters: 1920, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 826, iters: 2000, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 826, iters: 2080, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 826, iters: 2160, time: 0.095, data: 0.021) loss: 0.000 
(epoch: 826, iters: 2240, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 826, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 826, iters: 2400, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 826, iters: 2480, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 826, iters: 2560, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 826, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 826, iters: 2720, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 826, iters: 2800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 826, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 826, iters: 2960, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 826, iters: 3040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 826, iters: 3120, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 826, iters: 3200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 826, iters: 3280, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 826, iters: 3360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 826, iters: 3440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 826, iters: 3520, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 826, iters: 3600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 826, iters: 3680, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 826, iters 3079328
End of epoch 826 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001273
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 826, TEST ACC: [94.385 %]

saving the latest model (epoch 827, total_steps 3079344)
(epoch: 827, iters: 32, time: 0.093, data: 0.006) loss: 0.000 
(epoch: 827, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 827, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 827, iters: 272, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 827, iters: 352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 827, iters: 432, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 827, iters: 512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 827, iters: 592, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 827, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 827, iters: 752, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 827, iters: 832, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 827, iters: 912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 827, iters: 992, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 827, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 827, iters: 1152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 827, iters: 1232, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 827, iters: 1312, time: 0.094, data: 0.000) loss: 0.023 
(epoch: 827, iters: 1392, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 827, iters: 1472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 827, iters: 1552, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 827, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 827, iters: 1712, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 827, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 827, iters: 1872, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 827, iters: 1952, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 827, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 827, iters: 2112, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 827, iters: 2192, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 827, iters: 2272, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 827, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 827, iters: 2432, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 827, iters: 2512, time: 0.094, data: 0.039) loss: 0.003 
(epoch: 827, iters: 2592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 827, iters: 2672, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 827, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 827, iters: 2832, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 827, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 827, iters: 2992, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 827, iters: 3072, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 827, iters: 3152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 827, iters: 3232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 827, iters: 3312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 827, iters: 3392, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 827, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 827, iters: 3552, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 827, iters: 3632, time: 0.091, data: 0.040) loss: 0.000 
(epoch: 827, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 827, iters 3083056
End of epoch 827 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001272
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 827, TEST ACC: [96.206 %]

saving the latest model (epoch 828, total_steps 3083072)
(epoch: 828, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 828, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 828, iters: 224, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 828, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 828, iters: 384, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 828, iters: 464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 828, iters: 544, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 828, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 828, iters: 704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 828, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 828, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 828, iters: 944, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 828, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 828, iters: 1104, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 828, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 828, iters: 1264, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 828, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 828, iters: 1424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 828, iters: 1504, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 828, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 828, iters: 1664, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 828, iters: 1744, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 828, iters: 1824, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 828, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 828, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 828, iters: 2064, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 828, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 828, iters: 2224, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 828, iters: 2304, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 828, iters: 2384, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 828, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 828, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 828, iters: 2624, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 828, iters: 2704, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 828, iters: 2784, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 828, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 828, iters: 2944, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 828, iters: 3024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 828, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 828, iters: 3184, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 828, iters: 3264, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 828, iters: 3344, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 828, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 828, iters: 3504, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 828, iters: 3584, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 828, iters: 3664, time: 0.086, data: 0.000) loss: 0.000 
saving the model at the end of epoch 828, iters 3086784
End of epoch 828 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001271
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 828, TEST ACC: [96.662 %]

(epoch: 829, iters: 16, time: 0.111, data: 0.012) loss: 0.000 
saving the latest model (epoch 829, total_steps 3086800)
(epoch: 829, iters: 96, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 829, iters: 176, time: 0.092, data: 0.012) loss: 0.007 
(epoch: 829, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 829, iters: 336, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 829, iters: 416, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 829, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 829, iters: 576, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 829, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 829, iters: 736, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 829, iters: 816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 829, iters: 896, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 829, iters: 976, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 829, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 829, iters: 1136, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 829, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 829, iters: 1296, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 829, iters: 1376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 829, iters: 1456, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 829, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 829, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 829, iters: 1696, time: 0.094, data: 0.052) loss: 0.000 
(epoch: 829, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 829, iters: 1856, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 829, iters: 1936, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 829, iters: 2016, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 829, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 829, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 829, iters: 2256, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 829, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 829, iters: 2416, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 829, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 829, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 829, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 829, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 829, iters: 2816, time: 0.093, data: 0.040) loss: 0.005 
(epoch: 829, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 829, iters: 2976, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 829, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 829, iters: 3136, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 829, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 829, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 829, iters: 3376, time: 0.094, data: 0.048) loss: 0.020 
(epoch: 829, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 829, iters: 3536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 829, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 829, iters: 3696, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 829, iters 3090512
End of epoch 829 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001270
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 829, TEST ACC: [97.42 %]

saving the latest model (epoch 830, total_steps 3090528)
(epoch: 830, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 830, iters: 128, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 830, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 830, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 830, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 830, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 830, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 830, iters: 608, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 830, iters: 688, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 830, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 830, iters: 848, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 830, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 830, iters: 1008, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 830, iters: 1088, time: 0.095, data: 0.000) loss: 0.008 
(epoch: 830, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 830, iters: 1248, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 830, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 830, iters: 1408, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 830, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 830, iters: 1568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 830, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 830, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 830, iters: 1808, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 830, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 830, iters: 1968, time: 0.094, data: 0.011) loss: 0.004 
(epoch: 830, iters: 2048, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 830, iters: 2128, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 830, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 830, iters: 2288, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 830, iters: 2368, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 830, iters: 2448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 830, iters: 2528, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 830, iters: 2608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 830, iters: 2688, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 830, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 830, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 830, iters: 2928, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 830, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 830, iters: 3088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 830, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 830, iters: 3248, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 830, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 830, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 830, iters: 3488, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 830, iters: 3568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 830, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 830, iters: 3728, time: 0.057, data: 0.000) loss: 0.002 
saving the model at the end of epoch 830, iters 3094240
End of epoch 830 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001269
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 830, TEST ACC: [95.599 %]

saving the latest model (epoch 831, total_steps 3094256)
(epoch: 831, iters: 80, time: 0.094, data: 0.446) loss: 0.000 
(epoch: 831, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 831, iters: 240, time: 0.092, data: 0.000) loss: 0.002 
(epoch: 831, iters: 320, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 831, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 831, iters: 480, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 831, iters: 560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 831, iters: 640, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 831, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 831, iters: 800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 831, iters: 880, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 831, iters: 960, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 831, iters: 1040, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 831, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 831, iters: 1200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 831, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 831, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 831, iters: 1440, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 831, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 831, iters: 1600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 831, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 831, iters: 1760, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 831, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 831, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 831, iters: 2000, time: 0.096, data: 0.040) loss: 0.008 
(epoch: 831, iters: 2080, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 831, iters: 2160, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 831, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 831, iters: 2320, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 831, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 831, iters: 2480, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 831, iters: 2560, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 831, iters: 2640, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 831, iters: 2720, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 831, iters: 2800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 831, iters: 2880, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 831, iters: 2960, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 831, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 831, iters: 3120, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 831, iters: 3200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 831, iters: 3280, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 831, iters: 3360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 831, iters: 3440, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 831, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 831, iters: 3600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 831, iters: 3680, time: 0.089, data: 0.049) loss: 0.000 
saving the model at the end of epoch 831, iters 3097968
End of epoch 831 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001268
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 831, TEST ACC: [95.903 %]

saving the latest model (epoch 832, total_steps 3097984)
(epoch: 832, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 832, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 832, iters: 192, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 832, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 832, iters: 352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 832, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 832, iters: 512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 832, iters: 592, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 832, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 832, iters: 752, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 832, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 832, iters: 912, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 832, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 832, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 832, iters: 1152, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 832, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 832, iters: 1312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 832, iters: 1392, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 832, iters: 1472, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 832, iters: 1552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 832, iters: 1632, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 832, iters: 1712, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 832, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 832, iters: 1872, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 832, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 832, iters: 2032, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 832, iters: 2112, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 832, iters: 2192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 832, iters: 2272, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 832, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 832, iters: 2432, time: 0.092, data: 0.011) loss: 0.123 
(epoch: 832, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 832, iters: 2592, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 832, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 832, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 832, iters: 2832, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 832, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 832, iters: 2992, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 832, iters: 3072, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 832, iters: 3152, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 832, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 832, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 832, iters: 3392, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 832, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 832, iters: 3552, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 832, iters: 3632, time: 0.092, data: 0.000) loss: 0.013 
(epoch: 832, iters: 3712, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 832, iters 3101696
End of epoch 832 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001267
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 832, TEST ACC: [96.055 %]

saving the latest model (epoch 833, total_steps 3101712)
(epoch: 833, iters: 64, time: 0.095, data: 0.003) loss: 0.112 
(epoch: 833, iters: 144, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 833, iters: 224, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 833, iters: 304, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 833, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 833, iters: 464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 833, iters: 544, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 833, iters: 624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 833, iters: 704, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 833, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 833, iters: 864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 833, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 833, iters: 1024, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 833, iters: 1104, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 833, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 833, iters: 1264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 833, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 833, iters: 1424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 833, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 833, iters: 1584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 833, iters: 1664, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 833, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 833, iters: 1824, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 833, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 833, iters: 1984, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 833, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 833, iters: 2144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 833, iters: 2224, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 833, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 833, iters: 2384, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 833, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 833, iters: 2544, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 833, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 833, iters: 2704, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 833, iters: 2784, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 833, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 833, iters: 2944, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 833, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 833, iters: 3104, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 833, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 833, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 833, iters: 3344, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 833, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 833, iters: 3504, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 833, iters: 3584, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 833, iters: 3664, time: 0.087, data: 0.013) loss: 0.000 
saving the model at the end of epoch 833, iters 3105424
End of epoch 833 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001266
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 833, TEST ACC: [96.358 %]

(epoch: 834, iters: 16, time: 0.107, data: 0.000) loss: 0.000 
saving the latest model (epoch 834, total_steps 3105440)
(epoch: 834, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 834, iters: 176, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 834, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 834, iters: 336, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 834, iters: 416, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 834, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 834, iters: 576, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 834, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 834, iters: 736, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 834, iters: 816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 834, iters: 896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 834, iters: 976, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 834, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 834, iters: 1136, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 834, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 834, iters: 1296, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 834, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 834, iters: 1456, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 834, iters: 1536, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 834, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 834, iters: 1696, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 834, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 834, iters: 1856, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 834, iters: 1936, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 834, iters: 2016, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 834, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 834, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 834, iters: 2256, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 834, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 834, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 834, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 834, iters: 2576, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 834, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 834, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 834, iters: 2816, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 834, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 834, iters: 2976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 834, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 834, iters: 3136, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 834, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 834, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 834, iters: 3376, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 834, iters: 3456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 834, iters: 3536, time: 0.094, data: 0.022) loss: 0.000 
(epoch: 834, iters: 3616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 834, iters: 3696, time: 0.089, data: 0.012) loss: 0.000 
saving the model at the end of epoch 834, iters 3109152
End of epoch 834 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001265
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 834, TEST ACC: [96.206 %]

saving the latest model (epoch 835, total_steps 3109168)
(epoch: 835, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 835, iters: 128, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 835, iters: 208, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 835, iters: 288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 835, iters: 368, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 835, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 835, iters: 528, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 835, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 835, iters: 688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 835, iters: 768, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 835, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 835, iters: 928, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 835, iters: 1008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 835, iters: 1088, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 835, iters: 1168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 835, iters: 1248, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 835, iters: 1328, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 835, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 835, iters: 1488, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 835, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 835, iters: 1648, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 835, iters: 1728, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 835, iters: 1808, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 835, iters: 1888, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 835, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 835, iters: 2048, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 835, iters: 2128, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 835, iters: 2208, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 835, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 835, iters: 2368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 835, iters: 2448, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 835, iters: 2528, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 835, iters: 2608, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 835, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 835, iters: 2768, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 835, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 835, iters: 2928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 835, iters: 3008, time: 0.097, data: 0.042) loss: 0.000 
(epoch: 835, iters: 3088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 835, iters: 3168, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 835, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 835, iters: 3328, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 835, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 835, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 835, iters: 3568, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 835, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 835, iters: 3728, time: 0.056, data: 0.012) loss: 0.000 
saving the model at the end of epoch 835, iters 3112880
End of epoch 835 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001264
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 835, TEST ACC: [97.572 %]

saving the latest model (epoch 836, total_steps 3112896)
(epoch: 836, iters: 80, time: 0.092, data: 0.515) loss: 0.000 
(epoch: 836, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 836, iters: 240, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 836, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 836, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 836, iters: 480, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 836, iters: 560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 836, iters: 640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 836, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 836, iters: 800, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 836, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 836, iters: 960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 836, iters: 1040, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 836, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 836, iters: 1200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 836, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 836, iters: 1360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 836, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 836, iters: 1520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 836, iters: 1600, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 836, iters: 1680, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 836, iters: 1760, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 836, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 836, iters: 1920, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 836, iters: 2000, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 836, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 836, iters: 2160, time: 0.093, data: 0.051) loss: 0.000 
(epoch: 836, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 836, iters: 2320, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 836, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 836, iters: 2480, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 836, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 836, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 836, iters: 2720, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 836, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 836, iters: 2880, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 836, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 836, iters: 3040, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 836, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 836, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 836, iters: 3280, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 836, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 836, iters: 3440, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 836, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 836, iters: 3600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 836, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 836, iters 3116608
End of epoch 836 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001263
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 836, TEST ACC: [97.572 %]

saving the latest model (epoch 837, total_steps 3116624)
(epoch: 837, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 837, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 837, iters: 192, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 837, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 837, iters: 352, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 837, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 837, iters: 512, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 837, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 837, iters: 672, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 837, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 837, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 837, iters: 912, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 837, iters: 992, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 837, iters: 1072, time: 0.097, data: 0.012) loss: 0.001 
(epoch: 837, iters: 1152, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 837, iters: 1232, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 837, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 837, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 837, iters: 1472, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 837, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 837, iters: 1632, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 837, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 837, iters: 1792, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 837, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 837, iters: 1952, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 837, iters: 2032, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 837, iters: 2112, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 837, iters: 2192, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 837, iters: 2272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 837, iters: 2352, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 837, iters: 2432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 837, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 837, iters: 2592, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 837, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 837, iters: 2752, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 837, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 837, iters: 2912, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 837, iters: 2992, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 837, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 837, iters: 3152, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 837, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 837, iters: 3312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 837, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 837, iters: 3472, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 837, iters: 3552, time: 0.094, data: 0.000) loss: 0.075 
(epoch: 837, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 837, iters: 3712, time: 0.089, data: 0.046) loss: 0.000 
saving the model at the end of epoch 837, iters 3120336
End of epoch 837 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001262
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 837, TEST ACC: [97.42 %]

saving the latest model (epoch 838, total_steps 3120352)
(epoch: 838, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 838, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 838, iters: 224, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 838, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 838, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 838, iters: 464, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 838, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 838, iters: 624, time: 0.095, data: 0.014) loss: 0.000 
(epoch: 838, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 838, iters: 784, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 838, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 838, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 838, iters: 1024, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 838, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 838, iters: 1184, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 838, iters: 1264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 838, iters: 1344, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 838, iters: 1424, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 838, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 838, iters: 1584, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 838, iters: 1664, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 838, iters: 1744, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 838, iters: 1824, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 838, iters: 1904, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 838, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 838, iters: 2064, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 838, iters: 2144, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 838, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 838, iters: 2304, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 838, iters: 2384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 838, iters: 2464, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 838, iters: 2544, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 838, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 838, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 838, iters: 2784, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 838, iters: 2864, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 838, iters: 2944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 838, iters: 3024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 838, iters: 3104, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 838, iters: 3184, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 838, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 838, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 838, iters: 3424, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 838, iters: 3504, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 838, iters: 3584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 838, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 838, iters 3124064
End of epoch 838 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001261
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 838, TEST ACC: [96.965 %]

(epoch: 839, iters: 16, time: 0.109, data: 0.010) loss: 0.000 
saving the latest model (epoch 839, total_steps 3124080)
(epoch: 839, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 839, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 839, iters: 256, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 839, iters: 336, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 839, iters: 416, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 839, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 839, iters: 576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 839, iters: 656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 839, iters: 736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 839, iters: 816, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 839, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 839, iters: 976, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 839, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 839, iters: 1136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 839, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 839, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 839, iters: 1376, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 839, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 839, iters: 1536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 839, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 839, iters: 1696, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 839, iters: 1776, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 839, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 839, iters: 1936, time: 0.095, data: 0.040) loss: 0.002 
(epoch: 839, iters: 2016, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 839, iters: 2096, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 839, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 839, iters: 2256, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 839, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 839, iters: 2416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 839, iters: 2496, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 839, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 839, iters: 2656, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 839, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 839, iters: 2816, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 839, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 839, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 839, iters: 3056, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 839, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 839, iters: 3216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 839, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 839, iters: 3376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 839, iters: 3456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 839, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 839, iters: 3616, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 839, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 839, iters 3127792
End of epoch 839 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001260
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 839, TEST ACC: [97.117 %]

saving the latest model (epoch 840, total_steps 3127808)
(epoch: 840, iters: 48, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 840, iters: 128, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 840, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 840, iters: 288, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 840, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 840, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 840, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 840, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 840, iters: 688, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 840, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 840, iters: 848, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 840, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 840, iters: 1008, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 840, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 840, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 840, iters: 1248, time: 0.097, data: 0.039) loss: 0.000 
(epoch: 840, iters: 1328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 840, iters: 1408, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 840, iters: 1488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 840, iters: 1568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 840, iters: 1648, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 840, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 840, iters: 1808, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 840, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 840, iters: 1968, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 840, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 840, iters: 2128, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 840, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 840, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 840, iters: 2368, time: 0.094, data: 0.053) loss: 0.000 
(epoch: 840, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 840, iters: 2528, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 840, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 840, iters: 2688, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 840, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 840, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 840, iters: 2928, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 840, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 840, iters: 3088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 840, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 840, iters: 3248, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 840, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 840, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 840, iters: 3488, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 840, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 840, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 840, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 840, iters 3131520
End of epoch 840 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001259
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 840, TEST ACC: [97.269 %]

saving the latest model (epoch 841, total_steps 3131536)
(epoch: 841, iters: 80, time: 0.096, data: 0.443) loss: 0.000 
(epoch: 841, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 841, iters: 240, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 841, iters: 320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 841, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 841, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 841, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 841, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 841, iters: 720, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 841, iters: 800, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 841, iters: 880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 841, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 841, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 841, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 841, iters: 1200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 841, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 841, iters: 1360, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 841, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 841, iters: 1520, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 841, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 841, iters: 1680, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 841, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 841, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 841, iters: 1920, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 841, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 841, iters: 2080, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 841, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 841, iters: 2240, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 841, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 841, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 841, iters: 2480, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 841, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 841, iters: 2640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 841, iters: 2720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 841, iters: 2800, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 841, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 841, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 841, iters: 3040, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 841, iters: 3120, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 841, iters: 3200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 841, iters: 3280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 841, iters: 3360, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 841, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 841, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 841, iters: 3600, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 841, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 841, iters 3135248
End of epoch 841 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001258
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 841, TEST ACC: [97.117 %]

saving the latest model (epoch 842, total_steps 3135264)
(epoch: 842, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 842, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 842, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 842, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 842, iters: 352, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 842, iters: 432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 842, iters: 512, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 842, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 842, iters: 672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 842, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 842, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 842, iters: 912, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 842, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 842, iters: 1072, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 842, iters: 1152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 842, iters: 1232, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 842, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 842, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 842, iters: 1472, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 842, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 842, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 842, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 842, iters: 1792, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 842, iters: 1872, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 842, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 842, iters: 2032, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 842, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 842, iters: 2192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 842, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 842, iters: 2352, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 842, iters: 2432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 842, iters: 2512, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 842, iters: 2592, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 842, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 842, iters: 2752, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 842, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 842, iters: 2912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 842, iters: 2992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 842, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 842, iters: 3152, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 842, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 842, iters: 3312, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 842, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 842, iters: 3472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 842, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 842, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 842, iters: 3712, time: 0.088, data: 0.036) loss: 0.000 
saving the model at the end of epoch 842, iters 3138976
End of epoch 842 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001257
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 842, TEST ACC: [97.269 %]

saving the latest model (epoch 843, total_steps 3138992)
(epoch: 843, iters: 64, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 843, iters: 144, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 843, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 843, iters: 304, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 843, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 843, iters: 464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 843, iters: 544, time: 0.095, data: 0.039) loss: 0.002 
(epoch: 843, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 843, iters: 704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 843, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 843, iters: 864, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 843, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 843, iters: 1024, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 843, iters: 1104, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 843, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 843, iters: 1264, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 843, iters: 1344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 843, iters: 1424, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 843, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 843, iters: 1584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 843, iters: 1664, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 843, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 843, iters: 1824, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 843, iters: 1904, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 843, iters: 1984, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 843, iters: 2064, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 843, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 843, iters: 2224, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 843, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 843, iters: 2384, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 843, iters: 2464, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 843, iters: 2544, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 843, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 843, iters: 2704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 843, iters: 2784, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 843, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 843, iters: 2944, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 843, iters: 3024, time: 0.096, data: 0.000) loss: 0.046 
(epoch: 843, iters: 3104, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 843, iters: 3184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 843, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 843, iters: 3344, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 843, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 843, iters: 3504, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 843, iters: 3584, time: 0.093, data: 0.000) loss: 0.011 
(epoch: 843, iters: 3664, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 843, iters 3142704
End of epoch 843 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001256
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 843, TEST ACC: [86.343 %]

(epoch: 844, iters: 16, time: 0.113, data: 0.000) loss: 0.001 
saving the latest model (epoch 844, total_steps 3142720)
(epoch: 844, iters: 96, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 844, iters: 176, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 844, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 844, iters: 336, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 844, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 844, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 844, iters: 576, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 844, iters: 656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 844, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 844, iters: 816, time: 0.094, data: 0.039) loss: 0.024 
(epoch: 844, iters: 896, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 844, iters: 976, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 844, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 844, iters: 1136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 844, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 844, iters: 1296, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 844, iters: 1376, time: 0.094, data: 0.049) loss: 0.073 
(epoch: 844, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 844, iters: 1536, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 844, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 844, iters: 1696, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 844, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 844, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 844, iters: 1936, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 844, iters: 2016, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 844, iters: 2096, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 844, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 844, iters: 2256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 844, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 844, iters: 2416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 844, iters: 2496, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 844, iters: 2576, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 844, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 844, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 844, iters: 2816, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 844, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 844, iters: 2976, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 844, iters: 3056, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 844, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 844, iters: 3216, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 844, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 844, iters: 3376, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 844, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 844, iters: 3536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 844, iters: 3616, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 844, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 844, iters 3146432
End of epoch 844 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001255
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 844, TEST ACC: [96.965 %]

saving the latest model (epoch 845, total_steps 3146448)
(epoch: 845, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 845, iters: 128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 845, iters: 208, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 845, iters: 288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 845, iters: 368, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 845, iters: 448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 845, iters: 528, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 845, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 845, iters: 688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 845, iters: 768, time: 0.094, data: 0.052) loss: 0.000 
(epoch: 845, iters: 848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 845, iters: 928, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 845, iters: 1008, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 845, iters: 1088, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 845, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 845, iters: 1248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 845, iters: 1328, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 845, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 845, iters: 1488, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 845, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 845, iters: 1648, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 845, iters: 1728, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 845, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 845, iters: 1888, time: 0.094, data: 0.040) loss: 0.005 
(epoch: 845, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 845, iters: 2048, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 845, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 845, iters: 2208, time: 0.093, data: 0.011) loss: 0.008 
(epoch: 845, iters: 2288, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 845, iters: 2368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 845, iters: 2448, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 845, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 845, iters: 2608, time: 0.092, data: 0.012) loss: 0.060 
(epoch: 845, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 845, iters: 2768, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 845, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 845, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 845, iters: 3008, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 845, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 845, iters: 3168, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 845, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 845, iters: 3328, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 845, iters: 3408, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 845, iters: 3488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 845, iters: 3568, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 845, iters: 3648, time: 0.088, data: 0.000) loss: 0.002 
(epoch: 845, iters: 3728, time: 0.055, data: 0.011) loss: 0.000 
saving the model at the end of epoch 845, iters 3150160
End of epoch 845 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001254
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 845, TEST ACC: [95.903 %]

saving the latest model (epoch 846, total_steps 3150176)
(epoch: 846, iters: 80, time: 0.094, data: 0.457) loss: 0.000 
(epoch: 846, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 846, iters: 240, time: 0.097, data: 0.050) loss: 0.082 
(epoch: 846, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 846, iters: 400, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 846, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 846, iters: 560, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 846, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 846, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 846, iters: 800, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 846, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 846, iters: 960, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 846, iters: 1040, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 846, iters: 1120, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 846, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 846, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 846, iters: 1360, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 846, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 846, iters: 1520, time: 0.093, data: 0.011) loss: 0.028 
(epoch: 846, iters: 1600, time: 0.094, data: 0.000) loss: 0.123 
(epoch: 846, iters: 1680, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 846, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 846, iters: 1840, time: 0.093, data: 0.000) loss: 0.195 
(epoch: 846, iters: 1920, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 846, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 846, iters: 2080, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 846, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 846, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 846, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 846, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 846, iters: 2480, time: 0.095, data: 0.040) loss: 0.010 
(epoch: 846, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 846, iters: 2640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 846, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 846, iters: 2800, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 846, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 846, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 846, iters: 3040, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 846, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 846, iters: 3200, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 846, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 846, iters: 3360, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 846, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 846, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 846, iters: 3600, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 846, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 846, iters 3153888
End of epoch 846 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001253
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 846, TEST ACC: [97.42 %]

saving the latest model (epoch 847, total_steps 3153904)
(epoch: 847, iters: 32, time: 0.094, data: 0.004) loss: 0.000 
(epoch: 847, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 847, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 847, iters: 272, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 847, iters: 352, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 847, iters: 432, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 847, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 847, iters: 592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 847, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 847, iters: 752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 847, iters: 832, time: 0.093, data: 0.041) loss: 0.001 
(epoch: 847, iters: 912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 847, iters: 992, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 847, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 847, iters: 1152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 847, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 847, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 847, iters: 1392, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 847, iters: 1472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 847, iters: 1552, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 847, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 847, iters: 1712, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 847, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 847, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 847, iters: 1952, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 847, iters: 2032, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 847, iters: 2112, time: 0.092, data: 0.012) loss: 0.047 
(epoch: 847, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 847, iters: 2272, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 847, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 847, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 847, iters: 2512, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 847, iters: 2592, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 847, iters: 2672, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 847, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 847, iters: 2832, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 847, iters: 2912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 847, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 847, iters: 3072, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 847, iters: 3152, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 847, iters: 3232, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 847, iters: 3312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 847, iters: 3392, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 847, iters: 3472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 847, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 847, iters: 3632, time: 0.093, data: 0.051) loss: 0.000 
(epoch: 847, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 847, iters 3157616
End of epoch 847 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001252
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 847, TEST ACC: [96.358 %]

saving the latest model (epoch 848, total_steps 3157632)
(epoch: 848, iters: 64, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 848, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 848, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 848, iters: 304, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 848, iters: 384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 848, iters: 464, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 848, iters: 544, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 848, iters: 624, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 848, iters: 704, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 848, iters: 784, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 848, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 848, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 848, iters: 1024, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 848, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 848, iters: 1184, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 848, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 848, iters: 1344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 848, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 848, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 848, iters: 1584, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 848, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 848, iters: 1744, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 848, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 848, iters: 1904, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 848, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 848, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 848, iters: 2144, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 848, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 848, iters: 2304, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 848, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 848, iters: 2464, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 848, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 848, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 848, iters: 2704, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 848, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 848, iters: 2864, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 848, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 848, iters: 3024, time: 0.093, data: 0.012) loss: 0.020 
(epoch: 848, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 848, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 848, iters: 3264, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 848, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 848, iters: 3424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 848, iters: 3504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 848, iters: 3584, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 848, iters: 3664, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 848, iters 3161344
End of epoch 848 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001251
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 848, TEST ACC: [97.42 %]

(epoch: 849, iters: 16, time: 0.109, data: 0.000) loss: 0.000 
saving the latest model (epoch 849, total_steps 3161360)
(epoch: 849, iters: 96, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 849, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 849, iters: 256, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 849, iters: 336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 849, iters: 416, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 849, iters: 496, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 849, iters: 576, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 849, iters: 656, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 849, iters: 736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 849, iters: 816, time: 0.095, data: 0.053) loss: 0.000 
(epoch: 849, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 849, iters: 976, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 849, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 849, iters: 1136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 849, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 849, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 849, iters: 1376, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 849, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 849, iters: 1536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 849, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 849, iters: 1696, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 849, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 849, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 849, iters: 1936, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 849, iters: 2016, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 849, iters: 2096, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 849, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 849, iters: 2256, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 849, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 849, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 849, iters: 2496, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 849, iters: 2576, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 849, iters: 2656, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 849, iters: 2736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 849, iters: 2816, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 849, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 849, iters: 2976, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 849, iters: 3056, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 849, iters: 3136, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 849, iters: 3216, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 849, iters: 3296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 849, iters: 3376, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 849, iters: 3456, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 849, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 849, iters: 3616, time: 0.096, data: 0.052) loss: 0.001 
(epoch: 849, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 849, iters 3165072
End of epoch 849 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001250
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 849, TEST ACC: [95.903 %]

saving the latest model (epoch 850, total_steps 3165088)
(epoch: 850, iters: 48, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 850, iters: 128, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 850, iters: 208, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 850, iters: 288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 850, iters: 368, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 850, iters: 448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 850, iters: 528, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 850, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 850, iters: 688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 850, iters: 768, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 850, iters: 848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 850, iters: 928, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 850, iters: 1008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 850, iters: 1088, time: 0.095, data: 0.021) loss: 0.000 
(epoch: 850, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 850, iters: 1248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 850, iters: 1328, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 850, iters: 1408, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 850, iters: 1488, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 850, iters: 1568, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 850, iters: 1648, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 850, iters: 1728, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 850, iters: 1808, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 850, iters: 1888, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 850, iters: 1968, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 850, iters: 2048, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 850, iters: 2128, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 850, iters: 2208, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 850, iters: 2288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 850, iters: 2368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 850, iters: 2448, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 850, iters: 2528, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 850, iters: 2608, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 850, iters: 2688, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 850, iters: 2768, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 850, iters: 2848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 850, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 850, iters: 3008, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 850, iters: 3088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 850, iters: 3168, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 850, iters: 3248, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 850, iters: 3328, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 850, iters: 3408, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 850, iters: 3488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 850, iters: 3568, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 850, iters: 3648, time: 0.088, data: 0.000) loss: 0.001 
(epoch: 850, iters: 3728, time: 0.058, data: 0.011) loss: 0.002 
saving the model at the end of epoch 850, iters 3168800
End of epoch 850 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001249
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 850, TEST ACC: [89.833 %]

saving the latest model (epoch 851, total_steps 3168816)
(epoch: 851, iters: 80, time: 0.094, data: 0.539) loss: 0.000 
(epoch: 851, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 851, iters: 240, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 851, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 851, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 851, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 851, iters: 560, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 851, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 851, iters: 720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 851, iters: 800, time: 0.095, data: 0.040) loss: 0.003 
(epoch: 851, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 851, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 851, iters: 1040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 851, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 851, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 851, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 851, iters: 1360, time: 0.093, data: 0.048) loss: 0.001 
(epoch: 851, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 851, iters: 1520, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 851, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 851, iters: 1680, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 851, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 851, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 851, iters: 1920, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 851, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 851, iters: 2080, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 851, iters: 2160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 851, iters: 2240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 851, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 851, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 851, iters: 2480, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 851, iters: 2560, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 851, iters: 2640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 851, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 851, iters: 2800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 851, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 851, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 851, iters: 3040, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 851, iters: 3120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 851, iters: 3200, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 851, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 851, iters: 3360, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 851, iters: 3440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 851, iters: 3520, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 851, iters: 3600, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 851, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 851, iters 3172528
End of epoch 851 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001248
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 851, TEST ACC: [96.662 %]

saving the latest model (epoch 852, total_steps 3172544)
(epoch: 852, iters: 32, time: 0.094, data: 0.004) loss: 0.000 
(epoch: 852, iters: 112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 852, iters: 192, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 852, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 852, iters: 352, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 852, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 852, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 852, iters: 592, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 852, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 852, iters: 752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 852, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 852, iters: 912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 852, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 852, iters: 1072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 852, iters: 1152, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 852, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 852, iters: 1312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 852, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 852, iters: 1472, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 852, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 852, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 852, iters: 1712, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 852, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 852, iters: 1872, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 852, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 852, iters: 2032, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 852, iters: 2112, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 852, iters: 2192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 852, iters: 2272, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 852, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 852, iters: 2432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 852, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 852, iters: 2592, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 852, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 852, iters: 2752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 852, iters: 2832, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 852, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 852, iters: 2992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 852, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 852, iters: 3152, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 852, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 852, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 852, iters: 3392, time: 0.093, data: 0.040) loss: 0.027 
(epoch: 852, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 852, iters: 3552, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 852, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 852, iters: 3712, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 852, iters 3176256
End of epoch 852 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001247
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 852, TEST ACC: [96.813 %]

saving the latest model (epoch 853, total_steps 3176272)
(epoch: 853, iters: 64, time: 0.094, data: 0.003) loss: 0.000 
(epoch: 853, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 853, iters: 224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 853, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 853, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 853, iters: 464, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 853, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 853, iters: 624, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 853, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 853, iters: 784, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 853, iters: 864, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 853, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 853, iters: 1024, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 853, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 853, iters: 1184, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 853, iters: 1264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 853, iters: 1344, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 853, iters: 1424, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 853, iters: 1504, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 853, iters: 1584, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 853, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 853, iters: 1744, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 853, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 853, iters: 1904, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 853, iters: 1984, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 853, iters: 2064, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 853, iters: 2144, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 853, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 853, iters: 2304, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 853, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 853, iters: 2464, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 853, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 853, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 853, iters: 2704, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 853, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 853, iters: 2864, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 853, iters: 2944, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 853, iters: 3024, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 853, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 853, iters: 3184, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 853, iters: 3264, time: 0.096, data: 0.048) loss: 0.000 
(epoch: 853, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 853, iters: 3424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 853, iters: 3504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 853, iters: 3584, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 853, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 853, iters 3179984
End of epoch 853 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001246
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 853, TEST ACC: [96.965 %]

(epoch: 854, iters: 16, time: 0.115, data: 0.000) loss: 0.000 
saving the latest model (epoch 854, total_steps 3180000)
(epoch: 854, iters: 96, time: 0.096, data: 0.044) loss: 0.000 
(epoch: 854, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 854, iters: 256, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 854, iters: 336, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 854, iters: 416, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 854, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 854, iters: 576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 854, iters: 656, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 854, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 854, iters: 816, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 854, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 854, iters: 976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 854, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 854, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 854, iters: 1216, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 854, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 854, iters: 1376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 854, iters: 1456, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 854, iters: 1536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 854, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 854, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 854, iters: 1776, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 854, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 854, iters: 1936, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 854, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 854, iters: 2096, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 854, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 854, iters: 2256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 854, iters: 2336, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 854, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 854, iters: 2496, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 854, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 854, iters: 2656, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 854, iters: 2736, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 854, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 854, iters: 2896, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 854, iters: 2976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 854, iters: 3056, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 854, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 854, iters: 3216, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 854, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 854, iters: 3376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 854, iters: 3456, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 854, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 854, iters: 3616, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 854, iters: 3696, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 854, iters 3183712
End of epoch 854 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001245
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 854, TEST ACC: [91.654 %]

saving the latest model (epoch 855, total_steps 3183728)
(epoch: 855, iters: 48, time: 0.096, data: 0.004) loss: 0.000 
(epoch: 855, iters: 128, time: 0.095, data: 0.028) loss: 0.000 
(epoch: 855, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 855, iters: 288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 855, iters: 368, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 855, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 855, iters: 528, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 855, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 855, iters: 688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 855, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 855, iters: 848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 855, iters: 928, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 855, iters: 1008, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 855, iters: 1088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 855, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 855, iters: 1248, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 855, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 855, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 855, iters: 1488, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 855, iters: 1568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 855, iters: 1648, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 855, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 855, iters: 1808, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 855, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 855, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 855, iters: 2048, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 855, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 855, iters: 2208, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 855, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 855, iters: 2368, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 855, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 855, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 855, iters: 2608, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 855, iters: 2688, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 855, iters: 2768, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 855, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 855, iters: 2928, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 855, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 855, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 855, iters: 3168, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 855, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 855, iters: 3328, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 855, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 855, iters: 3488, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 855, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 855, iters: 3648, time: 0.087, data: 0.000) loss: 0.000 
(epoch: 855, iters: 3728, time: 0.056, data: 0.015) loss: 0.000 
saving the model at the end of epoch 855, iters 3187440
End of epoch 855 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001244
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 855, TEST ACC: [97.876 %]

saving the latest model (epoch 856, total_steps 3187456)
(epoch: 856, iters: 80, time: 0.094, data: 0.484) loss: 0.000 
(epoch: 856, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 856, iters: 240, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 856, iters: 320, time: 0.095, data: 0.000) loss: 0.063 
(epoch: 856, iters: 400, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 856, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 856, iters: 560, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 856, iters: 640, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 856, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 856, iters: 800, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 856, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 856, iters: 960, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 856, iters: 1040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 856, iters: 1120, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 856, iters: 1200, time: 0.096, data: 0.000) loss: 0.017 
(epoch: 856, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 856, iters: 1360, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 856, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 856, iters: 1520, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 856, iters: 1600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 856, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 856, iters: 1760, time: 0.095, data: 0.000) loss: 0.022 
(epoch: 856, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 856, iters: 1920, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 856, iters: 2000, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 856, iters: 2080, time: 0.093, data: 0.014) loss: 0.000 
(epoch: 856, iters: 2160, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 856, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 856, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 856, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 856, iters: 2480, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 856, iters: 2560, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 856, iters: 2640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 856, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 856, iters: 2800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 856, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 856, iters: 2960, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 856, iters: 3040, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 856, iters: 3120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 856, iters: 3200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 856, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 856, iters: 3360, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 856, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 856, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 856, iters: 3600, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 856, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 856, iters 3191168
End of epoch 856 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001243
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 856, TEST ACC: [95.296 %]

saving the latest model (epoch 857, total_steps 3191184)
(epoch: 857, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 857, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 857, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 857, iters: 272, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 857, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 857, iters: 432, time: 0.094, data: 0.011) loss: 0.048 
(epoch: 857, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 857, iters: 592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 857, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 857, iters: 752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 857, iters: 832, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 857, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 857, iters: 992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 857, iters: 1072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 857, iters: 1152, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 857, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 857, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 857, iters: 1392, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 857, iters: 1472, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 857, iters: 1552, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 857, iters: 1632, time: 0.094, data: 0.000) loss: 0.116 
(epoch: 857, iters: 1712, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 857, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 857, iters: 1872, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 857, iters: 1952, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 857, iters: 2032, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 857, iters: 2112, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 857, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 857, iters: 2272, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 857, iters: 2352, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 857, iters: 2432, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 857, iters: 2512, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 857, iters: 2592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 857, iters: 2672, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 857, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 857, iters: 2832, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 857, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 857, iters: 2992, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 857, iters: 3072, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 857, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 857, iters: 3232, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 857, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 857, iters: 3392, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 857, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 857, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 857, iters: 3632, time: 0.092, data: 0.049) loss: 0.000 
(epoch: 857, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 857, iters 3194896
End of epoch 857 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001242
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 857, TEST ACC: [95.751 %]

saving the latest model (epoch 858, total_steps 3194912)
(epoch: 858, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 858, iters: 144, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 858, iters: 224, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 858, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 858, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 858, iters: 464, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 858, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 858, iters: 624, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 858, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 858, iters: 784, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 858, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 858, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 858, iters: 1024, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 858, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 858, iters: 1184, time: 0.092, data: 0.012) loss: 0.023 
(epoch: 858, iters: 1264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 858, iters: 1344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 858, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 858, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 858, iters: 1584, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 858, iters: 1664, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 858, iters: 1744, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 858, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 858, iters: 1904, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 858, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 858, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 858, iters: 2144, time: 0.096, data: 0.048) loss: 0.009 
(epoch: 858, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 858, iters: 2304, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 858, iters: 2384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 858, iters: 2464, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 858, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 858, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 858, iters: 2704, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 858, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 858, iters: 2864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 858, iters: 2944, time: 0.094, data: 0.000) loss: 0.040 
(epoch: 858, iters: 3024, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 858, iters: 3104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 858, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 858, iters: 3264, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 858, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 858, iters: 3424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 858, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 858, iters: 3584, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 858, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 858, iters 3198624
End of epoch 858 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001241
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 858, TEST ACC: [97.117 %]

(epoch: 859, iters: 16, time: 0.108, data: 0.000) loss: 0.000 
saving the latest model (epoch 859, total_steps 3198640)
(epoch: 859, iters: 96, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 859, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 859, iters: 256, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 859, iters: 336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 859, iters: 416, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 859, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 859, iters: 576, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 859, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 859, iters: 736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 859, iters: 816, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 859, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 859, iters: 976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 859, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 859, iters: 1136, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 859, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 859, iters: 1296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 859, iters: 1376, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 859, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 859, iters: 1536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 859, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 859, iters: 1696, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 859, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 859, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 859, iters: 1936, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 859, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 859, iters: 2096, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 859, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 859, iters: 2256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 859, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 859, iters: 2416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 859, iters: 2496, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 859, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 859, iters: 2656, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 859, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 859, iters: 2816, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 859, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 859, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 859, iters: 3056, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 859, iters: 3136, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 859, iters: 3216, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 859, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 859, iters: 3376, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 859, iters: 3456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 859, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 859, iters: 3616, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 859, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 859, iters 3202352
End of epoch 859 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001240
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 859, TEST ACC: [96.51 %]

saving the latest model (epoch 860, total_steps 3202368)
(epoch: 860, iters: 48, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 860, iters: 128, time: 0.095, data: 0.043) loss: 0.015 
(epoch: 860, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 860, iters: 288, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 860, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 860, iters: 448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 860, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 860, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 860, iters: 688, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 860, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 860, iters: 848, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 860, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 860, iters: 1008, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 860, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 860, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 860, iters: 1248, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 860, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 860, iters: 1408, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 860, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 860, iters: 1568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 860, iters: 1648, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 860, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 860, iters: 1808, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 860, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 860, iters: 1968, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 860, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 860, iters: 2128, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 860, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 860, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 860, iters: 2368, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 860, iters: 2448, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 860, iters: 2528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 860, iters: 2608, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 860, iters: 2688, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 860, iters: 2768, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 860, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 860, iters: 2928, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 860, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 860, iters: 3088, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 860, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 860, iters: 3248, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 860, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 860, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 860, iters: 3488, time: 0.096, data: 0.041) loss: 0.009 
(epoch: 860, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 860, iters: 3648, time: 0.086, data: 0.011) loss: 0.003 
(epoch: 860, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 860, iters 3206080
End of epoch 860 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001239
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 860, TEST ACC: [96.055 %]

saving the latest model (epoch 861, total_steps 3206096)
(epoch: 861, iters: 80, time: 0.095, data: 0.467) loss: 0.000 
(epoch: 861, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 861, iters: 240, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 861, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 861, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 861, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 861, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 861, iters: 640, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 861, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 861, iters: 800, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 861, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 861, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 861, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 861, iters: 1120, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 861, iters: 1200, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 861, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 861, iters: 1360, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 861, iters: 1440, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 861, iters: 1520, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 861, iters: 1600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 861, iters: 1680, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 861, iters: 1760, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 861, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 861, iters: 1920, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 861, iters: 2000, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 861, iters: 2080, time: 0.094, data: 0.012) loss: 0.068 
(epoch: 861, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 861, iters: 2240, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 861, iters: 2320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 861, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 861, iters: 2480, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 861, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 861, iters: 2640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 861, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 861, iters: 2800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 861, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 861, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 861, iters: 3040, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 861, iters: 3120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 861, iters: 3200, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 861, iters: 3280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 861, iters: 3360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 861, iters: 3440, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 861, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 861, iters: 3600, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 861, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 861, iters 3209808
End of epoch 861 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001238
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 861, TEST ACC: [97.572 %]

saving the latest model (epoch 862, total_steps 3209824)
(epoch: 862, iters: 32, time: 0.094, data: 0.005) loss: 0.000 
(epoch: 862, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 862, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 862, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 862, iters: 352, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 862, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 862, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 862, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 862, iters: 672, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 862, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 862, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 862, iters: 912, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 862, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 862, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 862, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 862, iters: 1232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 862, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 862, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 862, iters: 1472, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 862, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 862, iters: 1632, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 862, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 862, iters: 1792, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 862, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 862, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 862, iters: 2032, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 862, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 862, iters: 2192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 862, iters: 2272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 862, iters: 2352, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 862, iters: 2432, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 862, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 862, iters: 2592, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 862, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 862, iters: 2752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 862, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 862, iters: 2912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 862, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 862, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 862, iters: 3152, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 862, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 862, iters: 3312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 862, iters: 3392, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 862, iters: 3472, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 862, iters: 3552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 862, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 862, iters: 3712, time: 0.089, data: 0.046) loss: 0.000 
saving the model at the end of epoch 862, iters 3213536
End of epoch 862 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001237
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 862, TEST ACC: [98.027 %]

saving the latest model (epoch 863, total_steps 3213552)
(epoch: 863, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 863, iters: 144, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 863, iters: 224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 863, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 863, iters: 384, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 863, iters: 464, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 863, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 863, iters: 624, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 863, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 863, iters: 784, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 863, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 863, iters: 944, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 863, iters: 1024, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 863, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 863, iters: 1184, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 863, iters: 1264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 863, iters: 1344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 863, iters: 1424, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 863, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 863, iters: 1584, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 863, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 863, iters: 1744, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 863, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 863, iters: 1904, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 863, iters: 1984, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 863, iters: 2064, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 863, iters: 2144, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 863, iters: 2224, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 863, iters: 2304, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 863, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 863, iters: 2464, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 863, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 863, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 863, iters: 2704, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 863, iters: 2784, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 863, iters: 2864, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 863, iters: 2944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 863, iters: 3024, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 863, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 863, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 863, iters: 3264, time: 0.096, data: 0.047) loss: 0.000 
(epoch: 863, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 863, iters: 3424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 863, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 863, iters: 3584, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 863, iters: 3664, time: 0.087, data: 0.000) loss: 0.002 
saving the model at the end of epoch 863, iters 3217264
End of epoch 863 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001236
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 863, TEST ACC: [96.206 %]

(epoch: 864, iters: 16, time: 0.136, data: 0.000) loss: 0.000 
saving the latest model (epoch 864, total_steps 3217280)
(epoch: 864, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 864, iters: 176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 864, iters: 256, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 864, iters: 336, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 864, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 864, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 864, iters: 576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 864, iters: 656, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 864, iters: 736, time: 0.094, data: 0.036) loss: 0.000 
(epoch: 864, iters: 816, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 864, iters: 896, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 864, iters: 976, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 864, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 864, iters: 1136, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 864, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 864, iters: 1296, time: 0.095, data: 0.030) loss: 0.000 
(epoch: 864, iters: 1376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 864, iters: 1456, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 864, iters: 1536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 864, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 864, iters: 1696, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 864, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 864, iters: 1856, time: 0.095, data: 0.037) loss: 0.000 
(epoch: 864, iters: 1936, time: 0.095, data: 0.035) loss: 0.000 
(epoch: 864, iters: 2016, time: 0.092, data: 0.018) loss: 0.000 
(epoch: 864, iters: 2096, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 864, iters: 2176, time: 0.096, data: 0.000) loss: 0.121 
(epoch: 864, iters: 2256, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 864, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 864, iters: 2416, time: 0.094, data: 0.033) loss: 0.002 
(epoch: 864, iters: 2496, time: 0.096, data: 0.025) loss: 0.000 
(epoch: 864, iters: 2576, time: 0.093, data: 0.017) loss: 0.000 
(epoch: 864, iters: 2656, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 864, iters: 2736, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 864, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 864, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 864, iters: 2976, time: 0.094, data: 0.033) loss: 0.000 
(epoch: 864, iters: 3056, time: 0.097, data: 0.038) loss: 0.005 
(epoch: 864, iters: 3136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 864, iters: 3216, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 864, iters: 3296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 864, iters: 3376, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 864, iters: 3456, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 864, iters: 3536, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 864, iters: 3616, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 864, iters: 3696, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 864, iters 3220992
End of epoch 864 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001235
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 864, TEST ACC: [95.903 %]

saving the latest model (epoch 865, total_steps 3221008)
(epoch: 865, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 865, iters: 128, time: 0.095, data: 0.044) loss: 0.000 
(epoch: 865, iters: 208, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 865, iters: 288, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 865, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 865, iters: 448, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 865, iters: 528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 865, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 865, iters: 688, time: 0.093, data: 0.032) loss: 0.000 
(epoch: 865, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 865, iters: 848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 865, iters: 928, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 865, iters: 1008, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 865, iters: 1088, time: 0.098, data: 0.040) loss: 0.000 
(epoch: 865, iters: 1168, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 865, iters: 1248, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 865, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 865, iters: 1408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 865, iters: 1488, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 865, iters: 1568, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 865, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 865, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 865, iters: 1808, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 865, iters: 1888, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 865, iters: 1968, time: 0.093, data: 0.015) loss: 0.000 
(epoch: 865, iters: 2048, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 865, iters: 2128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 865, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 865, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 865, iters: 2368, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 865, iters: 2448, time: 0.093, data: 0.025) loss: 0.001 
(epoch: 865, iters: 2528, time: 0.097, data: 0.031) loss: 0.000 
(epoch: 865, iters: 2608, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 865, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 865, iters: 2768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 865, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 865, iters: 2928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 865, iters: 3008, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 865, iters: 3088, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 865, iters: 3168, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 865, iters: 3248, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 865, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 865, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 865, iters: 3488, time: 0.096, data: 0.037) loss: 0.000 
(epoch: 865, iters: 3568, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 865, iters: 3648, time: 0.087, data: 0.011) loss: 0.000 
(epoch: 865, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 865, iters 3224720
End of epoch 865 / 2100 	 Time Taken: 365 sec
learning rate = 0.0001234
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 865, TEST ACC: [94.992 %]

saving the latest model (epoch 866, total_steps 3224736)
(epoch: 866, iters: 80, time: 0.094, data: 2.588) loss: 0.000 
(epoch: 866, iters: 160, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 866, iters: 240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 866, iters: 320, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 866, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 866, iters: 480, time: 0.096, data: 0.036) loss: 0.000 
(epoch: 866, iters: 560, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 866, iters: 640, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 866, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 866, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 866, iters: 880, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 866, iters: 960, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 866, iters: 1040, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 866, iters: 1120, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 866, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 866, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 866, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 866, iters: 1440, time: 0.093, data: 0.035) loss: 0.000 
(epoch: 866, iters: 1520, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 866, iters: 1600, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 866, iters: 1680, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 866, iters: 1760, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 866, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 866, iters: 1920, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 866, iters: 2000, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 866, iters: 2080, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 866, iters: 2160, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 866, iters: 2240, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 866, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 866, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 866, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 866, iters: 2560, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 866, iters: 2640, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 866, iters: 2720, time: 0.095, data: 0.034) loss: 0.000 
(epoch: 866, iters: 2800, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 866, iters: 2880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 866, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 866, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 866, iters: 3120, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 866, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 866, iters: 3280, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 866, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 866, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 866, iters: 3520, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 866, iters: 3600, time: 0.094, data: 0.047) loss: 0.000 
(epoch: 866, iters: 3680, time: 0.088, data: 0.026) loss: 0.000 
saving the model at the end of epoch 866, iters 3228448
End of epoch 866 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001233
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 866, TEST ACC: [96.358 %]

saving the latest model (epoch 867, total_steps 3228464)
(epoch: 867, iters: 32, time: 0.100, data: 0.005) loss: 0.000 
(epoch: 867, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 867, iters: 192, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 867, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 867, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 867, iters: 432, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 867, iters: 512, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 867, iters: 592, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 867, iters: 672, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 867, iters: 752, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 867, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 867, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 867, iters: 992, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 867, iters: 1072, time: 0.094, data: 0.025) loss: 0.009 
(epoch: 867, iters: 1152, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 867, iters: 1232, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 867, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 867, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 867, iters: 1472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 867, iters: 1552, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 867, iters: 1632, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 867, iters: 1712, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 867, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 867, iters: 1872, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 867, iters: 1952, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 867, iters: 2032, time: 0.092, data: 0.031) loss: 0.000 
(epoch: 867, iters: 2112, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 867, iters: 2192, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 867, iters: 2272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 867, iters: 2352, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 867, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 867, iters: 2512, time: 0.095, data: 0.037) loss: 0.000 
(epoch: 867, iters: 2592, time: 0.095, data: 0.032) loss: 0.000 
(epoch: 867, iters: 2672, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 867, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 867, iters: 2832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 867, iters: 2912, time: 0.098, data: 0.025) loss: 0.000 
(epoch: 867, iters: 2992, time: 0.094, data: 0.028) loss: 0.000 
(epoch: 867, iters: 3072, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 867, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 867, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 867, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 867, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 867, iters: 3472, time: 0.091, data: 0.047) loss: 0.000 
(epoch: 867, iters: 3552, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 867, iters: 3632, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 867, iters: 3712, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 867, iters 3232176
End of epoch 867 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001232
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 867, TEST ACC: [93.778 %]

saving the latest model (epoch 868, total_steps 3232192)
(epoch: 868, iters: 64, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 868, iters: 144, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 868, iters: 224, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 868, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 868, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 868, iters: 464, time: 0.094, data: 0.032) loss: 0.000 
(epoch: 868, iters: 544, time: 0.093, data: 0.030) loss: 0.000 
(epoch: 868, iters: 624, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 868, iters: 704, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 868, iters: 784, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 868, iters: 864, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 868, iters: 944, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 868, iters: 1024, time: 0.098, data: 0.030) loss: 0.000 
(epoch: 868, iters: 1104, time: 0.099, data: 0.000) loss: 0.119 
(epoch: 868, iters: 1184, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 868, iters: 1264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 868, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 868, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 868, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 868, iters: 1584, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 868, iters: 1664, time: 0.096, data: 0.027) loss: 0.001 
(epoch: 868, iters: 1744, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 868, iters: 1824, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 868, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 868, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 868, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 868, iters: 2144, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 868, iters: 2224, time: 0.095, data: 0.032) loss: 0.000 
(epoch: 868, iters: 2304, time: 0.091, data: 0.011) loss: 0.001 
(epoch: 868, iters: 2384, time: 0.092, data: 0.000) loss: 0.005 
(epoch: 868, iters: 2464, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 868, iters: 2544, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 868, iters: 2624, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 868, iters: 2704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 868, iters: 2784, time: 0.091, data: 0.014) loss: 0.000 
(epoch: 868, iters: 2864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 868, iters: 2944, time: 0.090, data: 0.011) loss: 0.000 
(epoch: 868, iters: 3024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 868, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 868, iters: 3184, time: 0.092, data: 0.043) loss: 0.001 
(epoch: 868, iters: 3264, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 868, iters: 3344, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 868, iters: 3424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 868, iters: 3504, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 868, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 868, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 868, iters 3235904
End of epoch 868 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001231
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 868, TEST ACC: [96.813 %]

(epoch: 869, iters: 16, time: 0.136, data: 0.000) loss: 0.000 
saving the latest model (epoch 869, total_steps 3235920)
(epoch: 869, iters: 96, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 869, iters: 176, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 869, iters: 256, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 869, iters: 336, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 869, iters: 416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 869, iters: 496, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 869, iters: 576, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 869, iters: 656, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 869, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 869, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 869, iters: 896, time: 0.095, data: 0.025) loss: 0.137 
(epoch: 869, iters: 976, time: 0.096, data: 0.025) loss: 0.000 
(epoch: 869, iters: 1056, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 869, iters: 1136, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 869, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 869, iters: 1296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 869, iters: 1376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 869, iters: 1456, time: 0.094, data: 0.018) loss: 0.000 
(epoch: 869, iters: 1536, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 869, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 869, iters: 1696, time: 0.097, data: 0.053) loss: 0.000 
(epoch: 869, iters: 1776, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 869, iters: 1856, time: 0.090, data: 0.013) loss: 0.000 
(epoch: 869, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 869, iters: 2016, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 869, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 869, iters: 2176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 869, iters: 2256, time: 0.095, data: 0.030) loss: 0.000 
(epoch: 869, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 869, iters: 2416, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 869, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 869, iters: 2576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 869, iters: 2656, time: 0.095, data: 0.027) loss: 0.107 
(epoch: 869, iters: 2736, time: 0.096, data: 0.043) loss: 0.000 
(epoch: 869, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 869, iters: 2896, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 869, iters: 2976, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 869, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 869, iters: 3136, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 869, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 869, iters: 3296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 869, iters: 3376, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 869, iters: 3456, time: 0.095, data: 0.038) loss: 0.014 
(epoch: 869, iters: 3536, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 869, iters: 3616, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 869, iters: 3696, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 869, iters 3239632
End of epoch 869 / 2100 	 Time Taken: 359 sec
learning rate = 0.0001230
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 869, TEST ACC: [91.806 %]

saving the latest model (epoch 870, total_steps 3239648)
(epoch: 870, iters: 48, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 870, iters: 128, time: 0.095, data: 0.015) loss: 0.000 
(epoch: 870, iters: 208, time: 0.096, data: 0.033) loss: 0.000 
(epoch: 870, iters: 288, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 870, iters: 368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 870, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 870, iters: 528, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 870, iters: 608, time: 0.095, data: 0.000) loss: 0.102 
(epoch: 870, iters: 688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 870, iters: 768, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 870, iters: 848, time: 0.094, data: 0.000) loss: 0.030 
(epoch: 870, iters: 928, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 870, iters: 1008, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 870, iters: 1088, time: 0.094, data: 0.037) loss: 0.000 
(epoch: 870, iters: 1168, time: 0.092, data: 0.017) loss: 0.000 
(epoch: 870, iters: 1248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 870, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 870, iters: 1408, time: 0.096, data: 0.000) loss: 0.185 
(epoch: 870, iters: 1488, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 870, iters: 1568, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 870, iters: 1648, time: 0.096, data: 0.025) loss: 0.000 
(epoch: 870, iters: 1728, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 870, iters: 1808, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 870, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 870, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 870, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 870, iters: 2128, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 870, iters: 2208, time: 0.095, data: 0.000) loss: 0.020 
(epoch: 870, iters: 2288, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 870, iters: 2368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 870, iters: 2448, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 870, iters: 2528, time: 0.098, data: 0.035) loss: 0.000 
(epoch: 870, iters: 2608, time: 0.098, data: 0.027) loss: 0.000 
(epoch: 870, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 870, iters: 2768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 870, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 870, iters: 2928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 870, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 870, iters: 3088, time: 0.096, data: 0.030) loss: 0.000 
(epoch: 870, iters: 3168, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 870, iters: 3248, time: 0.095, data: 0.018) loss: 0.000 
(epoch: 870, iters: 3328, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 870, iters: 3408, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 870, iters: 3488, time: 0.101, data: 0.000) loss: 0.000 
(epoch: 870, iters: 3568, time: 0.093, data: 0.030) loss: 0.000 
(epoch: 870, iters: 3648, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 870, iters: 3728, time: 0.057, data: 0.013) loss: 0.000 
saving the model at the end of epoch 870, iters 3243360
End of epoch 870 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001229
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 870, TEST ACC: [96.358 %]

saving the latest model (epoch 871, total_steps 3243376)
(epoch: 871, iters: 80, time: 0.095, data: 2.744) loss: 0.000 
(epoch: 871, iters: 160, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 871, iters: 240, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 871, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 871, iters: 400, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 871, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 871, iters: 560, time: 0.096, data: 0.035) loss: 0.000 
(epoch: 871, iters: 640, time: 0.098, data: 0.026) loss: 0.000 
(epoch: 871, iters: 720, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 871, iters: 800, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 871, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 871, iters: 960, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 871, iters: 1040, time: 0.095, data: 0.000) loss: 0.091 
(epoch: 871, iters: 1120, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 871, iters: 1200, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 871, iters: 1280, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 871, iters: 1360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 871, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 871, iters: 1520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 871, iters: 1600, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 871, iters: 1680, time: 0.098, data: 0.030) loss: 0.000 
(epoch: 871, iters: 1760, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 871, iters: 1840, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 871, iters: 1920, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 871, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 871, iters: 2080, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 871, iters: 2160, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 871, iters: 2240, time: 0.096, data: 0.045) loss: 0.033 
(epoch: 871, iters: 2320, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 871, iters: 2400, time: 0.094, data: 0.019) loss: 0.000 
(epoch: 871, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 871, iters: 2560, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 871, iters: 2640, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 871, iters: 2720, time: 0.100, data: 0.000) loss: 0.000 
(epoch: 871, iters: 2800, time: 0.097, data: 0.031) loss: 0.000 
(epoch: 871, iters: 2880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 871, iters: 2960, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 871, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 871, iters: 3120, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 871, iters: 3200, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 871, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 871, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 871, iters: 3440, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 871, iters: 3520, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 871, iters: 3600, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 871, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 871, iters 3247088
End of epoch 871 / 2100 	 Time Taken: 367 sec
learning rate = 0.0001228
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 871, TEST ACC: [96.206 %]

saving the latest model (epoch 872, total_steps 3247104)
(epoch: 872, iters: 32, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 872, iters: 112, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 872, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 872, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 872, iters: 352, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 872, iters: 432, time: 0.095, data: 0.037) loss: 0.000 
(epoch: 872, iters: 512, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 872, iters: 592, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 872, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 872, iters: 752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 872, iters: 832, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 872, iters: 912, time: 0.096, data: 0.030) loss: 0.000 
(epoch: 872, iters: 992, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 872, iters: 1072, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 872, iters: 1152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 872, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 872, iters: 1312, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 872, iters: 1392, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 872, iters: 1472, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 872, iters: 1552, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 872, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 872, iters: 1712, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 872, iters: 1792, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 872, iters: 1872, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 872, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 872, iters: 2032, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 872, iters: 2112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 872, iters: 2192, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 872, iters: 2272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 872, iters: 2352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 872, iters: 2432, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 872, iters: 2512, time: 0.096, data: 0.036) loss: 0.000 
(epoch: 872, iters: 2592, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 872, iters: 2672, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 872, iters: 2752, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 872, iters: 2832, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 872, iters: 2912, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 872, iters: 2992, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 872, iters: 3072, time: 0.098, data: 0.026) loss: 0.000 
(epoch: 872, iters: 3152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 872, iters: 3232, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 872, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 872, iters: 3392, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 872, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 872, iters: 3552, time: 0.097, data: 0.038) loss: 0.000 
(epoch: 872, iters: 3632, time: 0.095, data: 0.033) loss: 0.000 
(epoch: 872, iters: 3712, time: 0.090, data: 0.013) loss: 0.000 
saving the model at the end of epoch 872, iters 3250816
End of epoch 872 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001227
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 872, TEST ACC: [96.813 %]

saving the latest model (epoch 873, total_steps 3250832)
(epoch: 873, iters: 64, time: 0.095, data: 0.003) loss: 0.000 
(epoch: 873, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 873, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 873, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 873, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 873, iters: 464, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 873, iters: 544, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 873, iters: 624, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 873, iters: 704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 873, iters: 784, time: 0.096, data: 0.000) loss: 0.180 
(epoch: 873, iters: 864, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 873, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 873, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 873, iters: 1104, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 873, iters: 1184, time: 0.097, data: 0.033) loss: 0.000 
(epoch: 873, iters: 1264, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 873, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 873, iters: 1424, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 873, iters: 1504, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 873, iters: 1584, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 873, iters: 1664, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 873, iters: 1744, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 873, iters: 1824, time: 0.095, data: 0.018) loss: 0.000 
(epoch: 873, iters: 1904, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 873, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 873, iters: 2064, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 873, iters: 2144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 873, iters: 2224, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 873, iters: 2304, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 873, iters: 2384, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 873, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 873, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 873, iters: 2624, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 873, iters: 2704, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 873, iters: 2784, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 873, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 873, iters: 2944, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 873, iters: 3024, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 873, iters: 3104, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 873, iters: 3184, time: 0.094, data: 0.014) loss: 0.000 
(epoch: 873, iters: 3264, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 873, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 873, iters: 3424, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 873, iters: 3504, time: 0.097, data: 0.025) loss: 0.000 
(epoch: 873, iters: 3584, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 873, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 873, iters 3254544
End of epoch 873 / 2100 	 Time Taken: 366 sec
learning rate = 0.0001226
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 873, TEST ACC: [96.662 %]

(epoch: 874, iters: 16, time: 0.140, data: 0.000) loss: 0.000 
saving the latest model (epoch 874, total_steps 3254560)
(epoch: 874, iters: 96, time: 0.097, data: 0.010) loss: 0.000 
(epoch: 874, iters: 176, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 874, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 874, iters: 336, time: 0.096, data: 0.022) loss: 0.001 
(epoch: 874, iters: 416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 874, iters: 496, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 874, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 874, iters: 656, time: 0.101, data: 0.000) loss: 0.000 
(epoch: 874, iters: 736, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 874, iters: 816, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 874, iters: 896, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 874, iters: 976, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 874, iters: 1056, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 874, iters: 1136, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 874, iters: 1216, time: 0.093, data: 0.030) loss: 0.000 
(epoch: 874, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 874, iters: 1376, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 874, iters: 1456, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 874, iters: 1536, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 874, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 874, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 874, iters: 1776, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 874, iters: 1856, time: 0.096, data: 0.025) loss: 0.000 
(epoch: 874, iters: 1936, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 874, iters: 2016, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 874, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 874, iters: 2176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 874, iters: 2256, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 874, iters: 2336, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 874, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 874, iters: 2496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 874, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 874, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 874, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 874, iters: 2816, time: 0.093, data: 0.032) loss: 0.000 
(epoch: 874, iters: 2896, time: 0.093, data: 0.037) loss: 0.000 
(epoch: 874, iters: 2976, time: 0.091, data: 0.020) loss: 0.000 
(epoch: 874, iters: 3056, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 874, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 874, iters: 3216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 874, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 874, iters: 3376, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 874, iters: 3456, time: 0.094, data: 0.037) loss: 0.000 
(epoch: 874, iters: 3536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 874, iters: 3616, time: 0.092, data: 0.000) loss: 0.004 
(epoch: 874, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 874, iters 3258272
End of epoch 874 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001225
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 874, TEST ACC: [96.813 %]

saving the latest model (epoch 875, total_steps 3258288)
(epoch: 875, iters: 48, time: 0.100, data: 0.000) loss: 0.000 
(epoch: 875, iters: 128, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 875, iters: 208, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 875, iters: 288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 875, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 875, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 875, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 875, iters: 608, time: 0.092, data: 0.036) loss: 0.000 
(epoch: 875, iters: 688, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 875, iters: 768, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 875, iters: 848, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 875, iters: 928, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 875, iters: 1008, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 875, iters: 1088, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 875, iters: 1168, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 875, iters: 1248, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 875, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 875, iters: 1408, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 875, iters: 1488, time: 0.097, data: 0.026) loss: 0.001 
(epoch: 875, iters: 1568, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 875, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 875, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 875, iters: 1808, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 875, iters: 1888, time: 0.095, data: 0.035) loss: 0.000 
(epoch: 875, iters: 1968, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 875, iters: 2048, time: 0.093, data: 0.012) loss: 0.019 
(epoch: 875, iters: 2128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 875, iters: 2208, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 875, iters: 2288, time: 0.094, data: 0.029) loss: 0.000 
(epoch: 875, iters: 2368, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 875, iters: 2448, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 875, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 875, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 875, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 875, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 875, iters: 2848, time: 0.096, data: 0.043) loss: 0.059 
(epoch: 875, iters: 2928, time: 0.097, data: 0.038) loss: 0.000 
(epoch: 875, iters: 3008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 875, iters: 3088, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 875, iters: 3168, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 875, iters: 3248, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 875, iters: 3328, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 875, iters: 3408, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 875, iters: 3488, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 875, iters: 3568, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 875, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 875, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 875, iters 3262000
End of epoch 875 / 2100 	 Time Taken: 362 sec
learning rate = 0.0001224
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 875, TEST ACC: [96.206 %]

saving the latest model (epoch 876, total_steps 3262016)
(epoch: 876, iters: 80, time: 0.094, data: 1.912) loss: 0.000 
(epoch: 876, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 876, iters: 240, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 876, iters: 320, time: 0.097, data: 0.049) loss: 0.000 
(epoch: 876, iters: 400, time: 0.090, data: 0.012) loss: 0.000 
(epoch: 876, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 876, iters: 560, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 876, iters: 640, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 876, iters: 720, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 876, iters: 800, time: 0.095, data: 0.030) loss: 0.000 
(epoch: 876, iters: 880, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 876, iters: 960, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 876, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 876, iters: 1120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 876, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 876, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 876, iters: 1360, time: 0.090, data: 0.052) loss: 0.000 
(epoch: 876, iters: 1440, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 876, iters: 1520, time: 0.090, data: 0.000) loss: 0.230 
(epoch: 876, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 876, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 876, iters: 1760, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 876, iters: 1840, time: 0.091, data: 0.026) loss: 0.000 
(epoch: 876, iters: 1920, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 876, iters: 2000, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 876, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 876, iters: 2160, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 876, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 876, iters: 2320, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 876, iters: 2400, time: 0.095, data: 0.026) loss: 0.005 
(epoch: 876, iters: 2480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 876, iters: 2560, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 876, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 876, iters: 2720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 876, iters: 2800, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 876, iters: 2880, time: 0.097, data: 0.054) loss: 0.000 
(epoch: 876, iters: 2960, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 876, iters: 3040, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 876, iters: 3120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 876, iters: 3200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 876, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 876, iters: 3360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 876, iters: 3440, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 876, iters: 3520, time: 0.096, data: 0.029) loss: 0.000 
(epoch: 876, iters: 3600, time: 0.092, data: 0.035) loss: 0.000 
(epoch: 876, iters: 3680, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 876, iters 3265728
End of epoch 876 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001223
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 876, TEST ACC: [96.206 %]

saving the latest model (epoch 877, total_steps 3265744)
(epoch: 877, iters: 32, time: 0.105, data: 0.000) loss: 0.000 
(epoch: 877, iters: 112, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 877, iters: 192, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 877, iters: 272, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 877, iters: 352, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 877, iters: 432, time: 0.093, data: 0.028) loss: 0.000 
(epoch: 877, iters: 512, time: 0.094, data: 0.025) loss: 0.002 
(epoch: 877, iters: 592, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 877, iters: 672, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 877, iters: 752, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 877, iters: 832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 877, iters: 912, time: 0.094, data: 0.000) loss: 0.023 
(epoch: 877, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 877, iters: 1072, time: 0.095, data: 0.045) loss: 0.000 
(epoch: 877, iters: 1152, time: 0.098, data: 0.026) loss: 0.000 
(epoch: 877, iters: 1232, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 877, iters: 1312, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 877, iters: 1392, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 877, iters: 1472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 877, iters: 1552, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 877, iters: 1632, time: 0.096, data: 0.025) loss: 0.000 
(epoch: 877, iters: 1712, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 877, iters: 1792, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 877, iters: 1872, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 877, iters: 1952, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 877, iters: 2032, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 877, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 877, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 877, iters: 2272, time: 0.097, data: 0.025) loss: 0.000 
(epoch: 877, iters: 2352, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 877, iters: 2432, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 877, iters: 2512, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 877, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 877, iters: 2672, time: 0.095, data: 0.000) loss: 0.086 
(epoch: 877, iters: 2752, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 877, iters: 2832, time: 0.095, data: 0.031) loss: 0.000 
(epoch: 877, iters: 2912, time: 0.092, data: 0.026) loss: 0.001 
(epoch: 877, iters: 2992, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 877, iters: 3072, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 877, iters: 3152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 877, iters: 3232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 877, iters: 3312, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 877, iters: 3392, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 877, iters: 3472, time: 0.097, data: 0.035) loss: 0.000 
(epoch: 877, iters: 3552, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 877, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 877, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 877, iters 3269456
End of epoch 877 / 2100 	 Time Taken: 362 sec
learning rate = 0.0001222
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 877, TEST ACC: [95.751 %]

saving the latest model (epoch 878, total_steps 3269472)
(epoch: 878, iters: 64, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 878, iters: 144, time: 0.096, data: 0.016) loss: 0.000 
(epoch: 878, iters: 224, time: 0.093, data: 0.000) loss: 0.097 
(epoch: 878, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 878, iters: 384, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 878, iters: 464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 878, iters: 544, time: 0.096, data: 0.026) loss: 0.001 
(epoch: 878, iters: 624, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 878, iters: 704, time: 0.098, data: 0.011) loss: 0.000 
(epoch: 878, iters: 784, time: 0.096, data: 0.013) loss: 0.001 
(epoch: 878, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 878, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 878, iters: 1024, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 878, iters: 1104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 878, iters: 1184, time: 0.096, data: 0.026) loss: 0.004 
(epoch: 878, iters: 1264, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 878, iters: 1344, time: 0.094, data: 0.019) loss: 0.000 
(epoch: 878, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 878, iters: 1504, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 878, iters: 1584, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 878, iters: 1664, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 878, iters: 1744, time: 0.097, data: 0.031) loss: 0.000 
(epoch: 878, iters: 1824, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 878, iters: 1904, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 878, iters: 1984, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 878, iters: 2064, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 878, iters: 2144, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 878, iters: 2224, time: 0.096, data: 0.031) loss: 0.000 
(epoch: 878, iters: 2304, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 878, iters: 2384, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 878, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 878, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 878, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 878, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 878, iters: 2784, time: 0.093, data: 0.045) loss: 0.000 
(epoch: 878, iters: 2864, time: 0.097, data: 0.035) loss: 0.000 
(epoch: 878, iters: 2944, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 878, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 878, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 878, iters: 3184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 878, iters: 3264, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 878, iters: 3344, time: 0.096, data: 0.018) loss: 0.000 
(epoch: 878, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 878, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 878, iters: 3584, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 878, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 878, iters 3273184
End of epoch 878 / 2100 	 Time Taken: 367 sec
learning rate = 0.0001221
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 878, TEST ACC: [95.448 %]

(epoch: 879, iters: 16, time: 0.144, data: 0.011) loss: 0.000 
saving the latest model (epoch 879, total_steps 3273200)
(epoch: 879, iters: 96, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 879, iters: 176, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 879, iters: 256, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 879, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 879, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 879, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 879, iters: 576, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 879, iters: 656, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 879, iters: 736, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 879, iters: 816, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 879, iters: 896, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 879, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 879, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 879, iters: 1136, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 879, iters: 1216, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 879, iters: 1296, time: 0.097, data: 0.018) loss: 0.000 
(epoch: 879, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 879, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 879, iters: 1536, time: 0.095, data: 0.035) loss: 0.000 
(epoch: 879, iters: 1616, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 879, iters: 1696, time: 0.093, data: 0.018) loss: 0.000 
(epoch: 879, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 879, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 879, iters: 1936, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 879, iters: 2016, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 879, iters: 2096, time: 0.095, data: 0.030) loss: 0.000 
(epoch: 879, iters: 2176, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 879, iters: 2256, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 879, iters: 2336, time: 0.095, data: 0.016) loss: 0.084 
(epoch: 879, iters: 2416, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 879, iters: 2496, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 879, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 879, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 879, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 879, iters: 2816, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 879, iters: 2896, time: 0.095, data: 0.027) loss: 0.182 
(epoch: 879, iters: 2976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 879, iters: 3056, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 879, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 879, iters: 3216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 879, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 879, iters: 3376, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 879, iters: 3456, time: 0.096, data: 0.025) loss: 0.003 
(epoch: 879, iters: 3536, time: 0.092, data: 0.018) loss: 0.000 
(epoch: 879, iters: 3616, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 879, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 879, iters 3276912
End of epoch 879 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001220
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 879, TEST ACC: [95.296 %]

saving the latest model (epoch 880, total_steps 3276928)
(epoch: 880, iters: 48, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 880, iters: 128, time: 0.098, data: 0.055) loss: 0.000 
(epoch: 880, iters: 208, time: 0.097, data: 0.036) loss: 0.000 
(epoch: 880, iters: 288, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 880, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 880, iters: 448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 880, iters: 528, time: 0.094, data: 0.000) loss: 0.470 
(epoch: 880, iters: 608, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 880, iters: 688, time: 0.094, data: 0.016) loss: 0.000 
(epoch: 880, iters: 768, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 880, iters: 848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 880, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 880, iters: 1008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 880, iters: 1088, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 880, iters: 1168, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 880, iters: 1248, time: 0.093, data: 0.011) loss: 0.026 
(epoch: 880, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 880, iters: 1408, time: 0.090, data: 0.000) loss: 0.031 
(epoch: 880, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 880, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 880, iters: 1648, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 880, iters: 1728, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 880, iters: 1808, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 880, iters: 1888, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 880, iters: 1968, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 880, iters: 2048, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 880, iters: 2128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 880, iters: 2208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 880, iters: 2288, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 880, iters: 2368, time: 0.093, data: 0.031) loss: 0.000 
(epoch: 880, iters: 2448, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 880, iters: 2528, time: 0.093, data: 0.017) loss: 0.000 
(epoch: 880, iters: 2608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 880, iters: 2688, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 880, iters: 2768, time: 0.095, data: 0.032) loss: 0.000 
(epoch: 880, iters: 2848, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 880, iters: 2928, time: 0.091, data: 0.018) loss: 0.000 
(epoch: 880, iters: 3008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 880, iters: 3088, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 880, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 880, iters: 3248, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 880, iters: 3328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 880, iters: 3408, time: 0.093, data: 0.028) loss: 0.000 
(epoch: 880, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 880, iters: 3568, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 880, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 880, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 880, iters 3280640
End of epoch 880 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001219
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 880, TEST ACC: [96.965 %]

saving the latest model (epoch 881, total_steps 3280656)
(epoch: 881, iters: 80, time: 0.093, data: 4.013) loss: 0.000 
(epoch: 881, iters: 160, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 881, iters: 240, time: 0.095, data: 0.029) loss: 0.000 
(epoch: 881, iters: 320, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 881, iters: 400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 881, iters: 480, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 881, iters: 560, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 881, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 881, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 881, iters: 800, time: 0.092, data: 0.018) loss: 0.000 
(epoch: 881, iters: 880, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 881, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 881, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 881, iters: 1120, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 881, iters: 1200, time: 0.094, data: 0.026) loss: 0.003 
(epoch: 881, iters: 1280, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 881, iters: 1360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 881, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 881, iters: 1520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 881, iters: 1600, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 881, iters: 1680, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 881, iters: 1760, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 881, iters: 1840, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 881, iters: 1920, time: 0.092, data: 0.017) loss: 0.000 
(epoch: 881, iters: 2000, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 881, iters: 2080, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 881, iters: 2160, time: 0.091, data: 0.025) loss: 0.000 
(epoch: 881, iters: 2240, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 881, iters: 2320, time: 0.092, data: 0.017) loss: 0.000 
(epoch: 881, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 881, iters: 2480, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 881, iters: 2560, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 881, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 881, iters: 2720, time: 0.094, data: 0.054) loss: 0.010 
(epoch: 881, iters: 2800, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 881, iters: 2880, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 881, iters: 2960, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 881, iters: 3040, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 881, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 881, iters: 3200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 881, iters: 3280, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 881, iters: 3360, time: 0.099, data: 0.027) loss: 0.000 
(epoch: 881, iters: 3440, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 881, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 881, iters: 3600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 881, iters: 3680, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 881, iters 3284368
End of epoch 881 / 2100 	 Time Taken: 362 sec
learning rate = 0.0001218
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 881, TEST ACC: [96.965 %]

saving the latest model (epoch 882, total_steps 3284384)
(epoch: 882, iters: 32, time: 0.107, data: 0.000) loss: 0.000 
(epoch: 882, iters: 112, time: 0.095, data: 0.021) loss: 0.000 
(epoch: 882, iters: 192, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 882, iters: 272, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 882, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 882, iters: 432, time: 0.097, data: 0.037) loss: 0.000 
(epoch: 882, iters: 512, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 882, iters: 592, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 882, iters: 672, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 882, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 882, iters: 832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 882, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 882, iters: 992, time: 0.096, data: 0.037) loss: 0.000 
(epoch: 882, iters: 1072, time: 0.097, data: 0.027) loss: 0.000 
(epoch: 882, iters: 1152, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 882, iters: 1232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 882, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 882, iters: 1392, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 882, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 882, iters: 1552, time: 0.093, data: 0.031) loss: 0.000 
(epoch: 882, iters: 1632, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 882, iters: 1712, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 882, iters: 1792, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 882, iters: 1872, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 882, iters: 1952, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 882, iters: 2032, time: 0.100, data: 0.000) loss: 0.000 
(epoch: 882, iters: 2112, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 882, iters: 2192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 882, iters: 2272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 882, iters: 2352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 882, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 882, iters: 2512, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 882, iters: 2592, time: 0.094, data: 0.037) loss: 0.000 
(epoch: 882, iters: 2672, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 882, iters: 2752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 882, iters: 2832, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 882, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 882, iters: 2992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 882, iters: 3072, time: 0.096, data: 0.028) loss: 0.000 
(epoch: 882, iters: 3152, time: 0.096, data: 0.035) loss: 0.000 
(epoch: 882, iters: 3232, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 882, iters: 3312, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 882, iters: 3392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 882, iters: 3472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 882, iters: 3552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 882, iters: 3632, time: 0.094, data: 0.033) loss: 0.000 
(epoch: 882, iters: 3712, time: 0.087, data: 0.026) loss: 0.000 
saving the model at the end of epoch 882, iters 3288096
End of epoch 882 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001217
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 882, TEST ACC: [91.654 %]

saving the latest model (epoch 883, total_steps 3288112)
(epoch: 883, iters: 64, time: 0.095, data: 0.002) loss: 0.000 
(epoch: 883, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 883, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 883, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 883, iters: 384, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 883, iters: 464, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 883, iters: 544, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 883, iters: 624, time: 0.090, data: 0.011) loss: 0.002 
(epoch: 883, iters: 704, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 883, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 883, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 883, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 883, iters: 1024, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 883, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 883, iters: 1184, time: 0.091, data: 0.018) loss: 0.015 
(epoch: 883, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 883, iters: 1344, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 883, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 883, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 883, iters: 1584, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 883, iters: 1664, time: 0.096, data: 0.037) loss: 0.000 
(epoch: 883, iters: 1744, time: 0.094, data: 0.018) loss: 0.000 
(epoch: 883, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 883, iters: 1904, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 883, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 883, iters: 2064, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 883, iters: 2144, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 883, iters: 2224, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 883, iters: 2304, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 883, iters: 2384, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 883, iters: 2464, time: 0.091, data: 0.017) loss: 0.001 
(epoch: 883, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 883, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 883, iters: 2704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 883, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 883, iters: 2864, time: 0.095, data: 0.030) loss: 0.000 
(epoch: 883, iters: 2944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 883, iters: 3024, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 883, iters: 3104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 883, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 883, iters: 3264, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 883, iters: 3344, time: 0.096, data: 0.031) loss: 0.000 
(epoch: 883, iters: 3424, time: 0.093, data: 0.017) loss: 0.000 
(epoch: 883, iters: 3504, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 883, iters: 3584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 883, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 883, iters 3291824
End of epoch 883 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001216
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 883, TEST ACC: [97.117 %]

(epoch: 884, iters: 16, time: 0.139, data: 0.000) loss: 0.002 
saving the latest model (epoch 884, total_steps 3291840)
(epoch: 884, iters: 96, time: 0.096, data: 0.037) loss: 0.000 
(epoch: 884, iters: 176, time: 0.095, data: 0.036) loss: 0.000 
(epoch: 884, iters: 256, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 884, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 884, iters: 416, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 884, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 884, iters: 576, time: 0.094, data: 0.037) loss: 0.000 
(epoch: 884, iters: 656, time: 0.098, data: 0.026) loss: 0.000 
(epoch: 884, iters: 736, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 884, iters: 816, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 884, iters: 896, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 884, iters: 976, time: 0.103, data: 0.000) loss: 0.000 
(epoch: 884, iters: 1056, time: 0.094, data: 0.000) loss: 0.023 
(epoch: 884, iters: 1136, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 884, iters: 1216, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 884, iters: 1296, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 884, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 884, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 884, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 884, iters: 1616, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 884, iters: 1696, time: 0.096, data: 0.052) loss: 0.000 
(epoch: 884, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 884, iters: 1856, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 884, iters: 1936, time: 0.094, data: 0.037) loss: 0.000 
(epoch: 884, iters: 2016, time: 0.101, data: 0.011) loss: 0.000 
(epoch: 884, iters: 2096, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 884, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 884, iters: 2256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 884, iters: 2336, time: 0.091, data: 0.031) loss: 0.000 
(epoch: 884, iters: 2416, time: 0.094, data: 0.044) loss: 0.000 
(epoch: 884, iters: 2496, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 884, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 884, iters: 2656, time: 0.095, data: 0.000) loss: 0.026 
(epoch: 884, iters: 2736, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 884, iters: 2816, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 884, iters: 2896, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 884, iters: 2976, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 884, iters: 3056, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 884, iters: 3136, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 884, iters: 3216, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 884, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 884, iters: 3376, time: 0.091, data: 0.026) loss: 0.000 
(epoch: 884, iters: 3456, time: 0.097, data: 0.035) loss: 0.000 
(epoch: 884, iters: 3536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 884, iters: 3616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 884, iters: 3696, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 884, iters 3295552
End of epoch 884 / 2100 	 Time Taken: 371 sec
learning rate = 0.0001215
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 884, TEST ACC: [96.358 %]

saving the latest model (epoch 885, total_steps 3295568)
(epoch: 885, iters: 48, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 885, iters: 128, time: 0.096, data: 0.037) loss: 0.000 
(epoch: 885, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 885, iters: 288, time: 0.096, data: 0.035) loss: 0.000 
(epoch: 885, iters: 368, time: 0.094, data: 0.032) loss: 0.000 
(epoch: 885, iters: 448, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 885, iters: 528, time: 0.093, data: 0.004) loss: 0.000 
(epoch: 885, iters: 608, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 885, iters: 688, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 885, iters: 768, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 885, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 885, iters: 928, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 885, iters: 1008, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 885, iters: 1088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 885, iters: 1168, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 885, iters: 1248, time: 0.098, data: 0.030) loss: 0.000 
(epoch: 885, iters: 1328, time: 0.091, data: 0.005) loss: 0.000 
(epoch: 885, iters: 1408, time: 0.096, data: 0.021) loss: 0.000 
(epoch: 885, iters: 1488, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 885, iters: 1568, time: 0.095, data: 0.018) loss: 0.000 
(epoch: 885, iters: 1648, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 885, iters: 1728, time: 0.095, data: 0.000) loss: 0.010 
(epoch: 885, iters: 1808, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 885, iters: 1888, time: 0.088, data: 0.035) loss: 0.000 
(epoch: 885, iters: 1968, time: 0.095, data: 0.018) loss: 0.000 
(epoch: 885, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 885, iters: 2128, time: 0.093, data: 0.029) loss: 0.000 
(epoch: 885, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 885, iters: 2288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 885, iters: 2368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 885, iters: 2448, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 885, iters: 2528, time: 0.091, data: 0.000) loss: 0.019 
(epoch: 885, iters: 2608, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 885, iters: 2688, time: 0.097, data: 0.004) loss: 0.000 
(epoch: 885, iters: 2768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 885, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 885, iters: 2928, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 885, iters: 3008, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 885, iters: 3088, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 885, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 885, iters: 3248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 885, iters: 3328, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 885, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 885, iters: 3488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 885, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 885, iters: 3648, time: 0.089, data: 0.037) loss: 0.000 
(epoch: 885, iters: 3728, time: 0.056, data: 0.021) loss: 0.000 
saving the model at the end of epoch 885, iters 3299280
End of epoch 885 / 2100 	 Time Taken: 383 sec
learning rate = 0.0001214
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 885, TEST ACC: [96.965 %]

saving the latest model (epoch 886, total_steps 3299296)
(epoch: 886, iters: 80, time: 0.093, data: 2.328) loss: 0.000 
(epoch: 886, iters: 160, time: 0.094, data: 0.000) loss: 0.027 
(epoch: 886, iters: 240, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 886, iters: 320, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 886, iters: 400, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 886, iters: 480, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 886, iters: 560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 886, iters: 640, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 886, iters: 720, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 886, iters: 800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 886, iters: 880, time: 0.092, data: 0.037) loss: 0.000 
(epoch: 886, iters: 960, time: 0.097, data: 0.037) loss: 0.000 
(epoch: 886, iters: 1040, time: 0.089, data: 0.012) loss: 0.000 
(epoch: 886, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 886, iters: 1200, time: 0.092, data: 0.014) loss: 0.000 
(epoch: 886, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 886, iters: 1360, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 886, iters: 1440, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 886, iters: 1520, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 886, iters: 1600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 886, iters: 1680, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 886, iters: 1760, time: 0.093, data: 0.030) loss: 0.000 
(epoch: 886, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 886, iters: 1920, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 886, iters: 2000, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 886, iters: 2080, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 886, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 886, iters: 2240, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 886, iters: 2320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 886, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 886, iters: 2480, time: 0.096, data: 0.025) loss: 0.000 
(epoch: 886, iters: 2560, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 886, iters: 2640, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 886, iters: 2720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 886, iters: 2800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 886, iters: 2880, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 886, iters: 2960, time: 0.097, data: 0.025) loss: 0.000 
(epoch: 886, iters: 3040, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 886, iters: 3120, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 886, iters: 3200, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 886, iters: 3280, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 886, iters: 3360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 886, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 886, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 886, iters: 3600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 886, iters: 3680, time: 0.089, data: 0.035) loss: 0.000 
saving the model at the end of epoch 886, iters 3303008
End of epoch 886 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001213
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 886, TEST ACC: [97.269 %]

saving the latest model (epoch 887, total_steps 3303024)
(epoch: 887, iters: 32, time: 0.107, data: 0.011) loss: 0.000 
(epoch: 887, iters: 112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 887, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 887, iters: 272, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 887, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 887, iters: 432, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 887, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 887, iters: 592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 887, iters: 672, time: 0.094, data: 0.023) loss: 0.000 
(epoch: 887, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 887, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 887, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 887, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 887, iters: 1072, time: 0.092, data: 0.026) loss: 0.027 
(epoch: 887, iters: 1152, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 887, iters: 1232, time: 0.093, data: 0.013) loss: 0.002 
(epoch: 887, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 887, iters: 1392, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 887, iters: 1472, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 887, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 887, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 887, iters: 1712, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 887, iters: 1792, time: 0.096, data: 0.032) loss: 0.000 
(epoch: 887, iters: 1872, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 887, iters: 1952, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 887, iters: 2032, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 887, iters: 2112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 887, iters: 2192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 887, iters: 2272, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 887, iters: 2352, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 887, iters: 2432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 887, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 887, iters: 2592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 887, iters: 2672, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 887, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 887, iters: 2832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 887, iters: 2912, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 887, iters: 2992, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 887, iters: 3072, time: 0.092, data: 0.018) loss: 0.000 
(epoch: 887, iters: 3152, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 887, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 887, iters: 3312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 887, iters: 3392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 887, iters: 3472, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 887, iters: 3552, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 887, iters: 3632, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 887, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 887, iters 3306736
End of epoch 887 / 2100 	 Time Taken: 362 sec
learning rate = 0.0001212
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 887, TEST ACC: [96.965 %]

saving the latest model (epoch 888, total_steps 3306752)
(epoch: 888, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 888, iters: 144, time: 0.093, data: 0.024) loss: 0.000 
(epoch: 888, iters: 224, time: 0.095, data: 0.030) loss: 0.000 
(epoch: 888, iters: 304, time: 0.099, data: 0.026) loss: 0.000 
(epoch: 888, iters: 384, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 888, iters: 464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 888, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 888, iters: 624, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 888, iters: 704, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 888, iters: 784, time: 0.098, data: 0.040) loss: 0.000 
(epoch: 888, iters: 864, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 888, iters: 944, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 888, iters: 1024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 888, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 888, iters: 1184, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 888, iters: 1264, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 888, iters: 1344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 888, iters: 1424, time: 0.094, data: 0.017) loss: 0.000 
(epoch: 888, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 888, iters: 1584, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 888, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 888, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 888, iters: 1824, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 888, iters: 1904, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 888, iters: 1984, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 888, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 888, iters: 2144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 888, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 888, iters: 2304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 888, iters: 2384, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 888, iters: 2464, time: 0.099, data: 0.038) loss: 0.000 
(epoch: 888, iters: 2544, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 888, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 888, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 888, iters: 2784, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 888, iters: 2864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 888, iters: 2944, time: 0.096, data: 0.030) loss: 0.001 
(epoch: 888, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 888, iters: 3104, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 888, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 888, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 888, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 888, iters: 3424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 888, iters: 3504, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 888, iters: 3584, time: 0.095, data: 0.033) loss: 0.000 
(epoch: 888, iters: 3664, time: 0.089, data: 0.012) loss: 0.000 
saving the model at the end of epoch 888, iters 3310464
End of epoch 888 / 2100 	 Time Taken: 367 sec
learning rate = 0.0001211
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 888, TEST ACC: [95.599 %]

(epoch: 889, iters: 16, time: 0.144, data: 0.000) loss: 0.000 
saving the latest model (epoch 889, total_steps 3310480)
(epoch: 889, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 889, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 889, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 889, iters: 336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 889, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 889, iters: 496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 889, iters: 576, time: 0.097, data: 0.043) loss: 0.000 
(epoch: 889, iters: 656, time: 0.098, data: 0.026) loss: 0.000 
(epoch: 889, iters: 736, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 889, iters: 816, time: 0.096, data: 0.000) loss: 0.017 
(epoch: 889, iters: 896, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 889, iters: 976, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 889, iters: 1056, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 889, iters: 1136, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 889, iters: 1216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 889, iters: 1296, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 889, iters: 1376, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 889, iters: 1456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 889, iters: 1536, time: 0.097, data: 0.028) loss: 0.000 
(epoch: 889, iters: 1616, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 889, iters: 1696, time: 0.096, data: 0.017) loss: 0.000 
(epoch: 889, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 889, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 889, iters: 1936, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 889, iters: 2016, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 889, iters: 2096, time: 0.095, data: 0.033) loss: 0.000 
(epoch: 889, iters: 2176, time: 0.097, data: 0.044) loss: 0.000 
(epoch: 889, iters: 2256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 889, iters: 2336, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 889, iters: 2416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 889, iters: 2496, time: 0.092, data: 0.011) loss: 0.010 
(epoch: 889, iters: 2576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 889, iters: 2656, time: 0.096, data: 0.019) loss: 0.000 
(epoch: 889, iters: 2736, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 889, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 889, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 889, iters: 2976, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 889, iters: 3056, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 889, iters: 3136, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 889, iters: 3216, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 889, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 889, iters: 3376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 889, iters: 3456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 889, iters: 3536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 889, iters: 3616, time: 0.096, data: 0.031) loss: 0.000 
(epoch: 889, iters: 3696, time: 0.088, data: 0.032) loss: 0.000 
saving the model at the end of epoch 889, iters 3314192
End of epoch 889 / 2100 	 Time Taken: 365 sec
learning rate = 0.0001210
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 889, TEST ACC: [96.51 %]

saving the latest model (epoch 890, total_steps 3314208)
(epoch: 890, iters: 48, time: 0.093, data: 0.004) loss: 0.000 
(epoch: 890, iters: 128, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 890, iters: 208, time: 0.089, data: 0.011) loss: 0.000 
(epoch: 890, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 890, iters: 368, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 890, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 890, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 890, iters: 608, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 890, iters: 688, time: 0.096, data: 0.036) loss: 0.000 
(epoch: 890, iters: 768, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 890, iters: 848, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 890, iters: 928, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 890, iters: 1008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 890, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 890, iters: 1168, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 890, iters: 1248, time: 0.093, data: 0.032) loss: 0.000 
(epoch: 890, iters: 1328, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 890, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 890, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 890, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 890, iters: 1648, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 890, iters: 1728, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 890, iters: 1808, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 890, iters: 1888, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 890, iters: 1968, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 890, iters: 2048, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 890, iters: 2128, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 890, iters: 2208, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 890, iters: 2288, time: 0.092, data: 0.040) loss: 0.000 
(epoch: 890, iters: 2368, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 890, iters: 2448, time: 0.093, data: 0.017) loss: 0.000 
(epoch: 890, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 890, iters: 2608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 890, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 890, iters: 2768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 890, iters: 2848, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 890, iters: 2928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 890, iters: 3008, time: 0.090, data: 0.011) loss: 0.000 
(epoch: 890, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 890, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 890, iters: 3248, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 890, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 890, iters: 3408, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 890, iters: 3488, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 890, iters: 3568, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 890, iters: 3648, time: 0.087, data: 0.000) loss: 0.000 
(epoch: 890, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 890, iters 3317920
End of epoch 890 / 2100 	 Time Taken: 359 sec
learning rate = 0.0001209
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 890, TEST ACC: [96.358 %]

saving the latest model (epoch 891, total_steps 3317936)
(epoch: 891, iters: 80, time: 0.093, data: 2.858) loss: 0.000 
(epoch: 891, iters: 160, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 891, iters: 240, time: 0.097, data: 0.031) loss: 0.000 
(epoch: 891, iters: 320, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 891, iters: 400, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 891, iters: 480, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 891, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 891, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 891, iters: 720, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 891, iters: 800, time: 0.095, data: 0.031) loss: 0.000 
(epoch: 891, iters: 880, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 891, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 891, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 891, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 891, iters: 1200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 891, iters: 1280, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 891, iters: 1360, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 891, iters: 1440, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 891, iters: 1520, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 891, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 891, iters: 1680, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 891, iters: 1760, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 891, iters: 1840, time: 0.095, data: 0.037) loss: 0.000 
(epoch: 891, iters: 1920, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 891, iters: 2000, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 891, iters: 2080, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 891, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 891, iters: 2240, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 891, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 891, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 891, iters: 2480, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 891, iters: 2560, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 891, iters: 2640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 891, iters: 2720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 891, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 891, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 891, iters: 2960, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 891, iters: 3040, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 891, iters: 3120, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 891, iters: 3200, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 891, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 891, iters: 3360, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 891, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 891, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 891, iters: 3600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 891, iters: 3680, time: 0.088, data: 0.034) loss: 0.000 
saving the model at the end of epoch 891, iters 3321648
End of epoch 891 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001208
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 891, TEST ACC: [96.51 %]

saving the latest model (epoch 892, total_steps 3321664)
(epoch: 892, iters: 32, time: 0.102, data: 0.010) loss: 0.000 
(epoch: 892, iters: 112, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 892, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 892, iters: 272, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 892, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 892, iters: 432, time: 0.094, data: 0.033) loss: 0.000 
(epoch: 892, iters: 512, time: 0.095, data: 0.037) loss: 0.000 
(epoch: 892, iters: 592, time: 0.093, data: 0.018) loss: 0.002 
(epoch: 892, iters: 672, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 892, iters: 752, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 892, iters: 832, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 892, iters: 912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 892, iters: 992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 892, iters: 1072, time: 0.092, data: 0.039) loss: 0.000 
(epoch: 892, iters: 1152, time: 0.092, data: 0.026) loss: 0.002 
(epoch: 892, iters: 1232, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 892, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 892, iters: 1392, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 892, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 892, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 892, iters: 1632, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 892, iters: 1712, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 892, iters: 1792, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 892, iters: 1872, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 892, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 892, iters: 2032, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 892, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 892, iters: 2192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 892, iters: 2272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 892, iters: 2352, time: 0.096, data: 0.032) loss: 0.000 
(epoch: 892, iters: 2432, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 892, iters: 2512, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 892, iters: 2592, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 892, iters: 2672, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 892, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 892, iters: 2832, time: 0.094, data: 0.037) loss: 0.000 
(epoch: 892, iters: 2912, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 892, iters: 2992, time: 0.095, data: 0.032) loss: 0.000 
(epoch: 892, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 892, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 892, iters: 3232, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 892, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 892, iters: 3392, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 892, iters: 3472, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 892, iters: 3552, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 892, iters: 3632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 892, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 892, iters 3325376
End of epoch 892 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001207
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 892, TEST ACC: [97.42 %]

saving the latest model (epoch 893, total_steps 3325392)
(epoch: 893, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 893, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 893, iters: 224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 893, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 893, iters: 384, time: 0.092, data: 0.024) loss: 0.000 
(epoch: 893, iters: 464, time: 0.092, data: 0.029) loss: 0.000 
(epoch: 893, iters: 544, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 893, iters: 624, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 893, iters: 704, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 893, iters: 784, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 893, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 893, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 893, iters: 1024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 893, iters: 1104, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 893, iters: 1184, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 893, iters: 1264, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 893, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 893, iters: 1424, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 893, iters: 1504, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 893, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 893, iters: 1664, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 893, iters: 1744, time: 0.095, data: 0.031) loss: 0.000 
(epoch: 893, iters: 1824, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 893, iters: 1904, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 893, iters: 1984, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 893, iters: 2064, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 893, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 893, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 893, iters: 2304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 893, iters: 2384, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 893, iters: 2464, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 893, iters: 2544, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 893, iters: 2624, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 893, iters: 2704, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 893, iters: 2784, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 893, iters: 2864, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 893, iters: 2944, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 893, iters: 3024, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 893, iters: 3104, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 893, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 893, iters: 3264, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 893, iters: 3344, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 893, iters: 3424, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 893, iters: 3504, time: 0.097, data: 0.035) loss: 0.000 
(epoch: 893, iters: 3584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 893, iters: 3664, time: 0.086, data: 0.000) loss: 0.000 
saving the model at the end of epoch 893, iters 3329104
End of epoch 893 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001206
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 893, TEST ACC: [97.876 %]

(epoch: 894, iters: 16, time: 0.143, data: 0.000) loss: 0.000 
saving the latest model (epoch 894, total_steps 3329120)
(epoch: 894, iters: 96, time: 0.096, data: 0.012) loss: 0.008 
(epoch: 894, iters: 176, time: 0.089, data: 0.012) loss: 0.000 
(epoch: 894, iters: 256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 894, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 894, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 894, iters: 496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 894, iters: 576, time: 0.097, data: 0.045) loss: 0.000 
(epoch: 894, iters: 656, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 894, iters: 736, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 894, iters: 816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 894, iters: 896, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 894, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 894, iters: 1056, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 894, iters: 1136, time: 0.094, data: 0.035) loss: 0.000 
(epoch: 894, iters: 1216, time: 0.095, data: 0.044) loss: 0.000 
(epoch: 894, iters: 1296, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 894, iters: 1376, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 894, iters: 1456, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 894, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 894, iters: 1616, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 894, iters: 1696, time: 0.094, data: 0.037) loss: 0.000 
(epoch: 894, iters: 1776, time: 0.099, data: 0.026) loss: 0.000 
(epoch: 894, iters: 1856, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 894, iters: 1936, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 894, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 894, iters: 2096, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 894, iters: 2176, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 894, iters: 2256, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 894, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 894, iters: 2416, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 894, iters: 2496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 894, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 894, iters: 2656, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 894, iters: 2736, time: 0.096, data: 0.036) loss: 0.000 
(epoch: 894, iters: 2816, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 894, iters: 2896, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 894, iters: 2976, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 894, iters: 3056, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 894, iters: 3136, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 894, iters: 3216, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 894, iters: 3296, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 894, iters: 3376, time: 0.097, data: 0.036) loss: 0.000 
(epoch: 894, iters: 3456, time: 0.095, data: 0.021) loss: 0.000 
(epoch: 894, iters: 3536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 894, iters: 3616, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 894, iters: 3696, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 894, iters 3332832
End of epoch 894 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001205
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 894, TEST ACC: [97.572 %]

saving the latest model (epoch 895, total_steps 3332848)
(epoch: 895, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 895, iters: 128, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 895, iters: 208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 895, iters: 288, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 895, iters: 368, time: 0.099, data: 0.032) loss: 0.000 
(epoch: 895, iters: 448, time: 0.098, data: 0.026) loss: 0.000 
(epoch: 895, iters: 528, time: 0.096, data: 0.014) loss: 0.000 
(epoch: 895, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 895, iters: 688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 895, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 895, iters: 848, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 895, iters: 928, time: 0.093, data: 0.037) loss: 0.000 
(epoch: 895, iters: 1008, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 895, iters: 1088, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 895, iters: 1168, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 895, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 895, iters: 1328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 895, iters: 1408, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 895, iters: 1488, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 895, iters: 1568, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 895, iters: 1648, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 895, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 895, iters: 1808, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 895, iters: 1888, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 895, iters: 1968, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 895, iters: 2048, time: 0.096, data: 0.035) loss: 0.000 
(epoch: 895, iters: 2128, time: 0.094, data: 0.012) loss: 0.645 
(epoch: 895, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 895, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 895, iters: 2368, time: 0.093, data: 0.000) loss: 0.319 
(epoch: 895, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 895, iters: 2528, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 895, iters: 2608, time: 0.092, data: 0.032) loss: 0.000 
(epoch: 895, iters: 2688, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 895, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 895, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 895, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 895, iters: 3008, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 895, iters: 3088, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 895, iters: 3168, time: 0.097, data: 0.039) loss: 0.000 
(epoch: 895, iters: 3248, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 895, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 895, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 895, iters: 3488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 895, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 895, iters: 3648, time: 0.091, data: 0.031) loss: 0.000 
(epoch: 895, iters: 3728, time: 0.057, data: 0.022) loss: 0.509 
saving the model at the end of epoch 895, iters 3336560
End of epoch 895 / 2100 	 Time Taken: 363 sec
learning rate = 0.0001204
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 895, TEST ACC: [95.599 %]

saving the latest model (epoch 896, total_steps 3336576)
(epoch: 896, iters: 80, time: 0.095, data: 2.665) loss: 0.000 
(epoch: 896, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 896, iters: 240, time: 0.093, data: 0.025) loss: 0.010 
(epoch: 896, iters: 320, time: 0.094, data: 0.043) loss: 0.000 
(epoch: 896, iters: 400, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 896, iters: 480, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 896, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 896, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 896, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 896, iters: 800, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 896, iters: 880, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 896, iters: 960, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 896, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 896, iters: 1120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 896, iters: 1200, time: 0.098, data: 0.000) loss: 0.005 
(epoch: 896, iters: 1280, time: 0.097, data: 0.000) loss: 0.011 
(epoch: 896, iters: 1360, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 896, iters: 1440, time: 0.095, data: 0.021) loss: 0.001 
(epoch: 896, iters: 1520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 896, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 896, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 896, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 896, iters: 1840, time: 0.093, data: 0.043) loss: 0.000 
(epoch: 896, iters: 1920, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 896, iters: 2000, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 896, iters: 2080, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 896, iters: 2160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 896, iters: 2240, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 896, iters: 2320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 896, iters: 2400, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 896, iters: 2480, time: 0.096, data: 0.026) loss: 0.014 
(epoch: 896, iters: 2560, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 896, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 896, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 896, iters: 2800, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 896, iters: 2880, time: 0.095, data: 0.032) loss: 0.019 
(epoch: 896, iters: 2960, time: 0.093, data: 0.017) loss: 0.000 
(epoch: 896, iters: 3040, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 896, iters: 3120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 896, iters: 3200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 896, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 896, iters: 3360, time: 0.097, data: 0.030) loss: 0.000 
(epoch: 896, iters: 3440, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 896, iters: 3520, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 896, iters: 3600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 896, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 896, iters 3340288
End of epoch 896 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001203
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 896, TEST ACC: [96.662 %]

saving the latest model (epoch 897, total_steps 3340304)
(epoch: 897, iters: 32, time: 0.106, data: 0.000) loss: 0.050 
(epoch: 897, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 897, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 897, iters: 272, time: 0.097, data: 0.025) loss: 0.000 
(epoch: 897, iters: 352, time: 0.092, data: 0.035) loss: 0.000 
(epoch: 897, iters: 432, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 897, iters: 512, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 897, iters: 592, time: 0.093, data: 0.017) loss: 0.001 
(epoch: 897, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 897, iters: 752, time: 0.098, data: 0.029) loss: 0.000 
(epoch: 897, iters: 832, time: 0.098, data: 0.026) loss: 0.000 
(epoch: 897, iters: 912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 897, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 897, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 897, iters: 1152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 897, iters: 1232, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 897, iters: 1312, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 897, iters: 1392, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 897, iters: 1472, time: 0.095, data: 0.012) loss: 0.004 
(epoch: 897, iters: 1552, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 897, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 897, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 897, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 897, iters: 1872, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 897, iters: 1952, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 897, iters: 2032, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 897, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 897, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 897, iters: 2272, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 897, iters: 2352, time: 0.097, data: 0.031) loss: 0.000 
(epoch: 897, iters: 2432, time: 0.092, data: 0.017) loss: 0.000 
(epoch: 897, iters: 2512, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 897, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 897, iters: 2672, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 897, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 897, iters: 2832, time: 0.092, data: 0.031) loss: 0.000 
(epoch: 897, iters: 2912, time: 0.094, data: 0.026) loss: 0.002 
(epoch: 897, iters: 2992, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 897, iters: 3072, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 897, iters: 3152, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 897, iters: 3232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 897, iters: 3312, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 897, iters: 3392, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 897, iters: 3472, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 897, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 897, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 897, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 897, iters 3344016
End of epoch 897 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001202
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 897, TEST ACC: [96.055 %]

saving the latest model (epoch 898, total_steps 3344032)
(epoch: 898, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 898, iters: 144, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 898, iters: 224, time: 0.092, data: 0.000) loss: 0.205 
(epoch: 898, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 898, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 898, iters: 464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 898, iters: 544, time: 0.096, data: 0.030) loss: 0.000 
(epoch: 898, iters: 624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 898, iters: 704, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 898, iters: 784, time: 0.093, data: 0.018) loss: 0.000 
(epoch: 898, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 898, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 898, iters: 1024, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 898, iters: 1104, time: 0.092, data: 0.037) loss: 0.000 
(epoch: 898, iters: 1184, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 898, iters: 1264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 898, iters: 1344, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 898, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 898, iters: 1504, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 898, iters: 1584, time: 0.096, data: 0.053) loss: 0.000 
(epoch: 898, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 898, iters: 1744, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 898, iters: 1824, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 898, iters: 1904, time: 0.096, data: 0.000) loss: 0.004 
(epoch: 898, iters: 1984, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 898, iters: 2064, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 898, iters: 2144, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 898, iters: 2224, time: 0.095, data: 0.053) loss: 0.000 
(epoch: 898, iters: 2304, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 898, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 898, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 898, iters: 2544, time: 0.098, data: 0.000) loss: 0.003 
(epoch: 898, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 898, iters: 2704, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 898, iters: 2784, time: 0.097, data: 0.032) loss: 0.000 
(epoch: 898, iters: 2864, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 898, iters: 2944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 898, iters: 3024, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 898, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 898, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 898, iters: 3264, time: 0.092, data: 0.015) loss: 0.000 
(epoch: 898, iters: 3344, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 898, iters: 3424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 898, iters: 3504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 898, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 898, iters: 3664, time: 0.088, data: 0.036) loss: 0.000 
saving the model at the end of epoch 898, iters 3347744
End of epoch 898 / 2100 	 Time Taken: 362 sec
learning rate = 0.0001201
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 898, TEST ACC: [97.724 %]

(epoch: 899, iters: 16, time: 0.139, data: 0.016) loss: 0.000 
saving the latest model (epoch 899, total_steps 3347760)
(epoch: 899, iters: 96, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 899, iters: 176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 899, iters: 256, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 899, iters: 336, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 899, iters: 416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 899, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 899, iters: 576, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 899, iters: 656, time: 0.097, data: 0.037) loss: 0.000 
(epoch: 899, iters: 736, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 899, iters: 816, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 899, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 899, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 899, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 899, iters: 1136, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 899, iters: 1216, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 899, iters: 1296, time: 0.096, data: 0.047) loss: 0.000 
(epoch: 899, iters: 1376, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 899, iters: 1456, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 899, iters: 1536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 899, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 899, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 899, iters: 1776, time: 0.096, data: 0.025) loss: 0.150 
(epoch: 899, iters: 1856, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 899, iters: 1936, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 899, iters: 2016, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 899, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 899, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 899, iters: 2256, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 899, iters: 2336, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 899, iters: 2416, time: 0.095, data: 0.011) loss: 0.002 
(epoch: 899, iters: 2496, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 899, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 899, iters: 2656, time: 0.097, data: 0.030) loss: 0.000 
(epoch: 899, iters: 2736, time: 0.097, data: 0.027) loss: 0.000 
(epoch: 899, iters: 2816, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 899, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 899, iters: 2976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 899, iters: 3056, time: 0.096, data: 0.000) loss: 0.563 
(epoch: 899, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 899, iters: 3216, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 899, iters: 3296, time: 0.098, data: 0.040) loss: 0.000 
(epoch: 899, iters: 3376, time: 0.100, data: 0.026) loss: 0.000 
(epoch: 899, iters: 3456, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 899, iters: 3536, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 899, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 899, iters: 3696, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 899, iters 3351472
End of epoch 899 / 2100 	 Time Taken: 362 sec
learning rate = 0.0001200
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 899, TEST ACC: [97.572 %]

saving the latest model (epoch 900, total_steps 3351488)
(epoch: 900, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 900, iters: 128, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 900, iters: 208, time: 0.097, data: 0.032) loss: 0.000 
(epoch: 900, iters: 288, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 900, iters: 368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 900, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 900, iters: 528, time: 0.098, data: 0.000) loss: 0.008 
(epoch: 900, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 900, iters: 688, time: 0.094, data: 0.022) loss: 0.000 
(epoch: 900, iters: 768, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 900, iters: 848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 900, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 900, iters: 1008, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 900, iters: 1088, time: 0.096, data: 0.032) loss: 0.000 
(epoch: 900, iters: 1168, time: 0.097, data: 0.038) loss: 0.000 
(epoch: 900, iters: 1248, time: 0.095, data: 0.013) loss: 0.001 
(epoch: 900, iters: 1328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 900, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 900, iters: 1488, time: 0.097, data: 0.039) loss: 0.000 
(epoch: 900, iters: 1568, time: 0.094, data: 0.031) loss: 0.000 
(epoch: 900, iters: 1648, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 900, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 900, iters: 1808, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 900, iters: 1888, time: 0.096, data: 0.000) loss: 0.032 
(epoch: 900, iters: 1968, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 900, iters: 2048, time: 0.095, data: 0.055) loss: 0.000 
(epoch: 900, iters: 2128, time: 0.098, data: 0.032) loss: 0.000 
(epoch: 900, iters: 2208, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 900, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 900, iters: 2368, time: 0.093, data: 0.000) loss: 0.032 
(epoch: 900, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 900, iters: 2528, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 900, iters: 2608, time: 0.097, data: 0.027) loss: 0.000 
(epoch: 900, iters: 2688, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 900, iters: 2768, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 900, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 900, iters: 2928, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 900, iters: 3008, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 900, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 900, iters: 3168, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 900, iters: 3248, time: 0.094, data: 0.032) loss: 0.000 
(epoch: 900, iters: 3328, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 900, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 900, iters: 3488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 900, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 900, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 900, iters: 3728, time: 0.058, data: 0.030) loss: 0.000 
saving the model at the end of epoch 900, iters 3355200
End of epoch 900 / 2100 	 Time Taken: 365 sec
learning rate = 0.0001199
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 900, TEST ACC: [96.813 %]

saving the latest model (epoch 901, total_steps 3355216)
(epoch: 901, iters: 80, time: 0.097, data: 2.802) loss: 0.000 
(epoch: 901, iters: 160, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 901, iters: 240, time: 0.092, data: 0.038) loss: 0.000 
(epoch: 901, iters: 320, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 901, iters: 400, time: 0.090, data: 0.012) loss: 0.000 
(epoch: 901, iters: 480, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 901, iters: 560, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 901, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 901, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 901, iters: 800, time: 0.090, data: 0.013) loss: 0.000 
(epoch: 901, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 901, iters: 960, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 901, iters: 1040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 901, iters: 1120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 901, iters: 1200, time: 0.095, data: 0.037) loss: 0.000 
(epoch: 901, iters: 1280, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 901, iters: 1360, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 901, iters: 1440, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 901, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 901, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 901, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 901, iters: 1760, time: 0.093, data: 0.029) loss: 0.000 
(epoch: 901, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 901, iters: 1920, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 901, iters: 2000, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 901, iters: 2080, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 901, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 901, iters: 2240, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 901, iters: 2320, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 901, iters: 2400, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 901, iters: 2480, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 901, iters: 2560, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 901, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 901, iters: 2720, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 901, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 901, iters: 2880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 901, iters: 2960, time: 0.095, data: 0.054) loss: 0.000 
(epoch: 901, iters: 3040, time: 0.093, data: 0.037) loss: 0.000 
(epoch: 901, iters: 3120, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 901, iters: 3200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 901, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 901, iters: 3360, time: 0.093, data: 0.054) loss: 0.000 
(epoch: 901, iters: 3440, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 901, iters: 3520, time: 0.090, data: 0.011) loss: 0.000 
(epoch: 901, iters: 3600, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 901, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 901, iters 3358928
End of epoch 901 / 2100 	 Time Taken: 359 sec
learning rate = 0.0001198
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 901, TEST ACC: [97.269 %]

saving the latest model (epoch 902, total_steps 3358944)
(epoch: 902, iters: 32, time: 0.106, data: 0.000) loss: 0.000 
(epoch: 902, iters: 112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 902, iters: 192, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 902, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 902, iters: 352, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 902, iters: 432, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 902, iters: 512, time: 0.095, data: 0.034) loss: 0.000 
(epoch: 902, iters: 592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 902, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 902, iters: 752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 902, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 902, iters: 912, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 902, iters: 992, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 902, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 902, iters: 1152, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 902, iters: 1232, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 902, iters: 1312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 902, iters: 1392, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 902, iters: 1472, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 902, iters: 1552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 902, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 902, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 902, iters: 1792, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 902, iters: 1872, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 902, iters: 1952, time: 0.097, data: 0.031) loss: 0.000 
(epoch: 902, iters: 2032, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 902, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 902, iters: 2192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 902, iters: 2272, time: 0.097, data: 0.035) loss: 0.000 
(epoch: 902, iters: 2352, time: 0.094, data: 0.026) loss: 0.001 
(epoch: 902, iters: 2432, time: 0.090, data: 0.012) loss: 0.000 
(epoch: 902, iters: 2512, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 902, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 902, iters: 2672, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 902, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 902, iters: 2832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 902, iters: 2912, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 902, iters: 2992, time: 0.093, data: 0.031) loss: 0.000 
(epoch: 902, iters: 3072, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 902, iters: 3152, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 902, iters: 3232, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 902, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 902, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 902, iters: 3472, time: 0.092, data: 0.045) loss: 0.000 
(epoch: 902, iters: 3552, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 902, iters: 3632, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 902, iters: 3712, time: 0.086, data: 0.000) loss: 0.000 
saving the model at the end of epoch 902, iters 3362656
End of epoch 902 / 2100 	 Time Taken: 359 sec
learning rate = 0.0001197
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 902, TEST ACC: [96.206 %]

saving the latest model (epoch 903, total_steps 3362672)
(epoch: 903, iters: 64, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 903, iters: 144, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 903, iters: 224, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 903, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 903, iters: 384, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 903, iters: 464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 903, iters: 544, time: 0.093, data: 0.034) loss: 0.000 
(epoch: 903, iters: 624, time: 0.094, data: 0.033) loss: 0.000 
(epoch: 903, iters: 704, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 903, iters: 784, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 903, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 903, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 903, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 903, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 903, iters: 1184, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 903, iters: 1264, time: 0.092, data: 0.041) loss: 0.000 
(epoch: 903, iters: 1344, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 903, iters: 1424, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 903, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 903, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 903, iters: 1664, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 903, iters: 1744, time: 0.092, data: 0.031) loss: 0.000 
(epoch: 903, iters: 1824, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 903, iters: 1904, time: 0.090, data: 0.012) loss: 0.000 
(epoch: 903, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 903, iters: 2064, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 903, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 903, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 903, iters: 2304, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 903, iters: 2384, time: 0.093, data: 0.029) loss: 0.000 
(epoch: 903, iters: 2464, time: 0.099, data: 0.027) loss: 0.000 
(epoch: 903, iters: 2544, time: 0.096, data: 0.015) loss: 0.000 
(epoch: 903, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 903, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 903, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 903, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 903, iters: 2944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 903, iters: 3024, time: 0.093, data: 0.035) loss: 0.000 
(epoch: 903, iters: 3104, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 903, iters: 3184, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 903, iters: 3264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 903, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 903, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 903, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 903, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 903, iters: 3664, time: 0.088, data: 0.026) loss: 0.000 
saving the model at the end of epoch 903, iters 3366384
End of epoch 903 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001196
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 903, TEST ACC: [96.965 %]

(epoch: 904, iters: 16, time: 0.147, data: 0.016) loss: 0.000 
saving the latest model (epoch 904, total_steps 3366400)
(epoch: 904, iters: 96, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 904, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 904, iters: 256, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 904, iters: 336, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 904, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 904, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 904, iters: 576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 904, iters: 656, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 904, iters: 736, time: 0.099, data: 0.015) loss: 0.000 
(epoch: 904, iters: 816, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 904, iters: 896, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 904, iters: 976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 904, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 904, iters: 1136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 904, iters: 1216, time: 0.093, data: 0.029) loss: 0.000 
(epoch: 904, iters: 1296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 904, iters: 1376, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 904, iters: 1456, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 904, iters: 1536, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 904, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 904, iters: 1696, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 904, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 904, iters: 1856, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 904, iters: 1936, time: 0.091, data: 0.025) loss: 0.000 
(epoch: 904, iters: 2016, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 904, iters: 2096, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 904, iters: 2176, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 904, iters: 2256, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 904, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 904, iters: 2416, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 904, iters: 2496, time: 0.095, data: 0.037) loss: 0.000 
(epoch: 904, iters: 2576, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 904, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 904, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 904, iters: 2816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 904, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 904, iters: 2976, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 904, iters: 3056, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 904, iters: 3136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 904, iters: 3216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 904, iters: 3296, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 904, iters: 3376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 904, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 904, iters: 3536, time: 0.095, data: 0.035) loss: 0.000 
(epoch: 904, iters: 3616, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 904, iters: 3696, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 904, iters 3370112
End of epoch 904 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001195
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 904, TEST ACC: [96.51 %]

saving the latest model (epoch 905, total_steps 3370128)
(epoch: 905, iters: 48, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 905, iters: 128, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 905, iters: 208, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 905, iters: 288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 905, iters: 368, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 905, iters: 448, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 905, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 905, iters: 608, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 905, iters: 688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 905, iters: 768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 905, iters: 848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 905, iters: 928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 905, iters: 1008, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 905, iters: 1088, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 905, iters: 1168, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 905, iters: 1248, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 905, iters: 1328, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 905, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 905, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 905, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 905, iters: 1648, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 905, iters: 1728, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 905, iters: 1808, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 905, iters: 1888, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 905, iters: 1968, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 905, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 905, iters: 2128, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 905, iters: 2208, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 905, iters: 2288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 905, iters: 2368, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 905, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 905, iters: 2528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 905, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 905, iters: 2688, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 905, iters: 2768, time: 0.092, data: 0.046) loss: 0.000 
(epoch: 905, iters: 2848, time: 0.096, data: 0.035) loss: 0.000 
(epoch: 905, iters: 2928, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 905, iters: 3008, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 905, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 905, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 905, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 905, iters: 3328, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 905, iters: 3408, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 905, iters: 3488, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 905, iters: 3568, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 905, iters: 3648, time: 0.087, data: 0.000) loss: 0.000 
(epoch: 905, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 905, iters 3373840
End of epoch 905 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001194
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 905, TEST ACC: [96.51 %]

saving the latest model (epoch 906, total_steps 3373856)
(epoch: 906, iters: 80, time: 0.097, data: 3.135) loss: 0.000 
(epoch: 906, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 906, iters: 240, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 906, iters: 320, time: 0.094, data: 0.032) loss: 0.000 
(epoch: 906, iters: 400, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 906, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 906, iters: 560, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 906, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 906, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 906, iters: 800, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 906, iters: 880, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 906, iters: 960, time: 0.094, data: 0.018) loss: 0.000 
(epoch: 906, iters: 1040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 906, iters: 1120, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 906, iters: 1200, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 906, iters: 1280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 906, iters: 1360, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 906, iters: 1440, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 906, iters: 1520, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 906, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 906, iters: 1680, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 906, iters: 1760, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 906, iters: 1840, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 906, iters: 1920, time: 0.095, data: 0.036) loss: 0.000 
(epoch: 906, iters: 2000, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 906, iters: 2080, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 906, iters: 2160, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 906, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 906, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 906, iters: 2400, time: 0.096, data: 0.045) loss: 0.000 
(epoch: 906, iters: 2480, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 906, iters: 2560, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 906, iters: 2640, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 906, iters: 2720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 906, iters: 2800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 906, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 906, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 906, iters: 3040, time: 0.096, data: 0.037) loss: 0.020 
(epoch: 906, iters: 3120, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 906, iters: 3200, time: 0.089, data: 0.011) loss: 0.000 
(epoch: 906, iters: 3280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 906, iters: 3360, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 906, iters: 3440, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 906, iters: 3520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 906, iters: 3600, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 906, iters: 3680, time: 0.090, data: 0.026) loss: 0.000 
saving the model at the end of epoch 906, iters 3377568
End of epoch 906 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001193
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 906, TEST ACC: [97.269 %]

saving the latest model (epoch 907, total_steps 3377584)
(epoch: 907, iters: 32, time: 0.114, data: 0.004) loss: 0.000 
(epoch: 907, iters: 112, time: 0.093, data: 0.000) loss: 0.186 
(epoch: 907, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 907, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 907, iters: 352, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 907, iters: 432, time: 0.095, data: 0.035) loss: 0.000 
(epoch: 907, iters: 512, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 907, iters: 592, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 907, iters: 672, time: 0.094, data: 0.000) loss: 0.028 
(epoch: 907, iters: 752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 907, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 907, iters: 912, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 907, iters: 992, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 907, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 907, iters: 1152, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 907, iters: 1232, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 907, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 907, iters: 1392, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 907, iters: 1472, time: 0.093, data: 0.027) loss: 0.002 
(epoch: 907, iters: 1552, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 907, iters: 1632, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 907, iters: 1712, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 907, iters: 1792, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 907, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 907, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 907, iters: 2032, time: 0.096, data: 0.031) loss: 0.000 
(epoch: 907, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 907, iters: 2192, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 907, iters: 2272, time: 0.094, data: 0.038) loss: 0.002 
(epoch: 907, iters: 2352, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 907, iters: 2432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 907, iters: 2512, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 907, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 907, iters: 2672, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 907, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 907, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 907, iters: 2912, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 907, iters: 2992, time: 0.093, data: 0.034) loss: 0.000 
(epoch: 907, iters: 3072, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 907, iters: 3152, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 907, iters: 3232, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 907, iters: 3312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 907, iters: 3392, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 907, iters: 3472, time: 0.096, data: 0.045) loss: 0.000 
(epoch: 907, iters: 3552, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 907, iters: 3632, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 907, iters: 3712, time: 0.086, data: 0.000) loss: 0.000 
saving the model at the end of epoch 907, iters 3381296
End of epoch 907 / 2100 	 Time Taken: 359 sec
learning rate = 0.0001192
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 907, TEST ACC: [96.055 %]

saving the latest model (epoch 908, total_steps 3381312)
(epoch: 908, iters: 64, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 908, iters: 144, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 908, iters: 224, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 908, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 908, iters: 384, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 908, iters: 464, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 908, iters: 544, time: 0.095, data: 0.029) loss: 0.004 
(epoch: 908, iters: 624, time: 0.093, data: 0.038) loss: 0.001 
(epoch: 908, iters: 704, time: 0.097, data: 0.014) loss: 0.000 
(epoch: 908, iters: 784, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 908, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 908, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 908, iters: 1024, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 908, iters: 1104, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 908, iters: 1184, time: 0.091, data: 0.036) loss: 0.000 
(epoch: 908, iters: 1264, time: 0.092, data: 0.038) loss: 0.000 
(epoch: 908, iters: 1344, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 908, iters: 1424, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 908, iters: 1504, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 908, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 908, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 908, iters: 1744, time: 0.097, data: 0.043) loss: 0.000 
(epoch: 908, iters: 1824, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 908, iters: 1904, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 908, iters: 1984, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 908, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 908, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 908, iters: 2224, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 908, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 908, iters: 2384, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 908, iters: 2464, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 908, iters: 2544, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 908, iters: 2624, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 908, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 908, iters: 2784, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 908, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 908, iters: 2944, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 908, iters: 3024, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 908, iters: 3104, time: 0.089, data: 0.012) loss: 0.000 
(epoch: 908, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 908, iters: 3264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 908, iters: 3344, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 908, iters: 3424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 908, iters: 3504, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 908, iters: 3584, time: 0.096, data: 0.035) loss: 0.000 
(epoch: 908, iters: 3664, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 908, iters 3385024
End of epoch 908 / 2100 	 Time Taken: 359 sec
learning rate = 0.0001191
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 908, TEST ACC: [93.93 %]

(epoch: 909, iters: 16, time: 0.135, data: 0.000) loss: 0.000 
saving the latest model (epoch 909, total_steps 3385040)
(epoch: 909, iters: 96, time: 0.094, data: 0.013) loss: 0.001 
(epoch: 909, iters: 176, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 909, iters: 256, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 909, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 909, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 909, iters: 496, time: 0.095, data: 0.000) loss: 0.006 
(epoch: 909, iters: 576, time: 0.097, data: 0.038) loss: 0.008 
(epoch: 909, iters: 656, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 909, iters: 736, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 909, iters: 816, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 909, iters: 896, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 909, iters: 976, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 909, iters: 1056, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 909, iters: 1136, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 909, iters: 1216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 909, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 909, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 909, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 909, iters: 1536, time: 0.094, data: 0.034) loss: 0.000 
(epoch: 909, iters: 1616, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 909, iters: 1696, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 909, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 909, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 909, iters: 1936, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 909, iters: 2016, time: 0.094, data: 0.037) loss: 0.000 
(epoch: 909, iters: 2096, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 909, iters: 2176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 909, iters: 2256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 909, iters: 2336, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 909, iters: 2416, time: 0.095, data: 0.026) loss: 0.001 
(epoch: 909, iters: 2496, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 909, iters: 2576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 909, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 909, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 909, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 909, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 909, iters: 2976, time: 0.094, data: 0.033) loss: 0.000 
(epoch: 909, iters: 3056, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 909, iters: 3136, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 909, iters: 3216, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 909, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 909, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 909, iters: 3456, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 909, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 909, iters: 3616, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 909, iters: 3696, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 909, iters 3388752
End of epoch 909 / 2100 	 Time Taken: 362 sec
learning rate = 0.0001190
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 909, TEST ACC: [93.93 %]

saving the latest model (epoch 910, total_steps 3388768)
(epoch: 910, iters: 48, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 910, iters: 128, time: 0.095, data: 0.045) loss: 0.000 
(epoch: 910, iters: 208, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 910, iters: 288, time: 0.089, data: 0.012) loss: 0.000 
(epoch: 910, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 910, iters: 448, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 910, iters: 528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 910, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 910, iters: 688, time: 0.094, data: 0.038) loss: 0.017 
(epoch: 910, iters: 768, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 910, iters: 848, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 910, iters: 928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 910, iters: 1008, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 910, iters: 1088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 910, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 910, iters: 1248, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 910, iters: 1328, time: 0.096, data: 0.032) loss: 0.000 
(epoch: 910, iters: 1408, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 910, iters: 1488, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 910, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 910, iters: 1648, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 910, iters: 1728, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 910, iters: 1808, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 910, iters: 1888, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 910, iters: 1968, time: 0.092, data: 0.012) loss: 0.004 
(epoch: 910, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 910, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 910, iters: 2208, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 910, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 910, iters: 2368, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 910, iters: 2448, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 910, iters: 2528, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 910, iters: 2608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 910, iters: 2688, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 910, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 910, iters: 2848, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 910, iters: 2928, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 910, iters: 3008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 910, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 910, iters: 3168, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 910, iters: 3248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 910, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 910, iters: 3408, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 910, iters: 3488, time: 0.094, data: 0.044) loss: 0.000 
(epoch: 910, iters: 3568, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 910, iters: 3648, time: 0.086, data: 0.000) loss: 0.000 
(epoch: 910, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 910, iters 3392480
End of epoch 910 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001189
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 910, TEST ACC: [97.269 %]

saving the latest model (epoch 911, total_steps 3392496)
(epoch: 911, iters: 80, time: 0.094, data: 2.556) loss: 0.000 
(epoch: 911, iters: 160, time: 0.094, data: 0.038) loss: 0.346 
(epoch: 911, iters: 240, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 911, iters: 320, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 911, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 911, iters: 480, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 911, iters: 560, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 911, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 911, iters: 720, time: 0.094, data: 0.030) loss: 0.005 
(epoch: 911, iters: 800, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 911, iters: 880, time: 0.089, data: 0.011) loss: 0.000 
(epoch: 911, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 911, iters: 1040, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 911, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 911, iters: 1200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 911, iters: 1280, time: 0.094, data: 0.036) loss: 0.000 
(epoch: 911, iters: 1360, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 911, iters: 1440, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 911, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 911, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 911, iters: 1680, time: 0.096, data: 0.033) loss: 0.000 
(epoch: 911, iters: 1760, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 911, iters: 1840, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 911, iters: 1920, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 911, iters: 2000, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 911, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 911, iters: 2160, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 911, iters: 2240, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 911, iters: 2320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 911, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 911, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 911, iters: 2560, time: 0.093, data: 0.043) loss: 0.000 
(epoch: 911, iters: 2640, time: 0.093, data: 0.031) loss: 0.000 
(epoch: 911, iters: 2720, time: 0.093, data: 0.023) loss: 0.000 
(epoch: 911, iters: 2800, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 911, iters: 2880, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 911, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 911, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 911, iters: 3120, time: 0.094, data: 0.046) loss: 0.000 
(epoch: 911, iters: 3200, time: 0.095, data: 0.034) loss: 0.000 
(epoch: 911, iters: 3280, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 911, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 911, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 911, iters: 3520, time: 0.096, data: 0.025) loss: 0.000 
(epoch: 911, iters: 3600, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 911, iters: 3680, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 911, iters 3396208
End of epoch 911 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001188
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 911, TEST ACC: [96.813 %]

saving the latest model (epoch 912, total_steps 3396224)
(epoch: 912, iters: 32, time: 0.106, data: 0.000) loss: 0.001 
(epoch: 912, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 912, iters: 192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 912, iters: 272, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 912, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 912, iters: 432, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 912, iters: 512, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 912, iters: 592, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 912, iters: 672, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 912, iters: 752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 912, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 912, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 912, iters: 992, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 912, iters: 1072, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 912, iters: 1152, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 912, iters: 1232, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 912, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 912, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 912, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 912, iters: 1552, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 912, iters: 1632, time: 0.098, data: 0.037) loss: 0.000 
(epoch: 912, iters: 1712, time: 0.090, data: 0.019) loss: 0.000 
(epoch: 912, iters: 1792, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 912, iters: 1872, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 912, iters: 1952, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 912, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 912, iters: 2112, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 912, iters: 2192, time: 0.093, data: 0.032) loss: 0.000 
(epoch: 912, iters: 2272, time: 0.090, data: 0.021) loss: 0.000 
(epoch: 912, iters: 2352, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 912, iters: 2432, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 912, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 912, iters: 2592, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 912, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 912, iters: 2752, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 912, iters: 2832, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 912, iters: 2912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 912, iters: 2992, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 912, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 912, iters: 3152, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 912, iters: 3232, time: 0.092, data: 0.028) loss: 0.000 
(epoch: 912, iters: 3312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 912, iters: 3392, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 912, iters: 3472, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 912, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 912, iters: 3632, time: 0.091, data: 0.000) loss: 0.075 
(epoch: 912, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 912, iters 3399936
End of epoch 912 / 2100 	 Time Taken: 361 sec
learning rate = 0.0001187
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 912, TEST ACC: [96.662 %]

saving the latest model (epoch 913, total_steps 3399952)
(epoch: 913, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 913, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 913, iters: 224, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 913, iters: 304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 913, iters: 384, time: 0.094, data: 0.043) loss: 0.000 
(epoch: 913, iters: 464, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 913, iters: 544, time: 0.091, data: 0.017) loss: 0.000 
(epoch: 913, iters: 624, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 913, iters: 704, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 913, iters: 784, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 913, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 913, iters: 944, time: 0.093, data: 0.035) loss: 0.000 
(epoch: 913, iters: 1024, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 913, iters: 1104, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 913, iters: 1184, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 913, iters: 1264, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 913, iters: 1344, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 913, iters: 1424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 913, iters: 1504, time: 0.094, data: 0.036) loss: 0.000 
(epoch: 913, iters: 1584, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 913, iters: 1664, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 913, iters: 1744, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 913, iters: 1824, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 913, iters: 1904, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 913, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 913, iters: 2064, time: 0.097, data: 0.050) loss: 0.000 
(epoch: 913, iters: 2144, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 913, iters: 2224, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 913, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 913, iters: 2384, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 913, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 913, iters: 2544, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 913, iters: 2624, time: 0.096, data: 0.032) loss: 0.000 
(epoch: 913, iters: 2704, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 913, iters: 2784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 913, iters: 2864, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 913, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 913, iters: 3024, time: 0.092, data: 0.000) loss: 0.008 
(epoch: 913, iters: 3104, time: 0.091, data: 0.000) loss: 0.247 
(epoch: 913, iters: 3184, time: 0.092, data: 0.029) loss: 0.000 
(epoch: 913, iters: 3264, time: 0.096, data: 0.036) loss: 0.000 
(epoch: 913, iters: 3344, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 913, iters: 3424, time: 0.092, data: 0.000) loss: 0.026 
(epoch: 913, iters: 3504, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 913, iters: 3584, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 913, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 913, iters 3403664
End of epoch 913 / 2100 	 Time Taken: 360 sec
learning rate = 0.0001186
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 913, TEST ACC: [96.965 %]

(epoch: 914, iters: 16, time: 0.141, data: 0.012) loss: 0.000 
saving the latest model (epoch 914, total_steps 3403680)
(epoch: 914, iters: 96, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 914, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 914, iters: 256, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 914, iters: 336, time: 0.094, data: 0.037) loss: 0.001 
(epoch: 914, iters: 416, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 914, iters: 496, time: 0.091, data: 0.018) loss: 0.000 
(epoch: 914, iters: 576, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 914, iters: 656, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 914, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 914, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 914, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 914, iters: 976, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 914, iters: 1056, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 914, iters: 1136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 914, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 914, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 914, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 914, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 914, iters: 1536, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 914, iters: 1616, time: 0.095, data: 0.033) loss: 0.000 
(epoch: 914, iters: 1696, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 914, iters: 1776, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 914, iters: 1856, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 914, iters: 1936, time: 0.093, data: 0.000) loss: 0.009 
(epoch: 914, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 914, iters: 2096, time: 0.097, data: 0.025) loss: 0.000 
(epoch: 914, iters: 2176, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 914, iters: 2256, time: 0.095, data: 0.020) loss: 0.000 
(epoch: 914, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 914, iters: 2416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 914, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 914, iters: 2576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 914, iters: 2656, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 914, iters: 2736, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 914, iters: 2816, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 914, iters: 2896, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 914, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 914, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 914, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 914, iters: 3216, time: 0.095, data: 0.030) loss: 0.000 
(epoch: 914, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 914, iters: 3376, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 914, iters: 3456, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 914, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 914, iters: 3616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 914, iters: 3696, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 914, iters 3407392
End of epoch 914 / 2100 	 Time Taken: 358 sec
learning rate = 0.0001185
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 914, TEST ACC: [97.269 %]

saving the latest model (epoch 915, total_steps 3407408)
(epoch: 915, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 915, iters: 128, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 915, iters: 208, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 915, iters: 288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 915, iters: 368, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 915, iters: 448, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 915, iters: 528, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 915, iters: 608, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 915, iters: 688, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 915, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 915, iters: 848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 915, iters: 928, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 915, iters: 1008, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 915, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 915, iters: 1168, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 915, iters: 1248, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 915, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 915, iters: 1408, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 915, iters: 1488, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 915, iters: 1568, time: 0.093, data: 0.030) loss: 0.000 
(epoch: 915, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 915, iters: 1728, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 915, iters: 1808, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 915, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 915, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 915, iters: 2048, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 915, iters: 2128, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 915, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 915, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 915, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 915, iters: 2448, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 915, iters: 2528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 915, iters: 2608, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 915, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 915, iters: 2768, time: 0.093, data: 0.011) loss: 0.268 
(epoch: 915, iters: 2848, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 915, iters: 2928, time: 0.096, data: 0.000) loss: 0.014 
(epoch: 915, iters: 3008, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 915, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 915, iters: 3168, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 915, iters: 3248, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 915, iters: 3328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 915, iters: 3408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 915, iters: 3488, time: 0.095, data: 0.030) loss: 0.043 
(epoch: 915, iters: 3568, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 915, iters: 3648, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 915, iters: 3728, time: 0.056, data: 0.022) loss: 0.000 
saving the model at the end of epoch 915, iters 3411120
End of epoch 915 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001184
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 915, TEST ACC: [97.572 %]

saving the latest model (epoch 916, total_steps 3411136)
(epoch: 916, iters: 80, time: 0.093, data: 1.788) loss: 0.000 
(epoch: 916, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 916, iters: 240, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 916, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 916, iters: 400, time: 0.090, data: 0.012) loss: 0.000 
(epoch: 916, iters: 480, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 916, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 916, iters: 640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 916, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 916, iters: 800, time: 0.094, data: 0.035) loss: 0.000 
(epoch: 916, iters: 880, time: 0.091, data: 0.033) loss: 0.000 
(epoch: 916, iters: 960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 916, iters: 1040, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 916, iters: 1120, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 916, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 916, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 916, iters: 1360, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 916, iters: 1440, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 916, iters: 1520, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 916, iters: 1600, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 916, iters: 1680, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 916, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 916, iters: 1840, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 916, iters: 1920, time: 0.095, data: 0.045) loss: 0.000 
(epoch: 916, iters: 2000, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 916, iters: 2080, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 916, iters: 2160, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 916, iters: 2240, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 916, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 916, iters: 2400, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 916, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 916, iters: 2560, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 916, iters: 2640, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 916, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 916, iters: 2800, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 916, iters: 2880, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 916, iters: 2960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 916, iters: 3040, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 916, iters: 3120, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 916, iters: 3200, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 916, iters: 3280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 916, iters: 3360, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 916, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 916, iters: 3520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 916, iters: 3600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 916, iters: 3680, time: 0.088, data: 0.000) loss: 0.001 
saving the model at the end of epoch 916, iters 3414848
End of epoch 916 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001183
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 916, TEST ACC: [96.51 %]

saving the latest model (epoch 917, total_steps 3414864)
(epoch: 917, iters: 32, time: 0.092, data: 0.007) loss: 0.000 
(epoch: 917, iters: 112, time: 0.093, data: 0.043) loss: 0.000 
(epoch: 917, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 917, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 917, iters: 352, time: 0.096, data: 0.052) loss: 0.000 
(epoch: 917, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 917, iters: 512, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 917, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 917, iters: 672, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 917, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 917, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 917, iters: 912, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 917, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 917, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 917, iters: 1152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 917, iters: 1232, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 917, iters: 1312, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 917, iters: 1392, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 917, iters: 1472, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 917, iters: 1552, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 917, iters: 1632, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 917, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 917, iters: 1792, time: 0.094, data: 0.011) loss: 0.019 
(epoch: 917, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 917, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 917, iters: 2032, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 917, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 917, iters: 2192, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 917, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 917, iters: 2352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 917, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 917, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 917, iters: 2592, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 917, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 917, iters: 2752, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 917, iters: 2832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 917, iters: 2912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 917, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 917, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 917, iters: 3152, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 917, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 917, iters: 3312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 917, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 917, iters: 3472, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 917, iters: 3552, time: 0.094, data: 0.000) loss: 0.040 
(epoch: 917, iters: 3632, time: 0.090, data: 0.000) loss: 0.017 
(epoch: 917, iters: 3712, time: 0.087, data: 0.035) loss: 0.002 
saving the model at the end of epoch 917, iters 3418576
End of epoch 917 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001182
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 917, TEST ACC: [97.724 %]

saving the latest model (epoch 918, total_steps 3418592)
(epoch: 918, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 918, iters: 144, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 918, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 918, iters: 304, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 918, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 918, iters: 464, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 918, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 918, iters: 624, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 918, iters: 704, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 918, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 918, iters: 864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 918, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 918, iters: 1024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 918, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 918, iters: 1184, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 918, iters: 1264, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 918, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 918, iters: 1424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 918, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 918, iters: 1584, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 918, iters: 1664, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 918, iters: 1744, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 918, iters: 1824, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 918, iters: 1904, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 918, iters: 1984, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 918, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 918, iters: 2144, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 918, iters: 2224, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 918, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 918, iters: 2384, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 918, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 918, iters: 2544, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 918, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 918, iters: 2704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 918, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 918, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 918, iters: 2944, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 918, iters: 3024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 918, iters: 3104, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 918, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 918, iters: 3264, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 918, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 918, iters: 3424, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 918, iters: 3504, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 918, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 918, iters: 3664, time: 0.086, data: 0.011) loss: 0.000 
saving the model at the end of epoch 918, iters 3422304
End of epoch 918 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001181
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 918, TEST ACC: [95.751 %]

(epoch: 919, iters: 16, time: 0.111, data: 0.012) loss: 0.000 
saving the latest model (epoch 919, total_steps 3422320)
(epoch: 919, iters: 96, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 919, iters: 176, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 919, iters: 256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 919, iters: 336, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 919, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 919, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 919, iters: 576, time: 0.094, data: 0.040) loss: 0.002 
(epoch: 919, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 919, iters: 736, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 919, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 919, iters: 896, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 919, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 919, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 919, iters: 1136, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 919, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 919, iters: 1296, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 919, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 919, iters: 1456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 919, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 919, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 919, iters: 1696, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 919, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 919, iters: 1856, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 919, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 919, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 919, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 919, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 919, iters: 2256, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 919, iters: 2336, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 919, iters: 2416, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 919, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 919, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 919, iters: 2656, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 919, iters: 2736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 919, iters: 2816, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 919, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 919, iters: 2976, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 919, iters: 3056, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 919, iters: 3136, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 919, iters: 3216, time: 0.098, data: 0.000) loss: 0.007 
(epoch: 919, iters: 3296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 919, iters: 3376, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 919, iters: 3456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 919, iters: 3536, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 919, iters: 3616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 919, iters: 3696, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 919, iters 3426032
End of epoch 919 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001180
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 919, TEST ACC: [96.055 %]

saving the latest model (epoch 920, total_steps 3426048)
(epoch: 920, iters: 48, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 920, iters: 128, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 920, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 920, iters: 288, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 920, iters: 368, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 920, iters: 448, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 920, iters: 528, time: 0.096, data: 0.000) loss: 0.016 
(epoch: 920, iters: 608, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 920, iters: 688, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 920, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 920, iters: 848, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 920, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 920, iters: 1008, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 920, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 920, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 920, iters: 1248, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 920, iters: 1328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 920, iters: 1408, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 920, iters: 1488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 920, iters: 1568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 920, iters: 1648, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 920, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 920, iters: 1808, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 920, iters: 1888, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 920, iters: 1968, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 920, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 920, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 920, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 920, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 920, iters: 2368, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 920, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 920, iters: 2528, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 920, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 920, iters: 2688, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 920, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 920, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 920, iters: 2928, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 920, iters: 3008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 920, iters: 3088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 920, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 920, iters: 3248, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 920, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 920, iters: 3408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 920, iters: 3488, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 920, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 920, iters: 3648, time: 0.085, data: 0.012) loss: 0.000 
(epoch: 920, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 920, iters 3429760
End of epoch 920 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001179
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 920, TEST ACC: [95.144 %]

saving the latest model (epoch 921, total_steps 3429776)
(epoch: 921, iters: 80, time: 0.094, data: 0.454) loss: 0.000 
(epoch: 921, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 921, iters: 240, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 921, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 921, iters: 400, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 921, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 921, iters: 560, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 921, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 921, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 921, iters: 800, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 921, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 921, iters: 960, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 921, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 921, iters: 1120, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 921, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 921, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 921, iters: 1360, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 921, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 921, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 921, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 921, iters: 1680, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 921, iters: 1760, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 921, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 921, iters: 1920, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 921, iters: 2000, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 921, iters: 2080, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 921, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 921, iters: 2240, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 921, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 921, iters: 2400, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 921, iters: 2480, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 921, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 921, iters: 2640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 921, iters: 2720, time: 0.094, data: 0.000) loss: 0.045 
(epoch: 921, iters: 2800, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 921, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 921, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 921, iters: 3040, time: 0.096, data: 0.048) loss: 0.000 
(epoch: 921, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 921, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 921, iters: 3280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 921, iters: 3360, time: 0.095, data: 0.021) loss: 0.000 
(epoch: 921, iters: 3440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 921, iters: 3520, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 921, iters: 3600, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 921, iters: 3680, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 921, iters 3433488
End of epoch 921 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001178
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 921, TEST ACC: [95.448 %]

saving the latest model (epoch 922, total_steps 3433504)
(epoch: 922, iters: 32, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 922, iters: 112, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 922, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 922, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 922, iters: 352, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 922, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 922, iters: 512, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 922, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 922, iters: 672, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 922, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 922, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 922, iters: 912, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 922, iters: 992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 922, iters: 1072, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 922, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 922, iters: 1232, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 922, iters: 1312, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 922, iters: 1392, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 922, iters: 1472, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 922, iters: 1552, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 922, iters: 1632, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 922, iters: 1712, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 922, iters: 1792, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 922, iters: 1872, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 922, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 922, iters: 2032, time: 0.095, data: 0.049) loss: 0.217 
(epoch: 922, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 922, iters: 2192, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 922, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 922, iters: 2352, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 922, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 922, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 922, iters: 2592, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 922, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 922, iters: 2752, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 922, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 922, iters: 2912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 922, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 922, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 922, iters: 3152, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 922, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 922, iters: 3312, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 922, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 922, iters: 3472, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 922, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 922, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 922, iters: 3712, time: 0.087, data: 0.035) loss: 0.000 
saving the model at the end of epoch 922, iters 3437216
End of epoch 922 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001177
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 922, TEST ACC: [96.813 %]

saving the latest model (epoch 923, total_steps 3437232)
(epoch: 923, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 923, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 923, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 923, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 923, iters: 384, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 923, iters: 464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 923, iters: 544, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 923, iters: 624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 923, iters: 704, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 923, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 923, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 923, iters: 944, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 923, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 923, iters: 1104, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 923, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 923, iters: 1264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 923, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 923, iters: 1424, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 923, iters: 1504, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 923, iters: 1584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 923, iters: 1664, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 923, iters: 1744, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 923, iters: 1824, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 923, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 923, iters: 1984, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 923, iters: 2064, time: 0.093, data: 0.049) loss: 0.001 
(epoch: 923, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 923, iters: 2224, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 923, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 923, iters: 2384, time: 0.093, data: 0.019) loss: 0.000 
(epoch: 923, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 923, iters: 2544, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 923, iters: 2624, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 923, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 923, iters: 2784, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 923, iters: 2864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 923, iters: 2944, time: 0.095, data: 0.012) loss: 0.024 
(epoch: 923, iters: 3024, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 923, iters: 3104, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 923, iters: 3184, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 923, iters: 3264, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 923, iters: 3344, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 923, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 923, iters: 3504, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 923, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 923, iters: 3664, time: 0.086, data: 0.000) loss: 0.000 
saving the model at the end of epoch 923, iters 3440944
End of epoch 923 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001176
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 923, TEST ACC: [96.662 %]

(epoch: 924, iters: 16, time: 0.112, data: 0.012) loss: 0.000 
saving the latest model (epoch 924, total_steps 3440960)
(epoch: 924, iters: 96, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 924, iters: 176, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 924, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 924, iters: 336, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 924, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 924, iters: 496, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 924, iters: 576, time: 0.094, data: 0.039) loss: 0.065 
(epoch: 924, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 924, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 924, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 924, iters: 896, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 924, iters: 976, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 924, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 924, iters: 1136, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 924, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 924, iters: 1296, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 924, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 924, iters: 1456, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 924, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 924, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 924, iters: 1696, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 924, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 924, iters: 1856, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 924, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 924, iters: 2016, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 924, iters: 2096, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 924, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 924, iters: 2256, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 924, iters: 2336, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 924, iters: 2416, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 924, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 924, iters: 2576, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 924, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 924, iters: 2736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 924, iters: 2816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 924, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 924, iters: 2976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 924, iters: 3056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 924, iters: 3136, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 924, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 924, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 924, iters: 3376, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 924, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 924, iters: 3536, time: 0.091, data: 0.021) loss: 0.000 
(epoch: 924, iters: 3616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 924, iters: 3696, time: 0.086, data: 0.012) loss: 0.000 
saving the model at the end of epoch 924, iters 3444672
End of epoch 924 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001175
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 924, TEST ACC: [96.662 %]

saving the latest model (epoch 925, total_steps 3444688)
(epoch: 925, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 925, iters: 128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 925, iters: 208, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 925, iters: 288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 925, iters: 368, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 925, iters: 448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 925, iters: 528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 925, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 925, iters: 688, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 925, iters: 768, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 925, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 925, iters: 928, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 925, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 925, iters: 1088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 925, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 925, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 925, iters: 1328, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 925, iters: 1408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 925, iters: 1488, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 925, iters: 1568, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 925, iters: 1648, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 925, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 925, iters: 1808, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 925, iters: 1888, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 925, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 925, iters: 2048, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 925, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 925, iters: 2208, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 925, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 925, iters: 2368, time: 0.093, data: 0.000) loss: 0.258 
(epoch: 925, iters: 2448, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 925, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 925, iters: 2608, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 925, iters: 2688, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 925, iters: 2768, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 925, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 925, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 925, iters: 3008, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 925, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 925, iters: 3168, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 925, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 925, iters: 3328, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 925, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 925, iters: 3488, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 925, iters: 3568, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 925, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 925, iters: 3728, time: 0.056, data: 0.011) loss: 0.000 
saving the model at the end of epoch 925, iters 3448400
End of epoch 925 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001174
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 925, TEST ACC: [96.813 %]

saving the latest model (epoch 926, total_steps 3448416)
(epoch: 926, iters: 80, time: 0.094, data: 0.530) loss: 0.000 
(epoch: 926, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 926, iters: 240, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 926, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 926, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 926, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 926, iters: 560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 926, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 926, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 926, iters: 800, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 926, iters: 880, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 926, iters: 960, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 926, iters: 1040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 926, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 926, iters: 1200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 926, iters: 1280, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 926, iters: 1360, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 926, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 926, iters: 1520, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 926, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 926, iters: 1680, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 926, iters: 1760, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 926, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 926, iters: 1920, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 926, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 926, iters: 2080, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 926, iters: 2160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 926, iters: 2240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 926, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 926, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 926, iters: 2480, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 926, iters: 2560, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 926, iters: 2640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 926, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 926, iters: 2800, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 926, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 926, iters: 2960, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 926, iters: 3040, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 926, iters: 3120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 926, iters: 3200, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 926, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 926, iters: 3360, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 926, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 926, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 926, iters: 3600, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 926, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 926, iters 3452128
End of epoch 926 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001173
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 926, TEST ACC: [97.269 %]

saving the latest model (epoch 927, total_steps 3452144)
(epoch: 927, iters: 32, time: 0.092, data: 0.005) loss: 0.000 
(epoch: 927, iters: 112, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 927, iters: 192, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 927, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 927, iters: 352, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 927, iters: 432, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 927, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 927, iters: 592, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 927, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 927, iters: 752, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 927, iters: 832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 927, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 927, iters: 992, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 927, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 927, iters: 1152, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 927, iters: 1232, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 927, iters: 1312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 927, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 927, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 927, iters: 1552, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 927, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 927, iters: 1712, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 927, iters: 1792, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 927, iters: 1872, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 927, iters: 1952, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 927, iters: 2032, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 927, iters: 2112, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 927, iters: 2192, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 927, iters: 2272, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 927, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 927, iters: 2432, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 927, iters: 2512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 927, iters: 2592, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 927, iters: 2672, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 927, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 927, iters: 2832, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 927, iters: 2912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 927, iters: 2992, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 927, iters: 3072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 927, iters: 3152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 927, iters: 3232, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 927, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 927, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 927, iters: 3472, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 927, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 927, iters: 3632, time: 0.089, data: 0.012) loss: 0.000 
(epoch: 927, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 927, iters 3455856
End of epoch 927 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001172
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 927, TEST ACC: [97.117 %]

saving the latest model (epoch 928, total_steps 3455872)
(epoch: 928, iters: 64, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 928, iters: 144, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 928, iters: 224, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 928, iters: 304, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 928, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 928, iters: 464, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 928, iters: 544, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 928, iters: 624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 928, iters: 704, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 928, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 928, iters: 864, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 928, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 928, iters: 1024, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 928, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 928, iters: 1184, time: 0.092, data: 0.000) loss: 0.214 
(epoch: 928, iters: 1264, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 928, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 928, iters: 1424, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 928, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 928, iters: 1584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 928, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 928, iters: 1744, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 928, iters: 1824, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 928, iters: 1904, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 928, iters: 1984, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 928, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 928, iters: 2144, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 928, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 928, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 928, iters: 2384, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 928, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 928, iters: 2544, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 928, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 928, iters: 2704, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 928, iters: 2784, time: 0.094, data: 0.000) loss: 0.029 
(epoch: 928, iters: 2864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 928, iters: 2944, time: 0.096, data: 0.041) loss: 0.139 
(epoch: 928, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 928, iters: 3104, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 928, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 928, iters: 3264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 928, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 928, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 928, iters: 3504, time: 0.093, data: 0.040) loss: 0.106 
(epoch: 928, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 928, iters: 3664, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 928, iters 3459584
End of epoch 928 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001171
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 928, TEST ACC: [97.42 %]

(epoch: 929, iters: 16, time: 0.111, data: 0.013) loss: 0.000 
saving the latest model (epoch 929, total_steps 3459600)
(epoch: 929, iters: 96, time: 0.094, data: 0.059) loss: 0.000 
(epoch: 929, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 929, iters: 256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 929, iters: 336, time: 0.094, data: 0.000) loss: 0.133 
(epoch: 929, iters: 416, time: 0.096, data: 0.021) loss: 0.000 
(epoch: 929, iters: 496, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 929, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 929, iters: 656, time: 0.097, data: 0.051) loss: 0.000 
(epoch: 929, iters: 736, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 929, iters: 816, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 929, iters: 896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 929, iters: 976, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 929, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 929, iters: 1136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 929, iters: 1216, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 929, iters: 1296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 929, iters: 1376, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 929, iters: 1456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 929, iters: 1536, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 929, iters: 1616, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 929, iters: 1696, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 929, iters: 1776, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 929, iters: 1856, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 929, iters: 1936, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 929, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 929, iters: 2096, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 929, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 929, iters: 2256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 929, iters: 2336, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 929, iters: 2416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 929, iters: 2496, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 929, iters: 2576, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 929, iters: 2656, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 929, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 929, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 929, iters: 2896, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 929, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 929, iters: 3056, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 929, iters: 3136, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 929, iters: 3216, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 929, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 929, iters: 3376, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 929, iters: 3456, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 929, iters: 3536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 929, iters: 3616, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 929, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 929, iters 3463312
End of epoch 929 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001170
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 929, TEST ACC: [97.117 %]

saving the latest model (epoch 930, total_steps 3463328)
(epoch: 930, iters: 48, time: 0.092, data: 0.005) loss: 0.001 
(epoch: 930, iters: 128, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 930, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 930, iters: 288, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 930, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 930, iters: 448, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 930, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 930, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 930, iters: 688, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 930, iters: 768, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 930, iters: 848, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 930, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 930, iters: 1008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 930, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 930, iters: 1168, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 930, iters: 1248, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 930, iters: 1328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 930, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 930, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 930, iters: 1568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 930, iters: 1648, time: 0.094, data: 0.000) loss: 0.247 
(epoch: 930, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 930, iters: 1808, time: 0.093, data: 0.039) loss: 0.001 
(epoch: 930, iters: 1888, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 930, iters: 1968, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 930, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 930, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 930, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 930, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 930, iters: 2368, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 930, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 930, iters: 2528, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 930, iters: 2608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 930, iters: 2688, time: 0.093, data: 0.012) loss: 0.010 
(epoch: 930, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 930, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 930, iters: 2928, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 930, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 930, iters: 3088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 930, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 930, iters: 3248, time: 0.095, data: 0.020) loss: 0.000 
(epoch: 930, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 930, iters: 3408, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 930, iters: 3488, time: 0.094, data: 0.039) loss: 0.014 
(epoch: 930, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 930, iters: 3648, time: 0.087, data: 0.011) loss: 0.000 
(epoch: 930, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 930, iters 3467040
End of epoch 930 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001169
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 930, TEST ACC: [95.448 %]

saving the latest model (epoch 931, total_steps 3467056)
(epoch: 931, iters: 80, time: 0.094, data: 0.457) loss: 0.000 
(epoch: 931, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 931, iters: 240, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 931, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 931, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 931, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 931, iters: 560, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 931, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 931, iters: 720, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 931, iters: 800, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 931, iters: 880, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 931, iters: 960, time: 0.092, data: 0.011) loss: 0.020 
(epoch: 931, iters: 1040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 931, iters: 1120, time: 0.093, data: 0.012) loss: 0.100 
(epoch: 931, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 931, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 931, iters: 1360, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 931, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 931, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 931, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 931, iters: 1680, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 931, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 931, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 931, iters: 1920, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 931, iters: 2000, time: 0.094, data: 0.000) loss: 0.008 
(epoch: 931, iters: 2080, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 931, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 931, iters: 2240, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 931, iters: 2320, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 931, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 931, iters: 2480, time: 0.094, data: 0.039) loss: 0.015 
(epoch: 931, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 931, iters: 2640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 931, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 931, iters: 2800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 931, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 931, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 931, iters: 3040, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 931, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 931, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 931, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 931, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 931, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 931, iters: 3520, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 931, iters: 3600, time: 0.096, data: 0.041) loss: 0.009 
(epoch: 931, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 931, iters 3470768
End of epoch 931 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001168
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 931, TEST ACC: [96.662 %]

saving the latest model (epoch 932, total_steps 3470784)
(epoch: 932, iters: 32, time: 0.094, data: 0.005) loss: 0.000 
(epoch: 932, iters: 112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 932, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 932, iters: 272, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 932, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 932, iters: 432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 932, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 932, iters: 592, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 932, iters: 672, time: 0.094, data: 0.000) loss: 0.013 
(epoch: 932, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 932, iters: 832, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 932, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 932, iters: 992, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 932, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 932, iters: 1152, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 932, iters: 1232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 932, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 932, iters: 1392, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 932, iters: 1472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 932, iters: 1552, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 932, iters: 1632, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 932, iters: 1712, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 932, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 932, iters: 1872, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 932, iters: 1952, time: 0.096, data: 0.047) loss: 0.000 
(epoch: 932, iters: 2032, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 932, iters: 2112, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 932, iters: 2192, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 932, iters: 2272, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 932, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 932, iters: 2432, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 932, iters: 2512, time: 0.097, data: 0.039) loss: 0.000 
(epoch: 932, iters: 2592, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 932, iters: 2672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 932, iters: 2752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 932, iters: 2832, time: 0.095, data: 0.012) loss: 0.002 
(epoch: 932, iters: 2912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 932, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 932, iters: 3072, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 932, iters: 3152, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 932, iters: 3232, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 932, iters: 3312, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 932, iters: 3392, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 932, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 932, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 932, iters: 3632, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 932, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 932, iters 3474496
End of epoch 932 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001167
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 932, TEST ACC: [96.51 %]

saving the latest model (epoch 933, total_steps 3474512)
(epoch: 933, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 933, iters: 144, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 933, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 933, iters: 304, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 933, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 933, iters: 464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 933, iters: 544, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 933, iters: 624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 933, iters: 704, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 933, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 933, iters: 864, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 933, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 933, iters: 1024, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 933, iters: 1104, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 933, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 933, iters: 1264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 933, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 933, iters: 1424, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 933, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 933, iters: 1584, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 933, iters: 1664, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 933, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 933, iters: 1824, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 933, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 933, iters: 1984, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 933, iters: 2064, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 933, iters: 2144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 933, iters: 2224, time: 0.095, data: 0.052) loss: 0.000 
(epoch: 933, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 933, iters: 2384, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 933, iters: 2464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 933, iters: 2544, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 933, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 933, iters: 2704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 933, iters: 2784, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 933, iters: 2864, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 933, iters: 2944, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 933, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 933, iters: 3104, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 933, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 933, iters: 3264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 933, iters: 3344, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 933, iters: 3424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 933, iters: 3504, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 933, iters: 3584, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 933, iters: 3664, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 933, iters 3478224
End of epoch 933 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001166
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 933, TEST ACC: [96.662 %]

(epoch: 934, iters: 16, time: 0.112, data: 0.000) loss: 0.000 
saving the latest model (epoch 934, total_steps 3478240)
(epoch: 934, iters: 96, time: 0.096, data: 0.058) loss: 0.000 
(epoch: 934, iters: 176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 934, iters: 256, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 934, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 934, iters: 416, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 934, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 934, iters: 576, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 934, iters: 656, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 934, iters: 736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 934, iters: 816, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 934, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 934, iters: 976, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 934, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 934, iters: 1136, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 934, iters: 1216, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 934, iters: 1296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 934, iters: 1376, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 934, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 934, iters: 1536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 934, iters: 1616, time: 0.095, data: 0.000) loss: 0.027 
(epoch: 934, iters: 1696, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 934, iters: 1776, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 934, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 934, iters: 1936, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 934, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 934, iters: 2096, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 934, iters: 2176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 934, iters: 2256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 934, iters: 2336, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 934, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 934, iters: 2496, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 934, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 934, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 934, iters: 2736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 934, iters: 2816, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 934, iters: 2896, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 934, iters: 2976, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 934, iters: 3056, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 934, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 934, iters: 3216, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 934, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 934, iters: 3376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 934, iters: 3456, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 934, iters: 3536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 934, iters: 3616, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 934, iters: 3696, time: 0.091, data: 0.000) loss: 0.000 
saving the model at the end of epoch 934, iters 3481952
End of epoch 934 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001165
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 934, TEST ACC: [96.965 %]

saving the latest model (epoch 935, total_steps 3481968)
(epoch: 935, iters: 48, time: 0.094, data: 0.005) loss: 0.000 
(epoch: 935, iters: 128, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 935, iters: 208, time: 0.097, data: 0.048) loss: 0.000 
(epoch: 935, iters: 288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 935, iters: 368, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 935, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 935, iters: 528, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 935, iters: 608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 935, iters: 688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 935, iters: 768, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 935, iters: 848, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 935, iters: 928, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 935, iters: 1008, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 935, iters: 1088, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 935, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 935, iters: 1248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 935, iters: 1328, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 935, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 935, iters: 1488, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 935, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 935, iters: 1648, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 935, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 935, iters: 1808, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 935, iters: 1888, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 935, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 935, iters: 2048, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 935, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 935, iters: 2208, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 935, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 935, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 935, iters: 2448, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 935, iters: 2528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 935, iters: 2608, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 935, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 935, iters: 2768, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 935, iters: 2848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 935, iters: 2928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 935, iters: 3008, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 935, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 935, iters: 3168, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 935, iters: 3248, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 935, iters: 3328, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 935, iters: 3408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 935, iters: 3488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 935, iters: 3568, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 935, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 935, iters: 3728, time: 0.056, data: 0.011) loss: 0.000 
saving the model at the end of epoch 935, iters 3485680
End of epoch 935 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001164
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 935, TEST ACC: [96.662 %]

saving the latest model (epoch 936, total_steps 3485696)
(epoch: 936, iters: 80, time: 0.096, data: 0.448) loss: 0.000 
(epoch: 936, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 936, iters: 240, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 936, iters: 320, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 936, iters: 400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 936, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 936, iters: 560, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 936, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 936, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 936, iters: 800, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 936, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 936, iters: 960, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 936, iters: 1040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 936, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 936, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 936, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 936, iters: 1360, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 936, iters: 1440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 936, iters: 1520, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 936, iters: 1600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 936, iters: 1680, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 936, iters: 1760, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 936, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 936, iters: 1920, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 936, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 936, iters: 2080, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 936, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 936, iters: 2240, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 936, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 936, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 936, iters: 2480, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 936, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 936, iters: 2640, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 936, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 936, iters: 2800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 936, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 936, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 936, iters: 3040, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 936, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 936, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 936, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 936, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 936, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 936, iters: 3520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 936, iters: 3600, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 936, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 936, iters 3489408
End of epoch 936 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001163
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 936, TEST ACC: [95.448 %]

saving the latest model (epoch 937, total_steps 3489424)
(epoch: 937, iters: 32, time: 0.094, data: 0.005) loss: 0.000 
(epoch: 937, iters: 112, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 937, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 937, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 937, iters: 352, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 937, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 937, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 937, iters: 592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 937, iters: 672, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 937, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 937, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 937, iters: 912, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 937, iters: 992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 937, iters: 1072, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 937, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 937, iters: 1232, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 937, iters: 1312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 937, iters: 1392, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 937, iters: 1472, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 937, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 937, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 937, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 937, iters: 1792, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 937, iters: 1872, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 937, iters: 1952, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 937, iters: 2032, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 937, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 937, iters: 2192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 937, iters: 2272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 937, iters: 2352, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 937, iters: 2432, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 937, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 937, iters: 2592, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 937, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 937, iters: 2752, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 937, iters: 2832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 937, iters: 2912, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 937, iters: 2992, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 937, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 937, iters: 3152, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 937, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 937, iters: 3312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 937, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 937, iters: 3472, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 937, iters: 3552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 937, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 937, iters: 3712, time: 0.089, data: 0.035) loss: 0.000 
saving the model at the end of epoch 937, iters 3493136
End of epoch 937 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001162
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 937, TEST ACC: [96.965 %]

saving the latest model (epoch 938, total_steps 3493152)
(epoch: 938, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 938, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 938, iters: 224, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 938, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 938, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 938, iters: 464, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 938, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 938, iters: 624, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 938, iters: 704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 938, iters: 784, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 938, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 938, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 938, iters: 1024, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 938, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 938, iters: 1184, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 938, iters: 1264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 938, iters: 1344, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 938, iters: 1424, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 938, iters: 1504, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 938, iters: 1584, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 938, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 938, iters: 1744, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 938, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 938, iters: 1904, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 938, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 938, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 938, iters: 2144, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 938, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 938, iters: 2304, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 938, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 938, iters: 2464, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 938, iters: 2544, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 938, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 938, iters: 2704, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 938, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 938, iters: 2864, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 938, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 938, iters: 3024, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 938, iters: 3104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 938, iters: 3184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 938, iters: 3264, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 938, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 938, iters: 3424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 938, iters: 3504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 938, iters: 3584, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 938, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 938, iters 3496864
End of epoch 938 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001161
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 938, TEST ACC: [96.358 %]

(epoch: 939, iters: 16, time: 0.108, data: 0.000) loss: 0.000 
saving the latest model (epoch 939, total_steps 3496880)
(epoch: 939, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 939, iters: 176, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 939, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 939, iters: 336, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 939, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 939, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 939, iters: 576, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 939, iters: 656, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 939, iters: 736, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 939, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 939, iters: 896, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 939, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 939, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 939, iters: 1136, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 939, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 939, iters: 1296, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 939, iters: 1376, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 939, iters: 1456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 939, iters: 1536, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 939, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 939, iters: 1696, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 939, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 939, iters: 1856, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 939, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 939, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 939, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 939, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 939, iters: 2256, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 939, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 939, iters: 2416, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 939, iters: 2496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 939, iters: 2576, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 939, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 939, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 939, iters: 2816, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 939, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 939, iters: 2976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 939, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 939, iters: 3136, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 939, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 939, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 939, iters: 3376, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 939, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 939, iters: 3536, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 939, iters: 3616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 939, iters: 3696, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 939, iters 3500592
End of epoch 939 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001160
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 939, TEST ACC: [96.206 %]

saving the latest model (epoch 940, total_steps 3500608)
(epoch: 940, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 940, iters: 128, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 940, iters: 208, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 940, iters: 288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 940, iters: 368, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 940, iters: 448, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 940, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 940, iters: 608, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 940, iters: 688, time: 0.094, data: 0.000) loss: 0.009 
(epoch: 940, iters: 768, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 940, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 940, iters: 928, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 940, iters: 1008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 940, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 940, iters: 1168, time: 0.094, data: 0.047) loss: 0.000 
(epoch: 940, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 940, iters: 1328, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 940, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 940, iters: 1488, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 940, iters: 1568, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 940, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 940, iters: 1728, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 940, iters: 1808, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 940, iters: 1888, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 940, iters: 1968, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 940, iters: 2048, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 940, iters: 2128, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 940, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 940, iters: 2288, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 940, iters: 2368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 940, iters: 2448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 940, iters: 2528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 940, iters: 2608, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 940, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 940, iters: 2768, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 940, iters: 2848, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 940, iters: 2928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 940, iters: 3008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 940, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 940, iters: 3168, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 940, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 940, iters: 3328, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 940, iters: 3408, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 940, iters: 3488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 940, iters: 3568, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 940, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 940, iters: 3728, time: 0.056, data: 0.012) loss: 0.000 
saving the model at the end of epoch 940, iters 3504320
End of epoch 940 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001159
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 940, TEST ACC: [95.296 %]

saving the latest model (epoch 941, total_steps 3504336)
(epoch: 941, iters: 80, time: 0.092, data: 0.520) loss: 0.000 
(epoch: 941, iters: 160, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 941, iters: 240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 941, iters: 320, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 941, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 941, iters: 480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 941, iters: 560, time: 0.095, data: 0.000) loss: 0.604 
(epoch: 941, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 941, iters: 720, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 941, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 941, iters: 880, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 941, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 941, iters: 1040, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 941, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 941, iters: 1200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 941, iters: 1280, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 941, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 941, iters: 1440, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 941, iters: 1520, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 941, iters: 1600, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 941, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 941, iters: 1760, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 941, iters: 1840, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 941, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 941, iters: 2000, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 941, iters: 2080, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 941, iters: 2160, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 941, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 941, iters: 2320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 941, iters: 2400, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 941, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 941, iters: 2560, time: 0.092, data: 0.012) loss: 0.002 
(epoch: 941, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 941, iters: 2720, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 941, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 941, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 941, iters: 2960, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 941, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 941, iters: 3120, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 941, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 941, iters: 3280, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 941, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 941, iters: 3440, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 941, iters: 3520, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 941, iters: 3600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 941, iters: 3680, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 941, iters 3508048
End of epoch 941 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001158
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 941, TEST ACC: [97.269 %]

saving the latest model (epoch 942, total_steps 3508064)
(epoch: 942, iters: 32, time: 0.093, data: 0.008) loss: 0.000 
(epoch: 942, iters: 112, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 942, iters: 192, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 942, iters: 272, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 942, iters: 352, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 942, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 942, iters: 512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 942, iters: 592, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 942, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 942, iters: 752, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 942, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 942, iters: 912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 942, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 942, iters: 1072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 942, iters: 1152, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 942, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 942, iters: 1312, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 942, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 942, iters: 1472, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 942, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 942, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 942, iters: 1712, time: 0.096, data: 0.051) loss: 0.000 
(epoch: 942, iters: 1792, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 942, iters: 1872, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 942, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 942, iters: 2032, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 942, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 942, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 942, iters: 2272, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 942, iters: 2352, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 942, iters: 2432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 942, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 942, iters: 2592, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 942, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 942, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 942, iters: 2832, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 942, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 942, iters: 2992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 942, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 942, iters: 3152, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 942, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 942, iters: 3312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 942, iters: 3392, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 942, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 942, iters: 3552, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 942, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 942, iters: 3712, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 942, iters 3511776
End of epoch 942 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001157
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 942, TEST ACC: [96.662 %]

saving the latest model (epoch 943, total_steps 3511792)
(epoch: 943, iters: 64, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 943, iters: 144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 943, iters: 224, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 943, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 943, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 943, iters: 464, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 943, iters: 544, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 943, iters: 624, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 943, iters: 704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 943, iters: 784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 943, iters: 864, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 943, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 943, iters: 1024, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 943, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 943, iters: 1184, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 943, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 943, iters: 1344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 943, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 943, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 943, iters: 1584, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 943, iters: 1664, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 943, iters: 1744, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 943, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 943, iters: 1904, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 943, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 943, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 943, iters: 2144, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 943, iters: 2224, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 943, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 943, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 943, iters: 2464, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 943, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 943, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 943, iters: 2704, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 943, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 943, iters: 2864, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 943, iters: 2944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 943, iters: 3024, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 943, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 943, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 943, iters: 3264, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 943, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 943, iters: 3424, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 943, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 943, iters: 3584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 943, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 943, iters 3515504
End of epoch 943 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001156
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 943, TEST ACC: [95.448 %]

(epoch: 944, iters: 16, time: 0.113, data: 0.000) loss: 0.000 
saving the latest model (epoch 944, total_steps 3515520)
(epoch: 944, iters: 96, time: 0.096, data: 0.044) loss: 0.000 
(epoch: 944, iters: 176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 944, iters: 256, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 944, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 944, iters: 416, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 944, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 944, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 944, iters: 656, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 944, iters: 736, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 944, iters: 816, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 944, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 944, iters: 976, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 944, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 944, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 944, iters: 1216, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 944, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 944, iters: 1376, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 944, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 944, iters: 1536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 944, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 944, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 944, iters: 1776, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 944, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 944, iters: 1936, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 944, iters: 2016, time: 0.095, data: 0.000) loss: 0.193 
(epoch: 944, iters: 2096, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 944, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 944, iters: 2256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 944, iters: 2336, time: 0.096, data: 0.048) loss: 0.000 
(epoch: 944, iters: 2416, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 944, iters: 2496, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 944, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 944, iters: 2656, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 944, iters: 2736, time: 0.097, data: 0.000) loss: 0.007 
(epoch: 944, iters: 2816, time: 0.093, data: 0.000) loss: 0.030 
(epoch: 944, iters: 2896, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 944, iters: 2976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 944, iters: 3056, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 944, iters: 3136, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 944, iters: 3216, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 944, iters: 3296, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 944, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 944, iters: 3456, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 944, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 944, iters: 3616, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 944, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 944, iters 3519232
End of epoch 944 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001155
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 944, TEST ACC: [89.53 %]

saving the latest model (epoch 945, total_steps 3519248)
(epoch: 945, iters: 48, time: 0.094, data: 0.004) loss: 0.000 
(epoch: 945, iters: 128, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 945, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 945, iters: 288, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 945, iters: 368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 945, iters: 448, time: 0.092, data: 0.013) loss: 0.001 
(epoch: 945, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 945, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 945, iters: 688, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 945, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 945, iters: 848, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 945, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 945, iters: 1008, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 945, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 945, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 945, iters: 1248, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 945, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 945, iters: 1408, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 945, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 945, iters: 1568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 945, iters: 1648, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 945, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 945, iters: 1808, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 945, iters: 1888, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 945, iters: 1968, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 945, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 945, iters: 2128, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 945, iters: 2208, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 945, iters: 2288, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 945, iters: 2368, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 945, iters: 2448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 945, iters: 2528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 945, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 945, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 945, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 945, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 945, iters: 2928, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 945, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 945, iters: 3088, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 945, iters: 3168, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 945, iters: 3248, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 945, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 945, iters: 3408, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 945, iters: 3488, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 945, iters: 3568, time: 0.096, data: 0.000) loss: 0.031 
(epoch: 945, iters: 3648, time: 0.087, data: 0.012) loss: 0.000 
(epoch: 945, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 945, iters 3522960
End of epoch 945 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001154
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 945, TEST ACC: [95.448 %]

saving the latest model (epoch 946, total_steps 3522976)
(epoch: 946, iters: 80, time: 0.094, data: 0.608) loss: 0.000 
(epoch: 946, iters: 160, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 946, iters: 240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 946, iters: 320, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 946, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 946, iters: 480, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 946, iters: 560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 946, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 946, iters: 720, time: 0.097, data: 0.041) loss: 0.001 
(epoch: 946, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 946, iters: 880, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 946, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 946, iters: 1040, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 946, iters: 1120, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 946, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 946, iters: 1280, time: 0.096, data: 0.049) loss: 0.002 
(epoch: 946, iters: 1360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 946, iters: 1440, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 946, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 946, iters: 1600, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 946, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 946, iters: 1760, time: 0.093, data: 0.000) loss: 0.008 
(epoch: 946, iters: 1840, time: 0.098, data: 0.039) loss: 0.000 
(epoch: 946, iters: 1920, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 946, iters: 2000, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 946, iters: 2080, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 946, iters: 2160, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 946, iters: 2240, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 946, iters: 2320, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 946, iters: 2400, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 946, iters: 2480, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 946, iters: 2560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 946, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 946, iters: 2720, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 946, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 946, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 946, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 946, iters: 3040, time: 0.095, data: 0.011) loss: 0.001 
(epoch: 946, iters: 3120, time: 0.095, data: 0.035) loss: 0.000 
(epoch: 946, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 946, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 946, iters: 3360, time: 0.093, data: 0.012) loss: 0.004 
(epoch: 946, iters: 3440, time: 0.093, data: 0.024) loss: 0.000 
(epoch: 946, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 946, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 946, iters: 3680, time: 0.086, data: 0.011) loss: 0.000 
saving the model at the end of epoch 946, iters 3526688
End of epoch 946 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001153
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 946, TEST ACC: [97.117 %]

saving the latest model (epoch 947, total_steps 3526704)
(epoch: 947, iters: 32, time: 0.092, data: 0.006) loss: 0.000 
(epoch: 947, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 947, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 947, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 947, iters: 352, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 947, iters: 432, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 947, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 947, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 947, iters: 672, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 947, iters: 752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 947, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 947, iters: 912, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 947, iters: 992, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 947, iters: 1072, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 947, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 947, iters: 1232, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 947, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 947, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 947, iters: 1472, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 947, iters: 1552, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 947, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 947, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 947, iters: 1792, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 947, iters: 1872, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 947, iters: 1952, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 947, iters: 2032, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 947, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 947, iters: 2192, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 947, iters: 2272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 947, iters: 2352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 947, iters: 2432, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 947, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 947, iters: 2592, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 947, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 947, iters: 2752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 947, iters: 2832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 947, iters: 2912, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 947, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 947, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 947, iters: 3152, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 947, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 947, iters: 3312, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 947, iters: 3392, time: 0.094, data: 0.000) loss: 0.012 
(epoch: 947, iters: 3472, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 947, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 947, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 947, iters: 3712, time: 0.088, data: 0.035) loss: 0.000 
saving the model at the end of epoch 947, iters 3530416
End of epoch 947 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001152
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 947, TEST ACC: [93.778 %]

saving the latest model (epoch 948, total_steps 3530432)
(epoch: 948, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 948, iters: 144, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 948, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 948, iters: 304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 948, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 948, iters: 464, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 948, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 948, iters: 624, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 948, iters: 704, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 948, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 948, iters: 864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 948, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 948, iters: 1024, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 948, iters: 1104, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 948, iters: 1184, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 948, iters: 1264, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 948, iters: 1344, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 948, iters: 1424, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 948, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 948, iters: 1584, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 948, iters: 1664, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 948, iters: 1744, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 948, iters: 1824, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 948, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 948, iters: 1984, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 948, iters: 2064, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 948, iters: 2144, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 948, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 948, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 948, iters: 2384, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 948, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 948, iters: 2544, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 948, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 948, iters: 2704, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 948, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 948, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 948, iters: 2944, time: 0.095, data: 0.049) loss: 0.005 
(epoch: 948, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 948, iters: 3104, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 948, iters: 3184, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 948, iters: 3264, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 948, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 948, iters: 3424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 948, iters: 3504, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 948, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 948, iters: 3664, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 948, iters 3534144
End of epoch 948 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001151
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 948, TEST ACC: [94.385 %]

(epoch: 949, iters: 16, time: 0.111, data: 0.012) loss: 0.000 
saving the latest model (epoch 949, total_steps 3534160)
(epoch: 949, iters: 96, time: 0.094, data: 0.043) loss: 0.000 
(epoch: 949, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 949, iters: 256, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 949, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 949, iters: 416, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 949, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 949, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 949, iters: 656, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 949, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 949, iters: 816, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 949, iters: 896, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 949, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 949, iters: 1056, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 949, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 949, iters: 1216, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 949, iters: 1296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 949, iters: 1376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 949, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 949, iters: 1536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 949, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 949, iters: 1696, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 949, iters: 1776, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 949, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 949, iters: 1936, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 949, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 949, iters: 2096, time: 0.094, data: 0.012) loss: 0.012 
(epoch: 949, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 949, iters: 2256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 949, iters: 2336, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 949, iters: 2416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 949, iters: 2496, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 949, iters: 2576, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 949, iters: 2656, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 949, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 949, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 949, iters: 2896, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 949, iters: 2976, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 949, iters: 3056, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 949, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 949, iters: 3216, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 949, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 949, iters: 3376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 949, iters: 3456, time: 0.097, data: 0.039) loss: 0.000 
(epoch: 949, iters: 3536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 949, iters: 3616, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 949, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 949, iters 3537872
End of epoch 949 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001150
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 949, TEST ACC: [97.269 %]

saving the latest model (epoch 950, total_steps 3537888)
(epoch: 950, iters: 48, time: 0.093, data: 0.004) loss: 0.000 
(epoch: 950, iters: 128, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 950, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 950, iters: 288, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 950, iters: 368, time: 0.096, data: 0.026) loss: 0.000 
(epoch: 950, iters: 448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 950, iters: 528, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 950, iters: 608, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 950, iters: 688, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 950, iters: 768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 950, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 950, iters: 928, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 950, iters: 1008, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 950, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 950, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 950, iters: 1248, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 950, iters: 1328, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 950, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 950, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 950, iters: 1568, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 950, iters: 1648, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 950, iters: 1728, time: 0.094, data: 0.000) loss: 0.037 
(epoch: 950, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 950, iters: 1888, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 950, iters: 1968, time: 0.092, data: 0.034) loss: 0.000 
(epoch: 950, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 950, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 950, iters: 2208, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 950, iters: 2288, time: 0.094, data: 0.034) loss: 0.000 
(epoch: 950, iters: 2368, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 950, iters: 2448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 950, iters: 2528, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 950, iters: 2608, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 950, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 950, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 950, iters: 2848, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 950, iters: 2928, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 950, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 950, iters: 3088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 950, iters: 3168, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 950, iters: 3248, time: 0.094, data: 0.025) loss: 0.025 
(epoch: 950, iters: 3328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 950, iters: 3408, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 950, iters: 3488, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 950, iters: 3568, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 950, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 950, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 950, iters 3541600
End of epoch 950 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001149
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 950, TEST ACC: [95.296 %]

saving the latest model (epoch 951, total_steps 3541616)
(epoch: 951, iters: 80, time: 0.093, data: 0.435) loss: 0.000 
(epoch: 951, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 951, iters: 240, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 951, iters: 320, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 951, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 951, iters: 480, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 951, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 951, iters: 640, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 951, iters: 720, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 951, iters: 800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 951, iters: 880, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 951, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 951, iters: 1040, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 951, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 951, iters: 1200, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 951, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 951, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 951, iters: 1440, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 951, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 951, iters: 1600, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 951, iters: 1680, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 951, iters: 1760, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 951, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 951, iters: 1920, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 951, iters: 2000, time: 0.093, data: 0.022) loss: 0.000 
(epoch: 951, iters: 2080, time: 0.092, data: 0.034) loss: 0.000 
(epoch: 951, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 951, iters: 2240, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 951, iters: 2320, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 951, iters: 2400, time: 0.092, data: 0.036) loss: 0.000 
(epoch: 951, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 951, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 951, iters: 2640, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 951, iters: 2720, time: 0.095, data: 0.035) loss: 0.000 
(epoch: 951, iters: 2800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 951, iters: 2880, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 951, iters: 2960, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 951, iters: 3040, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 951, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 951, iters: 3200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 951, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 951, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 951, iters: 3440, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 951, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 951, iters: 3600, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 951, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 951, iters 3545328
End of epoch 951 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001148
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 951, TEST ACC: [96.055 %]

saving the latest model (epoch 952, total_steps 3545344)
(epoch: 952, iters: 32, time: 0.092, data: 0.005) loss: 0.000 
(epoch: 952, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 952, iters: 192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 952, iters: 272, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 952, iters: 352, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 952, iters: 432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 952, iters: 512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 952, iters: 592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 952, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 952, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 952, iters: 832, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 952, iters: 912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 952, iters: 992, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 952, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 952, iters: 1152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 952, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 952, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 952, iters: 1392, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 952, iters: 1472, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 952, iters: 1552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 952, iters: 1632, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 952, iters: 1712, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 952, iters: 1792, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 952, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 952, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 952, iters: 2032, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 952, iters: 2112, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 952, iters: 2192, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 952, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 952, iters: 2352, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 952, iters: 2432, time: 0.093, data: 0.026) loss: 0.010 
(epoch: 952, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 952, iters: 2592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 952, iters: 2672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 952, iters: 2752, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 952, iters: 2832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 952, iters: 2912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 952, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 952, iters: 3072, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 952, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 952, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 952, iters: 3312, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 952, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 952, iters: 3472, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 952, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 952, iters: 3632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 952, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 952, iters 3549056
End of epoch 952 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001147
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 952, TEST ACC: [91.806 %]

saving the latest model (epoch 953, total_steps 3549072)
(epoch: 953, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 953, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 953, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 953, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 953, iters: 384, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 953, iters: 464, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 953, iters: 544, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 953, iters: 624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 953, iters: 704, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 953, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 953, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 953, iters: 944, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 953, iters: 1024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 953, iters: 1104, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 953, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 953, iters: 1264, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 953, iters: 1344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 953, iters: 1424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 953, iters: 1504, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 953, iters: 1584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 953, iters: 1664, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 953, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 953, iters: 1824, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 953, iters: 1904, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 953, iters: 1984, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 953, iters: 2064, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 953, iters: 2144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 953, iters: 2224, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 953, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 953, iters: 2384, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 953, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 953, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 953, iters: 2624, time: 0.094, data: 0.041) loss: 0.001 
(epoch: 953, iters: 2704, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 953, iters: 2784, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 953, iters: 2864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 953, iters: 2944, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 953, iters: 3024, time: 0.094, data: 0.025) loss: 0.002 
(epoch: 953, iters: 3104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 953, iters: 3184, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 953, iters: 3264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 953, iters: 3344, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 953, iters: 3424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 953, iters: 3504, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 953, iters: 3584, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 953, iters: 3664, time: 0.088, data: 0.025) loss: 0.081 
saving the model at the end of epoch 953, iters 3552784
End of epoch 953 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001146
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 953, TEST ACC: [91.958 %]

(epoch: 954, iters: 16, time: 0.112, data: 0.000) loss: 0.001 
saving the latest model (epoch 954, total_steps 3552800)
(epoch: 954, iters: 96, time: 0.097, data: 0.012) loss: 0.019 
(epoch: 954, iters: 176, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 954, iters: 256, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 954, iters: 336, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 954, iters: 416, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 954, iters: 496, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 954, iters: 576, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 954, iters: 656, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 954, iters: 736, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 954, iters: 816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 954, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 954, iters: 976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 954, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 954, iters: 1136, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 954, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 954, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 954, iters: 1376, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 954, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 954, iters: 1536, time: 0.093, data: 0.012) loss: 0.017 
(epoch: 954, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 954, iters: 1696, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 954, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 954, iters: 1856, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 954, iters: 1936, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 954, iters: 2016, time: 0.099, data: 0.000) loss: 0.000 
(epoch: 954, iters: 2096, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 954, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 954, iters: 2256, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 954, iters: 2336, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 954, iters: 2416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 954, iters: 2496, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 954, iters: 2576, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 954, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 954, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 954, iters: 2816, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 954, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 954, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 954, iters: 3056, time: 0.096, data: 0.048) loss: 0.000 
(epoch: 954, iters: 3136, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 954, iters: 3216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 954, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 954, iters: 3376, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 954, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 954, iters: 3536, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 954, iters: 3616, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 954, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 954, iters 3556512
End of epoch 954 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001145
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 954, TEST ACC: [96.813 %]

saving the latest model (epoch 955, total_steps 3556528)
(epoch: 955, iters: 48, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 955, iters: 128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 955, iters: 208, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 955, iters: 288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 955, iters: 368, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 955, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 955, iters: 528, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 955, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 955, iters: 688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 955, iters: 768, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 955, iters: 848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 955, iters: 928, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 955, iters: 1008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 955, iters: 1088, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 955, iters: 1168, time: 0.094, data: 0.000) loss: 0.005 
(epoch: 955, iters: 1248, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 955, iters: 1328, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 955, iters: 1408, time: 0.094, data: 0.027) loss: 0.043 
(epoch: 955, iters: 1488, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 955, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 955, iters: 1648, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 955, iters: 1728, time: 0.093, data: 0.036) loss: 0.000 
(epoch: 955, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 955, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 955, iters: 1968, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 955, iters: 2048, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 955, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 955, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 955, iters: 2288, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 955, iters: 2368, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 955, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 955, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 955, iters: 2608, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 955, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 955, iters: 2768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 955, iters: 2848, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 955, iters: 2928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 955, iters: 3008, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 955, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 955, iters: 3168, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 955, iters: 3248, time: 0.097, data: 0.000) loss: 0.020 
(epoch: 955, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 955, iters: 3408, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 955, iters: 3488, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 955, iters: 3568, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 955, iters: 3648, time: 0.087, data: 0.000) loss: 0.000 
(epoch: 955, iters: 3728, time: 0.056, data: 0.012) loss: 0.000 
saving the model at the end of epoch 955, iters 3560240
End of epoch 955 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001144
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 955, TEST ACC: [96.965 %]

saving the latest model (epoch 956, total_steps 3560256)
(epoch: 956, iters: 80, time: 0.094, data: 0.518) loss: 0.000 
(epoch: 956, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 956, iters: 240, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 956, iters: 320, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 956, iters: 400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 956, iters: 480, time: 0.094, data: 0.039) loss: 0.010 
(epoch: 956, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 956, iters: 640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 956, iters: 720, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 956, iters: 800, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 956, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 956, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 956, iters: 1040, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 956, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 956, iters: 1200, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 956, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 956, iters: 1360, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 956, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 956, iters: 1520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 956, iters: 1600, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 956, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 956, iters: 1760, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 956, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 956, iters: 1920, time: 0.094, data: 0.012) loss: 0.059 
(epoch: 956, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 956, iters: 2080, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 956, iters: 2160, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 956, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 956, iters: 2320, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 956, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 956, iters: 2480, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 956, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 956, iters: 2640, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 956, iters: 2720, time: 0.095, data: 0.049) loss: 0.003 
(epoch: 956, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 956, iters: 2880, time: 0.091, data: 0.012) loss: 0.001 
(epoch: 956, iters: 2960, time: 0.094, data: 0.000) loss: 0.006 
(epoch: 956, iters: 3040, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 956, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 956, iters: 3200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 956, iters: 3280, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 956, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 956, iters: 3440, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 956, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 956, iters: 3600, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 956, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 956, iters 3563968
End of epoch 956 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001143
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 956, TEST ACC: [95.751 %]

saving the latest model (epoch 957, total_steps 3563984)
(epoch: 957, iters: 32, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 957, iters: 112, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 957, iters: 192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 957, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 957, iters: 352, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 957, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 957, iters: 512, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 957, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 957, iters: 672, time: 0.094, data: 0.011) loss: 0.003 
(epoch: 957, iters: 752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 957, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 957, iters: 912, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 957, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 957, iters: 1072, time: 0.092, data: 0.020) loss: 0.000 
(epoch: 957, iters: 1152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 957, iters: 1232, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 957, iters: 1312, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 957, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 957, iters: 1472, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 957, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 957, iters: 1632, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 957, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 957, iters: 1792, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 957, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 957, iters: 1952, time: 0.092, data: 0.000) loss: 0.008 
(epoch: 957, iters: 2032, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 957, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 957, iters: 2192, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 957, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 957, iters: 2352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 957, iters: 2432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 957, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 957, iters: 2592, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 957, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 957, iters: 2752, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 957, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 957, iters: 2912, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 957, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 957, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 957, iters: 3152, time: 0.094, data: 0.048) loss: 0.003 
(epoch: 957, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 957, iters: 3312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 957, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 957, iters: 3472, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 957, iters: 3552, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 957, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 957, iters: 3712, time: 0.087, data: 0.035) loss: 0.000 
saving the model at the end of epoch 957, iters 3567696
End of epoch 957 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001142
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 957, TEST ACC: [96.662 %]

saving the latest model (epoch 958, total_steps 3567712)
(epoch: 958, iters: 64, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 958, iters: 144, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 958, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 958, iters: 304, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 958, iters: 384, time: 0.095, data: 0.000) loss: 0.050 
(epoch: 958, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 958, iters: 544, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 958, iters: 624, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 958, iters: 704, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 958, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 958, iters: 864, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 958, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 958, iters: 1024, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 958, iters: 1104, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 958, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 958, iters: 1264, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 958, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 958, iters: 1424, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 958, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 958, iters: 1584, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 958, iters: 1664, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 958, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 958, iters: 1824, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 958, iters: 1904, time: 0.094, data: 0.000) loss: 0.056 
(epoch: 958, iters: 1984, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 958, iters: 2064, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 958, iters: 2144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 958, iters: 2224, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 958, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 958, iters: 2384, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 958, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 958, iters: 2544, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 958, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 958, iters: 2704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 958, iters: 2784, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 958, iters: 2864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 958, iters: 2944, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 958, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 958, iters: 3104, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 958, iters: 3184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 958, iters: 3264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 958, iters: 3344, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 958, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 958, iters: 3504, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 958, iters: 3584, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 958, iters: 3664, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 958, iters 3571424
End of epoch 958 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001141
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 958, TEST ACC: [92.261 %]

(epoch: 959, iters: 16, time: 0.108, data: 0.000) loss: 0.000 
saving the latest model (epoch 959, total_steps 3571440)
(epoch: 959, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 959, iters: 176, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 959, iters: 256, time: 0.094, data: 0.039) loss: 0.081 
(epoch: 959, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 959, iters: 416, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 959, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 959, iters: 576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 959, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 959, iters: 736, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 959, iters: 816, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 959, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 959, iters: 976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 959, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 959, iters: 1136, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 959, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 959, iters: 1296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 959, iters: 1376, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 959, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 959, iters: 1536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 959, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 959, iters: 1696, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 959, iters: 1776, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 959, iters: 1856, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 959, iters: 1936, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 959, iters: 2016, time: 0.093, data: 0.000) loss: 0.011 
(epoch: 959, iters: 2096, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 959, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 959, iters: 2256, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 959, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 959, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 959, iters: 2496, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 959, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 959, iters: 2656, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 959, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 959, iters: 2816, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 959, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 959, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 959, iters: 3056, time: 0.093, data: 0.035) loss: 0.000 
(epoch: 959, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 959, iters: 3216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 959, iters: 3296, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 959, iters: 3376, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 959, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 959, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 959, iters: 3616, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 959, iters: 3696, time: 0.088, data: 0.026) loss: 0.000 
saving the model at the end of epoch 959, iters 3575152
End of epoch 959 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001140
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 959, TEST ACC: [96.51 %]

saving the latest model (epoch 960, total_steps 3575168)
(epoch: 960, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 960, iters: 128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 208, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 960, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 960, iters: 448, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 960, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 608, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 960, iters: 688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 768, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 960, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 1008, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 960, iters: 1088, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 960, iters: 1168, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 960, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 1328, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 960, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 960, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 1568, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 960, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 1728, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 960, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 1888, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 960, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 960, iters: 2128, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 960, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 2288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 960, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 2448, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 960, iters: 2528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 960, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 960, iters: 2688, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 960, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 960, iters: 2848, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 960, iters: 2928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 3008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 960, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 3168, time: 0.092, data: 0.000) loss: 0.035 
(epoch: 960, iters: 3248, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 960, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 960, iters: 3408, time: 0.091, data: 0.011) loss: 0.020 
(epoch: 960, iters: 3488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 960, iters: 3568, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 960, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 960, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 960, iters 3578880
End of epoch 960 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001139
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 960, TEST ACC: [96.51 %]

saving the latest model (epoch 961, total_steps 3578896)
(epoch: 961, iters: 80, time: 0.096, data: 0.510) loss: 0.000 
(epoch: 961, iters: 160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 961, iters: 240, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 961, iters: 320, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 961, iters: 400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 961, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 961, iters: 560, time: 0.093, data: 0.019) loss: 0.000 
(epoch: 961, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 961, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 961, iters: 800, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 961, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 961, iters: 960, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 961, iters: 1040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 961, iters: 1120, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 961, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 961, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 961, iters: 1360, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 961, iters: 1440, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 961, iters: 1520, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 961, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 961, iters: 1680, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 961, iters: 1760, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 961, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 961, iters: 1920, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 961, iters: 2000, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 961, iters: 2080, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 961, iters: 2160, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 961, iters: 2240, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 961, iters: 2320, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 961, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 961, iters: 2480, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 961, iters: 2560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 961, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 961, iters: 2720, time: 0.097, data: 0.040) loss: 0.015 
(epoch: 961, iters: 2800, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 961, iters: 2880, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 961, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 961, iters: 3040, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 961, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 961, iters: 3200, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 961, iters: 3280, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 961, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 961, iters: 3440, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 961, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 961, iters: 3600, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 961, iters: 3680, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 961, iters 3582608
End of epoch 961 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001138
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 961, TEST ACC: [97.269 %]

saving the latest model (epoch 962, total_steps 3582624)
(epoch: 962, iters: 32, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 962, iters: 112, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 962, iters: 192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 962, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 962, iters: 352, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 962, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 962, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 592, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 962, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 962, iters: 752, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 962, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 912, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 962, iters: 992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 962, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 1152, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 962, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 1312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 962, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 962, iters: 1472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 962, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 1712, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 962, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 1872, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 962, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 2032, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 962, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 2192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 962, iters: 2272, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 962, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 962, iters: 2432, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 962, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 2592, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 962, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 2832, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 962, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 962, iters: 2992, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 962, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 3152, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 962, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 3312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 962, iters: 3392, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 962, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 962, iters: 3552, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 962, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 962, iters: 3712, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 962, iters 3586336
End of epoch 962 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001137
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 962, TEST ACC: [96.965 %]

saving the latest model (epoch 963, total_steps 3586352)
(epoch: 963, iters: 64, time: 0.092, data: 0.003) loss: 0.000 
(epoch: 963, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 963, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 963, iters: 304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 963, iters: 384, time: 0.094, data: 0.040) loss: 0.001 
(epoch: 963, iters: 464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 963, iters: 544, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 963, iters: 624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 963, iters: 704, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 963, iters: 784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 963, iters: 864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 963, iters: 944, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 963, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 963, iters: 1104, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 963, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 963, iters: 1264, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 963, iters: 1344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 963, iters: 1424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 963, iters: 1504, time: 0.095, data: 0.039) loss: 0.001 
(epoch: 963, iters: 1584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 963, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 963, iters: 1744, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 963, iters: 1824, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 963, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 963, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 963, iters: 2064, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 963, iters: 2144, time: 0.092, data: 0.025) loss: 0.001 
(epoch: 963, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 963, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 963, iters: 2384, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 963, iters: 2464, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 963, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 963, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 963, iters: 2704, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 963, iters: 2784, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 963, iters: 2864, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 963, iters: 2944, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 963, iters: 3024, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 963, iters: 3104, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 963, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 963, iters: 3264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 963, iters: 3344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 963, iters: 3424, time: 0.091, data: 0.026) loss: 0.000 
(epoch: 963, iters: 3504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 963, iters: 3584, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 963, iters: 3664, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 963, iters 3590064
End of epoch 963 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001136
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 963, TEST ACC: [96.965 %]

(epoch: 964, iters: 16, time: 0.112, data: 0.012) loss: 0.000 
saving the latest model (epoch 964, total_steps 3590080)
(epoch: 964, iters: 96, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 964, iters: 176, time: 0.095, data: 0.012) loss: 0.028 
(epoch: 964, iters: 256, time: 0.094, data: 0.029) loss: 0.001 
(epoch: 964, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 964, iters: 416, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 964, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 964, iters: 576, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 964, iters: 656, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 964, iters: 736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 964, iters: 816, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 964, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 964, iters: 976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 964, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 964, iters: 1136, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 964, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 964, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 964, iters: 1376, time: 0.095, data: 0.038) loss: 0.000 
(epoch: 964, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 964, iters: 1536, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 964, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 964, iters: 1696, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 964, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 964, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 964, iters: 1936, time: 0.095, data: 0.040) loss: 0.002 
(epoch: 964, iters: 2016, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 964, iters: 2096, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 964, iters: 2176, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 964, iters: 2256, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 964, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 964, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 964, iters: 2496, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 964, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 964, iters: 2656, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 964, iters: 2736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 964, iters: 2816, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 964, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 964, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 964, iters: 3056, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 964, iters: 3136, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 964, iters: 3216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 964, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 964, iters: 3376, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 964, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 964, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 964, iters: 3616, time: 0.095, data: 0.038) loss: 0.008 
(epoch: 964, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 964, iters 3593792
End of epoch 964 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001135
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 964, TEST ACC: [96.055 %]

saving the latest model (epoch 965, total_steps 3593808)
(epoch: 965, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 965, iters: 128, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 965, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 965, iters: 288, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 965, iters: 368, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 965, iters: 448, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 965, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 965, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 965, iters: 688, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 965, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 965, iters: 848, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 965, iters: 928, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 965, iters: 1008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 965, iters: 1088, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 965, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 965, iters: 1248, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 965, iters: 1328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 965, iters: 1408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 965, iters: 1488, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 965, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 965, iters: 1648, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 965, iters: 1728, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 965, iters: 1808, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 965, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 965, iters: 1968, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 965, iters: 2048, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 965, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 965, iters: 2208, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 965, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 965, iters: 2368, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 965, iters: 2448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 965, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 965, iters: 2608, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 965, iters: 2688, time: 0.096, data: 0.000) loss: 0.019 
(epoch: 965, iters: 2768, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 965, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 965, iters: 2928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 965, iters: 3008, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 965, iters: 3088, time: 0.092, data: 0.033) loss: 0.000 
(epoch: 965, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 965, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 965, iters: 3328, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 965, iters: 3408, time: 0.093, data: 0.034) loss: 0.000 
(epoch: 965, iters: 3488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 965, iters: 3568, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 965, iters: 3648, time: 0.089, data: 0.012) loss: 0.000 
(epoch: 965, iters: 3728, time: 0.057, data: 0.018) loss: 0.000 
saving the model at the end of epoch 965, iters 3597520
End of epoch 965 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001134
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 965, TEST ACC: [96.662 %]

saving the latest model (epoch 966, total_steps 3597536)
(epoch: 966, iters: 80, time: 0.096, data: 0.517) loss: 0.000 
(epoch: 966, iters: 160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 966, iters: 240, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 966, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 966, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 966, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 966, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 966, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 966, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 966, iters: 800, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 966, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 966, iters: 960, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 966, iters: 1040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 966, iters: 1120, time: 0.094, data: 0.019) loss: 0.000 
(epoch: 966, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 966, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 966, iters: 1360, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 966, iters: 1440, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 966, iters: 1520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 966, iters: 1600, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 966, iters: 1680, time: 0.096, data: 0.011) loss: 0.003 
(epoch: 966, iters: 1760, time: 0.094, data: 0.037) loss: 0.000 
(epoch: 966, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 966, iters: 1920, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 966, iters: 2000, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 966, iters: 2080, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 966, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 966, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 966, iters: 2320, time: 0.094, data: 0.011) loss: 0.002 
(epoch: 966, iters: 2400, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 966, iters: 2480, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 966, iters: 2560, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 966, iters: 2640, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 966, iters: 2720, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 966, iters: 2800, time: 0.096, data: 0.000) loss: 0.010 
(epoch: 966, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 966, iters: 2960, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 966, iters: 3040, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 966, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 966, iters: 3200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 966, iters: 3280, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 966, iters: 3360, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 966, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 966, iters: 3520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 966, iters: 3600, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 966, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 966, iters 3601248
End of epoch 966 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001133
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 966, TEST ACC: [95.448 %]

saving the latest model (epoch 967, total_steps 3601264)
(epoch: 967, iters: 32, time: 0.095, data: 0.008) loss: 0.000 
(epoch: 967, iters: 112, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 967, iters: 192, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 967, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 967, iters: 352, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 967, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 967, iters: 512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 967, iters: 592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 967, iters: 672, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 967, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 967, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 967, iters: 912, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 967, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 967, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 967, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 967, iters: 1232, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 967, iters: 1312, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 967, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 967, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 967, iters: 1552, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 967, iters: 1632, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 967, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 967, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 967, iters: 1872, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 967, iters: 1952, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 967, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 967, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 967, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 967, iters: 2272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 967, iters: 2352, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 967, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 967, iters: 2512, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 967, iters: 2592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 967, iters: 2672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 967, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 967, iters: 2832, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 967, iters: 2912, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 967, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 967, iters: 3072, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 967, iters: 3152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 967, iters: 3232, time: 0.097, data: 0.012) loss: 0.004 
(epoch: 967, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 967, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 967, iters: 3472, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 967, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 967, iters: 3632, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 967, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 967, iters 3604976
End of epoch 967 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001132
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 967, TEST ACC: [94.385 %]

saving the latest model (epoch 968, total_steps 3604992)
(epoch: 968, iters: 64, time: 0.092, data: 0.003) loss: 0.001 
(epoch: 968, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 968, iters: 224, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 968, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 968, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 968, iters: 464, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 968, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 968, iters: 624, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 968, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 968, iters: 784, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 968, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 968, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 968, iters: 1024, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 968, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 968, iters: 1184, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 968, iters: 1264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 968, iters: 1344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 968, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 968, iters: 1504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 968, iters: 1584, time: 0.095, data: 0.047) loss: 0.000 
(epoch: 968, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 968, iters: 1744, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 968, iters: 1824, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 968, iters: 1904, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 968, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 968, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 968, iters: 2144, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 968, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 968, iters: 2304, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 968, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 968, iters: 2464, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 968, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 968, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 968, iters: 2704, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 968, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 968, iters: 2864, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 968, iters: 2944, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 968, iters: 3024, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 968, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 968, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 968, iters: 3264, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 968, iters: 3344, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 968, iters: 3424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 968, iters: 3504, time: 0.095, data: 0.000) loss: 0.021 
(epoch: 968, iters: 3584, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 968, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 968, iters 3608704
End of epoch 968 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001131
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 968, TEST ACC: [95.751 %]

(epoch: 969, iters: 16, time: 0.117, data: 0.000) loss: 0.000 
saving the latest model (epoch 969, total_steps 3608720)
(epoch: 969, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 969, iters: 176, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 969, iters: 256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 969, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 969, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 969, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 969, iters: 576, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 969, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 969, iters: 736, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 969, iters: 816, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 969, iters: 896, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 969, iters: 976, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 969, iters: 1056, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 969, iters: 1136, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 969, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 969, iters: 1296, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 969, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 969, iters: 1456, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 969, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 969, iters: 1616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 969, iters: 1696, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 969, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 969, iters: 1856, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 969, iters: 1936, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 969, iters: 2016, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 969, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 969, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 969, iters: 2256, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 969, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 969, iters: 2416, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 969, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 969, iters: 2576, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 969, iters: 2656, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 969, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 969, iters: 2816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 969, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 969, iters: 2976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 969, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 969, iters: 3136, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 969, iters: 3216, time: 0.095, data: 0.000) loss: 0.052 
(epoch: 969, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 969, iters: 3376, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 969, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 969, iters: 3536, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 969, iters: 3616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 969, iters: 3696, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 969, iters 3612432
End of epoch 969 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001130
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 969, TEST ACC: [97.117 %]

saving the latest model (epoch 970, total_steps 3612448)
(epoch: 970, iters: 48, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 970, iters: 128, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 970, iters: 208, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 970, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 970, iters: 368, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 970, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 970, iters: 528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 970, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 970, iters: 688, time: 0.095, data: 0.020) loss: 0.001 
(epoch: 970, iters: 768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 970, iters: 848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 970, iters: 928, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 970, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 970, iters: 1088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 970, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 970, iters: 1248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 970, iters: 1328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 970, iters: 1408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 970, iters: 1488, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 970, iters: 1568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 970, iters: 1648, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 970, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 970, iters: 1808, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 970, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 970, iters: 1968, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 970, iters: 2048, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 970, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 970, iters: 2208, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 970, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 970, iters: 2368, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 970, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 970, iters: 2528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 970, iters: 2608, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 970, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 970, iters: 2768, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 970, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 970, iters: 2928, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 970, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 970, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 970, iters: 3168, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 970, iters: 3248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 970, iters: 3328, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 970, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 970, iters: 3488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 970, iters: 3568, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 970, iters: 3648, time: 0.088, data: 0.012) loss: 0.000 
(epoch: 970, iters: 3728, time: 0.056, data: 0.011) loss: 0.000 
saving the model at the end of epoch 970, iters 3616160
End of epoch 970 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001129
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 970, TEST ACC: [96.358 %]

saving the latest model (epoch 971, total_steps 3616176)
(epoch: 971, iters: 80, time: 0.093, data: 0.484) loss: 0.000 
(epoch: 971, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 971, iters: 240, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 971, iters: 320, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 971, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 971, iters: 480, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 971, iters: 560, time: 0.094, data: 0.029) loss: 0.000 
(epoch: 971, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 971, iters: 720, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 971, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 971, iters: 880, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 971, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 971, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 971, iters: 1120, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 971, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 971, iters: 1280, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 971, iters: 1360, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 971, iters: 1440, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 971, iters: 1520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 971, iters: 1600, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 971, iters: 1680, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 971, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 971, iters: 1840, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 971, iters: 1920, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 971, iters: 2000, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 971, iters: 2080, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 971, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 971, iters: 2240, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 971, iters: 2320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 971, iters: 2400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 971, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 971, iters: 2560, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 971, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 971, iters: 2720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 971, iters: 2800, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 971, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 971, iters: 2960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 971, iters: 3040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 971, iters: 3120, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 971, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 971, iters: 3280, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 971, iters: 3360, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 971, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 971, iters: 3520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 971, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 971, iters: 3680, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 971, iters 3619888
End of epoch 971 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001128
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 971, TEST ACC: [97.42 %]

saving the latest model (epoch 972, total_steps 3619904)
(epoch: 972, iters: 32, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 972, iters: 112, time: 0.094, data: 0.028) loss: 0.000 
(epoch: 972, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 972, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 972, iters: 352, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 972, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 972, iters: 512, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 972, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 972, iters: 672, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 972, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 972, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 972, iters: 912, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 972, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 972, iters: 1072, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 972, iters: 1152, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 972, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 972, iters: 1312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 972, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 972, iters: 1472, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 972, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 972, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 972, iters: 1712, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 972, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 972, iters: 1872, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 972, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 972, iters: 2032, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 972, iters: 2112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 972, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 972, iters: 2272, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 972, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 972, iters: 2432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 972, iters: 2512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 972, iters: 2592, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 972, iters: 2672, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 972, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 972, iters: 2832, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 972, iters: 2912, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 972, iters: 2992, time: 0.094, data: 0.013) loss: 0.012 
(epoch: 972, iters: 3072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 972, iters: 3152, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 972, iters: 3232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 972, iters: 3312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 972, iters: 3392, time: 0.095, data: 0.039) loss: 0.002 
(epoch: 972, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 972, iters: 3552, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 972, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 972, iters: 3712, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 972, iters 3623616
End of epoch 972 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001127
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 972, TEST ACC: [94.537 %]

saving the latest model (epoch 973, total_steps 3623632)
(epoch: 973, iters: 64, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 973, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 973, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 973, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 973, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 973, iters: 464, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 973, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 973, iters: 624, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 973, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 973, iters: 784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 973, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 973, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 973, iters: 1024, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 973, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 973, iters: 1184, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 973, iters: 1264, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 973, iters: 1344, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 973, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 973, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 973, iters: 1584, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 973, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 973, iters: 1744, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 973, iters: 1824, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 973, iters: 1904, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 973, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 973, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 973, iters: 2144, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 973, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 973, iters: 2304, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 973, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 973, iters: 2464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 973, iters: 2544, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 973, iters: 2624, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 973, iters: 2704, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 973, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 973, iters: 2864, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 973, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 973, iters: 3024, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 973, iters: 3104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 973, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 973, iters: 3264, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 973, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 973, iters: 3424, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 973, iters: 3504, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 973, iters: 3584, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 973, iters: 3664, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 973, iters 3627344
End of epoch 973 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001126
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 973, TEST ACC: [95.448 %]

(epoch: 974, iters: 16, time: 0.109, data: 0.000) loss: 0.000 
saving the latest model (epoch 974, total_steps 3627360)
(epoch: 974, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 974, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 974, iters: 256, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 974, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 974, iters: 416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 974, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 974, iters: 576, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 974, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 974, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 974, iters: 816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 974, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 974, iters: 976, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 974, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 974, iters: 1136, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 974, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 974, iters: 1296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 974, iters: 1376, time: 0.095, data: 0.050) loss: 0.001 
(epoch: 974, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 974, iters: 1536, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 974, iters: 1616, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 974, iters: 1696, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 974, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 974, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 974, iters: 1936, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 974, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 974, iters: 2096, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 974, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 974, iters: 2256, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 974, iters: 2336, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 974, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 974, iters: 2496, time: 0.094, data: 0.042) loss: 0.001 
(epoch: 974, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 974, iters: 2656, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 974, iters: 2736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 974, iters: 2816, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 974, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 974, iters: 2976, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 974, iters: 3056, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 974, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 974, iters: 3216, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 974, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 974, iters: 3376, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 974, iters: 3456, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 974, iters: 3536, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 974, iters: 3616, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 974, iters: 3696, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 974, iters 3631072
End of epoch 974 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001125
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 974, TEST ACC: [97.117 %]

saving the latest model (epoch 975, total_steps 3631088)
(epoch: 975, iters: 48, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 975, iters: 128, time: 0.094, data: 0.026) loss: 0.026 
(epoch: 975, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 975, iters: 288, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 975, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 975, iters: 448, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 975, iters: 528, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 975, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 975, iters: 688, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 975, iters: 768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 975, iters: 848, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 975, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 975, iters: 1008, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 975, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 975, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 975, iters: 1248, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 975, iters: 1328, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 975, iters: 1408, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 975, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 975, iters: 1568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 975, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 975, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 975, iters: 1808, time: 0.093, data: 0.049) loss: 0.000 
(epoch: 975, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 975, iters: 1968, time: 0.092, data: 0.012) loss: 0.007 
(epoch: 975, iters: 2048, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 975, iters: 2128, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 975, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 975, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 975, iters: 2368, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 975, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 975, iters: 2528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 975, iters: 2608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 975, iters: 2688, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 975, iters: 2768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 975, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 975, iters: 2928, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 975, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 975, iters: 3088, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 975, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 975, iters: 3248, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 975, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 975, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 975, iters: 3488, time: 0.095, data: 0.040) loss: 0.001 
(epoch: 975, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 975, iters: 3648, time: 0.087, data: 0.011) loss: 0.000 
(epoch: 975, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 975, iters 3634800
End of epoch 975 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001124
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 975, TEST ACC: [97.876 %]

saving the latest model (epoch 976, total_steps 3634816)
(epoch: 976, iters: 80, time: 0.095, data: 0.508) loss: 0.000 
(epoch: 976, iters: 160, time: 0.095, data: 0.031) loss: 0.000 
(epoch: 976, iters: 240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 976, iters: 320, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 976, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 976, iters: 480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 976, iters: 560, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 976, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 976, iters: 720, time: 0.096, data: 0.040) loss: 0.004 
(epoch: 976, iters: 800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 976, iters: 880, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 976, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 976, iters: 1040, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 976, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 976, iters: 1200, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 976, iters: 1280, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 976, iters: 1360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 976, iters: 1440, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 976, iters: 1520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 976, iters: 1600, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 976, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 976, iters: 1760, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 976, iters: 1840, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 976, iters: 1920, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 976, iters: 2000, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 976, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 976, iters: 2160, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 976, iters: 2240, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 976, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 976, iters: 2400, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 976, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 976, iters: 2560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 976, iters: 2640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 976, iters: 2720, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 976, iters: 2800, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 976, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 976, iters: 2960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 976, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 976, iters: 3120, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 976, iters: 3200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 976, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 976, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 976, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 976, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 976, iters: 3600, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 976, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 976, iters 3638528
End of epoch 976 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001123
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 976, TEST ACC: [97.724 %]

saving the latest model (epoch 977, total_steps 3638544)
(epoch: 977, iters: 32, time: 0.092, data: 0.005) loss: 0.000 
(epoch: 977, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 977, iters: 192, time: 0.095, data: 0.020) loss: 0.000 
(epoch: 977, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 977, iters: 352, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 977, iters: 432, time: 0.097, data: 0.039) loss: 0.088 
(epoch: 977, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 977, iters: 592, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 977, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 977, iters: 752, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 977, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 977, iters: 912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 977, iters: 992, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 977, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 977, iters: 1152, time: 0.092, data: 0.022) loss: 0.000 
(epoch: 977, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 977, iters: 1312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 977, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 977, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 977, iters: 1552, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 977, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 977, iters: 1712, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 977, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 977, iters: 1872, time: 0.093, data: 0.020) loss: 0.001 
(epoch: 977, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 977, iters: 2032, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 977, iters: 2112, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 977, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 977, iters: 2272, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 977, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 977, iters: 2432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 977, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 977, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 977, iters: 2672, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 977, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 977, iters: 2832, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 977, iters: 2912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 977, iters: 2992, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 977, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 977, iters: 3152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 977, iters: 3232, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 977, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 977, iters: 3392, time: 0.093, data: 0.011) loss: 0.013 
(epoch: 977, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 977, iters: 3552, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 977, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 977, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 977, iters 3642256
End of epoch 977 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001122
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 977, TEST ACC: [96.358 %]

saving the latest model (epoch 978, total_steps 3642272)
(epoch: 978, iters: 64, time: 0.092, data: 0.002) loss: 0.000 
(epoch: 978, iters: 144, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 978, iters: 224, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 978, iters: 304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 978, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 978, iters: 464, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 978, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 978, iters: 624, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 978, iters: 704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 978, iters: 784, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 978, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 978, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 978, iters: 1024, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 978, iters: 1104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 978, iters: 1184, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 978, iters: 1264, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 978, iters: 1344, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 978, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 978, iters: 1504, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 978, iters: 1584, time: 0.093, data: 0.000) loss: 0.003 
(epoch: 978, iters: 1664, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 978, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 978, iters: 1824, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 978, iters: 1904, time: 0.095, data: 0.000) loss: 0.065 
(epoch: 978, iters: 1984, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 978, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 978, iters: 2144, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 978, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 978, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 978, iters: 2384, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 978, iters: 2464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 978, iters: 2544, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 978, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 978, iters: 2704, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 978, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 978, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 978, iters: 2944, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 978, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 978, iters: 3104, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 978, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 978, iters: 3264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 978, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 978, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 978, iters: 3504, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 978, iters: 3584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 978, iters: 3664, time: 0.087, data: 0.013) loss: 0.000 
saving the model at the end of epoch 978, iters 3645984
End of epoch 978 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001121
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 978, TEST ACC: [96.358 %]

(epoch: 979, iters: 16, time: 0.111, data: 0.021) loss: 0.000 
saving the latest model (epoch 979, total_steps 3646000)
(epoch: 979, iters: 96, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 979, iters: 176, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 979, iters: 256, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 979, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 979, iters: 416, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 979, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 979, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 979, iters: 656, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 979, iters: 736, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 979, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 979, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 979, iters: 976, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 979, iters: 1056, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 979, iters: 1136, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 979, iters: 1216, time: 0.095, data: 0.000) loss: 0.009 
(epoch: 979, iters: 1296, time: 0.094, data: 0.012) loss: 0.075 
(epoch: 979, iters: 1376, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 979, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 979, iters: 1536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 979, iters: 1616, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 979, iters: 1696, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 979, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 979, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 979, iters: 1936, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 979, iters: 2016, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 979, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 979, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 979, iters: 2256, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 979, iters: 2336, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 979, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 979, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 979, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 979, iters: 2656, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 979, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 979, iters: 2816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 979, iters: 2896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 979, iters: 2976, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 979, iters: 3056, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 979, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 979, iters: 3216, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 979, iters: 3296, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 979, iters: 3376, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 979, iters: 3456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 979, iters: 3536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 979, iters: 3616, time: 0.093, data: 0.036) loss: 0.002 
(epoch: 979, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 979, iters 3649712
End of epoch 979 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001120
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 979, TEST ACC: [94.234 %]

saving the latest model (epoch 980, total_steps 3649728)
(epoch: 980, iters: 48, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 980, iters: 128, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 980, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 980, iters: 288, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 980, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 980, iters: 448, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 980, iters: 528, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 980, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 980, iters: 688, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 980, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 980, iters: 848, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 980, iters: 928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 980, iters: 1008, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 980, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 980, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 980, iters: 1248, time: 0.095, data: 0.047) loss: 0.000 
(epoch: 980, iters: 1328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 980, iters: 1408, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 980, iters: 1488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 980, iters: 1568, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 980, iters: 1648, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 980, iters: 1728, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 980, iters: 1808, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 980, iters: 1888, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 980, iters: 1968, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 980, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 980, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 980, iters: 2208, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 980, iters: 2288, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 980, iters: 2368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 980, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 980, iters: 2528, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 980, iters: 2608, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 980, iters: 2688, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 980, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 980, iters: 2848, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 980, iters: 2928, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 980, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 980, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 980, iters: 3168, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 980, iters: 3248, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 980, iters: 3328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 980, iters: 3408, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 980, iters: 3488, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 980, iters: 3568, time: 0.092, data: 0.036) loss: 0.000 
(epoch: 980, iters: 3648, time: 0.088, data: 0.000) loss: 0.034 
(epoch: 980, iters: 3728, time: 0.056, data: 0.000) loss: 0.001 
saving the model at the end of epoch 980, iters 3653440
End of epoch 980 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001119
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 980, TEST ACC: [96.51 %]

saving the latest model (epoch 981, total_steps 3653456)
(epoch: 981, iters: 80, time: 0.092, data: 0.557) loss: 0.000 
(epoch: 981, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 981, iters: 240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 981, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 981, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 981, iters: 480, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 981, iters: 560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 981, iters: 640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 981, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 981, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 981, iters: 880, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 981, iters: 960, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 981, iters: 1040, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 981, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 981, iters: 1200, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 981, iters: 1280, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 981, iters: 1360, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 981, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 981, iters: 1520, time: 0.092, data: 0.011) loss: 0.001 
(epoch: 981, iters: 1600, time: 0.093, data: 0.025) loss: 0.014 
(epoch: 981, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 981, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 981, iters: 1840, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 981, iters: 1920, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 981, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 981, iters: 2080, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 981, iters: 2160, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 981, iters: 2240, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 981, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 981, iters: 2400, time: 0.095, data: 0.000) loss: 0.054 
(epoch: 981, iters: 2480, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 981, iters: 2560, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 981, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 981, iters: 2720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 981, iters: 2800, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 981, iters: 2880, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 981, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 981, iters: 3040, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 981, iters: 3120, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 981, iters: 3200, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 981, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 981, iters: 3360, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 981, iters: 3440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 981, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 981, iters: 3600, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 981, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 981, iters 3657168
End of epoch 981 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001118
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 981, TEST ACC: [95.751 %]

saving the latest model (epoch 982, total_steps 3657184)
(epoch: 982, iters: 32, time: 0.093, data: 0.003) loss: 0.000 
(epoch: 982, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 982, iters: 192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 982, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 982, iters: 352, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 982, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 982, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 982, iters: 592, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 982, iters: 672, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 982, iters: 752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 982, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 982, iters: 912, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 982, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 982, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 982, iters: 1152, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 982, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 982, iters: 1312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 982, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 982, iters: 1472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 982, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 982, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 982, iters: 1712, time: 0.097, data: 0.050) loss: 0.000 
(epoch: 982, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 982, iters: 1872, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 982, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 982, iters: 2032, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 982, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 982, iters: 2192, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 982, iters: 2272, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 982, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 982, iters: 2432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 982, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 982, iters: 2592, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 982, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 982, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 982, iters: 2832, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 982, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 982, iters: 2992, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 982, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 982, iters: 3152, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 982, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 982, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 982, iters: 3392, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 982, iters: 3472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 982, iters: 3552, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 982, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 982, iters: 3712, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 982, iters 3660896
End of epoch 982 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001117
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 982, TEST ACC: [96.206 %]

saving the latest model (epoch 983, total_steps 3660912)
(epoch: 983, iters: 64, time: 0.092, data: 0.003) loss: 0.000 
(epoch: 983, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 983, iters: 224, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 983, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 983, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 983, iters: 464, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 983, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 983, iters: 624, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 983, iters: 704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 983, iters: 784, time: 0.093, data: 0.012) loss: 0.020 
(epoch: 983, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 983, iters: 944, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 983, iters: 1024, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 983, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 983, iters: 1184, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 983, iters: 1264, time: 0.094, data: 0.000) loss: 0.010 
(epoch: 983, iters: 1344, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 983, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 983, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 983, iters: 1584, time: 0.097, data: 0.049) loss: 0.000 
(epoch: 983, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 983, iters: 1744, time: 0.092, data: 0.011) loss: 0.097 
(epoch: 983, iters: 1824, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 983, iters: 1904, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 983, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 983, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 983, iters: 2144, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 983, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 983, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 983, iters: 2384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 983, iters: 2464, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 983, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 983, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 983, iters: 2704, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 983, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 983, iters: 2864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 983, iters: 2944, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 983, iters: 3024, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 983, iters: 3104, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 983, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 983, iters: 3264, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 983, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 983, iters: 3424, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 983, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 983, iters: 3584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 983, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 983, iters 3664624
End of epoch 983 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001116
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 983, TEST ACC: [91.958 %]

(epoch: 984, iters: 16, time: 0.110, data: 0.000) loss: 0.000 
saving the latest model (epoch 984, total_steps 3664640)
(epoch: 984, iters: 96, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 984, iters: 176, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 984, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 984, iters: 336, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 984, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 984, iters: 496, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 984, iters: 576, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 984, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 984, iters: 736, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 984, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 984, iters: 896, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 984, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 984, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 984, iters: 1136, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 984, iters: 1216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 984, iters: 1296, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 984, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 984, iters: 1456, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 984, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 984, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 984, iters: 1696, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 984, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 984, iters: 1856, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 984, iters: 1936, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 984, iters: 2016, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 984, iters: 2096, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 984, iters: 2176, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 984, iters: 2256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 984, iters: 2336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 984, iters: 2416, time: 0.097, data: 0.011) loss: 0.000 
(epoch: 984, iters: 2496, time: 0.095, data: 0.027) loss: 0.000 
(epoch: 984, iters: 2576, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 984, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 984, iters: 2736, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 984, iters: 2816, time: 0.092, data: 0.034) loss: 0.000 
(epoch: 984, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 984, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 984, iters: 3056, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 984, iters: 3136, time: 0.093, data: 0.034) loss: 0.000 
(epoch: 984, iters: 3216, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 984, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 984, iters: 3376, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 984, iters: 3456, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 984, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 984, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 984, iters: 3696, time: 0.087, data: 0.012) loss: 0.000 
saving the model at the end of epoch 984, iters 3668352
End of epoch 984 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001115
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 984, TEST ACC: [97.117 %]

saving the latest model (epoch 985, total_steps 3668368)
(epoch: 985, iters: 48, time: 0.093, data: 0.004) loss: 0.000 
(epoch: 985, iters: 128, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 985, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 985, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 985, iters: 368, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 985, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 985, iters: 528, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 985, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 985, iters: 688, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 985, iters: 768, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 985, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 985, iters: 928, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 985, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 985, iters: 1088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 985, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 985, iters: 1248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 985, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 985, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 985, iters: 1488, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 985, iters: 1568, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 985, iters: 1648, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 985, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 985, iters: 1808, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 985, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 985, iters: 1968, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 985, iters: 2048, time: 0.092, data: 0.047) loss: 0.000 
(epoch: 985, iters: 2128, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 985, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 985, iters: 2288, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 985, iters: 2368, time: 0.093, data: 0.036) loss: 0.000 
(epoch: 985, iters: 2448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 985, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 985, iters: 2608, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 985, iters: 2688, time: 0.093, data: 0.035) loss: 0.000 
(epoch: 985, iters: 2768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 985, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 985, iters: 2928, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 985, iters: 3008, time: 0.092, data: 0.035) loss: 0.000 
(epoch: 985, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 985, iters: 3168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 985, iters: 3248, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 985, iters: 3328, time: 0.094, data: 0.035) loss: 0.003 
(epoch: 985, iters: 3408, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 985, iters: 3488, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 985, iters: 3568, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 985, iters: 3648, time: 0.087, data: 0.034) loss: 0.000 
(epoch: 985, iters: 3728, time: 0.057, data: 0.000) loss: 0.000 
saving the model at the end of epoch 985, iters 3672080
End of epoch 985 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001114
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 985, TEST ACC: [97.269 %]

saving the latest model (epoch 986, total_steps 3672096)
(epoch: 986, iters: 80, time: 0.095, data: 0.527) loss: 0.000 
(epoch: 986, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 986, iters: 240, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 986, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 986, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 986, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 986, iters: 560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 986, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 986, iters: 720, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 986, iters: 800, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 986, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 986, iters: 960, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 986, iters: 1040, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 986, iters: 1120, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 986, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 986, iters: 1280, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 986, iters: 1360, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 986, iters: 1440, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 986, iters: 1520, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 986, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 986, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 986, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 986, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 986, iters: 1920, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 986, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 986, iters: 2080, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 986, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 986, iters: 2240, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 986, iters: 2320, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 986, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 986, iters: 2480, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 986, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 986, iters: 2640, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 986, iters: 2720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 986, iters: 2800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 986, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 986, iters: 2960, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 986, iters: 3040, time: 0.093, data: 0.050) loss: 0.000 
(epoch: 986, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 986, iters: 3200, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 986, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 986, iters: 3360, time: 0.093, data: 0.019) loss: 0.000 
(epoch: 986, iters: 3440, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 986, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 986, iters: 3600, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 986, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 986, iters 3675808
End of epoch 986 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001113
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 986, TEST ACC: [96.965 %]

saving the latest model (epoch 987, total_steps 3675824)
(epoch: 987, iters: 32, time: 0.094, data: 0.005) loss: 0.000 
(epoch: 987, iters: 112, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 987, iters: 192, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 987, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 987, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 987, iters: 432, time: 0.096, data: 0.052) loss: 0.000 
(epoch: 987, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 987, iters: 592, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 987, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 987, iters: 752, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 987, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 987, iters: 912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 987, iters: 992, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 987, iters: 1072, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 987, iters: 1152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 987, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 987, iters: 1312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 987, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 987, iters: 1472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 987, iters: 1552, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 987, iters: 1632, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 987, iters: 1712, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 987, iters: 1792, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 987, iters: 1872, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 987, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 987, iters: 2032, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 987, iters: 2112, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 987, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 987, iters: 2272, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 987, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 987, iters: 2432, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 987, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 987, iters: 2592, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 987, iters: 2672, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 987, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 987, iters: 2832, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 987, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 987, iters: 2992, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 987, iters: 3072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 987, iters: 3152, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 987, iters: 3232, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 987, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 987, iters: 3392, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 987, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 987, iters: 3552, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 987, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 987, iters: 3712, time: 0.091, data: 0.000) loss: 0.000 
saving the model at the end of epoch 987, iters 3679536
End of epoch 987 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001112
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 987, TEST ACC: [95.903 %]

saving the latest model (epoch 988, total_steps 3679552)
(epoch: 988, iters: 64, time: 0.092, data: 0.004) loss: 0.000 
(epoch: 988, iters: 144, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 988, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 988, iters: 304, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 988, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 988, iters: 464, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 988, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 988, iters: 624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 988, iters: 704, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 988, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 988, iters: 864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 988, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 988, iters: 1024, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 988, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 988, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 988, iters: 1264, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 988, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 988, iters: 1424, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 988, iters: 1504, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 988, iters: 1584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 988, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 988, iters: 1744, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 988, iters: 1824, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 988, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 988, iters: 1984, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 988, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 988, iters: 2144, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 988, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 988, iters: 2304, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 988, iters: 2384, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 988, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 988, iters: 2544, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 988, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 988, iters: 2704, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 988, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 988, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 988, iters: 2944, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 988, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 988, iters: 3104, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 988, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 988, iters: 3264, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 988, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 988, iters: 3424, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 988, iters: 3504, time: 0.096, data: 0.048) loss: 0.000 
(epoch: 988, iters: 3584, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 988, iters: 3664, time: 0.087, data: 0.011) loss: 0.000 
saving the model at the end of epoch 988, iters 3683264
End of epoch 988 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001111
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 988, TEST ACC: [97.269 %]

(epoch: 989, iters: 16, time: 0.113, data: 0.013) loss: 0.000 
saving the latest model (epoch 989, total_steps 3683280)
(epoch: 989, iters: 96, time: 0.092, data: 0.024) loss: 0.000 
(epoch: 989, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 989, iters: 256, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 989, iters: 336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 989, iters: 416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 496, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 989, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 989, iters: 656, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 989, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 816, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 989, iters: 896, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 989, iters: 976, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 989, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 1216, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 989, iters: 1296, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 989, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 1456, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 989, iters: 1536, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 989, iters: 1616, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 989, iters: 1696, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 1856, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 989, iters: 1936, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 989, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 2096, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 989, iters: 2176, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 989, iters: 2256, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 989, iters: 2336, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 989, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 2576, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 989, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 989, iters: 2736, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 989, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 2896, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 989, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 3136, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 989, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 3296, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 989, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 3456, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 989, iters: 3536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 989, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 989, iters: 3696, time: 0.089, data: 0.041) loss: 0.000 
saving the model at the end of epoch 989, iters 3686992
End of epoch 989 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001110
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 989, TEST ACC: [97.269 %]

saving the latest model (epoch 990, total_steps 3687008)
(epoch: 990, iters: 48, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 990, iters: 128, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 990, iters: 208, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 990, iters: 288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 990, iters: 368, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 990, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 990, iters: 528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 990, iters: 608, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 990, iters: 688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 990, iters: 768, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 990, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 990, iters: 928, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 990, iters: 1008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 990, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 990, iters: 1168, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 990, iters: 1248, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 990, iters: 1328, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 990, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 990, iters: 1488, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 990, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 990, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 990, iters: 1728, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 990, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 990, iters: 1888, time: 0.094, data: 0.014) loss: 0.000 
(epoch: 990, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 990, iters: 2048, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 990, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 990, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 990, iters: 2288, time: 0.095, data: 0.052) loss: 0.000 
(epoch: 990, iters: 2368, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 990, iters: 2448, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 990, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 990, iters: 2608, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 990, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 990, iters: 2768, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 990, iters: 2848, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 990, iters: 2928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 990, iters: 3008, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 990, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 990, iters: 3168, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 990, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 990, iters: 3328, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 990, iters: 3408, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 990, iters: 3488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 990, iters: 3568, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 990, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 990, iters: 3728, time: 0.055, data: 0.012) loss: 0.000 
saving the model at the end of epoch 990, iters 3690720
End of epoch 990 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001109
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 990, TEST ACC: [97.572 %]

saving the latest model (epoch 991, total_steps 3690736)
(epoch: 991, iters: 80, time: 0.094, data: 0.445) loss: 0.000 
(epoch: 991, iters: 160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 991, iters: 240, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 991, iters: 320, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 991, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 991, iters: 480, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 991, iters: 560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 991, iters: 640, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 991, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 991, iters: 800, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 991, iters: 880, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 991, iters: 960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 991, iters: 1040, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 991, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 991, iters: 1200, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 991, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 991, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 991, iters: 1440, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 991, iters: 1520, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 991, iters: 1600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 991, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 991, iters: 1760, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 991, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 991, iters: 1920, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 991, iters: 2000, time: 0.093, data: 0.047) loss: 0.000 
(epoch: 991, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 991, iters: 2160, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 991, iters: 2240, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 991, iters: 2320, time: 0.093, data: 0.020) loss: 0.012 
(epoch: 991, iters: 2400, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 991, iters: 2480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 991, iters: 2560, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 991, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 991, iters: 2720, time: 0.091, data: 0.012) loss: 0.002 
(epoch: 991, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 991, iters: 2880, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 991, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 991, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 991, iters: 3120, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 991, iters: 3200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 991, iters: 3280, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 991, iters: 3360, time: 0.093, data: 0.034) loss: 0.002 
(epoch: 991, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 991, iters: 3520, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 991, iters: 3600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 991, iters: 3680, time: 0.088, data: 0.027) loss: 0.000 
saving the model at the end of epoch 991, iters 3694448
End of epoch 991 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001108
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 991, TEST ACC: [96.662 %]

saving the latest model (epoch 992, total_steps 3694464)
(epoch: 992, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 992, iters: 112, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 992, iters: 192, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 992, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 992, iters: 352, time: 0.096, data: 0.040) loss: 0.024 
(epoch: 992, iters: 432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 992, iters: 512, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 992, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 992, iters: 672, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 992, iters: 752, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 992, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 992, iters: 912, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 992, iters: 992, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 992, iters: 1072, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 992, iters: 1152, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 992, iters: 1232, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 992, iters: 1312, time: 0.096, data: 0.000) loss: 0.067 
(epoch: 992, iters: 1392, time: 0.096, data: 0.000) loss: 0.005 
(epoch: 992, iters: 1472, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 992, iters: 1552, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 992, iters: 1632, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 992, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 992, iters: 1792, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 992, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 992, iters: 1952, time: 0.096, data: 0.000) loss: 0.008 
(epoch: 992, iters: 2032, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 992, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 992, iters: 2192, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 992, iters: 2272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 992, iters: 2352, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 992, iters: 2432, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 992, iters: 2512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 992, iters: 2592, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 992, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 992, iters: 2752, time: 0.095, data: 0.021) loss: 0.000 
(epoch: 992, iters: 2832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 992, iters: 2912, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 992, iters: 2992, time: 0.094, data: 0.000) loss: 0.007 
(epoch: 992, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 992, iters: 3152, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 992, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 992, iters: 3312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 992, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 992, iters: 3472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 992, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 992, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 992, iters: 3712, time: 0.089, data: 0.035) loss: 0.000 
saving the model at the end of epoch 992, iters 3698176
End of epoch 992 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001107
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 992, TEST ACC: [97.572 %]

saving the latest model (epoch 993, total_steps 3698192)
(epoch: 993, iters: 64, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 993, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 993, iters: 224, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 993, iters: 304, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 993, iters: 384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 993, iters: 464, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 993, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 993, iters: 624, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 993, iters: 704, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 993, iters: 784, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 993, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 993, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 993, iters: 1024, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 993, iters: 1104, time: 0.097, data: 0.000) loss: 0.084 
(epoch: 993, iters: 1184, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 993, iters: 1264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 993, iters: 1344, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 993, iters: 1424, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 993, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 993, iters: 1584, time: 0.096, data: 0.041) loss: 0.012 
(epoch: 993, iters: 1664, time: 0.097, data: 0.000) loss: 0.109 
(epoch: 993, iters: 1744, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 993, iters: 1824, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 993, iters: 1904, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 993, iters: 1984, time: 0.098, data: 0.000) loss: 0.005 
(epoch: 993, iters: 2064, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 993, iters: 2144, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 993, iters: 2224, time: 0.098, data: 0.000) loss: 0.071 
(epoch: 993, iters: 2304, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 993, iters: 2384, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 993, iters: 2464, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 993, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 993, iters: 2624, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 993, iters: 2704, time: 0.096, data: 0.048) loss: 0.000 
(epoch: 993, iters: 2784, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 993, iters: 2864, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 993, iters: 2944, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 993, iters: 3024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 993, iters: 3104, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 993, iters: 3184, time: 0.096, data: 0.000) loss: 0.026 
(epoch: 993, iters: 3264, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 993, iters: 3344, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 993, iters: 3424, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 993, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 993, iters: 3584, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 993, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 993, iters 3701904
End of epoch 993 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001106
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 993, TEST ACC: [96.358 %]

(epoch: 994, iters: 16, time: 0.110, data: 0.000) loss: 0.000 
saving the latest model (epoch 994, total_steps 3701920)
(epoch: 994, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 994, iters: 176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 994, iters: 256, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 994, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 994, iters: 416, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 994, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 994, iters: 576, time: 0.095, data: 0.011) loss: 0.003 
(epoch: 994, iters: 656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 994, iters: 736, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 994, iters: 816, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 994, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 994, iters: 976, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 994, iters: 1056, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 994, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 994, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 994, iters: 1296, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 994, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 994, iters: 1456, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 994, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 994, iters: 1616, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 994, iters: 1696, time: 0.091, data: 0.026) loss: 0.000 
(epoch: 994, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 994, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 994, iters: 1936, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 994, iters: 2016, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 994, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 994, iters: 2176, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 994, iters: 2256, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 994, iters: 2336, time: 0.092, data: 0.036) loss: 0.000 
(epoch: 994, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 994, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 994, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 994, iters: 2656, time: 0.093, data: 0.034) loss: 0.000 
(epoch: 994, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 994, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 994, iters: 2896, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 994, iters: 2976, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 994, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 994, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 994, iters: 3216, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 994, iters: 3296, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 994, iters: 3376, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 994, iters: 3456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 994, iters: 3536, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 994, iters: 3616, time: 0.097, data: 0.026) loss: 0.000 
(epoch: 994, iters: 3696, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 994, iters 3705632
End of epoch 994 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001105
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 994, TEST ACC: [96.662 %]

saving the latest model (epoch 995, total_steps 3705648)
(epoch: 995, iters: 48, time: 0.097, data: 0.007) loss: 0.000 
(epoch: 995, iters: 128, time: 0.096, data: 0.027) loss: 0.000 
(epoch: 995, iters: 208, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 995, iters: 288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 995, iters: 368, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 995, iters: 448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 995, iters: 528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 995, iters: 608, time: 0.094, data: 0.048) loss: 0.011 
(epoch: 995, iters: 688, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 995, iters: 768, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 995, iters: 848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 995, iters: 928, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 995, iters: 1008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 995, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 995, iters: 1168, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 995, iters: 1248, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 995, iters: 1328, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 995, iters: 1408, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 995, iters: 1488, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 995, iters: 1568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 995, iters: 1648, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 995, iters: 1728, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 995, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 995, iters: 1888, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 995, iters: 1968, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 995, iters: 2048, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 995, iters: 2128, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 995, iters: 2208, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 995, iters: 2288, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 995, iters: 2368, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 995, iters: 2448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 995, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 995, iters: 2608, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 995, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 995, iters: 2768, time: 0.093, data: 0.000) loss: 0.070 
(epoch: 995, iters: 2848, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 995, iters: 2928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 995, iters: 3008, time: 0.092, data: 0.021) loss: 0.019 
(epoch: 995, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 995, iters: 3168, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 995, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 995, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 995, iters: 3408, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 995, iters: 3488, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 995, iters: 3568, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 995, iters: 3648, time: 0.089, data: 0.000) loss: 0.000 
(epoch: 995, iters: 3728, time: 0.057, data: 0.011) loss: 0.000 
saving the model at the end of epoch 995, iters 3709360
End of epoch 995 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001104
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 995, TEST ACC: [95.903 %]

saving the latest model (epoch 996, total_steps 3709376)
(epoch: 996, iters: 80, time: 0.093, data: 0.529) loss: 0.000 
(epoch: 996, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 996, iters: 240, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 996, iters: 320, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 996, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 996, iters: 480, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 996, iters: 560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 996, iters: 640, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 996, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 996, iters: 800, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 996, iters: 880, time: 0.094, data: 0.047) loss: 0.000 
(epoch: 996, iters: 960, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 996, iters: 1040, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 996, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 996, iters: 1200, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 996, iters: 1280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 996, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 996, iters: 1440, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 996, iters: 1520, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 996, iters: 1600, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 996, iters: 1680, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 996, iters: 1760, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 996, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 996, iters: 1920, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 996, iters: 2000, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 996, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 996, iters: 2160, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 996, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 996, iters: 2320, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 996, iters: 2400, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 996, iters: 2480, time: 0.094, data: 0.000) loss: 0.020 
(epoch: 996, iters: 2560, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 996, iters: 2640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 996, iters: 2720, time: 0.092, data: 0.012) loss: 0.003 
(epoch: 996, iters: 2800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 996, iters: 2880, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 996, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 996, iters: 3040, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 996, iters: 3120, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 996, iters: 3200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 996, iters: 3280, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 996, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 996, iters: 3440, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 996, iters: 3520, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 996, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 996, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 996, iters 3713088
End of epoch 996 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001103
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 996, TEST ACC: [96.662 %]

saving the latest model (epoch 997, total_steps 3713104)
(epoch: 997, iters: 32, time: 0.094, data: 0.005) loss: 0.000 
(epoch: 997, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 997, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 997, iters: 272, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 997, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 997, iters: 432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 997, iters: 512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 997, iters: 592, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 997, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 997, iters: 752, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 997, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 997, iters: 912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 997, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 997, iters: 1072, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 997, iters: 1152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 997, iters: 1232, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 997, iters: 1312, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 997, iters: 1392, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 997, iters: 1472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 997, iters: 1552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 997, iters: 1632, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 997, iters: 1712, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 997, iters: 1792, time: 0.094, data: 0.012) loss: 0.435 
(epoch: 997, iters: 1872, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 997, iters: 1952, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 997, iters: 2032, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 997, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 997, iters: 2192, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 997, iters: 2272, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 997, iters: 2352, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 997, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 997, iters: 2512, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 997, iters: 2592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 997, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 997, iters: 2752, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 997, iters: 2832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 997, iters: 2912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 997, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 997, iters: 3072, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 997, iters: 3152, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 997, iters: 3232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 997, iters: 3312, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 997, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 997, iters: 3472, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 997, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 997, iters: 3632, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 997, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 997, iters 3716816
End of epoch 997 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001102
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 997, TEST ACC: [94.234 %]

saving the latest model (epoch 998, total_steps 3716832)
(epoch: 998, iters: 64, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 998, iters: 144, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 998, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 998, iters: 304, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 998, iters: 384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 998, iters: 464, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 998, iters: 544, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 998, iters: 624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 998, iters: 704, time: 0.094, data: 0.012) loss: 0.001 
(epoch: 998, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 998, iters: 864, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 998, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 998, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 998, iters: 1104, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 998, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 998, iters: 1264, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 998, iters: 1344, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 998, iters: 1424, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 998, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 998, iters: 1584, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 998, iters: 1664, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 998, iters: 1744, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 998, iters: 1824, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 998, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 998, iters: 1984, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 998, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 998, iters: 2144, time: 0.094, data: 0.000) loss: 0.026 
(epoch: 998, iters: 2224, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 998, iters: 2304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 998, iters: 2384, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 998, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 998, iters: 2544, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 998, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 998, iters: 2704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 998, iters: 2784, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 998, iters: 2864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 998, iters: 2944, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 998, iters: 3024, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 998, iters: 3104, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 998, iters: 3184, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 998, iters: 3264, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 998, iters: 3344, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 998, iters: 3424, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 998, iters: 3504, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 998, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 998, iters: 3664, time: 0.087, data: 0.012) loss: 0.023 
saving the model at the end of epoch 998, iters 3720544
End of epoch 998 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001101
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 998, TEST ACC: [96.358 %]

(epoch: 999, iters: 16, time: 0.110, data: 0.000) loss: 0.000 
saving the latest model (epoch 999, total_steps 3720560)
(epoch: 999, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 999, iters: 176, time: 0.094, data: 0.012) loss: 0.016 
(epoch: 999, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 999, iters: 336, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 999, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 999, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 999, iters: 576, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 999, iters: 656, time: 0.097, data: 0.000) loss: 0.009 
(epoch: 999, iters: 736, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 999, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 999, iters: 896, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 999, iters: 976, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 999, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 999, iters: 1136, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 999, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 999, iters: 1296, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 999, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 999, iters: 1456, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 999, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 999, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 999, iters: 1696, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 999, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 999, iters: 1856, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 999, iters: 1936, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 999, iters: 2016, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 999, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 999, iters: 2176, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 999, iters: 2256, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 999, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 999, iters: 2416, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 999, iters: 2496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 999, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 999, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 999, iters: 2736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 999, iters: 2816, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 999, iters: 2896, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 999, iters: 2976, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 999, iters: 3056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 999, iters: 3136, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 999, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 999, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 999, iters: 3376, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 999, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 999, iters: 3536, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 999, iters: 3616, time: 0.094, data: 0.000) loss: 0.015 
(epoch: 999, iters: 3696, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 999, iters 3724272
End of epoch 999 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001100
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 999, TEST ACC: [96.813 %]

saving the latest model (epoch 1000, total_steps 3724288)
(epoch: 1000, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 128, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 1000, iters: 208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 368, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 1000, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 528, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1000, iters: 608, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 688, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1000, iters: 768, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 928, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 1000, iters: 1008, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 1088, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1000, iters: 1168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 1248, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1000, iters: 1328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 1408, time: 0.093, data: 0.000) loss: 0.006 
(epoch: 1000, iters: 1488, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 1000, iters: 1568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 1648, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1000, iters: 1728, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 1808, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1000, iters: 1888, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 2048, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 1000, iters: 2128, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 2208, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1000, iters: 2288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 2368, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1000, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 2608, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 1000, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 2768, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 1000, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 2928, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1000, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 3168, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 1000, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 3328, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1000, iters: 3408, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 3488, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1000, iters: 3568, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 1000, iters: 3728, time: 0.056, data: 0.023) loss: 0.000 
saving the model at the end of epoch 1000, iters 3728000
End of epoch 1000 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001099
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1000, TEST ACC: [91.199 %]

saving the latest model (epoch 1001, total_steps 3728016)
(epoch: 1001, iters: 80, time: 0.095, data: 0.572) loss: 0.000 
(epoch: 1001, iters: 160, time: 0.094, data: 0.030) loss: 0.000 
(epoch: 1001, iters: 240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 320, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1001, iters: 400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 480, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1001, iters: 560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 640, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 720, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 1001, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 880, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 960, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1001, iters: 1040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 1120, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1001, iters: 1200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 1280, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1001, iters: 1360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 1440, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 1520, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 1001, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 1680, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1001, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 1840, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1001, iters: 1920, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 2000, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 2080, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1001, iters: 2160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 2240, time: 0.092, data: 0.021) loss: 0.000 
(epoch: 1001, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 2400, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1001, iters: 2480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 2640, time: 0.095, data: 0.047) loss: 0.000 
(epoch: 1001, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 2800, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 1001, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 2960, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1001, iters: 3040, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 1001, iters: 3120, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 1001, iters: 3200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 3280, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 3360, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 1001, iters: 3440, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 1001, iters: 3520, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1001, iters: 3680, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 1001, iters 3731728
End of epoch 1001 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001098
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1001, TEST ACC: [97.117 %]

saving the latest model (epoch 1002, total_steps 3731744)
(epoch: 1002, iters: 32, time: 0.092, data: 0.007) loss: 0.000 
(epoch: 1002, iters: 112, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 1002, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 352, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1002, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 512, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1002, iters: 592, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 672, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1002, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 912, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 1002, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 1072, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1002, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 1232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1002, iters: 1312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 1472, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1002, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1002, iters: 1712, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 1792, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1002, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 2032, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1002, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 2192, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1002, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 2352, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1002, iters: 2432, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 2592, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1002, iters: 2672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 2752, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1002, iters: 2832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 2912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1002, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 3072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 3152, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 1002, iters: 3232, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 3312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1002, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 3472, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 1002, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1002, iters: 3712, time: 0.088, data: 0.036) loss: 0.000 
saving the model at the end of epoch 1002, iters 3735456
End of epoch 1002 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001097
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1002, TEST ACC: [97.269 %]

saving the latest model (epoch 1003, total_steps 3735472)
(epoch: 1003, iters: 64, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 384, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 464, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1003, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 624, time: 0.093, data: 0.011) loss: 0.001 
(epoch: 1003, iters: 704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 784, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1003, iters: 864, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 1024, time: 0.093, data: 0.046) loss: 0.000 
(epoch: 1003, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 1264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1003, iters: 1344, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 1003, iters: 1424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 1584, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1003, iters: 1664, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 1003, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 1904, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1003, iters: 1984, time: 0.093, data: 0.024) loss: 0.000 
(epoch: 1003, iters: 2064, time: 0.094, data: 0.000) loss: 0.002 
(epoch: 1003, iters: 2144, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 2224, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1003, iters: 2304, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 1003, iters: 2384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 2544, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1003, iters: 2624, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 1003, iters: 2704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 2864, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1003, iters: 2944, time: 0.094, data: 0.034) loss: 0.000 
(epoch: 1003, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 3184, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1003, iters: 3264, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 1003, iters: 3344, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1003, iters: 3424, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 1003, iters: 3504, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1003, iters: 3584, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 1003, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1003, iters 3739184
End of epoch 1003 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001096
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1003, TEST ACC: [97.572 %]

(epoch: 1004, iters: 16, time: 0.111, data: 0.000) loss: 0.000 
saving the latest model (epoch 1004, total_steps 3739200)
(epoch: 1004, iters: 96, time: 0.094, data: 0.043) loss: 0.000 
(epoch: 1004, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 256, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1004, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 416, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1004, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 576, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 656, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1004, iters: 736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 816, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1004, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 976, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 1004, iters: 1056, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 1216, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 1004, iters: 1296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 1376, time: 0.093, data: 0.012) loss: 0.005 
(epoch: 1004, iters: 1456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 1536, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1004, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 1696, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 1776, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 1004, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 1936, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1004, iters: 2016, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 2096, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1004, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 2256, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 2336, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1004, iters: 2416, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 1004, iters: 2496, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1004, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 2656, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1004, iters: 2736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 2896, time: 0.094, data: 0.039) loss: 0.005 
(epoch: 1004, iters: 2976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 3056, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1004, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 3216, time: 0.095, data: 0.026) loss: 0.000 
(epoch: 1004, iters: 3296, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1004, iters: 3376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 3456, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1004, iters: 3536, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 3616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1004, iters: 3696, time: 0.088, data: 0.040) loss: 0.000 
saving the model at the end of epoch 1004, iters 3742912
End of epoch 1004 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001095
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1004, TEST ACC: [96.965 %]

saving the latest model (epoch 1005, total_steps 3742928)
(epoch: 1005, iters: 48, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 1005, iters: 128, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 1005, iters: 208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 288, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1005, iters: 368, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1005, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 688, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1005, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 848, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1005, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 1008, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 1005, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 1248, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 1005, iters: 1328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 1408, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1005, iters: 1488, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 1568, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 1005, iters: 1648, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 1808, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 1005, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 1968, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1005, iters: 2048, time: 0.095, data: 0.030) loss: 0.000 
(epoch: 1005, iters: 2128, time: 0.096, data: 0.000) loss: 0.002 
(epoch: 1005, iters: 2208, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1005, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 2368, time: 0.096, data: 0.011) loss: 0.001 
(epoch: 1005, iters: 2448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 2608, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 1005, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 2768, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1005, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 2928, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1005, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 3168, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 1005, iters: 3248, time: 0.095, data: 0.000) loss: 0.005 
(epoch: 1005, iters: 3328, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1005, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 3488, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1005, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 3648, time: 0.087, data: 0.000) loss: 0.000 
(epoch: 1005, iters: 3728, time: 0.056, data: 0.015) loss: 0.000 
saving the model at the end of epoch 1005, iters 3746640
End of epoch 1005 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001094
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1005, TEST ACC: [97.117 %]

saving the latest model (epoch 1006, total_steps 3746656)
(epoch: 1006, iters: 80, time: 0.094, data: 0.511) loss: 0.000 
(epoch: 1006, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 240, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1006, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 400, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1006, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 560, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1006, iters: 640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1006, iters: 720, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 1006, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 960, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1006, iters: 1040, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 1006, iters: 1120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 1280, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1006, iters: 1360, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 1006, iters: 1440, time: 0.097, data: 0.000) loss: 0.001 
(epoch: 1006, iters: 1520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 1600, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1006, iters: 1680, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 1006, iters: 1760, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 1920, time: 0.096, data: 0.021) loss: 0.000 
(epoch: 1006, iters: 2000, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 1006, iters: 2080, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 2240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1006, iters: 2320, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 1006, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 2480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 2560, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 1006, iters: 2640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 2720, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1006, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 2880, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1006, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 3040, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 3120, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1006, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 3280, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1006, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 3440, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1006, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1006, iters: 3680, time: 0.087, data: 0.039) loss: 0.000 
saving the model at the end of epoch 1006, iters 3750368
End of epoch 1006 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001093
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1006, TEST ACC: [97.117 %]

saving the latest model (epoch 1007, total_steps 3750384)
(epoch: 1007, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 272, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1007, iters: 352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 432, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1007, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 592, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1007, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 832, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1007, iters: 912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 992, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1007, iters: 1072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 1152, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 1007, iters: 1232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 1392, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 1007, iters: 1472, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 1552, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1007, iters: 1632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 1712, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1007, iters: 1792, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 1952, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 1007, iters: 2032, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 2112, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1007, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 2272, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1007, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 2432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 2512, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1007, iters: 2592, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 1007, iters: 2672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1007, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 2832, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1007, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 2992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 3072, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1007, iters: 3152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 3232, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1007, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 3392, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1007, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 3552, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1007, iters: 3632, time: 0.092, data: 0.039) loss: 0.000 
(epoch: 1007, iters: 3712, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1007, iters 3754096
End of epoch 1007 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001092
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1007, TEST ACC: [97.117 %]

saving the latest model (epoch 1008, total_steps 3754112)
(epoch: 1008, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 224, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1008, iters: 304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 384, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 1008, iters: 464, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 1008, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 624, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1008, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 784, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1008, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 1024, time: 0.098, data: 0.050) loss: 0.000 
(epoch: 1008, iters: 1104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 1184, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1008, iters: 1264, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 1344, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1008, iters: 1424, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 1584, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 1008, iters: 1664, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 1744, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1008, iters: 1824, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 1904, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1008, iters: 1984, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 2144, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 1008, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 2304, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1008, iters: 2384, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 1008, iters: 2464, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1008, iters: 2544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 2624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 2704, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1008, iters: 2784, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 1008, iters: 2864, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 2944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 3024, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1008, iters: 3104, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 1008, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 3264, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 1008, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 3424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1008, iters: 3504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1008, iters: 3584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1008, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1008, iters 3757824
End of epoch 1008 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001091
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1008, TEST ACC: [97.117 %]

(epoch: 1009, iters: 16, time: 0.108, data: 0.000) loss: 0.000 
saving the latest model (epoch 1009, total_steps 3757840)
(epoch: 1009, iters: 96, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 176, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 256, time: 0.093, data: 0.042) loss: 0.000 
(epoch: 1009, iters: 336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1009, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 576, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1009, iters: 656, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 1009, iters: 736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 816, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 896, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1009, iters: 976, time: 0.092, data: 0.034) loss: 0.000 
(epoch: 1009, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 1136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 1216, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1009, iters: 1296, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 1009, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 1536, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1009, iters: 1616, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 1009, iters: 1696, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 1856, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1009, iters: 1936, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 1009, iters: 2016, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 2096, time: 0.095, data: 0.000) loss: 0.016 
(epoch: 1009, iters: 2176, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1009, iters: 2256, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 1009, iters: 2336, time: 0.095, data: 0.000) loss: 0.025 
(epoch: 1009, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1009, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 2576, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1009, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 2816, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 1009, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 2976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1009, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 3136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1009, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 3296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 3376, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1009, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 3536, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1009, iters: 3616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1009, iters: 3696, time: 0.090, data: 0.012) loss: 0.000 
saving the model at the end of epoch 1009, iters 3761552
End of epoch 1009 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001090
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1009, TEST ACC: [95.903 %]

saving the latest model (epoch 1010, total_steps 3761568)
(epoch: 1010, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 128, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 1010, iters: 208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 288, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 368, time: 0.094, data: 0.040) loss: 0.003 
(epoch: 1010, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 528, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 1010, iters: 608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1010, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 928, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1010, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 1088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1010, iters: 1168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 1248, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1010, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 1488, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 1010, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 1648, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1010, iters: 1728, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 1808, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1010, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 1968, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 2048, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1010, iters: 2128, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 2208, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 1010, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 2368, time: 0.093, data: 0.011) loss: 0.005 
(epoch: 1010, iters: 2448, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 2528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 2608, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 1010, iters: 2688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 2768, time: 0.094, data: 0.012) loss: 0.003 
(epoch: 1010, iters: 2848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 2928, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1010, iters: 3008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 3088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 3168, time: 0.097, data: 0.051) loss: 0.000 
(epoch: 1010, iters: 3248, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 3328, time: 0.093, data: 0.013) loss: 0.001 
(epoch: 1010, iters: 3408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 3488, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1010, iters: 3568, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 3648, time: 0.090, data: 0.000) loss: 0.000 
(epoch: 1010, iters: 3728, time: 0.056, data: 0.016) loss: 0.000 
saving the model at the end of epoch 1010, iters 3765280
End of epoch 1010 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001089
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1010, TEST ACC: [96.51 %]

saving the latest model (epoch 1011, total_steps 3765296)
(epoch: 1011, iters: 80, time: 0.096, data: 0.518) loss: 0.000 
(epoch: 1011, iters: 160, time: 0.095, data: 0.031) loss: 0.000 
(epoch: 1011, iters: 240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 320, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1011, iters: 400, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 480, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1011, iters: 560, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 720, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 1011, iters: 800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 880, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1011, iters: 960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 1040, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 1011, iters: 1120, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 1280, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 1011, iters: 1360, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 1440, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1011, iters: 1520, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 1011, iters: 1600, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1011, iters: 1680, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 1760, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 1840, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 1011, iters: 1920, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 2000, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1011, iters: 2080, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 2160, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 1011, iters: 2240, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 2400, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 1011, iters: 2480, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 2560, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1011, iters: 2640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 2720, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1011, iters: 2800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 2960, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 1011, iters: 3040, time: 0.098, data: 0.000) loss: 0.029 
(epoch: 1011, iters: 3120, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1011, iters: 3200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 3280, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1011, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 3440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1011, iters: 3520, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 1011, iters: 3600, time: 0.094, data: 0.000) loss: 0.003 
(epoch: 1011, iters: 3680, time: 0.088, data: 0.021) loss: 0.000 
saving the model at the end of epoch 1011, iters 3769008
End of epoch 1011 / 2100 	 Time Taken: 356 sec
learning rate = 0.0001088
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1011, TEST ACC: [97.117 %]

saving the latest model (epoch 1012, total_steps 3769024)
(epoch: 1012, iters: 32, time: 0.093, data: 0.007) loss: 0.000 
(epoch: 1012, iters: 112, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 1012, iters: 192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 352, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1012, iters: 432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 512, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1012, iters: 592, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 1012, iters: 672, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1012, iters: 752, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 832, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 912, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1012, iters: 992, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1012, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 1232, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 1012, iters: 1312, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 1472, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 1012, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1012, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 1792, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1012, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 1952, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 2032, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1012, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 2192, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1012, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 2352, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1012, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 2592, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 1012, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 2752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1012, iters: 2832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 2912, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1012, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 3072, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 3152, time: 0.094, data: 0.047) loss: 0.000 
(epoch: 1012, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 3312, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1012, iters: 3392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 3472, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 1012, iters: 3552, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 1012, iters: 3632, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1012, iters: 3712, time: 0.090, data: 0.036) loss: 0.000 
saving the model at the end of epoch 1012, iters 3772736
End of epoch 1012 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001087
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1012, TEST ACC: [97.572 %]

saving the latest model (epoch 1013, total_steps 3772752)
(epoch: 1013, iters: 64, time: 0.095, data: 0.000) loss: 0.007 
(epoch: 1013, iters: 144, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1013, iters: 224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 304, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1013, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 464, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 544, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 624, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 704, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 784, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1013, iters: 864, time: 0.095, data: 0.000) loss: 0.122 
(epoch: 1013, iters: 944, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1013, iters: 1024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 1104, time: 0.094, data: 0.013) loss: 0.002 
(epoch: 1013, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 1264, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 1013, iters: 1344, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 1013, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 1504, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 1013, iters: 1584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 1664, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1013, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 1824, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 1904, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 1013, iters: 1984, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 2064, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 2144, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 1013, iters: 2224, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 1013, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 2464, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1013, iters: 2544, time: 0.091, data: 0.025) loss: 0.000 
(epoch: 1013, iters: 2624, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 2784, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 2944, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1013, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 3104, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 1013, iters: 3184, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 3264, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1013, iters: 3344, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 1013, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 3504, time: 0.094, data: 0.047) loss: 0.000 
(epoch: 1013, iters: 3584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1013, iters: 3664, time: 0.087, data: 0.012) loss: 0.238 
saving the model at the end of epoch 1013, iters 3776464
End of epoch 1013 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001086
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1013, TEST ACC: [96.358 %]

(epoch: 1014, iters: 16, time: 0.110, data: 0.012) loss: 0.000 
saving the latest model (epoch 1014, total_steps 3776480)
(epoch: 1014, iters: 96, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 176, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1014, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 336, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1014, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 576, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1014, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 736, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1014, iters: 816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 896, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1014, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 1136, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 1014, iters: 1216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 1296, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1014, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 1456, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1014, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 1696, time: 0.097, data: 0.039) loss: 0.000 
(epoch: 1014, iters: 1776, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 1856, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1014, iters: 1936, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 2016, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1014, iters: 2096, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 2256, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1014, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1014, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 2576, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 1014, iters: 2656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 2816, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1014, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 2976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1014, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 3136, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1014, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 3376, time: 0.093, data: 0.040) loss: 0.004 
(epoch: 1014, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 3536, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1014, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1014, iters: 3696, time: 0.088, data: 0.011) loss: 0.000 
saving the model at the end of epoch 1014, iters 3780192
End of epoch 1014 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001085
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1014, TEST ACC: [97.117 %]

saving the latest model (epoch 1015, total_steps 3780208)
(epoch: 1015, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 128, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 1015, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 288, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1015, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1015, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 608, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 688, time: 0.096, data: 0.038) loss: 0.000 
(epoch: 1015, iters: 768, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 848, time: 0.095, data: 0.022) loss: 0.000 
(epoch: 1015, iters: 928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 1008, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1015, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 1168, time: 0.093, data: 0.000) loss: 0.011 
(epoch: 1015, iters: 1248, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 1015, iters: 1328, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 1408, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1015, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 1568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1015, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 1808, time: 0.094, data: 0.038) loss: 0.000 
(epoch: 1015, iters: 1888, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 1968, time: 0.096, data: 0.012) loss: 0.001 
(epoch: 1015, iters: 2048, time: 0.096, data: 0.029) loss: 0.000 
(epoch: 1015, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 2208, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1015, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 2368, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1015, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 2608, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1015, iters: 2688, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 2768, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 1015, iters: 2848, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 2928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 3008, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1015, iters: 3088, time: 0.095, data: 0.036) loss: 0.000 
(epoch: 1015, iters: 3168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 3248, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 3328, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1015, iters: 3408, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 1015, iters: 3488, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1015, iters: 3648, time: 0.087, data: 0.011) loss: 0.000 
(epoch: 1015, iters: 3728, time: 0.056, data: 0.018) loss: 0.000 
saving the model at the end of epoch 1015, iters 3783920
End of epoch 1015 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001084
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1015, TEST ACC: [86.95 %]

saving the latest model (epoch 1016, total_steps 3783936)
(epoch: 1016, iters: 80, time: 0.095, data: 0.492) loss: 0.000 
(epoch: 1016, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 240, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 1016, iters: 320, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 400, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1016, iters: 480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 560, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1016, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 800, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1016, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 960, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1016, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1016, iters: 1200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 1360, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 1016, iters: 1440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1016, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 1680, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 1016, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 1840, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 1920, time: 0.093, data: 0.038) loss: 0.000 
(epoch: 1016, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 2080, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1016, iters: 2160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 2240, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1016, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 2480, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 1016, iters: 2560, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 1016, iters: 2640, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 1016, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 2800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1016, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 2960, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 3040, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1016, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 3200, time: 0.091, data: 0.021) loss: 0.045 
(epoch: 1016, iters: 3280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 3360, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 1016, iters: 3440, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 3520, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1016, iters: 3600, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1016, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1016, iters 3787648
End of epoch 1016 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001083
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1016, TEST ACC: [93.93 %]

saving the latest model (epoch 1017, total_steps 3787664)
(epoch: 1017, iters: 32, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 112, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 1017, iters: 192, time: 0.093, data: 0.000) loss: 0.001 
(epoch: 1017, iters: 272, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 1017, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1017, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 592, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1017, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 832, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1017, iters: 912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 992, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1017, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 1152, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1017, iters: 1232, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 1392, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1017, iters: 1472, time: 0.096, data: 0.000) loss: 0.108 
(epoch: 1017, iters: 1552, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1017, iters: 1632, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 1712, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1017, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 1872, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 1952, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 1017, iters: 2032, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 2112, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 1017, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 2272, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1017, iters: 2352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 2512, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 1017, iters: 2592, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 2672, time: 0.095, data: 0.022) loss: 0.000 
(epoch: 1017, iters: 2752, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 2832, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 1017, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 3072, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 1017, iters: 3152, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 3232, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1017, iters: 3312, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 1017, iters: 3392, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1017, iters: 3472, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 3552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1017, iters: 3632, time: 0.091, data: 0.041) loss: 0.000 
(epoch: 1017, iters: 3712, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1017, iters 3791376
End of epoch 1017 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001082
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1017, TEST ACC: [97.572 %]

saving the latest model (epoch 1018, total_steps 3791392)
(epoch: 1018, iters: 64, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 224, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 1018, iters: 304, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 464, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 1018, iters: 544, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 624, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1018, iters: 704, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 784, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 1018, iters: 864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 944, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 1024, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 1018, iters: 1104, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 1184, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1018, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 1344, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1018, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 1504, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 1018, iters: 1584, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 1018, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 1744, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 1018, iters: 1824, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 1904, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1018, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 2064, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 1018, iters: 2144, time: 0.097, data: 0.048) loss: 0.000 
(epoch: 1018, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1018, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 2464, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1018, iters: 2544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 2704, time: 0.093, data: 0.035) loss: 0.001 
(epoch: 1018, iters: 2784, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 2864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 2944, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1018, iters: 3024, time: 0.092, data: 0.024) loss: 0.000 
(epoch: 1018, iters: 3104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 3264, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1018, iters: 3344, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 1018, iters: 3424, time: 0.094, data: 0.000) loss: 0.069 
(epoch: 1018, iters: 3504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1018, iters: 3584, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1018, iters: 3664, time: 0.087, data: 0.026) loss: 0.000 
saving the model at the end of epoch 1018, iters 3795104
End of epoch 1018 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001081
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1018, TEST ACC: [96.813 %]

(epoch: 1019, iters: 16, time: 0.108, data: 0.000) loss: 0.000 
saving the latest model (epoch 1019, total_steps 3795120)
(epoch: 1019, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 176, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1019, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 336, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1019, iters: 416, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 496, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 1019, iters: 576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1019, iters: 656, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 1019, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 896, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1019, iters: 976, time: 0.092, data: 0.024) loss: 0.000 
(epoch: 1019, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 1136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 1216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1019, iters: 1296, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 1019, iters: 1376, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 1456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 1536, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1019, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 1696, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1019, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 1856, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 1019, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 2016, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1019, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 2256, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1019, iters: 2336, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 2416, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1019, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 2576, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1019, iters: 2656, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 2736, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 2816, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 1019, iters: 2896, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 1019, iters: 2976, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1019, iters: 3056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 3136, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1019, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 3296, time: 0.093, data: 0.000) loss: 0.011 
(epoch: 1019, iters: 3376, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1019, iters: 3456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 3536, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1019, iters: 3616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1019, iters: 3696, time: 0.087, data: 0.012) loss: 0.002 
saving the model at the end of epoch 1019, iters 3798832
End of epoch 1019 / 2100 	 Time Taken: 351 sec
learning rate = 0.0001080
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1019, TEST ACC: [96.965 %]

saving the latest model (epoch 1020, total_steps 3798848)
(epoch: 1020, iters: 48, time: 0.094, data: 0.000) loss: 0.672 
(epoch: 1020, iters: 128, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1020, iters: 208, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 1020, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1020, iters: 368, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 448, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1020, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 688, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 1020, iters: 768, time: 0.096, data: 0.000) loss: 0.003 
(epoch: 1020, iters: 848, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 1020, iters: 928, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 1008, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1020, iters: 1088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 1168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 1248, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 1020, iters: 1328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1020, iters: 1488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 1568, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 1020, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 1808, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 1020, iters: 1888, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 1968, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1020, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 2128, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1020, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 2288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 2368, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 1020, iters: 2448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 2528, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1020, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1020, iters: 2768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 2928, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 1020, iters: 3008, time: 0.094, data: 0.000) loss: 0.004 
(epoch: 1020, iters: 3088, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1020, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 3248, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1020, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 3488, time: 0.096, data: 0.039) loss: 0.000 
(epoch: 1020, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1020, iters: 3648, time: 0.086, data: 0.012) loss: 0.000 
(epoch: 1020, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1020, iters 3802560
End of epoch 1020 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001079
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1020, TEST ACC: [96.51 %]

saving the latest model (epoch 1021, total_steps 3802576)
(epoch: 1021, iters: 80, time: 0.095, data: 0.502) loss: 0.000 
(epoch: 1021, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 240, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 1021, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 400, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1021, iters: 480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 560, time: 0.095, data: 0.011) loss: 0.108 
(epoch: 1021, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 800, time: 0.094, data: 0.040) loss: 0.034 
(epoch: 1021, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 960, time: 0.094, data: 0.011) loss: 0.020 
(epoch: 1021, iters: 1040, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 1021, iters: 1120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 1200, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 1280, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1021, iters: 1360, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 1021, iters: 1440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 1520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 1600, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1021, iters: 1680, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 1021, iters: 1760, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 1840, time: 0.097, data: 0.000) loss: 0.002 
(epoch: 1021, iters: 1920, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1021, iters: 2000, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 1021, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1021, iters: 2320, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 1021, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 2480, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 2560, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1021, iters: 2640, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 1021, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 2880, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1021, iters: 2960, time: 0.093, data: 0.028) loss: 0.000 
(epoch: 1021, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 3120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 3200, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 1021, iters: 3280, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 1021, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 3440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1021, iters: 3520, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 1021, iters: 3600, time: 0.094, data: 0.035) loss: 0.000 
(epoch: 1021, iters: 3680, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1021, iters 3806288
End of epoch 1021 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001078
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1021, TEST ACC: [93.323 %]

saving the latest model (epoch 1022, total_steps 3806304)
(epoch: 1022, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 112, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 352, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 1022, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 512, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1022, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 672, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1022, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 912, time: 0.093, data: 0.039) loss: 0.000 
(epoch: 1022, iters: 992, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 1022, iters: 1072, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1022, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 1232, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1022, iters: 1312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 1472, time: 0.093, data: 0.040) loss: 0.004 
(epoch: 1022, iters: 1552, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 1632, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1022, iters: 1712, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 1792, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 1022, iters: 1872, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 1952, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 2032, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 1022, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 2192, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1022, iters: 2272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 2352, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1022, iters: 2432, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 2512, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 2592, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 1022, iters: 2672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 2752, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1022, iters: 2832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 2912, time: 0.093, data: 0.012) loss: 0.011 
(epoch: 1022, iters: 2992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 3152, time: 0.096, data: 0.041) loss: 0.016 
(epoch: 1022, iters: 3232, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 3312, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1022, iters: 3392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 3472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1022, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 3632, time: 0.091, data: 0.000) loss: 0.000 
(epoch: 1022, iters: 3712, time: 0.089, data: 0.037) loss: 0.000 
saving the model at the end of epoch 1022, iters 3810016
End of epoch 1022 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001077
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1022, TEST ACC: [96.965 %]

saving the latest model (epoch 1023, total_steps 3810032)
(epoch: 1023, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 144, time: 0.096, data: 0.036) loss: 0.032 
(epoch: 1023, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1023, iters: 384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 464, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1023, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 704, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 1023, iters: 784, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 864, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 1023, iters: 944, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 1023, iters: 1024, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1023, iters: 1104, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 1023, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 1264, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 1023, iters: 1344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 1424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1023, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 1584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1023, iters: 1664, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 1744, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 1824, time: 0.094, data: 0.041) loss: 0.069 
(epoch: 1023, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 1984, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1023, iters: 2064, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 2144, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 1023, iters: 2224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 2304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 2384, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1023, iters: 2464, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 2544, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1023, iters: 2624, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 1023, iters: 2704, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1023, iters: 2784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 2864, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 2944, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 1023, iters: 3024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 3104, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1023, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 3264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1023, iters: 3344, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 3424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 3504, time: 0.095, data: 0.040) loss: 0.007 
(epoch: 1023, iters: 3584, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1023, iters: 3664, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1023, iters 3813744
End of epoch 1023 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001076
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1023, TEST ACC: [96.813 %]

(epoch: 1024, iters: 16, time: 0.110, data: 0.012) loss: 0.000 
saving the latest model (epoch 1024, total_steps 3813760)
(epoch: 1024, iters: 96, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 176, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1024, iters: 256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 336, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 1024, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 496, time: 0.095, data: 0.000) loss: 0.003 
(epoch: 1024, iters: 576, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1024, iters: 656, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 736, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1024, iters: 816, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1024, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 1136, time: 0.094, data: 0.039) loss: 0.001 
(epoch: 1024, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 1296, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1024, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 1456, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1024, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 1696, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1024, iters: 1776, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 1856, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1024, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 2016, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1024, iters: 2096, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 2256, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 1024, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 2416, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1024, iters: 2496, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 2576, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 1024, iters: 2656, time: 0.097, data: 0.000) loss: 0.041 
(epoch: 1024, iters: 2736, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 2816, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 1024, iters: 2896, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 2976, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1024, iters: 3056, time: 0.096, data: 0.000) loss: 0.009 
(epoch: 1024, iters: 3136, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1024, iters: 3216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 3296, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 3376, time: 0.097, data: 0.039) loss: 0.000 
(epoch: 1024, iters: 3456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 3536, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1024, iters: 3616, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 1024, iters: 3696, time: 0.089, data: 0.013) loss: 0.000 
saving the model at the end of epoch 1024, iters 3817472
End of epoch 1024 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001075
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1024, TEST ACC: [97.572 %]

saving the latest model (epoch 1025, total_steps 3817488)
(epoch: 1025, iters: 48, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 128, time: 0.097, data: 0.043) loss: 0.000 
(epoch: 1025, iters: 208, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 288, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1025, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 448, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1025, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 688, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1025, iters: 768, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 848, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1025, iters: 928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 1008, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1025, iters: 1088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 1168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 1248, time: 0.093, data: 0.041) loss: 0.001 
(epoch: 1025, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 1408, time: 0.092, data: 0.012) loss: 0.001 
(epoch: 1025, iters: 1488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 1568, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 1025, iters: 1648, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 1808, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 1025, iters: 1888, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 1968, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1025, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 2128, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1025, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 2368, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1025, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 2528, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1025, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 2688, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1025, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 2928, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 1025, iters: 3008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 3088, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 3168, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1025, iters: 3248, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 1025, iters: 3328, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 3408, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 3488, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1025, iters: 3568, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 1025, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 1025, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1025, iters 3821200
End of epoch 1025 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001074
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1025, TEST ACC: [95.903 %]

saving the latest model (epoch 1026, total_steps 3821216)
(epoch: 1026, iters: 80, time: 0.094, data: 0.545) loss: 0.000 
(epoch: 1026, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 240, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 1026, iters: 320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 400, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1026, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 560, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1026, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 800, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 1026, iters: 880, time: 0.097, data: 0.000) loss: 0.005 
(epoch: 1026, iters: 960, time: 0.096, data: 0.012) loss: 0.026 
(epoch: 1026, iters: 1040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 1120, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 1026, iters: 1200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 1360, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1026, iters: 1440, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1026, iters: 1600, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1026, iters: 1760, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 1920, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1026, iters: 2000, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 2080, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1026, iters: 2160, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 2240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1026, iters: 2320, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 2400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 2480, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 1026, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 2640, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1026, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 2800, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1026, iters: 2880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 3040, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1026, iters: 3120, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 3200, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1026, iters: 3280, time: 0.094, data: 0.025) loss: 0.000 
(epoch: 1026, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 3440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1026, iters: 3520, time: 0.094, data: 0.020) loss: 0.000 
(epoch: 1026, iters: 3600, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 1026, iters: 3680, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1026, iters 3824928
End of epoch 1026 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001073
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1026, TEST ACC: [95.903 %]

saving the latest model (epoch 1027, total_steps 3824944)
(epoch: 1027, iters: 32, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 112, time: 0.094, data: 0.028) loss: 0.000 
(epoch: 1027, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 352, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1027, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 512, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1027, iters: 592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 672, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1027, iters: 752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 832, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 912, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1027, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 1072, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1027, iters: 1152, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 1232, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1027, iters: 1312, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 1472, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1027, iters: 1552, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 1632, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 1712, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 1027, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 1872, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1027, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 2032, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1027, iters: 2112, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 2192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 2272, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 1027, iters: 2352, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 2432, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 1027, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 2592, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1027, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 2752, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 2832, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1027, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 2992, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1027, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 3152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1027, iters: 3232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 3312, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 3392, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1027, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 3552, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1027, iters: 3632, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1027, iters: 3712, time: 0.089, data: 0.012) loss: 0.000 
saving the model at the end of epoch 1027, iters 3828656
End of epoch 1027 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001072
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1027, TEST ACC: [96.358 %]

saving the latest model (epoch 1028, total_steps 3828672)
(epoch: 1028, iters: 64, time: 0.094, data: 0.003) loss: 0.000 
(epoch: 1028, iters: 144, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 224, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1028, iters: 304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 384, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 1028, iters: 464, time: 0.095, data: 0.047) loss: 0.000 
(epoch: 1028, iters: 544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 624, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1028, iters: 704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 784, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 1028, iters: 864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 1024, time: 0.093, data: 0.040) loss: 0.000 
(epoch: 1028, iters: 1104, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 1184, time: 0.093, data: 0.012) loss: 0.003 
(epoch: 1028, iters: 1264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 1344, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1028, iters: 1424, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 1504, time: 0.094, data: 0.000) loss: 0.112 
(epoch: 1028, iters: 1584, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1028, iters: 1664, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 1744, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1028, iters: 1824, time: 0.095, data: 0.000) loss: 0.163 
(epoch: 1028, iters: 1904, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1028, iters: 1984, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 2064, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 2144, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 1028, iters: 2224, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1028, iters: 2384, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 2464, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1028, iters: 2544, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 1028, iters: 2624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 2704, time: 0.095, data: 0.049) loss: 0.166 
(epoch: 1028, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 2864, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1028, iters: 2944, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 3024, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1028, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 3184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 3264, time: 0.095, data: 0.052) loss: 0.001 
(epoch: 1028, iters: 3344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 3424, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1028, iters: 3504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1028, iters: 3584, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1028, iters: 3664, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1028, iters 3832384
End of epoch 1028 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001071
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1028, TEST ACC: [94.385 %]

(epoch: 1029, iters: 16, time: 0.110, data: 0.000) loss: 0.000 
saving the latest model (epoch 1029, total_steps 3832400)
(epoch: 1029, iters: 96, time: 0.094, data: 0.044) loss: 0.000 
(epoch: 1029, iters: 176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 256, time: 0.094, data: 0.021) loss: 0.000 
(epoch: 1029, iters: 336, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 416, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1029, iters: 496, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 576, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 656, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1029, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 816, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1029, iters: 896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 976, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1029, iters: 1056, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 1136, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 1216, time: 0.096, data: 0.011) loss: 0.000 
(epoch: 1029, iters: 1296, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 1029, iters: 1376, time: 0.094, data: 0.012) loss: 0.046 
(epoch: 1029, iters: 1456, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 1536, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1029, iters: 1616, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 1696, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 1776, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 1029, iters: 1856, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 1936, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1029, iters: 2016, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 2096, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1029, iters: 2176, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 2256, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 2336, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 1029, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 2496, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1029, iters: 2576, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 2656, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1029, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 2896, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1029, iters: 2976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 3056, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1029, iters: 3136, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 1029, iters: 3216, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 3296, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 3376, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1029, iters: 3456, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 1029, iters: 3536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 3616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1029, iters: 3696, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1029, iters 3836112
End of epoch 1029 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001070
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1029, TEST ACC: [95.296 %]

saving the latest model (epoch 1030, total_steps 3836128)
(epoch: 1030, iters: 48, time: 0.095, data: 0.005) loss: 0.000 
(epoch: 1030, iters: 128, time: 0.094, data: 0.042) loss: 0.000 
(epoch: 1030, iters: 208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 288, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1030, iters: 368, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 448, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1030, iters: 528, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 688, time: 0.096, data: 0.050) loss: 0.000 
(epoch: 1030, iters: 768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 848, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1030, iters: 928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 1008, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1030, iters: 1088, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 1168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 1248, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 1030, iters: 1328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 1408, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1030, iters: 1488, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 1568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1030, iters: 1648, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 1728, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 1808, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1030, iters: 1888, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 1968, time: 0.093, data: 0.011) loss: 0.002 
(epoch: 1030, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 2128, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1030, iters: 2208, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 2288, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 2368, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1030, iters: 2448, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 2528, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1030, iters: 2608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 2688, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1030, iters: 2768, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 2848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 2928, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1030, iters: 3008, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 3088, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1030, iters: 3168, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 3248, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1030, iters: 3328, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 3408, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 1030, iters: 3488, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 1030, iters: 3568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1030, iters: 3648, time: 0.089, data: 0.011) loss: 0.000 
(epoch: 1030, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1030, iters 3839840
End of epoch 1030 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001069
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1030, TEST ACC: [95.448 %]

saving the latest model (epoch 1031, total_steps 3839856)
(epoch: 1031, iters: 80, time: 0.096, data: 0.449) loss: 0.000 
(epoch: 1031, iters: 160, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 240, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 320, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 1031, iters: 400, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 480, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1031, iters: 560, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 640, time: 0.095, data: 0.022) loss: 0.000 
(epoch: 1031, iters: 720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 800, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 880, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 1031, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 1040, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1031, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 1200, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1031, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 1360, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 1440, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1031, iters: 1520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 1600, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1031, iters: 1680, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 1760, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1031, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 1920, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 2000, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1031, iters: 2080, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 2160, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1031, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 2320, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1031, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 2480, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 2560, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 1031, iters: 2640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 2720, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1031, iters: 2800, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 2880, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1031, iters: 2960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 3040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 3120, time: 0.095, data: 0.048) loss: 0.000 
(epoch: 1031, iters: 3200, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 3280, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 1031, iters: 3360, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 3440, time: 0.093, data: 0.020) loss: 0.000 
(epoch: 1031, iters: 3520, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 1031, iters: 3600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1031, iters: 3680, time: 0.089, data: 0.050) loss: 0.000 
saving the model at the end of epoch 1031, iters 3843568
End of epoch 1031 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001068
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1031, TEST ACC: [94.385 %]

saving the latest model (epoch 1032, total_steps 3843584)
(epoch: 1032, iters: 32, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 112, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1032, iters: 192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 352, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 1032, iters: 432, time: 0.095, data: 0.000) loss: 0.004 
(epoch: 1032, iters: 512, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1032, iters: 592, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 672, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1032, iters: 752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 832, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 1152, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1032, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 1312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1032, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 1472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1032, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 1632, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 1032, iters: 1712, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 1032, iters: 1792, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 1872, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1032, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 2032, time: 0.093, data: 0.012) loss: 0.001 
(epoch: 1032, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 2192, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 2272, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 1032, iters: 2352, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 2432, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1032, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 2592, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1032, iters: 2672, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 2752, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 2832, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 1032, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 2992, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1032, iters: 3072, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 3152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1032, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 3312, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 3392, time: 0.093, data: 0.041) loss: 0.260 
(epoch: 1032, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 3552, time: 0.093, data: 0.021) loss: 0.001 
(epoch: 1032, iters: 3632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1032, iters: 3712, time: 0.088, data: 0.012) loss: 0.000 
saving the model at the end of epoch 1032, iters 3847296
End of epoch 1032 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001067
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1032, TEST ACC: [95.296 %]

saving the latest model (epoch 1033, total_steps 3847312)
(epoch: 1033, iters: 64, time: 0.094, data: 0.003) loss: 0.046 
(epoch: 1033, iters: 144, time: 0.093, data: 0.011) loss: 0.019 
(epoch: 1033, iters: 224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 304, time: 0.094, data: 0.012) loss: 0.002 
(epoch: 1033, iters: 384, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 544, time: 0.098, data: 0.040) loss: 0.000 
(epoch: 1033, iters: 624, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 704, time: 0.093, data: 0.012) loss: 0.002 
(epoch: 1033, iters: 784, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 864, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1033, iters: 944, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 1024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 1104, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1033, iters: 1184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 1264, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1033, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 1424, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1033, iters: 1504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 1584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 1664, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1033, iters: 1744, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 1824, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1033, iters: 1904, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 1984, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1033, iters: 2064, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 2144, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 2224, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 1033, iters: 2304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 2384, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1033, iters: 2464, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 2544, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1033, iters: 2624, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 2784, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1033, iters: 2864, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 2944, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1033, iters: 3024, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 3104, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1033, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 3264, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 3344, time: 0.094, data: 0.049) loss: 0.000 
(epoch: 1033, iters: 3424, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 3504, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1033, iters: 3584, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1033, iters: 3664, time: 0.086, data: 0.012) loss: 0.000 
saving the model at the end of epoch 1033, iters 3851024
End of epoch 1033 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001066
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1033, TEST ACC: [97.269 %]

(epoch: 1034, iters: 16, time: 0.110, data: 0.000) loss: 0.000 
saving the latest model (epoch 1034, total_steps 3851040)
(epoch: 1034, iters: 96, time: 0.093, data: 0.044) loss: 0.000 
(epoch: 1034, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 256, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1034, iters: 336, time: 0.094, data: 0.000) loss: 0.024 
(epoch: 1034, iters: 416, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1034, iters: 496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 656, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 1034, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 816, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 1034, iters: 896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 976, time: 0.097, data: 0.011) loss: 0.002 
(epoch: 1034, iters: 1056, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1034, iters: 1136, time: 0.092, data: 0.034) loss: 0.000 
(epoch: 1034, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 1296, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 1376, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1034, iters: 1456, time: 0.093, data: 0.035) loss: 0.000 
(epoch: 1034, iters: 1536, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 1616, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 1696, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1034, iters: 1776, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 1034, iters: 1856, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 1936, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 2016, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1034, iters: 2096, time: 0.092, data: 0.036) loss: 0.000 
(epoch: 1034, iters: 2176, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 2256, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 2336, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1034, iters: 2416, time: 0.094, data: 0.026) loss: 0.002 
(epoch: 1034, iters: 2496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 2576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 2656, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1034, iters: 2736, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 1034, iters: 2816, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 2896, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 2976, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1034, iters: 3056, time: 0.094, data: 0.026) loss: 0.000 
(epoch: 1034, iters: 3136, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 3216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 3296, time: 0.094, data: 0.011) loss: 0.001 
(epoch: 1034, iters: 3376, time: 0.093, data: 0.036) loss: 0.000 
(epoch: 1034, iters: 3456, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 3536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1034, iters: 3616, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 1034, iters: 3696, time: 0.088, data: 0.036) loss: 0.000 
saving the model at the end of epoch 1034, iters 3854752
End of epoch 1034 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001065
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1034, TEST ACC: [97.269 %]

saving the latest model (epoch 1035, total_steps 3854768)
(epoch: 1035, iters: 48, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 128, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 208, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1035, iters: 288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 368, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1035, iters: 448, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1035, iters: 608, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 768, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1035, iters: 848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 928, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 1008, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 1035, iters: 1088, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 1168, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1035, iters: 1248, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 1328, time: 0.091, data: 0.013) loss: 0.000 
(epoch: 1035, iters: 1408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 1488, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 1568, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1035, iters: 1648, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 1728, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1035, iters: 1808, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 1035, iters: 1888, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1035, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 2048, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 2128, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 1035, iters: 2208, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 2288, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 1035, iters: 2368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 2448, time: 0.093, data: 0.012) loss: 0.011 
(epoch: 1035, iters: 2528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 2608, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 2688, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1035, iters: 2768, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 2848, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 1035, iters: 2928, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 3008, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 1035, iters: 3088, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 3168, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 3248, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1035, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 3408, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 1035, iters: 3488, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 3568, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1035, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 1035, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1035, iters 3858480
End of epoch 1035 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001064
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1035, TEST ACC: [96.51 %]

saving the latest model (epoch 1036, total_steps 3858496)
(epoch: 1036, iters: 80, time: 0.095, data: 0.550) loss: 0.000 
(epoch: 1036, iters: 160, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 240, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1036, iters: 320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 400, time: 0.094, data: 0.022) loss: 0.000 
(epoch: 1036, iters: 480, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 560, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1036, iters: 640, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 720, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 800, time: 0.096, data: 0.043) loss: 0.000 
(epoch: 1036, iters: 880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 960, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1036, iters: 1040, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 1120, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1036, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 1280, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 1360, time: 0.094, data: 0.050) loss: 0.000 
(epoch: 1036, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 1520, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1036, iters: 1600, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 1680, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1036, iters: 1760, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 1840, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 1920, time: 0.095, data: 0.040) loss: 0.000 
(epoch: 1036, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 2080, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1036, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 2240, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1036, iters: 2320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 2400, time: 0.092, data: 0.000) loss: 0.019 
(epoch: 1036, iters: 2480, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1036, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 2640, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 1036, iters: 2720, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 2800, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1036, iters: 2880, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 2960, time: 0.093, data: 0.000) loss: 0.002 
(epoch: 1036, iters: 3040, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 1036, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 3200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1036, iters: 3280, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 3360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1036, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1036, iters: 3600, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 1036, iters: 3680, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1036, iters 3862208
End of epoch 1036 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001063
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1036, TEST ACC: [97.724 %]

saving the latest model (epoch 1037, total_steps 3862224)
(epoch: 1037, iters: 32, time: 0.092, data: 0.005) loss: 0.000 
(epoch: 1037, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 192, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 1037, iters: 272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 432, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1037, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1037, iters: 672, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1037, iters: 832, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 912, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 992, time: 0.093, data: 0.048) loss: 0.000 
(epoch: 1037, iters: 1072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 1152, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1037, iters: 1232, time: 0.096, data: 0.000) loss: 0.001 
(epoch: 1037, iters: 1312, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1037, iters: 1392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 1472, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 1552, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 1037, iters: 1632, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 1712, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1037, iters: 1792, time: 0.092, data: 0.026) loss: 0.001 
(epoch: 1037, iters: 1872, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 2032, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1037, iters: 2112, time: 0.093, data: 0.025) loss: 0.000 
(epoch: 1037, iters: 2192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 2272, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 2352, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1037, iters: 2432, time: 0.094, data: 0.027) loss: 0.000 
(epoch: 1037, iters: 2512, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 2592, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 2672, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1037, iters: 2752, time: 0.093, data: 0.027) loss: 0.001 
(epoch: 1037, iters: 2832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 2912, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 2992, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 1037, iters: 3072, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 1037, iters: 3152, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 3232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 3312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1037, iters: 3392, time: 0.094, data: 0.025) loss: 0.001 
(epoch: 1037, iters: 3472, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 3552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1037, iters: 3632, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 1037, iters: 3712, time: 0.090, data: 0.021) loss: 0.000 
saving the model at the end of epoch 1037, iters 3865936
End of epoch 1037 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001062
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1037, TEST ACC: [96.813 %]

saving the latest model (epoch 1038, total_steps 3865952)
(epoch: 1038, iters: 64, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 144, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 224, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 1038, iters: 304, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 384, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 464, time: 0.095, data: 0.050) loss: 0.000 
(epoch: 1038, iters: 544, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 624, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1038, iters: 704, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 784, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1038, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 944, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 1024, time: 0.094, data: 0.022) loss: 0.000 
(epoch: 1038, iters: 1104, time: 0.092, data: 0.035) loss: 0.000 
(epoch: 1038, iters: 1184, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 1264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 1344, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1038, iters: 1424, time: 0.091, data: 0.026) loss: 0.000 
(epoch: 1038, iters: 1504, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 1584, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 1664, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 1038, iters: 1744, time: 0.092, data: 0.028) loss: 0.000 
(epoch: 1038, iters: 1824, time: 0.093, data: 0.000) loss: 0.015 
(epoch: 1038, iters: 1904, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 1984, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1038, iters: 2064, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 1038, iters: 2144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 2224, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 2304, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1038, iters: 2384, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 1038, iters: 2464, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 2624, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1038, iters: 2704, time: 0.093, data: 0.026) loss: 0.000 
(epoch: 1038, iters: 2784, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 2864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 2944, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1038, iters: 3024, time: 0.093, data: 0.027) loss: 0.000 
(epoch: 1038, iters: 3104, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 3184, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 3264, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 1038, iters: 3344, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 1038, iters: 3424, time: 0.093, data: 0.000) loss: 0.004 
(epoch: 1038, iters: 3504, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1038, iters: 3584, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1038, iters: 3664, time: 0.087, data: 0.026) loss: 0.000 
saving the model at the end of epoch 1038, iters 3869664
End of epoch 1038 / 2100 	 Time Taken: 352 sec
learning rate = 0.0001061
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1038, TEST ACC: [97.42 %]

(epoch: 1039, iters: 16, time: 0.112, data: 0.000) loss: 0.000 
saving the latest model (epoch 1039, total_steps 3869680)
(epoch: 1039, iters: 96, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1039, iters: 176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 256, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1039, iters: 336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 416, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 496, time: 0.095, data: 0.039) loss: 0.000 
(epoch: 1039, iters: 576, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 656, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 1039, iters: 736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 816, time: 0.093, data: 0.012) loss: 0.304 
(epoch: 1039, iters: 896, time: 0.092, data: 0.027) loss: 0.000 
(epoch: 1039, iters: 976, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 1056, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 1136, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 1039, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 1296, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 1039, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 1456, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1039, iters: 1536, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 1696, time: 0.095, data: 0.040) loss: 0.002 
(epoch: 1039, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 1856, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1039, iters: 1936, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 2016, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 1039, iters: 2096, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 2176, time: 0.095, data: 0.000) loss: 0.002 
(epoch: 1039, iters: 2256, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1039, iters: 2336, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 2416, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1039, iters: 2496, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 2576, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1039, iters: 2656, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 2736, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 2816, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 1039, iters: 2896, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 2976, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1039, iters: 3056, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 3136, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1039, iters: 3216, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 3296, time: 0.093, data: 0.000) loss: 0.017 
(epoch: 1039, iters: 3376, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1039, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 3536, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 1039, iters: 3616, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1039, iters: 3696, time: 0.087, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1039, iters 3873392
End of epoch 1039 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001060
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1039, TEST ACC: [95.448 %]

saving the latest model (epoch 1040, total_steps 3873408)
(epoch: 1040, iters: 48, time: 0.095, data: 0.005) loss: 0.000 
(epoch: 1040, iters: 128, time: 0.095, data: 0.000) loss: 0.013 
(epoch: 1040, iters: 208, time: 0.095, data: 0.051) loss: 0.000 
(epoch: 1040, iters: 288, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 368, time: 0.091, data: 0.011) loss: 0.000 
(epoch: 1040, iters: 448, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 528, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1040, iters: 608, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 688, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 768, time: 0.097, data: 0.040) loss: 0.000 
(epoch: 1040, iters: 848, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 928, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1040, iters: 1008, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 1088, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1040, iters: 1168, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 1248, time: 0.092, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 1328, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1040, iters: 1408, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 1040, iters: 1488, time: 0.092, data: 0.011) loss: 0.002 
(epoch: 1040, iters: 1568, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 1040, iters: 1648, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1040, iters: 1728, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 1808, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 1888, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 1040, iters: 1968, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 2048, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1040, iters: 2128, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 2208, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1040, iters: 2288, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 2368, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 2448, time: 0.093, data: 0.044) loss: 0.000 
(epoch: 1040, iters: 2528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 2608, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 1040, iters: 2688, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 2768, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1040, iters: 2848, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 2928, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 3008, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1040, iters: 3088, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 3168, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1040, iters: 3248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 3328, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1040, iters: 3408, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 3488, time: 0.092, data: 0.000) loss: 0.001 
(epoch: 1040, iters: 3568, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1040, iters: 3648, time: 0.088, data: 0.000) loss: 0.000 
(epoch: 1040, iters: 3728, time: 0.057, data: 0.011) loss: 0.000 
saving the model at the end of epoch 1040, iters 3877120
End of epoch 1040 / 2100 	 Time Taken: 353 sec
learning rate = 0.0001059
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1040, TEST ACC: [95.599 %]

saving the latest model (epoch 1041, total_steps 3877136)
(epoch: 1041, iters: 80, time: 0.092, data: 0.499) loss: 0.000 
(epoch: 1041, iters: 160, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1041, iters: 320, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 400, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 480, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 1041, iters: 560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 640, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1041, iters: 720, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 800, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1041, iters: 880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 960, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 1040, time: 0.094, data: 0.044) loss: 0.000 
(epoch: 1041, iters: 1120, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 1200, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1041, iters: 1280, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 1360, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1041, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 1520, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 1600, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1041, iters: 1680, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 1760, time: 0.094, data: 0.013) loss: 0.000 
(epoch: 1041, iters: 1840, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 1920, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 1041, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 2080, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 2160, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 1041, iters: 2240, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 2320, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1041, iters: 2400, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 2480, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 1041, iters: 2560, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 2640, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 2720, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 1041, iters: 2800, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 2880, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 1041, iters: 2960, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 3040, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1041, iters: 3120, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 3200, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 3280, time: 0.095, data: 0.044) loss: 0.000 
(epoch: 1041, iters: 3360, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 3440, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 1041, iters: 3520, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1041, iters: 3600, time: 0.096, data: 0.013) loss: 0.000 
(epoch: 1041, iters: 3680, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1041, iters 3880848
End of epoch 1041 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001058
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1041, TEST ACC: [97.269 %]

saving the latest model (epoch 1042, total_steps 3880864)
(epoch: 1042, iters: 32, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 112, time: 0.097, data: 0.013) loss: 0.000 
(epoch: 1042, iters: 192, time: 0.092, data: 0.013) loss: 0.000 
(epoch: 1042, iters: 272, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 352, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1042, iters: 432, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 592, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 1042, iters: 672, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 752, time: 0.094, data: 0.022) loss: 0.000 
(epoch: 1042, iters: 832, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1042, iters: 992, time: 0.098, data: 0.000) loss: 0.017 
(epoch: 1042, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 1152, time: 0.096, data: 0.041) loss: 0.000 
(epoch: 1042, iters: 1232, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 1312, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1042, iters: 1392, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 1472, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1042, iters: 1552, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 1042, iters: 1632, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 1712, time: 0.097, data: 0.041) loss: 0.001 
(epoch: 1042, iters: 1792, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 1872, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1042, iters: 1952, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 2032, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1042, iters: 2112, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 2192, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 2272, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 1042, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 2432, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1042, iters: 2512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 2592, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1042, iters: 2672, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 2832, time: 0.097, data: 0.052) loss: 0.000 
(epoch: 1042, iters: 2912, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 2992, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1042, iters: 3072, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 3152, time: 0.097, data: 0.012) loss: 0.000 
(epoch: 1042, iters: 3232, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1042, iters: 3312, time: 0.092, data: 0.025) loss: 0.000 
(epoch: 1042, iters: 3392, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 3472, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1042, iters: 3552, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1042, iters: 3632, time: 0.090, data: 0.027) loss: 0.000 
(epoch: 1042, iters: 3712, time: 0.088, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1042, iters 3884576
End of epoch 1042 / 2100 	 Time Taken: 357 sec
learning rate = 0.0001057
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1042, TEST ACC: [96.813 %]

saving the latest model (epoch 1043, total_steps 3884592)
(epoch: 1043, iters: 64, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 144, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 224, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 384, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 1043, iters: 464, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 544, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1043, iters: 624, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 704, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1043, iters: 784, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 864, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 944, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1043, iters: 1024, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 1104, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1043, iters: 1184, time: 0.094, data: 0.000) loss: 0.001 
(epoch: 1043, iters: 1264, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1043, iters: 1344, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 1424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 1504, time: 0.095, data: 0.041) loss: 0.000 
(epoch: 1043, iters: 1584, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 1664, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 1043, iters: 1744, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 1824, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1043, iters: 1904, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 1984, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 2064, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1043, iters: 2144, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 2224, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1043, iters: 2304, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 2384, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1043, iters: 2464, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 2544, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 2624, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1043, iters: 2704, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 2784, time: 0.091, data: 0.012) loss: 0.000 
(epoch: 1043, iters: 2864, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 2944, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1043, iters: 3024, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 3104, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 3184, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 1043, iters: 3264, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 3344, time: 0.095, data: 0.011) loss: 0.000 
(epoch: 1043, iters: 3424, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 3504, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1043, iters: 3584, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1043, iters: 3664, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1043, iters 3888304
End of epoch 1043 / 2100 	 Time Taken: 355 sec
learning rate = 0.0001056
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1043, TEST ACC: [96.358 %]

(epoch: 1044, iters: 16, time: 0.111, data: 0.013) loss: 0.000 
saving the latest model (epoch 1044, total_steps 3888320)
(epoch: 1044, iters: 96, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 176, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1044, iters: 256, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 336, time: 0.095, data: 0.012) loss: 0.001 
(epoch: 1044, iters: 416, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 496, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 576, time: 0.096, data: 0.049) loss: 0.000 
(epoch: 1044, iters: 656, time: 0.098, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 736, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1044, iters: 816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 896, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1044, iters: 976, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 1056, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 1136, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 1044, iters: 1216, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 1296, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1044, iters: 1376, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 1456, time: 0.093, data: 0.021) loss: 0.000 
(epoch: 1044, iters: 1536, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 1616, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 1696, time: 0.094, data: 0.039) loss: 0.127 
(epoch: 1044, iters: 1776, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 1856, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1044, iters: 1936, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 2016, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1044, iters: 2096, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 2176, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 2256, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1044, iters: 2336, time: 0.092, data: 0.029) loss: 0.000 
(epoch: 1044, iters: 2416, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 2496, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 2576, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1044, iters: 2656, time: 0.092, data: 0.026) loss: 0.000 
(epoch: 1044, iters: 2736, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 2816, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 2896, time: 0.096, data: 0.021) loss: 0.000 
(epoch: 1044, iters: 2976, time: 0.093, data: 0.000) loss: 0.005 
(epoch: 1044, iters: 3056, time: 0.095, data: 0.039) loss: 0.127 
(epoch: 1044, iters: 3136, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 3216, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1044, iters: 3296, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 3376, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1044, iters: 3456, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 3536, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1044, iters: 3616, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1044, iters: 3696, time: 0.089, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1044, iters 3892032
End of epoch 1044 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001055
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1044, TEST ACC: [97.117 %]

saving the latest model (epoch 1045, total_steps 3892048)
(epoch: 1045, iters: 48, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 128, time: 0.097, data: 0.041) loss: 0.000 
(epoch: 1045, iters: 208, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1045, iters: 288, time: 0.095, data: 0.000) loss: 0.001 
(epoch: 1045, iters: 368, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1045, iters: 448, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 528, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 608, time: 0.098, data: 0.040) loss: 0.000 
(epoch: 1045, iters: 688, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 768, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1045, iters: 848, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 928, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1045, iters: 1008, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 1088, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 1168, time: 0.093, data: 0.041) loss: 0.000 
(epoch: 1045, iters: 1248, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 1328, time: 0.093, data: 0.011) loss: 0.003 
(epoch: 1045, iters: 1408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 1488, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1045, iters: 1568, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 1648, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 1728, time: 0.094, data: 0.039) loss: 0.000 
(epoch: 1045, iters: 1808, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 1888, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 1968, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1045, iters: 2048, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 2128, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1045, iters: 2208, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 2288, time: 0.096, data: 0.012) loss: 0.000 
(epoch: 1045, iters: 2368, time: 0.092, data: 0.011) loss: 0.000 
(epoch: 1045, iters: 2448, time: 0.091, data: 0.026) loss: 0.000 
(epoch: 1045, iters: 2528, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 2608, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 2688, time: 0.093, data: 0.013) loss: 0.000 
(epoch: 1045, iters: 2768, time: 0.095, data: 0.025) loss: 0.000 
(epoch: 1045, iters: 2848, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 2928, time: 0.097, data: 0.049) loss: 0.000 
(epoch: 1045, iters: 3008, time: 0.097, data: 0.000) loss: 0.004 
(epoch: 1045, iters: 3088, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1045, iters: 3168, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 3248, time: 0.095, data: 0.020) loss: 0.000 
(epoch: 1045, iters: 3328, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 3408, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 3488, time: 0.094, data: 0.051) loss: 0.000 
(epoch: 1045, iters: 3568, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1045, iters: 3648, time: 0.086, data: 0.011) loss: 0.000 
(epoch: 1045, iters: 3728, time: 0.056, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1045, iters 3895760
End of epoch 1045 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001054
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1045, TEST ACC: [96.813 %]

saving the latest model (epoch 1046, total_steps 3895776)
(epoch: 1046, iters: 80, time: 0.095, data: 0.520) loss: 0.000 
(epoch: 1046, iters: 160, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 240, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 1046, iters: 320, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 400, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1046, iters: 480, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 560, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1046, iters: 640, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 800, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1046, iters: 880, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 960, time: 0.095, data: 0.012) loss: 0.000 
(epoch: 1046, iters: 1040, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 1120, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1046, iters: 1200, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 1280, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 1360, time: 0.094, data: 0.040) loss: 0.000 
(epoch: 1046, iters: 1440, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 1520, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1046, iters: 1600, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 1680, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1046, iters: 1760, time: 0.095, data: 0.000) loss: 0.012 
(epoch: 1046, iters: 1840, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 1920, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 1046, iters: 2000, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 2080, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1046, iters: 2160, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 2240, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1046, iters: 2320, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 2400, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 2480, time: 0.096, data: 0.040) loss: 0.000 
(epoch: 1046, iters: 2560, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 2640, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1046, iters: 2720, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 2800, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1046, iters: 2880, time: 0.096, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 2960, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 3040, time: 0.094, data: 0.048) loss: 0.000 
(epoch: 1046, iters: 3120, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 3200, time: 0.093, data: 0.011) loss: 0.000 
(epoch: 1046, iters: 3280, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 3360, time: 0.094, data: 0.012) loss: 0.000 
(epoch: 1046, iters: 3440, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 3520, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1046, iters: 3600, time: 0.095, data: 0.049) loss: 0.000 
(epoch: 1046, iters: 3680, time: 0.090, data: 0.000) loss: 0.000 
saving the model at the end of epoch 1046, iters 3899488
End of epoch 1046 / 2100 	 Time Taken: 354 sec
learning rate = 0.0001053
Running Test
loaded mean / std from cache
loading the model from ./checkpoints/cubes/latest_net.pth
epoch: 1046, TEST ACC: [96.51 %]

saving the latest model (epoch 1047, total_steps 3899504)
(epoch: 1047, iters: 32, time: 0.094, data: 0.005) loss: 0.000 
(epoch: 1047, iters: 112, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 192, time: 0.092, data: 0.012) loss: 0.000 
(epoch: 1047, iters: 272, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 352, time: 0.094, data: 0.011) loss: 0.000 
(epoch: 1047, iters: 432, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 512, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 592, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1047, iters: 672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 752, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1047, iters: 832, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 912, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1047, iters: 992, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 1072, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 1152, time: 0.097, data: 0.042) loss: 0.000 
(epoch: 1047, iters: 1232, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 1312, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1047, iters: 1392, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 1472, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1047, iters: 1552, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 1632, time: 0.093, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 1712, time: 0.094, data: 0.041) loss: 0.000 
(epoch: 1047, iters: 1792, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 1872, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1047, iters: 1952, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 2032, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1047, iters: 2112, time: 0.097, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 2192, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 2272, time: 0.095, data: 0.042) loss: 0.000 
(epoch: 1047, iters: 2352, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 2432, time: 0.095, data: 0.013) loss: 0.000 
(epoch: 1047, iters: 2512, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 2592, time: 0.093, data: 0.012) loss: 0.000 
(epoch: 1047, iters: 2672, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 2752, time: 0.095, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 2832, time: 0.096, data: 0.042) loss: 0.000 
(epoch: 1047, iters: 2912, time: 0.094, data: 0.000) loss: 0.000 
(epoch: 1047, iters: 2992, time: 0.096, data: 0.012) loss: 0.000 
Traceback (most recent call last):
  File "train.py", line 35, in <module>
    writer.print_current_losses(epoch, epoch_iter, loss, t, t_data)
  File "/home/dpere013/MeshCNN/util/writer.py", line 42, in print_current_losses
    with open(self.log_name, "a") as log_file:
FileNotFoundError: [Errno 2] No such file or directory: './checkpoints/cubes/loss_log.txt'
